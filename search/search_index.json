{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"assets/jupyter/dft/dft/","title":"Dft","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n</pre> import numpy as np import matplotlib.pyplot as plt In\u00a0[2]: Copied! <pre>def generate_continous_signal(N, f_s):\n    # Consider a continuous signal containing frequency components 1kHz and 2kHz (shifted in phase by 135 degrees relative to the 1kHz)\n    # x_input(t) = sin(2pi 1000 t) + 0.5 sin(2pi 2000t + 3pi/4)\n    \n    t_max = N / f_s\n    \n    t = np.linspace(0, t_max, 1000)\n    x = np.zeros((len(t), ))\n    \n    for i in range(len(t)):\n        x[i] = np.sin(2 * np.pi * 1000 * t[i]) + 0.5 * np.sin(2 * np.pi * 2000 * t[i] + 3 * np.pi / 4)\n    return x\n\ndef generate_discrete_points(N, f_s):\n    # 8-point DFT, i.e., N = 8\n    # x(n) = x_input(n t_s) = sin(2pi 1000 n t_s) + 0.5sin(2pi 2000 n t_s + 3pi/4)\n    # Assume f_s = 8kHz    \n    x = np.zeros((N, ))\n    t_s = 1. / f_s\n    \n    for i in range(N):\n        x[i] = np.sin(2 * np.pi * 1000 * i * t_s) + 0.5 * np.sin(2 * np.pi * 2000 * i * t_s + 3 * np.pi / 4)\n    \n    return x\n</pre> def generate_continous_signal(N, f_s):     # Consider a continuous signal containing frequency components 1kHz and 2kHz (shifted in phase by 135 degrees relative to the 1kHz)     # x_input(t) = sin(2pi 1000 t) + 0.5 sin(2pi 2000t + 3pi/4)          t_max = N / f_s          t = np.linspace(0, t_max, 1000)     x = np.zeros((len(t), ))          for i in range(len(t)):         x[i] = np.sin(2 * np.pi * 1000 * t[i]) + 0.5 * np.sin(2 * np.pi * 2000 * t[i] + 3 * np.pi / 4)     return x  def generate_discrete_points(N, f_s):     # 8-point DFT, i.e., N = 8     # x(n) = x_input(n t_s) = sin(2pi 1000 n t_s) + 0.5sin(2pi 2000 n t_s + 3pi/4)     # Assume f_s = 8kHz         x = np.zeros((N, ))     t_s = 1. / f_s          for i in range(N):         x[i] = np.sin(2 * np.pi * 1000 * i * t_s) + 0.5 * np.sin(2 * np.pi * 2000 * i * t_s + 3 * np.pi / 4)          return x In\u00a0[3]: Copied! <pre>N = 8\nf_s = 8000\n\nx = generate_discrete_points(N, f_s)\n# Signal amplitude exists in x(n) at the analysis frequencies of mf_s / N, or 0kHz, 1kHz, ..., 7kHz with f_s = 8000Hz\n# The sampled x's are:\nx\n</pre> N = 8 f_s = 8000  x = generate_discrete_points(N, f_s) # Signal amplitude exists in x(n) at the analysis frequencies of mf_s / N, or 0kHz, 1kHz, ..., 7kHz with f_s = 8000Hz # The sampled x's are: x Out[3]: <pre>array([ 0.35355339,  0.35355339,  0.64644661,  1.06066017,  0.35355339,\n       -1.06066017, -1.35355339, -0.35355339])</pre> In\u00a0[4]: Copied! <pre>x_input = generate_continous_signal(N, f_s)\nindex_x = np.arange(0, N)\nindex_x_input = np.linspace(0, N, len(x_input))\n\n\nfig, ax = plt.subplots()\nax.plot(index_x_input, x_input, \"-\", color=\"red\", label=\"Input\")\nax.plot(index_x, x, \"o\", color=\"blue\", label=\"Sampled\")\nax.set_xlabel(\"Index\")\nax.set_ylabel(\"x\")\nax.grid(True)\nax.legend()\nax.set_title(\"Input Signal and Sampled Values\")\nplt.show()\n</pre> x_input = generate_continous_signal(N, f_s) index_x = np.arange(0, N) index_x_input = np.linspace(0, N, len(x_input))   fig, ax = plt.subplots() ax.plot(index_x_input, x_input, \"-\", color=\"red\", label=\"Input\") ax.plot(index_x, x, \"o\", color=\"blue\", label=\"Sampled\") ax.set_xlabel(\"Index\") ax.set_ylabel(\"x\") ax.grid(True) ax.legend() ax.set_title(\"Input Signal and Sampled Values\") plt.show() In\u00a0[5]: Copied! <pre># FFT\n# E.g., Case m = 1 or the 1 kHz (m f_s / N = 1 * 8000 / 8) DFT frequency term\n# X(1) = \\sum^7_{n = 0} x(n) \\cos(2 pi n / 8) - j x (n) sin (2 pi n / 8)\nX = np.fft.fft(x)\nX\n</pre> # FFT # E.g., Case m = 1 or the 1 kHz (m f_s / N = 1 * 8000 / 8) DFT frequency term # X(1) = \\sum^7_{n = 0} x(n) \\cos(2 pi n / 8) - j x (n) sin (2 pi n / 8) X = np.fft.fft(x) X Out[5]: <pre>array([ 7.77156117e-16+0.00000000e+00j, -9.70628099e-16-4.00000000e+00j,\n        1.41421356e+00+1.41421356e+00j, -2.85726235e-17+1.11022302e-15j,\n       -5.55111512e-16+0.00000000e+00j, -2.85726235e-17-1.11022302e-15j,\n        1.41421356e+00-1.41421356e+00j, -9.70628099e-16+4.00000000e+00j])</pre> In\u00a0[6]: Copied! <pre># Input x(n) contains a signal component at a frequency of 1kHz (-9.43689571e-16-4.00000000e+00j ~= 0.0 - j4.0 = 4 \\angle -90 degrees). Magnitude is 4, PS is 16, and X(1)'s phase angle relative to a 1kHz cosine is -90 degrees\n# Input x(n) contains a signal component at a frequency of 2kHz (1.41421356e+00+1.41421356e+00j ~= 1.414 + j1.414 = 2 \\angle 45 degrees). Magnitude is 2, PS is 4, and X(1)'s phase angle relative to a 2kHz cosine is 45 degrees\n</pre> # Input x(n) contains a signal component at a frequency of 1kHz (-9.43689571e-16-4.00000000e+00j ~= 0.0 - j4.0 = 4 \\angle -90 degrees). Magnitude is 4, PS is 16, and X(1)'s phase angle relative to a 1kHz cosine is -90 degrees # Input x(n) contains a signal component at a frequency of 2kHz (1.41421356e+00+1.41421356e+00j ~= 1.414 + j1.414 = 2 \\angle 45 degrees). Magnitude is 2, PS is 4, and X(1)'s phase angle relative to a 2kHz cosine is 45 degrees In\u00a0[7]: Copied! <pre># Plot the X(m) output magnitude and phases as a function of frequency to get the magnitude spectrum of the x(n) input sequence\nmag_X = np.abs(X)\nphase_X = np.zeros(X.shape)\nfor i in range(len(X)):\n    if (mag_X[i] &gt; 0.1):\n        phase_X[i] = np.arctan2(np.imag(X[i]), np.real(X[i]))\n    \nphase_X = np.rad2deg(phase_X)\n\nfig, ax = plt.subplots(2, 1)\nax[0].plot(mag_X, \"o\", color=\"blue\")\nax[0].set_xlabel(\"m [kHz]\")\nax[0].set_ylabel(\"Magnitude of X(m)\")\nax[0].grid(True)\nax[0].set_title(\"Magnitute Spectrum\")\n\n\nax[1].plot(phase_X, \"o\", color=\"blue\")\nax[1].set_xlabel(\"m [kHz]\")\nax[1].set_ylabel(\"Phase of X(m) [deg] \")\nax[1].grid(True)\n\nprint(X)\nprint(phase_X)\n</pre> # Plot the X(m) output magnitude and phases as a function of frequency to get the magnitude spectrum of the x(n) input sequence mag_X = np.abs(X) phase_X = np.zeros(X.shape) for i in range(len(X)):     if (mag_X[i] &gt; 0.1):         phase_X[i] = np.arctan2(np.imag(X[i]), np.real(X[i]))      phase_X = np.rad2deg(phase_X)  fig, ax = plt.subplots(2, 1) ax[0].plot(mag_X, \"o\", color=\"blue\") ax[0].set_xlabel(\"m [kHz]\") ax[0].set_ylabel(\"Magnitude of X(m)\") ax[0].grid(True) ax[0].set_title(\"Magnitute Spectrum\")   ax[1].plot(phase_X, \"o\", color=\"blue\") ax[1].set_xlabel(\"m [kHz]\") ax[1].set_ylabel(\"Phase of X(m) [deg] \") ax[1].grid(True)  print(X) print(phase_X) <pre>[ 7.77156117e-16+0.00000000e+00j -9.70628099e-16-4.00000000e+00j\n  1.41421356e+00+1.41421356e+00j -2.85726235e-17+1.11022302e-15j\n -5.55111512e-16+0.00000000e+00j -2.85726235e-17-1.11022302e-15j\n  1.41421356e+00-1.41421356e+00j -9.70628099e-16+4.00000000e+00j]\n[  0. -90.  45.   0.   0.   0. -45.  90.]\n</pre> In\u00a0[8]: Copied! <pre>## Example 2: Leak\n\n# Consider 64 samples of 7Hz =&gt; t_s = 1 / 7\n# Input: 3.4Hz with amplitude 1 and 7Hz with amplitude 0.1 discrete input\n# Hanning function: 0.5 - 0.5 cos(2 pi n / 64)\n\n# x(n) = sin(2pi3.4n / 64) + 0.1sin(2pi7n / 64)\n\ndef generate_discrete_input_signal(N, f_s):\n    \n    x = np.zeros((N, ))\n    x_w = np.zeros((N, ))\n    t_s = 1. / f_s\n    \n    for i in range(N):\n        x[i] = np.sin(2 * np.pi * 3.4 * i / 64 ) + 0.1 * np.sin(2 * np.pi * 7 * i /64)\n\n        w = 0.5 - 0.5 * np.cos(2 * np.pi * i / 64)\n        x_w[i] = w * x[i]\n    return x, x_w\n\n\nN = 64\nf_s = 7\n\nx, x_w = generate_discrete_input_signal(N, f_s)\n\nX = np.abs(np.fft.fft(x))\nX_w = np.abs(np.fft.fft(x_w))\n\nfig, ax = plt.subplots(2, 1)\nax[0].plot(x, \"-x\", color=\"blue\", label=\"x\")\nax[0].plot(x_w, \"-x\", color=\"red\", label=\"x_w\")\nax[0].set_ylabel(\"x\")\nax[0].set_xlabel(\"N\")\nax[0].grid(True)\nax[0].legend()\n\nax[1].plot(X[:32], \"-x\", color=\"blue\", label=\"X\")\nax[1].plot(X_w[:32], \"-x\", color=\"red\", label=\"X_w\")\nax[1].set_xlabel(\"Freq m [Hz]\")\nax[1].grid(True)\nax[1].legend()\n\nplt.show()\n</pre> ## Example 2: Leak  # Consider 64 samples of 7Hz =&gt; t_s = 1 / 7 # Input: 3.4Hz with amplitude 1 and 7Hz with amplitude 0.1 discrete input # Hanning function: 0.5 - 0.5 cos(2 pi n / 64)  # x(n) = sin(2pi3.4n / 64) + 0.1sin(2pi7n / 64)  def generate_discrete_input_signal(N, f_s):          x = np.zeros((N, ))     x_w = np.zeros((N, ))     t_s = 1. / f_s          for i in range(N):         x[i] = np.sin(2 * np.pi * 3.4 * i / 64 ) + 0.1 * np.sin(2 * np.pi * 7 * i /64)          w = 0.5 - 0.5 * np.cos(2 * np.pi * i / 64)         x_w[i] = w * x[i]     return x, x_w   N = 64 f_s = 7  x, x_w = generate_discrete_input_signal(N, f_s)  X = np.abs(np.fft.fft(x)) X_w = np.abs(np.fft.fft(x_w))  fig, ax = plt.subplots(2, 1) ax[0].plot(x, \"-x\", color=\"blue\", label=\"x\") ax[0].plot(x_w, \"-x\", color=\"red\", label=\"x_w\") ax[0].set_ylabel(\"x\") ax[0].set_xlabel(\"N\") ax[0].grid(True) ax[0].legend()  ax[1].plot(X[:32], \"-x\", color=\"blue\", label=\"X\") ax[1].plot(X_w[:32], \"-x\", color=\"red\", label=\"X_w\") ax[1].set_xlabel(\"Freq m [Hz]\") ax[1].grid(True) ax[1].legend()  plt.show() In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"assets/jupyter/probability/cellarea_analysis/","title":"Cellarea analysis","text":"<p>Here we explore descriptive statistics for cell area of embryonic stem cells.</p> In\u00a0[1]: Copied! <pre>import pandas as pd\nimport numpy as np\n\n# Load the data\ndata = pd.read_excel(\"cellarea.xlsx\", header=None, index_col=None)\ndata.head()\n</pre> import pandas as pd import numpy as np  # Load the data data = pd.read_excel(\"cellarea.xlsx\", header=None, index_col=None) data.head() Out[1]: 0 0 48000 1 42000 2 11000 3 26000 4 15000 In\u00a0[2]: Copied! <pre>hist = data.hist(bins=100)\n</pre> hist = data.hist(bins=100) <p>We can see an outliers at the very right end of the graph.</p> In\u00a0[3]: Copied! <pre># Remove the outlier using 99% percentile\nq = data.quantile(0.99)\ncar = data[data &lt; q]\nhist2 = car.hist(bins=100)\n</pre> # Remove the outlier using 99% percentile q = data.quantile(0.99) car = data[data &lt; q] hist2 = car.hist(bins=100) In\u00a0[4]: Copied! <pre># Rescale the data to moderate values so that the area is expressed in thousands of \n# micro m^2\ncar_scaled = car / 1000.0\n\n# Compute the locations of the car\nprint(\"Median: \" + str(car_scaled.median()))\nprint(\"Mode: \" + str(car_scaled.mode()))\n\n# Compute variability\nprint(\"Var: \" + str(car_scaled.var()))\nprint(\"Std: \" + str(car_scaled.std()))\n</pre> # Rescale the data to moderate values so that the area is expressed in thousands of  # micro m^2 car_scaled = car / 1000.0  # Compute the locations of the car print(\"Median: \" + str(car_scaled.median())) print(\"Mode: \" + str(car_scaled.mode()))  # Compute variability print(\"Var: \" + str(car_scaled.var())) print(\"Std: \" + str(car_scaled.std()))  <pre>Median: 0    17.0\ndtype: float64\nMode:       0\n0  10.0\nVar: 0    360.630484\ndtype: float64\nStd: 0    18.990273\ndtype: float64\n</pre> In\u00a0[5]: Copied! <pre># Box-and-Whiskers Plot\n# The top and bottom of the \"box\" are the 25th and 75th percentile of the data, \n# respectively, with the distances between the representing the IQR. The green line inside the box \n# is the median. Since the median is not centered in the box, the sample is skewed. Whiskers \n# extend from the lower and upper sides of the box to the data's most extreme values\n# within 1.5 times the IQR. Potential outliers are displayed with black \"o\" beyond\n# the endpoints of the wiskers.\ncar_scaled.boxplot()\n</pre> # Box-and-Whiskers Plot # The top and bottom of the \"box\" are the 25th and 75th percentile of the data,  # respectively, with the distances between the representing the IQR. The green line inside the box  # is the median. Since the median is not centered in the box, the sample is skewed. Whiskers  # extend from the lower and upper sides of the box to the data's most extreme values # within 1.5 times the IQR. Potential outliers are displayed with black \"o\" beyond # the endpoints of the wiskers. car_scaled.boxplot() Out[5]: <pre>&lt;Axes: &gt;</pre> In\u00a0[6]: Copied! <pre># Histogram\n# Histogram is a rough approximation of the population distribution based on a sample. \n# Plotted in histogram are frequencies for interval-grouped data. Common way to determine the bin size\n# is to use Sturges'r rule:\n# k = 1 + log2n, where n is the size of the sample\nk = 1 + np.log2(car_scaled.size)\nhist3 = car_scaled.hist(bins=int(k))\n</pre> # Histogram # Histogram is a rough approximation of the population distribution based on a sample.  # Plotted in histogram are frequencies for interval-grouped data. Common way to determine the bin size # is to use Sturges'r rule: # k = 1 + log2n, where n is the size of the sample k = 1 + np.log2(car_scaled.size) hist3 = car_scaled.hist(bins=int(k)) In\u00a0[7]: Copied! <pre># Empirical Cumulative Distribution Function\n# The empirical cumulative distribution function (ECDF) F_n(x) for sample, X_1, ..., X_n\n# is defined as:\n# F_n(x) = (1 / n) \\sum^n_{i = 1} \\mathbf{1} (X_i \\leq x)\n# and represents the proportion of sample values smaller than x. \n</pre> # Empirical Cumulative Distribution Function # The empirical cumulative distribution function (ECDF) F_n(x) for sample, X_1, ..., X_n # is defined as: # F_n(x) = (1 / n) \\sum^n_{i = 1} \\mathbf{1} (X_i \\leq x) # and represents the proportion of sample values smaller than x."},{"location":"computer_vision/image_compression/compression_by_low_rank_matrix_approximation/","title":"Compression via Low-Rank Matrix Approximation","text":""},{"location":"computer_vision/image_compression/compression_by_low_rank_matrix_approximation/#compression-via-low-rank-matrix-approximation","title":"Compression via Low-Rank Matrix Approximation","text":"<p>See SVD for more details on low-rank matrix approximation.</p> <p>Algorithm: Low-Rank Matrix Approximation</p> <p>\\(\\quad\\) Given an image \\(\\mathbf{A}\\), do SVD on \\(\\mathbf{A}\\).  \\(\\quad\\) Keep the first \\(r\\) largest singular values and associated left and right singular vectors.  \\(\\quad\\) Construct \\(\\tilde{\\mathbf{A}} = \\sum^r_{i = 1} \\sigma_i \\mathbf{u}_i \\mathbf{v}^T_i\\).   </p>"},{"location":"computer_vision/image_compression/compression_by_low_rank_matrix_approximation/#relative-error","title":"Relative Error","text":"<p>The relative error can be defined as:</p> \\[ \\epsilon_r = \\frac{\\sigma_{r + 1}}{\\sigma_1}. \\]"},{"location":"computer_vision/image_compression/compression_by_low_rank_matrix_approximation/#space-complexity","title":"Space Complexity","text":"<p>Given an image \\(\\mathbf{A}\\), we need to store \\(m \\times n \\times 8\\) bytes. By using the low-rank matrix approximation, we'd need to store \\(m \\times r \\times 8\\) in \\(\\begin{array}{ccc}\\mathbf{u}_1, \\ldots, \\mathbf{u}_r \\end{array}\\) and \\(n \\times r \\times 8\\) in \\(\\begin{array}{ccc}\\mathbf{v}_1, \\ldots, \\mathbf{v}_r \\end{array}\\), thus in total \\((m + n) \\times r \\times 8\\). The compression ratio is:</p> \\[ \\frac{(m + n) \\times r}{(m \\times n)}. \\]"},{"location":"computer_vision/image_compression/compression_by_low_rank_matrix_approximation/#example","title":"Example","text":"<p>Consider the fat cat grayscale image in Figure 1.</p>"},{"location":"computer_vision/image_features/orb/","title":"ORB","text":""},{"location":"computer_vision/image_features/orb/#definition","title":"Definition","text":"<p>Oriented FAST and Rotated BRIEF (ORB) solves the problem that the FAST detector does not have descriptors and uses the extremely fast binary descriptor BRIEF. It composes of two parts: ORB key points and ORB descriptor. The extraction of ORB features consists of two steps:</p> <ol> <li> <p>FAST corner point extraction</p> <p>Find the corner points in the image. Compared to the original FAST, the main direction of the feature points are calculated in ORB, making the subsequent BRIEF descriptor rotation-invariant.</p> </li> <li> <p>Binary Robust Independent Elementary Feature (BRIEF) descriptor</p> <p>Describe the surrounding image area where the feature points were extracted in the previous step. ORB has made some improvements to BRIEF, mainly referring to utilizing the previously calculated direction.</p> </li> </ol>"},{"location":"computer_vision/image_features/orb/#fast-key-point-and-oriented-fast","title":"FAST Key Point and Oriented FAST","text":"<p>FAST detects the local grayscale changes and is known for its fast speed. If a pixel is very different from the neighboring pixels (either too bright or too dark), it is more likely to be a corner point. FAST procedure is as follows:</p> <p>FAST Key Point Algorithm</p> <ol> <li>Select pixel \\(p\\) in the image. Denote its intensity as \\(I_p\\).</li> <li>Select a threshold \\(T\\) (for example, 20\\% of \\(I_p\\)).</li> <li>Take the pixel \\(p\\) as the center and select 16 pixels on a circle with a radius of 3.   </li> <li>If there are \\(N\\) consecutive points on the selected circle whose intensity is greater than \\(I_p + T\\) or less than \\(I_p - T\\), then the central pixel \\(p\\) can be considered a feature point. \\(N\\) usually takes 12, which is FAST-12.  </li> <li>Iterative through 1-4 on each pixel.</li> </ol> <p>For speed up, the intensity of the 1, 5, 9, and 13 pixels on the circle can be checked to quickly exclude many pixels that are not corner points. Furthermore, the original FAST corners are often clustered, meaning a lot of FAST corners may be present in the same area. Hence, non-maximal suppresion is often required.</p> <p>FAST corner points do not include direction information and has scaling problem. ORB adds the secription of scale and rotation. The scale invariance is achieved by the image pyramid. The rotation of features is realized by the intensity centroid method.</p> <p>Intensity Centroid Method</p> <ol> <li> <p>In a small image block \\(B\\), define the moment of the image block as:</p> \\[ m_{pq} = \\sum_{x, y \\in B} x^p y^q I(x, y), \\quad p, q = \\left\\{0, 1 \\right\\}. \\] </li> <li> <p>Calculate the centroid of the image block by the moment:</p> \\[ C = \\left(\\frac{m_{10}}{m_{00}}, \\frac{m_{01}}{m_{00}} \\right). \\] </li> <li> <p>Connect the geometric center \\(O\\) and the centroid \\(C\\) of the image block to get a direction vector \\(\\overrightarrow{OC}\\), so the direction of the feature point can be defined as:</p> \\[ \\theta = \\arctan(m_{01} / m_{10}). \\] </li> </ol> <p>This improved FAST is called oriented FAST in ORB.</p>"},{"location":"computer_vision/image_features/orb/#brief-descriptor","title":"BRIEF Descriptor","text":"<p>BRIEF is a binary descriptor. Its description vector consists of many zeroes and ones, which encode the size relationship between two random pixels near the key point (such as \\(p\\) and \\(q\\)). If \\(p\\) is greater than \\(q\\), then take 1, otherwise take 0. BRIEF descriptor does not have rotation invariance. The ORB calculates the direction of the key points in the FAST feature corner point extraction stage. The direction information can be used to calculate the Steer BRIEF feature after the rotation so that the ORB descriptor has better rotation invariance.</p>"},{"location":"computer_vision/image_features/orb/#example-orb-features","title":"Example ORB Features","text":"<p>Figure 1 shows the two views of the same setup along with their ORB features and matched features.</p> <p> </p> Figure 1 ORB Feature Matching OpenCV <pre><code>import numpy as np\nimport cv2 as cv\nfrom matplotlib import pyplot as plt\n\nimg_1 = cv.imread(\"1.png\", cv.IMREAD_GRAYSCALE)\nimg_2 = cv.imread(\"2.png\", cv.IMREAD_GRAYSCALE)\n\n# Initiate ORB detector\norb_1 = cv.ORB_create()\norb_2 = cv.ORB_create()\n\n# Find the ORB keypoints\nkp_1 = orb_1.detect(img_1, None)\nkp_2 = orb_2.detect(img_2, None)\n\n# Compute the ORB descriptors\nkp_1, des_1 = orb_1.compute(img_1, kp_1)\nkp_2, des_2 = orb_2.compute(img_2, kp_2)\n\n# Create Brute Force Matches object\nbf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n\n# Match descriptors\nmatches = bf.match(des_1, des_2)\n\n# Sort them in the order of their distnace\nmatches = sorted(matches, key = lambda x : x.distance)\n\n\n# Draw only the keypoints location, not size and orientation\nimg_1_orb = cv.drawKeypoints(img_1, kp_1, None, color=(0, 255, 0), flags = 0)\nimg_2_orb = cv.drawKeypoints(img_2, kp_2, None, color=(0, 255, 0), flags = 0)\n\n# Draw the first 50 matches\nimg_3 = cv.drawMatches(img_1, kp_1, img_2, kp_2, matches[:50], None, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n\n\nplt.subplot(2, 2, 1)\nplt.imshow(img_1_orb)\n\nplt.subplot(2, 2, 2)\nplt.imshow(img_1_orb)\n\nplt.subplot(2, 1, 2)\nplt.imshow(img_3)\n\nplt.savefig(\"orb_features.png\", bbox_inches=\"tight\", dpi=1000)\n</code></pre>"},{"location":"computer_vision/image_features/primer_on_features/","title":"Primer on Features","text":"<p>A feature point is composed of two parts: key point and descriptor. The key point refers to the 2D position of the feature point. Some type of key points also hold other information, such as the orientation and size. The descriptor is usually a vector, describing the information of the pixels around the key point. The descriptor should be designed according to the principle that features with similar appearance should have similar descriptors. </p>"},{"location":"computer_vision/image_features/sift/","title":"Scale-Invariant Feature Transform (SIFT)","text":""},{"location":"computer_vision/image_processing/correlation_filter/","title":"Correlation Filter","text":""},{"location":"computer_vision/image_processing/correlation_filter/#uniform-weights","title":"Uniform Weights","text":"<p>If we let the average window size to be \\((2k + 1) \\times (2k + 1)\\):</p> \\[ G(i, j) = \\underbrace{\\frac{1}{(2k + 1)^2}}_{\\text{A}} \\underbrace{\\sum^k_{u = -k} \\sum^k_{v = -k} F(i + u, j + v)}_{B}, \\] <p>where:</p> \\[ \\begin{align} A&amp;: \\ \\text{Uniform weight for each pixel} \\\\ B&amp;: \\ \\text{Loop over all pixels in neighborhood around image pixel } F(i, j). \\end{align} \\]"},{"location":"estimation_theory/low_pass/","title":"Low pass","text":"<p>Order of the filter depends on the frequency components of the signal you are trying to estimate.</p> <p>If it has a combination of two frequency signals (5Hz and 50Hz) and you want to treat anything 50Hz+ as noise, you set a second order filter with two time constants (0.2s and 0.02s). You can use combination of two first-order filter (which would effectively be a 2nd order filter).</p> <p>given y(i) = coef * x(i) + (1 - coef) * y(i - 1)</p> <p>coef = dt / (dt + tau)</p> <p>https://elib.dlr.de/144642/1/2021__ION__Baro_Modeling__Simonetti_GarciaCrespillo.pdf https://academic.csuohio.edu/simon-daniel/state-estimation/</p>"},{"location":"estimation_theory/references/","title":"References","text":"<p>All contents are from:</p> <ol> <li>Vidakovic, B., Engineering Biostatistics</li> <li>Simon, D., Optimal State Estimation, 2006</li> <li>Dellaert, F., Kaess, M., Factor Graphs for Robot Perception, 2017</li> <li>Bar-Shalom et al., Estimation with Applications to Tracking and Navigation, 2001</li> <li>Taylor, C., Factor Graphs for Navigation Applications: A Tutorial, 2023</li> <li>Boyd S., Convex Optimization, 2014</li> <li>Course notes from Deterministic Optimization, GaTech, 2022</li> </ol>"},{"location":"estimation_theory/bayesian_inference/bayesian_inference/","title":"Bayesian Inference","text":""},{"location":"estimation_theory/bayesian_inference/bayesian_inference/#introduction","title":"Introduction","text":"<p>In Bayesian inference, the unobserved parameters in a statistical model are treated as random variables. Before the data is collected, prior distributions are elicited to quantify our knowledge about the parameters. The prior distribution comes from expert opinion, theoretical considerations, or previous similar experiments. When data is available, the prior distributions are updated to the posterior distributions. These are conditional distributions that incorporate the observed data. The transition from prior to the posterior is possible via Bayes' theorem.</p> <p>Prior to observing whether an event \\(A\\) has appeared or not, we set the probabilities of \\(n\\) hypotheses, \\(H_1, H_2, \\ldots, H_n\\), under which event \\(A\\) may happen. These are called prior probabilities of the hypotheses, \\(\\mathbb{P}(H_1), \\ldots, \\mathbb{P}(H_n)\\). Bayes' rule gives recipe to update these prior probabilities to the posterior probabilities once we obtained additional information from the experiment (information about the event \\(A\\)):</p> \\[ \\mathbb{P}(H_i | A) = \\frac{\\mathbb{P}(A | H_i) \\mathbb{P}(H_i)}{\\mathbb{P}(A)}. \\] <p>Suppose that before the data is observed, a description of the population parameter \\(\\theta\\) is given by a probability density \\(\\pi(\\theta)\\). The process of specifying the prior distribution is called prior elicitation. The data is modeled via the likelihood, which depends on \\(\\theta\\) and is denoted by \\(f(x | \\theta)\\). Bayes' theorem updates the prior \\(\\pi(\\theta)\\) to the posterior \\(\\pi(\\theta | x)\\) by incorporating observations \\(x\\) summarized via the likelihood:</p> \\[ \\pi(\\theta | x) = \\frac{f(x | \\theta) \\pi (\\theta)}{m(x)}, \\] <p>where \\(m(x)\\) is a normalization factor so that the posterior is a proper density and is a constant once the prior is specified and the data is observed. Given the parameter \\(\\theta\\), with values in the parameter space \\(\\Theta\\), the normalization factor is:</p> \\[ m(x) = \\int_{\\Theta} (h, \\theta) d \\theta = \\int_{\\Theta} f(x | \\theta) \\pi (\\theta)d \\theta, \\] <p>where the joint distribution of \\(X\\) and \\(\\theta\\), \\(h(x, \\theta)\\) is:</p> \\[ h(x, \\theta) = f(x | \\theta) \\pi (\\theta) = \\pi(\\theta | x) m(x). \\] <p>All information about \\(\\theta\\) coming from the prior distribution and the observations are contained in the posterior distribution. The posterior distribution is the ultimate summary of the parameter and serves as the basis for all Bayesian inferences.</p> <p>Hyperparameters</p> <p>The parameter \\(\\theta\\), with values in the parameter space \\(\\Theta\\), is not directly observable and is considered a random variable. This is the key difference between Bayesian and classical approaches. Classical statistics consider the parameter to be fixed number or vector of numbers, while Bayesians express the uncertainty about \\(\\theta\\) by considering it as a random variable. This random variable has a distribution \\(\\pi(\\theta)\\) (prior). The prior distribution not only quantifies available knowledge, it also describes the uncertainty about a parameter before data is observed. If the prior distribution for \\(\\theta\\) is specified up to a parameter \\(\\tau\\), \\(\\pi(\\theta | \\tau)\\), then \\(\\tau\\) is called a hyperparameter. Hyperparameters are parameters of a prior distribution, and they are either specified or may have their own priors. </p> <p>Bayesian inference</p> \\[\\begin{align} \\mathbb{P}(\\text{hypothesis}) \\quad &amp;\\xrightarrow{\\text{Bayes' Rule}} \\quad \\mathbb{P}(\\text{hypothesis}|\\text{evidence}) \\\\ \\pi(\\theta) \\quad &amp;\\xrightarrow{\\text{Bayes' Theorem}} \\quad \\pi(\\theta | \\text{data}) \\end{align}\\]"},{"location":"estimation_theory/bayesian_inference/bayesian_inference/#bayesian-inference-advantages","title":"Bayesian Inference Advantages","text":"<ol> <li>Valuable prior information is often available (e.g., medical devices).</li> <li>Use of prior information may alleviate the need for a larger sized trial. We don't need to do millions of experimental trials to deduce an inference.</li> <li>The Bayesian approach can sometimes be used to obtain an exact analysis when the corresponding frequentist analysis is only approximate or is too difficult to implement.</li> <li>Bayesian methods allow for great flexibility in dealing with missing data.</li> </ol>"},{"location":"estimation_theory/bayesian_inference/bayesian_network/","title":"Bayesian Network","text":""},{"location":"estimation_theory/bayesian_inference/bayesian_network/#introduction","title":"Introduction","text":"<p>A Bayesian network or Bayes net is a directed graphical model (directed acyclic graphs (DAGs)) where the nodes represent events and where the directed edges capture their hierarchy and dependence. Hard evidence for a node \\(\\theta\\) is evidence that the outcome of \\(\\theta\\) is known. Hard evidence about nodes is the information that we bring to the network, and it affects the probabilities of other nodes. Bayesian networks possess Markovian property, i.e., the conditional distribution of any node depends only on its parental nodes.</p> <p>Let the entire set of random variables of interest (nodes) as \\(\\Theta = \\left\\{ \\theta_1, \\ldots, \\theta_n\\right\\}\\). A Bayes net then defines a joint probability density \\(p(\\Theta)\\) over all variables \\(\\Theta\\) as the product of conditional densities associated with each of the nodes:</p> \\[ p(\\Theta) \\triangleq \\prod_j p(\\theta_j | \\pi_j), \\] <p>where \\(p(\\theta_j | \\pi_j)\\) is the conditional density associated with node \\(\\theta_j\\), and \\(\\pi_j\\) is an assignment of values to the parents of \\(\\theta_j\\). Hence, in a Bayes net, the factorization of the join density is dictated by its graph structure, in particular the node-parent relationships.</p>"},{"location":"estimation_theory/bayesian_inference/bayesian_network/#example-toy-slam","title":"Example Toy SLAM","text":"<p>Consider a toy SLAM problem shown in Figure 1. Here, \\(x_i\\) is the \\(i\\)'th robot pose, \\(l_j\\) is the \\(j\\)'th landmark. \\(z_k\\)s are the measurements.</p> <p> </p> Figure 1 Bayes net for toy SLAM (Dellaert p6) <p>Let \\(X\\) be a random variable denoting the robot poses and the unknown landmark positions and \\(Z\\) be the set of observed measurements.</p> <p>The joint density is then:</p> \\[ \\begin{align} p(X, Z) &amp;= p(x_1, x_2, x_3, l_1, l_2, z_1, z_2, z_3, z_4) \\\\ &amp;= p(x_1) p(x_2 | x_1) p(x_3 | x_2) \\\\ &amp;\\times p(l_1) p (l_2) \\\\ &amp;\\times p(z_1 | x_1) \\\\ &amp;\\times p(z_2 | x_1, l_1) p(z_3 | x_2, l_1) p(z_4 | x_3, l_2). \\end{align} \\] <p>Here we have:</p> <ol> <li> <p>A Markov chain \\(p(x_1) p(x_2 | x_1) p(x_3 | x_2)\\) on the poses \\(x_1\\), \\(x_2\\), and \\(x_3\\). The conditional densities \\(p(x_{t + 1} | x_t)\\) might represent prior knowledge or can be derived from known control inputs.</p> </li> <li> <p>Prior densities \\(p(l_1)\\) and \\(p(l_2)\\) on the landmarks \\(l_1\\) and \\(l_2\\). </p> </li> <li> <p>A conditional density or likelihood \\(p(z_1 | x_1)\\) corresponding to the absolute pose measurement on the first pose \\(x_1\\).</p> </li> <li> <p>Product of three conditional densities.</p> </li> </ol>"},{"location":"estimation_theory/bayesian_inference/bayesian_network/#probability-densities","title":"Probability Densities","text":"<p>The most often-used denisities involve the multivariate Gaussian distribution, with PDF:</p> \\[ \\mathcal{N}(\\theta; \\mu; \\Sigma) = \\frac{1}{\\sqrt{|2 \\pi \\Sigma}} \\exp \\left\\{ -\\frac{1}{2} ||\\theta - \\mu||^2_{\\Sigma} \\right\\}, \\] <p>where \\(\\mu \\in \\mathbb{R}^n\\) is the mean, and \\(\\Sigma \\in \\mathbb{R}^{n \\times n}\\) is the covariance matrix and:</p> \\[ ||\\theta - \\mu||^2_{\\Sigma} \\triangleq (\\theta - \\mu)^T \\Sigma^{-1} (\\theta - \\mu), \\] <p>denotes the squared Mahalanobis distance. In most cases, it is both justified and convenient to model measurements as corrupted by a zero-mean Gaussian noise. For example, a bearing measurement from a given pose \\(x\\) to a given landmark \\(l\\) would be modeled as:</p> \\[ z = h(x, l) + v, \\] <p>where \\(h(\\cdot)\\) is a measurement prediction function, and the noise \\(v\\) is drawn from a zero-mean Gaussian density with measurement covariance \\(\\mathbf{R}\\). Then the conditional density on the measurement \\(z\\) would be:</p> \\[ p(z | x, l) = \\mathcal{N}(z; h(x, l), \\mathbf{R}) = \\frac{1}{\\sqrt{|2 \\pi \\mathbf{R}|}} \\exp \\left\\{ -\\frac{1}{2} ||h(x, l) - z||^2_{\\mathbf{R}} \\right\\}. \\]"},{"location":"estimation_theory/bayesian_inference/bayesian_network/#probabilistic-motion-model","title":"Probabilistic Motion Model","text":"<p>The probabilistic motion model \\(p(x_{t + 1} | x_t)\\) can be derived from odometry measurements, or alternatively, from the known control inputs \\(u_t\\). We use a conditional Gaussian assumption:</p> \\[ p(x_{t + 1} | x_t, u_t ) = \\frac{1}{\\sqrt{|2 \\pi \\mathbf{Q}|}} \\exp \\left\\{-\\frac{1}{2} ||g(x_t, u_t) - x_{t + 1}||^2_{\\mathbf{Q}} \\right\\}, \\] <p>where \\(g(\\cdot)\\) is the motion model and \\(\\mathbf{Q}\\) is the process noise. </p>"},{"location":"estimation_theory/bayesian_inference/maximum_a_posteriori_estimator/","title":"Maximum a Posteriori Estimator","text":""},{"location":"estimation_theory/bayesian_inference/maximum_a_posteriori_estimator/#introduction","title":"Introduction","text":"<p>Given random variable \\(X\\), such as poses and/or landmarks, and the measurements \\(Z\\), we are interested in finding \\(X\\) given \\(Z\\). The maximum a posteriori (MAP) estimator is defined as:</p> \\[ \\begin{align} \\hat{X}^{MAP} &amp;= \\arg \\max_{X} p(X | Z) \\\\ &amp;= \\arg \\max_{X} \\frac{p(Z | X) p(X)}{p (Z)} \\\\ &amp;= \\arg \\max_{X} L(X; Z) p (X), \\end{align} \\] <p>where \\(L(X; Z)\\) is the likelihood of the states \\(X\\) given the measurements \\(Z\\) and is defined as any function proportional to \\(p(Z | X)\\):</p> \\[ L(X; Z) \\propto p(Z | X). \\] <p>Bayes' rule tells us that solving the maximum posterior probability is equivalent to the esitmate of the product of maximum likelihood and a priori. The notation \\(L(X; Z)\\) emphasizes the fact that the likelihood is a function of \\(X\\) and not \\(Z\\), which acts merely as a paremeter in this context.</p> <p>If we have no information about the prior, the estimator converts to MLE.</p>"},{"location":"estimation_theory/factor_graph/definition/","title":"Factor Graph Overview","text":""},{"location":"estimation_theory/factor_graph/definition/#overview","title":"Overview","text":"<p>A factor graph is a bipartite graph, \\(F = (\\mathcal{U}, \\mathcal{V}, \\mathcal{E})\\), with two types of nodes: </p> <ol> <li>Hidden variables, \\(x_j \\in \\mathcal{V}\\). Hidden variable nodes represent the variables being estimated and can only connect with factor nodes.</li> <li>Factors, \\(\\phi_i \\in \\mathcal{U}\\). Factor nodes represent functions of the hidden variables and can only connect with hidden variable nodes (i.e., factors cannot be functions of other factors). In navigation applications, factors typically represent measurements or dynamics. Each factor in a factor graph has three items associated with it: a function of the hidden variables, a measured value for that factor, and a PDF returning the likelihood of the measured value given the current values of the hidden variables.</li> </ol> <p>Edges, \\(e_{ij} \\in \\mathcal{E}\\), exist only between the hidden variables and the factor nodes. Factor graph is a representation of the probabilistic relationship between the measurements that have been received and state variables (i.e., hidden variables) that are being estimated given the received measurements.</p>"},{"location":"estimation_theory/factor_graph/definition/#definition","title":"Definition","text":"Figure 1 A factor graph representation (Factor Graph Tutorial, ION, GNSS+ 2023) <p>Let \\(\\mathbf{x}_i\\) denote a set of hidden variable nodes adjacent to a factor \\(\\phi_i\\). The factor graph, \\(F\\), defines the factorization of a global function \\(\\phi(\\mathbf{x})\\) as:</p> \\[ \\phi(\\mathbf{x}) = \\prod_i \\phi_i (\\mathbf{x}_i). \\] <p>Figure 1 shows an example factor graph where the factors are denoted as \\(z_i\\) and the hidden variables denoted as \\(x_i\\). \\(\\gamma\\) is a prior. In state estimation, the hidden variables are the states to be estimated and the factors are the measurements or anything gives information about the hidden variables. The square factors between the hidden variables are also factors that represent the dynamics of the system.</p>"},{"location":"estimation_theory/factor_graph/definition/#advantages-of-factor-graph","title":"Advantages of Factor Graph","text":"<ol> <li>Better for non-linear systems than EKF and simplifies implementation of extensions to the EKF.</li> <li>Extensible to multiple different estimation scenarios (e.g., bundle adjustment, calibration, different input PDFs, multiple dynamics, etc.)</li> <li>Enables batch analysis of input data \\(\\Rightarrow\\) better outlier detection / input characterization etc.</li> </ol>"},{"location":"estimation_theory/factor_graph/representations/","title":"Representations","text":""},{"location":"estimation_theory/factor_graph/representations/#system-definition","title":"System Definition","text":"<p>Consider a system with dynamics:</p> \\[ \\begin{align} \\mathbf{x}_{k + 1} &amp;= \\mathbf{f}(\\mathbf{x}_k, \\mathbf{u}_k) + \\mathbf{w}, \\quad \\mathbf{w} \\in \\mathcal{N}(\\mathbf{0},\\,\\mathbf{Q}) \\\\ \\mathbf{f}(\\mathbf{x}_k, \\mathbf{u}_k) &amp;\\approx \\mathbf{f}(\\hat{\\mathbf{x}}_k, \\mathbf{u}_k) + \\mathbf{F}(\\mathbf{x}_k - \\hat{\\mathbf{x}}_k) \\\\  \\mathbf{F} &amp; \\triangleq \\left. \\frac{\\partial \\mathbf{f}(\\mathbf{x}_k, \\mathbf{u}_k)}{\\partial \\mathbf{x}_k} \\right|_{\\mathbf{x}_k = \\hat{\\mathbf{x}}_k} \\end{align} \\] <p>and measurements:</p> \\[ \\begin{align} \\mathbf{z}_{k} &amp;= \\mathbf{h}_k(\\mathbf{x}_k) + \\mathbf{v}, \\quad \\mathbf{v} \\in \\mathcal{N}(\\mathbf{0},\\,\\mathbf{R}) \\\\ \\mathbf{h}_k(\\mathbf{x}_k) &amp;\\approx \\mathbf{h}_k(\\hat{\\mathbf{x}}_k) + \\mathbf{H}(\\mathbf{x}_k - \\hat{\\mathbf{x}}_k) \\\\ \\mathbf{H}_k &amp; \\triangleq \\left. \\frac{\\partial \\mathbf{h}_k(\\mathbf{x}_k)}{\\partial \\mathbf{x}_k} \\right|_{\\mathbf{x}_k = \\hat{\\mathbf{x}}_k} \\end{align} \\] <p>with prior:</p> \\[ \\mathbf{x}_0 = \\gamma + \\xi, \\quad \\xi \\in \\mathcal{N}(0, \\boldsymbol{\\Xi}_0). \\]"},{"location":"estimation_theory/factor_graph/representations/#equivalent-representations","title":"Equivalent Representations","text":"<p>The Bayesian graphical representation of a factor graph is equivalent to a (sparse) matrix representation or the optimization representation as shown in Figure 1.</p> <p> </p> Figure 1 Factor graph representations (Factor Graph Tutorial, ION, GNSS+ 2023)"},{"location":"estimation_theory/factor_graph/representations/#optimization-representation","title":"Optimization Representation","text":"<p>The goal of a maximum likelihood estimator (MLE) is to find the values of the hidden variables that maximize the probability of those values. MLE converts factor graph into an optimization problem. Let \\(\\mathbf{X}\\) be the set of all states from \\(0\\) to \\(N\\). To find the maximum probability state estimate:</p> \\[ \\hat{\\mathbf{x}} = \\arg \\max_{\\mathbf{X}} \\left[ p (\\mathbf{x}_0 \\ | \\ \\gamma) \\cdot \\prod^N_{k = 0} p(\\mathbf{x}_k \\ | \\ \\mathbf{z}_k) \\cdot \\prod^N_{k = 1} p(\\mathbf{x}_k \\ | \\ \\mathbf{x}_{k - 1}) \\right]. \\] <p>If we assume Gaussian PDFs on the factors and take the logarithm:</p> \\[ \\begin{align} \\hat{\\mathbf{x}} = &amp;\\arg \\min_{\\mathbf{X}} \\Biggl[ \\frac{1}{2}|| \\mathbf{x}_0 - \\gamma ||^2_{\\mathbf{\\boldsymbol{\\Xi}}_0} +  \\Biggr. \\\\ &amp;\\frac{1}{2} \\sum^N_{k = 0} ||\\mathbf{h}_k(\\mathbf{x}_k) - \\mathbf{z}_k ||^2_{\\mathbf{R}} + \\\\ &amp;\\frac{1}{2} \\left. \\sum^N_{k = 1} ||\\mathbf{f}(\\mathbf{x}_{k - 1}, \\mathbf{u}_{k - 1}) - \\mathbf{x}_k ||^2_{\\mathbf{Q}} \\right]. \\end{align} \\] <p>This is a non-linear least squares problem and can be solved with any optimization methods. While converting a factor graph to its equivalent optimization explains at a high level how to find the maximum likelihood variables as a weighted least-squares problem, the true computational savings are realized by analyzing the sparse matrix representation.</p>"},{"location":"estimation_theory/factor_graph/representations/#sparse-matrix-representation","title":"Sparse Matrix Representation","text":"<p>The Bayesian graph can be converted into an adjacency matrix \\(\\mathbf{L}\\) as shown in Figure 2. The squares are the non-zero elements. Every column of the \\(\\mathbf{L}\\) matrix corresponds to a hidden variable, and every row corresponds to a factor. The graph structure enforces sparsity. The \\(d_i\\)s are the \"special\" factors that correspond to the dynamics of the system.</p> <p> </p> Figure 2 Adjacency matrix (Factor Graph Tutorial, ION, GNSS+ 2023)"},{"location":"estimation_theory/factor_graph/using_factor_graph/dynamical_systems/","title":"Dynamical Systems","text":""},{"location":"estimation_theory/factor_graph/using_factor_graph/dynamical_systems/#problem-formulation","title":"Problem Formulation","text":"<p>Consider a system shown in Figure 1. The state space model of the system is given as:</p> \\[ \\begin{alignat}{2} \\mathbf{x}_k &amp;= f(\\mathbf{x}_{k - 1}, \\mathbf{u}_{k - 1}) + \\mathbf{w}, \\quad &amp;&amp;\\mathbf{w} \\in \\mathcal{N}(\\mathbf{0}, \\mathbf{Q}_k) \\\\ \\mathbf{z}_i &amp;= h_i(\\mathbf{x}_i) + \\mathbf{v}, \\quad &amp;&amp; \\mathbf{v} \\in \\mathcal{N}(\\mathbf{0}, \\mathbf{R}_i). \\end{alignat} \\] <p> </p> Figure 1 Factor graph (Factor Graph Tutorial, ION, GNSS+ 2023)"},{"location":"estimation_theory/factor_graph/using_factor_graph/dynamical_systems/#solving-with-factor-graph","title":"Solving with Factor Graph","text":"<p>Let \\(\\mathbf{X}\\) denote the set of all possible \\(\\mathbf{x}\\) and \\(\\mathbf{Z}\\) denote the set of all possible measurements \\(\\mathbf{z}\\) such that:</p> \\[ \\begin{align} \\mathbf{X} &amp;\\triangleq \\left\\{\\mathbf{x}_0, \\ldots, \\mathbf{x}_N  \\right\\} \\\\ \\mathbf{Z} &amp;\\triangleq \\left\\{\\mathbf{z}_0, \\ldots, \\mathbf{z}_N \\right\\}. \\end{align} \\] <p>Then the conditional probability without adding the dynamics is:</p> \\[ \\begin{align} p(\\mathbf{X} | \\mathbf{Z}) &amp;= \\prod^N_{i = 0} \\exp \\left\\{-\\frac{1}{2} \\left( (h_i(\\mathbf{x}) - \\mathbf{z}_i)^T \\mathbf{R}^{-1}_i (h_i(\\mathbf{x}) - \\mathbf{z}_i) \\right) \\right\\}. \\end{align} \\] <p>An estimator can be found with:</p> \\[ \\begin{align} \\hat{\\mathbf{x}} &amp;= \\arg \\max_{\\mathbf{x}} \\prod^n_{i = 0} \\exp \\left\\{-\\frac{1}{2} \\left( (h_i(\\mathbf{x}) - \\mathbf{z}_i)^T \\mathbf{R}^{-1}_i (h_i(\\mathbf{x}) - \\mathbf{z}_i) \\right) \\right\\} \\\\ &amp;= \\arg \\max_{\\mathbf{x}} \\sum^n_{i = 0} \\ln \\exp \\left\\{-\\frac{1}{2} \\left( (h_i(\\mathbf{x}) - \\mathbf{z}_i)^T \\mathbf{R}^{-1}_i (h_i(\\mathbf{x}) - \\mathbf{z}_i) \\right) \\right\\} \\\\ &amp;= \\arg \\min_{\\mathbf{x}} \\sum^n_{i = 0} ||h_i(\\mathbf{x}) - \\mathbf{z}_i||^2_{\\mathbf{R}_i}. \\end{align} \\] <p>Combining the conditional probability with a probabilistic motion model, we get:</p> \\[ \\begin{align} p(\\mathbf{X} | \\mathbf{Z}) &amp;= \\prod^N_{i = 0} \\exp \\left\\{-\\frac{1}{2} \\left( (h_i(\\mathbf{x}_i) - \\mathbf{z}_i)^T \\mathbf{R}^{-1}_i (h_i(\\mathbf{x}_i) - \\mathbf{z}_i) \\right) \\right\\} \\\\ \\ &amp;\\times \\prod^N_{k = 1} \\exp \\left\\{ -\\frac{1}{2} \\left(f(\\mathbf{x}_{k - 1}, \\mathbf{u}_{k - 1}) - \\mathbf{x}_k \\right)^T \\mathbf{Q}^{-1}_k \\left(f(\\mathbf{x}_{k - 1}, \\mathbf{u}_{k - 1}) - \\mathbf{x}_k \\right) \\right\\}. \\end{align} \\] <p>Then we get:</p> \\[ \\hat{\\mathbf{X}} = \\arg \\min_{\\mathbf{X}}  \\sum^N_{i = 0} ||h_i(\\mathbf{x}_i) - \\mathbf{z}_i||^2_{\\mathbf{R}_i} +  \\sum^N_{k = 1} ||f(\\mathbf{x}_{k - 1}, \\mathbf{u}_{k - 1}) - \\mathbf{x}_k||^2_{\\mathbf{Q}_k}. \\]"},{"location":"estimation_theory/factor_graph/using_factor_graph/simple_averaging/","title":"Simple Averaging","text":""},{"location":"estimation_theory/factor_graph/using_factor_graph/simple_averaging/#problem-formulation","title":"Problem Formulation","text":"<p>Consider a simple averaging problem as shown in Figure 1. Let \\(x \\in \\mathbb{R}\\) be a constant hidden variable to be estimated and \\(z_i\\) be multiple measurements. Assume all measurements are perturbed by noise \\(\\mathcal{N}(0, \\sigma = 1)\\).</p> <p> </p> Figure 1 Simple Averaging (Factor Graph Tutorial, ION, GNSS+ 2023)"},{"location":"estimation_theory/factor_graph/using_factor_graph/simple_averaging/#solving-with-factor-graph","title":"Solving with Factor Graph","text":"<p>Denote the measurement vector as \\(\\mathbf{z} \\in \\mathbb{R}^n\\). Then the measurement equation is:</p> \\[ \\mathbf{z} = \\mathbf{L} x + \\boldsymbol{\\epsilon}. \\] <p>The adjacency matrix \\(\\mathbf{L} \\in \\mathbb{R}^n\\) will have a single column and \\(n\\) rows since no dynamics is involved and \\(x\\) is assumed to be a constant:</p> \\[ \\mathbf{L} = \\left[ \\begin{array}{cccc} 1 &amp; 1 &amp; \\cdots &amp; 1 \\end{array} \\right]^T. \\] <p>The pseudo-inverse of \\(\\mathbf{L}\\) is:</p> \\[ \\begin{align} \\mathbf{L}^{\\dagger} = \\left(\\mathbf{L}^T \\mathbf{L} \\right)^{-1} \\mathbf{L}^T = \\frac{1}{n}  \\left[ \\begin{array}{cccc} 1 &amp; 1 &amp; \\cdots &amp; 1 \\end{array} \\right]. \\end{align} \\] <p>Then we have an estimator:</p> \\[ \\hat{x} = \\mathbf{L}^{\\dagger} \\mathbf{z}. \\]"},{"location":"estimation_theory/factor_graph/using_factor_graph/weighted_averaging/","title":"Weighted Averaging","text":""},{"location":"estimation_theory/factor_graph/using_factor_graph/weighted_averaging/#problem-statement","title":"Problem Statement","text":"<p>Consider a weighted averaging problem as shown in Figure 1. Let \\(x \\in \\mathbb{R}\\) be a constant hidden variable to be estimated and \\(z_i\\) be multiple measurements. Assume all measurements are i.i.d and perturbed by noise \\(\\mathcal{N}(0, \\sigma_i)\\).</p> <p> </p> Figure 1 Weighted Averaging (Factor Graph Tutorial, ION, GNSS+ 2023)"},{"location":"estimation_theory/factor_graph/using_factor_graph/weighted_averaging/#solving-with-factor-graph","title":"Solving with Factor Graph","text":""},{"location":"estimation_theory/factor_graph/using_factor_graph/weighted_averaging/#weighting-matrix-properties","title":"Weighting Matrix Properties","text":"<p>The measurement covariance matrix \\(\\mathbf{R}\\) or equivalently the weighting matrix \\(\\mathbf{W} = \\mathbf{R}^{-1}\\) is symmetric. Hence, we can decompose it using Cholesky decomposition \\(\\mathbf{W} = \\mathbf{S}_{\\mathbf{W}} \\mathbf{S}^T_{\\mathbf{W}}\\), where \\(\\mathbf{S}_{\\mathbf{W}}\\) is a real lower triangular matrix with positive diagonal entries.</p> <p>Furthermore, since \\(\\mathbf{W}\\) is a block diagonal matrix, the factors are conditionally independenty.</p> \\[ \\mathbf{W} = \\left[ \\begin{array}{ccc} \\mathbf{W}_1 &amp; 0 &amp; \\cdots &amp; 0 \\\\ 0 &amp; \\mathbf{W}_2 &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; \\mathbf{W}_n \\end{array} \\right], \\quad \\mathbf{S}_{\\mathbf{W}} = \\left[ \\begin{array}{ccc} \\mathbf{S}_{\\mathbf{W},1} &amp; 0 &amp; \\cdots &amp; 0 \\\\ 0 &amp; \\mathbf{S}_{\\mathbf{W},2} &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; \\mathbf{S}_{\\mathbf{W}, n} \\end{array} \\right]. \\]"},{"location":"estimation_theory/factor_graph/using_factor_graph/weighted_averaging/#mapping-weighted-least-squares-to-least-squares","title":"Mapping Weighted Least Squares to Least Squares","text":"<p>By pre-multiplying \\(\\mathbf{L}\\) and \\(\\mathbf{z}\\) by \\(\\mathbf{S}_\\mathbf{W}\\), we can use the same computational techniques as the regular least squares. Denote:</p> \\[ \\begin{align} \\mathbf{L}^\\prime &amp;= \\mathbf{S}_\\mathbf{W} \\mathbf{L} \\\\ \\mathbf{z}^\\prime &amp;= \\mathbf{S}_\\mathbf{W} \\mathbf{z}. \\end{align} \\] <p>Then:</p> \\[ \\begin{align} \\left( \\mathbf{L}^T \\mathbf{W} \\mathbf{L} \\right)^{-1} \\mathbf{L}^T \\mathbf{W} \\mathbf{z} &amp;= \\left(\\mathbf{L}^T \\mathbf{S}^T_\\mathbf{W} \\mathbf{S}_\\mathbf{W} \\mathbf{L} \\right)^{-1} \\mathbf{L}^T \\mathbf{S}^T_\\mathbf{W} \\mathbf{S}_\\mathbf{W} \\mathbf{z} \\\\ &amp;= \\left(\\mathbf{L}^{\\prime T} \\mathbf{L}^\\prime \\right)^{-1} \\mathbf{L}^{\\prime T} \\mathbf{z}^\\prime. \\end{align} \\] <p>We have:</p> \\[ \\begin{align} \\mathbf{L}^{\\prime} &amp;= \\left[ \\begin{array}{cccc} \\frac{1}{\\sigma_1} &amp; \\frac{1}{\\sigma_2} &amp; \\cdots &amp; \\frac{1}{\\sigma_n} \\end{array} \\right]^T \\\\ \\mathbf{L}^{\\prime \\dagger} &amp;= \\frac{1}{\\sum^n_{i = 1} \\frac{1}{\\sigma^2_i}} \\left[ \\begin{array}{cccc} \\frac{1}{\\sigma_1} &amp; \\frac{1}{\\sigma_2} &amp; \\cdots &amp; \\frac{1}{\\sigma_n} \\end{array} \\right] \\\\ \\mathbf{z}^\\prime &amp;= \\left[ \\begin{array}{cccc} \\frac{z_1}{\\sigma_1} &amp; \\frac{z_2}{\\sigma_2} &amp; \\cdots &amp; \\frac{z_n}{\\sigma_n} \\end{array} \\right]^T. \\end{align} \\] <p>Finally, we compute the state estimate as:</p> \\[ \\hat{x} = \\frac{\\sum^n_{i = 1} w_i z_i}{\\sum^n_{i = 1} w_i}. \\]"},{"location":"estimation_theory/factor_graph/using_factor_graph/weighted_averaging/#notes","title":"Notes","text":"<p>The matrix \\(\\mathbf{M} = \\left(\\mathbf{L}^T \\mathbf{W} \\mathbf{L} \\right)^{-1}\\) is the covariance of the hidden variables. We can relate \\(\\mathbf{M}\\) with the covariance \\(\\mathbf{P}\\) of a KF:</p> <ol> <li>The ordering of \\(\\mathbf{M}\\) corresponds with the columns of \\(\\mathbf{L}\\) (hidden variables).</li> <li>Different blocks on the diagonal correspond with \\(\\mathbf{P}\\) matrix over time of KF.</li> <li>In general, covariance blocks will be \"smaller\" than KF \\(\\mathbf{P}\\) because factor graph is not causal. However, the \"last \\(\\mathbf{P}\\)\" will be the same as the KF for a linear system.</li> <li>Off-diagonal elements express correlated errors over time. While the input to KFs is \"white\", the output is not.</li> </ol>"},{"location":"estimation_theory/factor_graph/using_factor_graph/weighted_non_linear_least_squares/","title":"Weighted Non-Linear Least Squares","text":""},{"location":"estimation_theory/factor_graph/using_factor_graph/weighted_non_linear_least_squares/#problem-statement","title":"Problem Statement","text":"<p>Consider a weighted averaging problem similar as prevous example. Let \\(x \\in \\mathbb{R}\\) be a constant hidden variable to be estimated and \\(z_i\\) be multiple measurements. Assume all measurements are i.i.d and perturbed by noise \\(\\mathcal{N}(0, \\sigma_i)\\). Consider each measurement has its own non-linear measurement function:</p> \\[ z_i = h_i(x) + \\epsilon. \\]"},{"location":"estimation_theory/factor_graph/using_factor_graph/weighted_non_linear_least_squares/#solving-with-factor-graph","title":"Solving with Factor Graph","text":""},{"location":"estimation_theory/factor_graph/using_factor_graph/weighted_non_linear_least_squares/#non-linear-to-linear-least-squares","title":"Non-Linear to Linear Least Squares","text":"<p>An estimator can be found as:</p> \\[ \\hat{x} = \\arg \\min_{x} \\sum^{n}_{i = 1} ||h_i(x) - z_i||^2_{\\sigma_i}. \\] <p>We can replace \\(h_i(x)\\) with an affine approximation by linearizing the non-linear function:</p> \\[ h_i(x) \\approx H_i \\Delta x + h_i(x_0), \\] <p>where \\(H_i = \\left. \\frac{\\partial h_i(x)}{\\partial x} \\right|_{x = x_0}\\) and \\(\\Delta x = x - x_0\\).</p> <p>Then:</p> \\[ \\begin{align} \\hat{x} = x_0 + \\left( \\Delta x = \\arg \\min_{\\Delta \\mathbf{x}} \\sum^n_{i = 1} || H_i \\Delta x + h_i(\\mathbf{x}_0) - z_i ||^2_{\\sigma_i} \\right), \\end{align} \\] \\[ \\begin{align} \\mathbf{L} &amp;= \\left[ \\begin{array}{cccc} \\frac{H_1}{\\sigma_1} &amp; \\frac{H_2}{\\sigma_2} &amp; \\cdots &amp; \\frac{H_n}{\\sigma_n} \\end{array} \\right]^T, \\\\ \\mathbf{y} &amp;= \\left[ \\begin{array}{cccc} \\frac{z_1 - h_1(x_0)}{\\sigma_1} &amp; \\frac{z_2- h_2(x_0)}{\\sigma_2} &amp; \\cdots &amp; \\frac{z_n - h_n(x_0)}{\\sigma_n} \\end{array} \\right], \\\\ \\Delta x &amp;= \\mathbf{L}^{\\dagger} \\mathbf{y}. \\end{align} \\] <p>Note that \\(H_i\\) is the negative derivative of the residual vector \\(\\mathbf{y}\\) and is not constant. When \\(\\hat{x}\\) changes, \\(H_i\\)s change as well.</p> <p>Algorithm: Non-Linear Least Squares</p> <p>\\(\\quad\\)Input: \\(\\mathbf{x}_0\\), \\(\\mathbf{R}\\) \\(\\quad\\)Result: \\(\\hat{\\mathbf{x}}\\) \\(\\quad\\)Initialize: \\(\\hat{\\mathbf{x}} = \\mathbf{x}_0\\) \\(\\quad\\)Repeat \\(\\quad\\quad\\) \\(\\mathbf{H} = \\left. \\frac{\\partial h(\\mathbf{x})}{\\partial \\mathbf{x}} \\right|_{\\mathbf{x} = \\hat{\\mathbf{x}}}\\) \\(\\quad\\quad\\) \\(\\Delta \\mathbf{x} = \\arg \\min_{\\Delta \\mathbf{x}} \\sum^n_{i = 1} || \\mathbf{H} \\Delta \\mathbf{x} + h(\\mathbf{x_0}) - \\mathbf{z}_i ||^2_{\\mathbf{R}}\\) - Run (linear) least squares   \\(\\quad\\quad\\) \\(\\hat{\\mathbf{x}} = \\hat{\\mathbf{x}} + \\Delta \\mathbf{x}\\) \\(\\quad\\)until convergence.    </p>"},{"location":"estimation_theory/factor_graph/using_factor_graph/weighted_non_linear_least_squares/#numerical-example","title":"Numerical Example","text":"<p>Let \\(x\\) be a scalar state to be estimated. Assume that the true value of \\(x\\) is \\(x = 200\\).</p> <p>Consider two noisy measurements of \\(x\\) (hidden variable):</p> \\[ \\begin{align} z_1 &amp;= -7800.52, \\quad (\\text{noiseless} = -7795) \\\\ z_2 &amp;= 605.79, \\quad (\\text{noiseless} = 605). \\end{align} \\] <p>Let the non-linear measurement functions be:</p> \\[ \\begin{alignat}{2} h_1(x) &amp;= 0.05 (x + 10)^2 - 10000, \\quad &amp;&amp;\\sigma_1 = 100 \\\\ h_2(x) &amp;= 3x + 5, \\quad &amp;&amp;\\sigma_2 = 1. \\end{alignat} \\] <p>The Jacobian is:</p> \\[ \\mathbf{J} = \\left[ \\begin{array}{c} \\frac{\\partial h_1}{\\partial x} \\\\ \\frac{\\partial h_2}{\\partial x} \\end{array} \\right] = \\left[ \\begin{array}{c} 0.1 (x + 10) \\\\ 3 \\end{array} \\right]. \\]"},{"location":"estimation_theory/factor_graph/using_factor_graph/weighted_non_linear_least_squares/#iteration-1","title":"Iteration 1","text":"<p>Start with estimate \\(\\hat{x} = 0\\). We have:</p> \\[ \\begin{align} \\mathbf{L} &amp;= \\left[ \\begin{array}{c} \\sigma^{-1/2}_1 \\left. \\frac{\\partial h_1}{\\partial x} \\right|_{x = \\hat{x}} \\\\ \\sigma^{-1/2}_2 \\left. \\frac{\\partial h_2}{\\partial x} \\right|_{x = \\hat{x}} \\\\ \\end{array} \\right] = \\left[ \\begin{array}{c} 0.1 \\\\ 3.0 \\end{array} \\right] \\\\ \\mathbf{y} &amp;= \\left[ \\begin{array}{c} \\sigma^{-1/2}_1 (z_1 - h_1(\\hat{x})) \\\\ \\sigma^{-1/2}_2 (z_2 - h_2(\\hat{x})) \\\\ \\end{array} \\right] \\approx \\left[ \\begin{array}{c} 219.448 \\\\ 600.79 \\end{array} \\right] \\\\ \\Delta x &amp;= \\mathbf{L}^{\\dagger} \\mathbf{y} \\approx 202.48. \\end{align} \\]"},{"location":"estimation_theory/factor_graph/using_factor_graph/weighted_non_linear_least_squares/#iteration-2","title":"Iteration 2","text":"<p>Start with estimate \\(\\hat{x} \\approx 202.48\\). We have:</p> \\[ \\begin{align} \\mathbf{L} &amp;= \\left[ \\begin{array}{c} \\sigma^{-1/2}_1 \\left. \\frac{\\partial h_1}{\\partial x} \\right|_{x = \\hat{x}} \\\\ \\sigma^{-1/2}_2 \\left. \\frac{\\partial h_2}{\\partial x} \\right|_{x = \\hat{x}} \\\\ \\end{array} \\right] = \\left[ \\begin{array}{c} 2.12 \\\\ 3.0 \\end{array} \\right] \\\\ \\mathbf{y} &amp;= \\left[ \\begin{array}{c} \\sigma^{-1/2}_1 (z_1 - h_1(\\hat{x})) \\\\ \\sigma^{-1/2}_2 (z_2 - h_2(\\hat{x})) \\\\ \\end{array} \\right] \\approx \\left[ \\begin{array}{c} -5.78 \\\\ -6.64 \\end{array} \\right] \\\\ \\Delta x &amp;= \\mathbf{L}^{\\dagger} \\mathbf{y} \\approx -2.38. \\end{align} \\]"},{"location":"estimation_theory/factor_graph/using_factor_graph/weighted_non_linear_least_squares/#iteration-3","title":"Iteration 3","text":"<p>Start with estimate \\(\\hat{x} = 202.48 - 2.38 = 200.1\\). We have:</p> \\[ \\begin{align} \\mathbf{L} &amp;= \\left[ \\begin{array}{c} \\sigma^{-1/2}_1 \\left. \\frac{\\partial h_1}{\\partial x} \\right|_{x = \\hat{x}} \\\\ \\sigma^{-1/2}_2 \\left. \\frac{\\partial h_2}{\\partial x} \\right|_{x = \\hat{x}} \\\\ \\end{array} \\right] = \\left[ \\begin{array}{c} 2.10 \\\\ 3.0 \\end{array} \\right] \\\\ \\mathbf{y} &amp;= \\left[ \\begin{array}{c} \\sigma^{-1/2}_1 (z_1 - h_1(\\hat{x})) \\\\ \\sigma^{-1/2}_2 (z_2 - h_2(\\hat{x})) \\\\ \\end{array} \\right] \\approx \\left[ \\begin{array}{c} -0.74 \\\\ 0.51 \\end{array} \\right] \\\\ \\Delta x &amp;= \\mathbf{L}^{\\dagger} \\mathbf{y} \\approx -0.003. \\end{align} \\]"},{"location":"estimation_theory/factor_graph/using_factor_graph/weighted_non_linear_least_squares/#notes","title":"Notes","text":"<ol> <li>Non-linear optimization presented so far is Gauss-Newton optimization routine. In general, any techniques in literature for improving Gauss-Newton can be applied here. Other optimizations are also often applied for very non-linear systems (e.g., Levenburg-Marquardt, Dogleg, etc.).</li> <li>Convergence is not guaranteed. Must be \"close enough\" to converge.</li> </ol>"},{"location":"estimation_theory/kalman_filter/discrete_time_kalman_filter/","title":"Discrete-Time Kalman Filter","text":""},{"location":"estimation_theory/kalman_filter/discrete_time_kalman_filter/#overview","title":"Overview","text":"<p>Consider a linear, time-varying system with the following dynamics:</p> \\[ \\begin{align} \\mathbf{x}_k &amp;= \\mathbf{F}_{k - 1} \\mathbf{x}_{k - 1} + \\mathbf{G}_{k - 1} + \\mathbf{w}_{k - 1} \\\\ \\mathbf{y}_k &amp;= \\mathbf{H}_{k} \\mathbf{x}_k + \\mathbf{v}_k, \\end{align} \\] <p>where \\(\\mathbf{w}_{k - 1}\\) and \\(\\mathbf{v}_{k}\\) are zero-mean, </p> <p>Discrete-Time Kalman Filter</p> <p>Consider a linear time-varying system with the following dynamics:</p> <p>$$ \\begin{align}</p> <p>\\end{align} $$</p>"},{"location":"estimation_theory/kalman_filter/discrete_time_kalman_filter/#discrete-time-systems","title":"Discrete-Time Systems","text":"<p>Consider the following linear discrete-time system:</p> \\[ \\mathbf{x}_k = \\mathbf{F}_{k - 1} \\mathbf{x}_{k - 1} + \\mathbf{G}_{k - 1} \\mathbf{u}_{k - 1} + \\mathbf{w}_{k - 1}, \\] <p>where \\(\\mathbf{u}_{k - 1}\\) is a known input and \\(\\mathbf{w}_{k - 1}\\) is a Gaussian zero-mean white noise with covariance \\(\\mathbf{Q}_{k - 1}\\).</p> <p>The expetation of \\(\\mathbf{x}_k\\) is:</p> \\[ \\bar{\\mathbf{x}}_k = \\mathbb{E}\\left[ \\mathbf{x}_k \\right] = \\mathbf{F}_{k - 1} \\bar{\\mathbf{x}}_{k - 1} + \\mathbf{G}_{k - 1} \\mathbf{u}_{k - 1}. \\] <p>The covariance of \\(\\mathbf{x}_k\\) is:</p> \\[ \\begin{align} \\mathbf{P}_{k} &amp;= \\mathbb{E} \\left[ \\left( \\mathbf{x}_k - \\bar{\\mathbf{x}}_k \\right) \\left( \\cdots \\right)^T \\right] \\\\ &amp;= \\mathbb{E} \\left[ \\left(\\mathbf{F}_{k - 1} \\mathbf{x}_{k - 1} + \\mathbf{G}_{k - 1} \\mathbf{u}_{k - 1} + \\mathbf{w}_{k - 1} - \\bar{\\mathbf{x}}_k \\right) \\left( \\cdots \\right)^T \\right] \\\\ &amp;= \\mathbb{E} \\left[ \\left( \\mathbf{F}_{k - 1} \\left( \\mathbf{x}_{k - 1} - \\bar{\\mathbf{x}}_{k - 1} \\right) + \\mathbf{w}_{k - 1} \\right) \\left( \\cdots \\right)^T \\right] \\\\ &amp;= \\mathbb{E} \\left[ \\mathbf{F}_{k - 1} \\left(\\mathbf{x}_{k - 1} - \\bar{\\mathbf{x}}_{k - 1} \\right) \\left(\\mathbf{x}_{k - 1} - \\bar{\\mathbf{x}}_{k - 1} \\right)^T \\mathbf{F}^T_{k - 1} \\right]\\\\ &amp;\\quad + \\mathbb{E} \\left[ \\mathbf{w}_{k - 1} \\mathbf{w}^T_{k - 1} \\right] \\\\ &amp;\\quad + \\underbrace{\\mathbb{E} \\left[ \\mathbf{F}_{k - 1} \\left( \\mathbf{x}_{k - 1} + \\bar{\\mathbf{x}}_{k - 1} \\right) \\mathbf{w}^T_{k - 1} \\right]}_{\\mathbf{0}} \\\\ &amp;\\quad + \\underbrace{\\mathbb{E} \\left[ \\mathbf{w}_{k - 1} \\left( \\mathbf{x}_{k - 1} - \\bar{\\mathbf{x}}_{k - 1} \\right)^T \\mathbf{F}^T_{k - 1} \\right]}_{\\mathbf{0}}. \\end{align} \\] <p>Hence, the covariance of \\(\\mathbf{x}_k\\) is:</p> \\[ \\begin{align} \\mathbf{P}_k = \\mathbf{F}_{k - 1} \\mathbf{P}_{k - 1} \\mathbf{F}^T_{k - 1} + \\mathbf{Q}_{k - 1}, \\end{align} \\] <p>which is known as the discrete-time Lyapunov equation. The mean and the covariance completely characterizes \\(\\mathbf{x}\\) in a statistical sense since it is a Gaussian random variable:</p> \\[ \\mathbf{x}_{k} \\sim \\mathcal{N}(\\bar{\\mathbf{x}}_k, \\mathbf{P}_k). \\]"},{"location":"estimation_theory/least_squares_estimator/batch_least_squares_estimator/","title":"Batch Least Squares Estimator","text":""},{"location":"estimation_theory/least_squares_estimator/batch_least_squares_estimator/#problem-statement","title":"Problem statement","text":"<p>Given a matrix \\(\\mathbf{H} \\in \\mathbb{R}^{k \\times n}\\) and a vector \\(\\mathbf{y} \\in \\mathbb{R}^k\\), where \\(k &gt; n\\), we are interested in finding a constant solution \\(\\mathbf{x} \\in \\mathbb{R}^n\\) that satisfies \\(\\mathbf{H} \\mathbf{x} = \\mathbf{y}\\). In general, \\(\\mathbf{y} \\in \\mathbb{R}^k\\) with linear observation matrix \\(\\mathbf{H} \\in \\mathbb{R}^{k \\times n}\\) has a measurement noise \\(\\boldsymbol{v} \\in \\mathbb{R}^k\\) such that:</p> \\[ \\mathbf{y} = \\mathbf{H} \\mathbf{x} + \\boldsymbol{v}, \\label{least_squares_main} \\] <p>The measurement residual is defined as:</p> \\[ \\boldsymbol{\\epsilon}_{\\mathbf{y}} = \\mathbf{y} - \\mathbf{H} \\hat{\\mathbf{x}}, \\] <p>where \\(\\hat{\\mathbf{x}}\\) is the \"best\" estimate of \\(\\mathbf{x}\\).</p>"},{"location":"estimation_theory/least_squares_estimator/batch_least_squares_estimator/#solution","title":"Solution","text":"<p>The most probable value of the vector \\(\\mathbf{x}\\) is the vector \\(\\hat{\\mathbf{x}}\\) that minimizes the sum of squares between the observed values \\(\\mathbf{y}\\) and the vector \\(\\mathbf{H} \\hat{\\mathbf{x}}\\). This makes it an optimization problem with the objective function as:</p> \\[ \\begin{align} \\mathbf{J} &amp;= \\epsilon^2_{y1} + \\ldots + \\epsilon^2_{yk} = \\boldsymbol{\\epsilon}^T_{\\mathbf{y}} \\boldsymbol{\\epsilon}_{\\mathbf{y}} \\\\ &amp;= (\\mathbf{y} - \\mathbf{H} \\hat{\\mathbf{x}})^T (\\mathbf{y} - \\mathbf{H} \\hat{\\mathbf{x}}) \\\\ &amp;= (\\mathbf{y}^T - \\hat{\\mathbf{x}}^T \\mathbf{H}^T) (\\mathbf{y} - \\mathbf{H} \\hat{\\mathbf{x}}) \\\\  &amp;= \\mathbf{y}^T \\mathbf{y} - \\hat{\\mathbf{x}}^T \\mathbf{H}^T \\mathbf{y} - \\mathbf{y}^T \\mathbf{H} \\hat{\\mathbf{x}} + \\hat{\\mathbf{x}}^T \\mathbf{H}^T \\mathbf{H} \\hat{\\mathbf{x}} \\end{align} \\] <p>Hence, the least squares problem can be formulated as:</p> \\[ \\begin{align} \\arg \\min_{\\hat{\\mathbf{x}}} \\quad || \\mathbf{H} \\hat{\\mathbf{x}} - \\mathbf{y} ||_2 = \\arg \\min_{\\hat{\\mathbf{x}}} \\quad \\sqrt{\\sum^m_{i = 1} \\left( \\mathbf{h}^T_i \\hat{\\mathbf{x}} - y_i \\right)^2}, \\end{align} \\] <p>or equivalently:</p> \\[ \\begin{align} &amp;\\arg \\min_{\\hat{\\mathbf{x}}} \\quad || \\mathbf{H} \\hat{\\mathbf{x}} - \\mathbf{y} ||^2_2 = \\arg \\min_{\\hat{\\mathbf{x}}} \\quad \\sum^m_{i = 1} \\left( \\mathbf{h}^T_i \\hat{\\mathbf{x}} - y_i \\right)^2 \\Rightarrow \\\\ &amp;\\arg \\min_{\\hat{\\mathbf{x}}} \\quad \\left( \\mathbf{H} \\hat{\\mathbf{x}} - \\mathbf{y} \\right)^T \\left( \\mathbf{H} \\hat{\\mathbf{x}} - \\mathbf{y} \\right) = \\arg \\min_{\\hat{\\mathbf{x}}} \\quad \\hat{\\mathbf{x}}^T \\mathbf{H}^T \\mathbf{H} \\hat{\\mathbf{x}} - 2 \\left( \\mathbf{H}^T \\mathbf{y} \\right)^T \\hat{\\mathbf{x}} + \\mathbf{y}^T \\mathbf{y}. \\end{align} \\] <p>The optimization variable is \\(\\hat{\\mathbf{x}}\\) and \\(\\mathbf{J}\\) is a quadratic convex function. Hence, the optimality condition is:</p> \\[ \\begin{align} \\nabla_{\\hat{\\mathbf{x}}} \\mathbf{J} &amp;=  \\nabla \\left( \\mathbf{H} \\hat{\\mathbf{x}} - \\mathbf{y} \\right)^T \\left( \\mathbf{H} \\hat{\\mathbf{x}} - \\mathbf{b} \\right) = 0 \\\\ &amp;\\Rightarrow -\\mathbf{y}^T \\mathbf{H} - \\mathbf{y}^T \\mathbf{H} + 2 \\hat{\\mathbf{x}}^T \\mathbf{H}^T \\mathbf{H} \\\\ &amp;\\Rightarrow \\mathbf{H}^T \\mathbf{H} \\hat{\\mathbf{x}} = \\mathbf{H}^T \\mathbf{y}. \\label{normal_equation} \\end{align} \\] <p>Equation (\\(\\ref{normal_equation}\\)) is called the normal equation. Solving the least squares problem is equivalent to solving the normal equation. Since \\(\\mathbf{H}\\) has a full column rank, \\(\\mathbf{H}^T \\mathbf{H}\\) is invertible. Hence, the optimal solution to the normal equation (equivalently to the least squares problem) is:</p> \\[ \\hat{\\mathbf{x}} = \\left( \\mathbf{H}^T \\mathbf{H} \\right)^{-1} \\mathbf{H}^T \\mathbf{y}. \\label{pseudoinverse} \\] <p>The right hand side of equation (\\(\\ref{pseudoinverse}\\)) is called the Moore-Penrose pseudoinverse and is defined as:</p> \\[ \\mathbf{H}^{+} = \\left( \\mathbf{H}^T \\mathbf{H} \\right)^{-1} \\mathbf{H}^T. \\] <p>The solution to the least squares is then \\(\\hat{\\mathbf{x}} = \\mathbf{H}^+ \\mathbf{y}\\). If \\(\\mathbf{H}\\) is an invertible square matrix, then \\(\\mathbf{H}^+ = \\mathbf{H}^{-1} \\left( \\mathbf{H}^T \\right)^{-1} \\mathbf{H}^T = \\mathbf{H}^{-1}\\).</p> <p>Rather than computing the matrix inversion, it is more efficient to use SVD. Since \\(\\mathbf{H}^T \\mathbf{H} = \\mathbf{V} \\boldsymbol{\\Sigma}^2 \\mathbf{V}^T\\), we have \\(\\left ( \\mathbf{H}^T \\mathbf{H} \\right)^{-1} = \\mathbf{V} \\boldsymbol{\\Sigma}^{-2} \\mathbf{V}^T\\). Then:</p> \\[ \\left( \\mathbf{H}^T \\mathbf{H} \\right)^{-1} \\mathbf{H}^T =  \\mathbf{V} \\boldsymbol{\\Sigma}^{-2} \\mathbf{V}^T \\mathbf{V} \\boldsymbol{\\Sigma} \\mathbf{U}^T = \\mathbf{V} \\boldsymbol{\\Sigma}^{-1} \\mathbf{U}^T. \\] <p>Hence, the optimal solution is:</p> \\[ \\hat{\\mathbf{x}} = \\mathbf{V} \\boldsymbol{\\Sigma}^{-1} \\mathbf{U}^T \\mathbf{y}. \\]"},{"location":"estimation_theory/least_squares_estimator/batch_least_squares_estimator/#relationship-to-the-maximum-likelihood-estimator","title":"Relationship to the Maximum Likelihood Estimator","text":"<p>If the measurement errors \\(\\boldsymbol{v} \\in \\mathbb{R}^k\\) are independent Gaussian random variables, then minimizing the quadratic error is equivalent to maximizing the likelihood function:</p> \\[ \\begin{align} L(\\mathbf{y} | \\mathbf{x}) = \\prod^k_{i = 1} f_\\mathbf{x} (\\mathbf{y}_i | \\mathbf{x}). \\end{align} \\]"},{"location":"estimation_theory/least_squares_estimator/least_squares/","title":"Least Squares","text":""},{"location":"estimation_theory/least_squares_estimator/least_squares/#problem-statement","title":"Problem Statement","text":"<p>Consider a set of \\(k\\) data points:</p> \\[ (x, z_i), \\quad i = 1, \\ldots, k, \\] <p>where \\(x\\) is an independent variable to be estimated and \\(z_i\\) is a dependent variable whose value can be obtained by an observation or a measurement. We have a measurement model:</p> \\[ z_i = h_i(x) + w_i, \\quad i = 1, \\ldots, k, \\] <p>where \\(w_i\\) is the measurement noise. The goal of the least squares method is to find an estimator, \\(\\hat{x}\\), that \"best\" fits the measurement data. The fit of a model to a data point is measured by its residual or error, defined as the difference between the observed value of the dependent variable and the value predicted by the model:</p> \\[ e_i = z_i - h_i(x). \\] <p>The least squares method finds the optimal parameter values by minimizing objective function defined as the sum of the squared residuals:</p> \\[ J = \\sum^k_{i = 1} e^2_i. \\]"},{"location":"estimation_theory/least_squares_estimator/least_squares/#solving-least-squares","title":"Solving Least Squares","text":"<p>The solution to the least squares problem is a a solution to an optimization problem:</p> \\[ \\hat{\\mathbf{x}} = \\arg \\min_{\\mathbf{x}} J = \\arg \\min_{\\mathbf{x}} \\sum^k_{j = 1} e^2_i. \\] <p>This is the nonlinear least squares problem. If the functions \\(h_i\\) are linear in \\(x\\), then the problem is ordinary or linear least squares problem.</p>"},{"location":"estimation_theory/least_squares_estimator/least_squares/#relationship-to-mle","title":"Relationship to MLE","text":"<p>Note here that there is no assumption about the measurement noises \\(w_i\\). If the measurement noise is independent and identically distributed zero-mean Gaussian random variables such that:</p> \\[ w_i \\sim \\mathcal{N}(0, \\sigma^2), \\] <p>then the least squares estimator coincides with the MLE under these assumptions. In this case:</p> \\[ z_i \\sim \\mathcal{N}(h_i(x), \\sigma^2), \\quad i = 1, \\ldots, k. \\] <p>The likelihood function of \\(x\\) is then:</p> \\[ \\begin{align} L(x) &amp;= p(\\mathbf{z} | x) = p(z_1, \\ldots, z_k | x) \\\\ &amp;= \\prod^k_{i = 1} \\mathcal{N}(z_i; h_i(x), \\sigma^2) = c \\exp \\left\\{ -\\frac{1}{2 \\sigma^2} \\sum^k_{i = 1} (z_i - h_i(x))^2 \\right\\}, \\end{align} \\] <p>where \\(c\\) is some constant.</p>"},{"location":"estimation_theory/least_squares_estimator/least_squares/#parametric-model-and-alternative-formulation","title":"Parametric Model and Alternative Formulation","text":"<p>In the context of regression analysis or data fitting, we can formulate the problem differently. Consider a set of \\(k\\) data points:</p> \\[ (x_i, z_i), \\quad i = 1, \\ldots, k, \\] <p>Assume that the model function has the form \\(f(x_i, \\boldsymbol{\\beta})\\), where \\(m\\) adjustable parameters are held in the vector \\(\\boldsymbol{\\beta}\\). The goal of the least squares method here is to find the parameter values for the model that \"best\" fits the data. The residual is:</p> \\[ e_i = y_i - f(x_i, \\boldsymbol{\\beta}). \\] <p>The least squares method minimizes objective function defined as the sum of the squared residuals:</p> \\[ J = \\sum^k_{i = 1} e^2_i. \\] <p>The minimum of the objective function is found by setting the gradient to zero. Since the model contains \\(m\\) parameters, there are \\(m\\) gradient equations:</p> \\[ \\frac{\\partial J}{\\partial \\beta_j} = 2 \\sum_i e_i \\frac{\\partial e_i}{\\partial \\beta_j} = -2 \\sum_i e_i \\frac{\\partial f(x_i, \\boldsymbol{\\beta})}{\\partial \\beta_j} = 0, \\quad j = 1, \\ldots, m. \\] <p>The minimum of the objective function is found by setting the gradient to zero. Since the model contains \\(m\\) parameters, there are \\(m\\) gradient equations:</p> \\[ \\frac{\\partial J}{\\partial \\beta_j} = 2 \\sum_i e_i \\frac{\\partial e_i}{\\partial \\beta_j} = -2 \\sum_i e_i \\frac{\\partial f(x_i, \\boldsymbol{\\beta})}{\\partial \\beta_j} = 0, \\quad j = 1, \\ldots, m. \\] <p>This is particularly useful for polynomial fitting.</p>"},{"location":"estimation_theory/least_squares_estimator/least_squares_with_dynamics/","title":"Least Squares with Dynamics","text":""},{"location":"estimation_theory/least_squares_estimator/least_squares_with_dynamics/#problem-statement","title":"Problem statement","text":"<p>Consider a state-space model:</p> \\[ \\begin{align} \\mathbf{x}_k &amp;= \\mathbf{f}(\\mathbf{x}_{k - 1}, \\mathbf{u}_k) + \\mathbf{w}_k \\\\ \\mathbf{z}_{k, j} &amp;= \\mathbf{h}(\\mathbf{y}_j, \\mathbf{x}_k) + \\mathbf{v}_{k, j}, \\end{align} \\] <p>where at time \\(k \\in \\mathbb{Z}^{+}\\), we have:</p> <ol> <li>State vectors, \\(\\mathbf{x} \\in \\mathbb{R}^n\\) and \\(\\mathbf{y}_j \\in \\mathbb{R}^k\\) (here we included \\(\\mathbf{y}_j\\) as the \\(j\\)'th landmark state since it can be a SLAM/VSLAM estimation problem. Generally, it can be just \\(\\mathbf{x}\\) and the formulation wouldn't change), control input, \\(\\mathbf{u}\\), and the \\(j\\)'th measurement, \\(\\mathbf{z}_j \\in \\mathbb{R}^m\\).</li> <li>Discrete nonlinear motion and measurement models, \\(\\mathbf{f}( \\ \\cdot \\ )\\) and \\(\\mathbf{h}( \\ \\cdot \\ )\\)</li> <li>Zero-mean Gaussian process and measurement noises, \\(\\mathbf{w}_k \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{Q}_k)\\) and \\(\\mathbf{v}_k \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{R}_{k, j})\\).</li> </ol> <p>For the measurement model:</p> \\[ \\mathbf{z}_{k, j} = \\mathbf{h}(\\mathbf{y}_j, \\mathbf{x}_k) + \\mathbf{v}_{k, j}, \\] <p>since we assumed that the measurement noise is zero-mean Gaussian, i.e., \\(\\mathbf{v}_k \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{R}_{k, j})\\), the conditional probability of the observation data is:</p> \\[ \\mathbb{P}(\\mathbf{z}_{j, k} | \\mathbf{x}_k, \\mathbf{y}_j) =  \\mathcal{N}(\\mathbf{h}(\\mathbf{y}_j, \\mathbf{x}_k), \\mathbf{R}_{k, j}), \\] <p>which is a Gaussian distribution. The probability densitiy function for multi-dimensional Gaussian distribution \\(\\mathbf{x} \\sim \\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})\\) is given as:</p> \\[ p(\\mathbf{x}) = \\frac{1}{\\sqrt{(2 \\pi)^N \\text{det}(\\boldsymbol{\\Sigma})}} \\exp \\biggl( -\\frac{1}{2} (\\mathbf{x} - \\boldsymbol{\\mu})^T \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu}) \\biggr). \\] <p>We can take the negative logarithm from both sides since the logarithm function is monotonically increasing and maximizing the original function is equivalent to minimizing the negative logarithm:</p> \\[ -\\ln(\\mathbb{P}(\\mathbf{x})) = \\underbrace{\\frac{1}{2} \\ln \\biggl((2 \\pi)^N \\text{det}(\\boldsymbol{\\Sigma}) \\biggr)}_{\\text{ommitted}} + \\frac{1}{2}(\\mathbf{x} - \\boldsymbol{\\mu})^T \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu})). \\] <p>The first term can be ommitted since it doesn't have dependency on \\(\\mathbf{x}\\). The MLE for the problem is then:</p> \\[ \\begin{align} (\\hat{\\mathbf{x}}_k, \\hat{\\mathbf{y}}_k)_{\\text{MLE}} &amp;= \\arg \\max \\mathcal{N}(\\mathbf{h}(\\mathbf{y}_j, \\mathbf{x}_k), \\mathbf{R}_{k, j}) \\\\ &amp;= \\arg \\min \\biggl((\\mathbf{z}_{k, j} - \\mathbf{h}(\\mathbf{x}_k, \\mathbf{y}_j))^T \\mathbf{R}^{-1}_{k, j} (\\mathbf{z}_{k, j} - \\mathbf{h}(\\mathbf{x}_{k}, \\mathbf{y}_j)) \\biggr), \\end{align} \\] <p>which is the Mahalanobis distance. If we assume that the inputs and the observations are independent of each other, the joint probability distribution can be factorized if we put all the measurements together:</p> \\[ \\mathbb{P}(\\mathbf{z}, \\mathbf{u} | \\mathbf{x}, \\mathbf{y}) = \\prod_{k} \\mathbb{P}(\\mathbf{u}_k | \\mathbf{x}_{k - 1}, \\mathbf{x}_k) \\prod_{k, j} \\mathbb{P}(\\mathbf{z}_{k, j} | \\mathbf{x}_k, \\mathbf{y}_j). \\] <p>The error between the model and the measurement can be defined as:</p> \\[ \\begin{align} \\mathbf{e}_{u, k} &amp;= \\mathbf{x}_k - \\mathbf{f}(\\mathbf{x}_{k - 1}, \\mathbf{u}_k) \\\\ \\mathbf{e}_{z, j, k} &amp;= \\mathbf{z}_{k, j} - \\mathbf{h}(\\mathbf{x}_k, \\mathbf{y}_j). \\end{align} \\] <p>Then, minimizing the Mahalanobis distance between the estimated value and the measurements from sensors is equivalent to finding the MLE. The negative logarithm turns the product into a summation:</p> \\[ \\min J(\\mathbf{x}, \\mathbf{y}) = \\sum_k \\mathbf{e}^T_{u, k} \\mathbf{Q}^{-1}_k \\mathbf{e}_{u, k} + \\sum_k \\sum_j \\mathbf{e}^T_{z, k, j} \\mathbf{R}^{-1}_{k, j} \\mathbf{e}_{z, k, j}. \\]"},{"location":"estimation_theory/least_squares_estimator/least_squares_with_dynamics/#example-batch-state-estimation","title":"Example: Batch State Estimation","text":"<p>Consider a simple discrete-time system:</p> \\[ \\begin{alignat}{2} x_k &amp;= x_{k - 1} + u_k + w_k, \\quad &amp;&amp; w_k \\sim \\mathcal{N}(0, Q_k) \\\\ z_k &amp;= x_k + v_k, \\quad &amp;&amp; v_k \\sim \\mathcal{N}(0, R_k). \\end{alignat} \\] <p>Suppose the initial state \\(x_0\\) is known. Denote the batch state variable as \\(\\mathbf{x}= \\left[\\begin{array}{cccc} x_0 &amp; x_1 &amp; x_2 &amp; x_3 \\end{array} \\right]^T\\), the batch observation as \\(\\mathbf{z}= \\left[\\begin{array}{ccc} z_1 &amp; z_2 &amp; z_3\\end{array} \\right]^T\\), and the input as \\(\\mathbf{u} = \\left[\\begin{array}{ccc} u_1 &amp; u_2 &amp; u_3 \\end{array} \\right]^T\\). The maximum likelihood estimate is then:</p> \\[ \\begin{align} \\hat{\\mathbf{x}}_{\\text{MLE}} &amp;= \\arg \\max \\mathbb{P}(\\mathbf{x} | \\mathbf{u}, \\mathbf{z}) = \\arg \\max \\mathbb{P}(\\mathbf{u}, \\mathbf{z} | \\mathbf{x}) \\\\ &amp;= \\prod^3_{k = 1} \\mathbb{P}(u_k | x_{k - 1}, x_k) \\prod^3_{k = 1} \\mathbb{P}(z_k | x_k). \\end{align} \\] <p>The motion model and the measurement equation are:</p> \\[ \\begin{align} \\mathbb{P}(u_k | x_{k - 1}, x_k) &amp;= \\mathcal{N}(x_k - x_{k - 1}, Q_k) \\\\ \\mathbb{P}(z_k | x_k) &amp;= \\mathcal{N}(x_k, R_k). \\end{align} \\] <p>The error residuals are:</p> \\[ \\begin{align} e_{u, k} = x_k - x_{k - 1} - u_k \\\\ e_{z, k} = z_k - x_k. \\end{align} \\] <p>Finally, the objective function is:</p> \\[ J = \\min \\sum^3_{k = 1} e^T_{u, k}Q^{-1}_k e_{u, k} + \\sum^3_{k = 1}e^T_{z, k} R^{-1}_{k} e_{z, k}. \\]"},{"location":"estimation_theory/least_squares_estimator/linear_least_squares/","title":"Linear Least Squares","text":""},{"location":"estimation_theory/least_squares_estimator/linear_least_squares/#problem-statement","title":"Problem Statement","text":"<p>Consider a problem of estimating a constant but unknown \\(\\mathbf{x} \\in \\mathbb{R}^n\\) given \\(m\\) measurements, \\(\\mathbf{y} \\in \\mathbb{R}^m\\) where \\(m &gt; n\\). Assume that the measurement model is linear:</p> \\[ \\mathbf{y} = \\mathbf{H} \\mathbf{x} + \\boldsymbol{v} \\label{least_squares_main}, \\] <p>where \\(\\mathbf{H} \\in \\mathbb{R}^{m \\times n}\\) is the linear observation matrix and \\(\\boldsymbol{v} \\in \\mathbb{R}^m\\) is the measurement noise.</p> <p>The measurement residual is defined as:</p> \\[ \\boldsymbol{\\epsilon}_{\\mathbf{y}} = \\mathbf{y} - \\mathbf{H} \\hat{\\mathbf{x}}, \\] <p>where \\(\\hat{\\mathbf{x}}\\) is the \"best\" estimate of \\(\\mathbf{x}\\).</p>"},{"location":"estimation_theory/least_squares_estimator/linear_least_squares/#solving-linear-least-squares","title":"Solving Linear Least Squares","text":"<p>The most probable value of the vector \\(\\mathbf{x}\\) is the vector \\(\\hat{\\mathbf{x}}\\) that minimizes the sum of squares between the observed values \\(\\mathbf{y}\\) and the vector \\(\\mathbf{H} \\hat{\\mathbf{x}}\\). This makes it an optimization problem:</p> <p>Hence, the least squares problem can be formulated as:</p> \\[ \\begin{align} \\arg \\min_{\\hat{\\mathbf{x}}} \\mathbf{J} &amp;= \\arg \\min_{\\hat{\\mathbf{x}}} \\quad || \\mathbf{H} \\hat{\\mathbf{x}} - \\mathbf{y} ||^2_2 \\\\ &amp;= \\arg \\min_{\\hat{\\mathbf{x}}} \\quad \\sum^m_{i = 1} \\left( \\mathbf{h}^T_i \\hat{\\mathbf{x}} - y_i \\right)^2. \\end{align} \\] <p>The cost function \\(\\mathbf{J}\\) can be rewritten as:</p> \\[ \\begin{align} \\mathbf{J} &amp;= \\epsilon^2_{y1} + \\ldots + \\epsilon^2_{yk} = \\boldsymbol{\\epsilon}^T_{\\mathbf{y}} \\boldsymbol{\\epsilon}_{\\mathbf{y}} \\\\ &amp;= (\\mathbf{y} - \\mathbf{H} \\hat{\\mathbf{x}})^T (\\mathbf{y} - \\mathbf{H} \\hat{\\mathbf{x}}) \\\\ &amp;= (\\mathbf{y}^T - \\hat{\\mathbf{x}}^T \\mathbf{H}^T) (\\mathbf{y} - \\mathbf{H} \\hat{\\mathbf{x}}) \\\\  &amp;= \\mathbf{y}^T \\mathbf{y} - \\hat{\\mathbf{x}}^T \\mathbf{H}^T \\mathbf{y} - \\mathbf{y}^T \\mathbf{H} \\hat{\\mathbf{x}} + \\hat{\\mathbf{x}}^T \\mathbf{H}^T \\mathbf{H} \\hat{\\mathbf{x}} \\end{align} \\] <p>or equivalently:</p> \\[ \\begin{align} &amp;\\arg \\min_{\\hat{\\mathbf{x}}} \\quad || \\mathbf{H} \\hat{\\mathbf{x}} - \\mathbf{y} ||^2_2 = \\arg \\min_{\\hat{\\mathbf{x}}} \\quad \\sum^m_{i = 1} \\left( \\mathbf{h}^T_i \\hat{\\mathbf{x}} - y_i \\right)^2 \\Rightarrow \\\\ &amp;\\arg \\min_{\\hat{\\mathbf{x}}} \\quad \\left( \\mathbf{H} \\hat{\\mathbf{x}} - \\mathbf{y} \\right)^T \\left( \\mathbf{H} \\hat{\\mathbf{x}} - \\mathbf{y} \\right) = \\arg \\min_{\\hat{\\mathbf{x}}} \\quad \\hat{\\mathbf{x}}^T \\mathbf{H}^T \\mathbf{H} \\hat{\\mathbf{x}} - 2 \\left( \\mathbf{H}^T \\mathbf{y} \\right)^T \\hat{\\mathbf{x}} + \\mathbf{y}^T \\mathbf{y}. \\end{align} \\] <p>The optimization variable is \\(\\hat{\\mathbf{x}}\\) and \\(\\mathbf{J}\\) is a quadratic convex function. Hence, the optimality condition is:</p> \\[ \\begin{align} \\nabla_{\\hat{\\mathbf{x}}} \\mathbf{J} &amp;=  \\nabla \\left( \\mathbf{H} \\hat{\\mathbf{x}} - \\mathbf{y} \\right)^T \\left( \\mathbf{H} \\hat{\\mathbf{x}} - \\mathbf{b} \\right) = 0 \\\\ &amp;\\Rightarrow -\\mathbf{y}^T \\mathbf{H} - \\mathbf{y}^T \\mathbf{H} + 2 \\hat{\\mathbf{x}}^T \\mathbf{H}^T \\mathbf{H} \\\\ &amp;\\Rightarrow \\mathbf{H}^T \\mathbf{H} \\hat{\\mathbf{x}} = \\mathbf{H}^T \\mathbf{y}. \\label{normal_equation} \\end{align} \\] <p>Equation (\\(\\ref{normal_equation}\\)) is called the normal equation. Solving the least squares problem is equivalent to solving the normal equation. Since \\(\\mathbf{H}\\) has a full column rank, \\(\\mathbf{H}^T \\mathbf{H}\\) is invertible. Hence, the optimal solution to the normal equation (equivalently to the least squares problem) is:</p> \\[ \\hat{\\mathbf{x}} = \\left( \\mathbf{H}^T \\mathbf{H} \\right)^{-1} \\mathbf{H}^T \\mathbf{y}. \\label{pseudoinverse} \\] <p>The right hand side of equation (\\(\\ref{pseudoinverse}\\)) is called the Moore-Penrose pseudoinverse and is defined as:</p> \\[ \\mathbf{H}^{+} = \\left( \\mathbf{H}^T \\mathbf{H} \\right)^{-1} \\mathbf{H}^T. \\] <p>The solution to the least squares is then \\(\\hat{\\mathbf{x}} = \\mathbf{H}^+ \\mathbf{y}\\). If \\(\\mathbf{H}\\) is an invertible square matrix, then \\(\\mathbf{H}^+ = \\mathbf{H}^{-1} \\left( \\mathbf{H}^T \\right)^{-1} \\mathbf{H}^T = \\mathbf{H}^{-1}\\).</p> <p>Rather than computing the matrix inversion, it is more efficient to use SVD. Since \\(\\mathbf{H}^T \\mathbf{H} = \\mathbf{V} \\boldsymbol{\\Sigma}^2 \\mathbf{V}^T\\), we have \\(\\left ( \\mathbf{H}^T \\mathbf{H} \\right)^{-1} = \\mathbf{V} \\boldsymbol{\\Sigma}^{-2} \\mathbf{V}^T\\). Then:</p> \\[ \\left( \\mathbf{H}^T \\mathbf{H} \\right)^{-1} \\mathbf{H}^T =  \\mathbf{V} \\boldsymbol{\\Sigma}^{-2} \\mathbf{V}^T \\mathbf{V} \\boldsymbol{\\Sigma} \\mathbf{U}^T = \\mathbf{V} \\boldsymbol{\\Sigma}^{-1} \\mathbf{U}^T. \\] <p>Hence, the optimal solution is:</p> \\[ \\hat{\\mathbf{x}} = \\mathbf{V} \\boldsymbol{\\Sigma}^{-1} \\mathbf{U}^T \\mathbf{y}. \\]"},{"location":"estimation_theory/least_squares_estimator/linear_least_squares/#example-polynomial-fitting","title":"Example - Polynomial Fitting","text":"<p>Suppose we have \\(m\\) pairs of data points \\((a_1, \\ b_1), \\ldots, (a_m, \\ b_m)\\) and we'd like to fit a cubic polynomial:</p> \\[ p(a) = b = x_0 + x_1 a + x_2 a^2 + x_3 a^3. \\] <p>The problem can be solved via least squares estimator. Let \\(\\mathbf{x} = \\left[\\begin{array}{ccc} x_0 &amp; \\ldots &amp; x_3 \\end{array} \\right]\\) be the coefficients of \\(p(a)\\). The residual can be written as:</p> \\[ \\begin{align} r(\\mathbf{x}) &amp;=  \\left[ \\begin{array}{c} p(a_1) - b_1 \\\\ \\vdots \\\\ p(a_m) - b_m \\end{array} \\right] =  \\left[ \\begin{array}{c} p(a_1) \\\\ \\vdots \\\\ p(a_m) \\end{array} \\right] -  \\left[ \\begin{array}{c} b_1 \\\\ \\vdots \\\\ b_m \\end{array} \\right] =  \\left[ \\begin{array}{c} x_0 + x_1 a_1 + x_2 a^2_1 + x_3 a^3_1 \\\\ \\vdots \\\\ x_0 + x_1 a_m + x_2 a^2_m + x_3 a^3_m \\end{array} \\right] -  \\left[ \\begin{array}{c} b_1 \\\\ \\vdots \\\\ b_m \\end{array} \\right] \\\\  &amp;=  \\left[ \\begin{array}{cccc} 1 &amp; a_1 &amp; a^2_1 &amp; a^3_1 \\\\ \\vdots &amp; \\ddots &amp; \\ddots &amp; \\vdots \\\\ 1 &amp; a_m &amp; a^2_m &amp; a^3_m \\end{array} \\right] \\left[ \\begin{array}{c} x_0 \\\\ x_1 \\\\ x_2 \\\\ x_3 \\end{array} \\right] -  \\left[ \\begin{array}{c} b_1 \\\\ \\vdots \\\\ b_m \\end{array} \\right] \\\\ &amp;= \\mathbf{A} \\mathbf{x} - \\mathbf{b}. \\end{align} \\] <p>The matrix \\(\\mathbf{A}\\) is called the Vandermonde matrix.</p>"},{"location":"estimation_theory/least_squares_estimator/linear_recursive_least_squares/","title":"Linear Recursive Least Squares","text":""},{"location":"estimation_theory/least_squares_estimator/linear_recursive_least_squares/#problem-statement","title":"Problem Statement","text":"<p>Suppose we have an estimate \\(\\hat{\\mathbf{x}}\\) after \\((k - 1)\\) measurements, and we obtain a new measurement \\(y_k\\) at time \\(k\\). If we obtain measurements sequentially and want to update our estimate of the constant \\(\\mathbf{x}\\) with each new measurement, we need to augment the observation matrix \\(\\mathbf{H} \\in \\mathbb{R}^{k \\times n}\\) matrix and completely recompute the estimate \\(\\hat{\\mathbf{x}}\\). Recursive least squares avoids this recomputation.</p> <p>A linear recursive least squares estimator can be written as:</p> \\[ \\begin{align} y_k &amp;= \\mathbf{H}_k \\mathbf{x} + v_k \\\\ \\hat{\\mathbf{x}}_k &amp;= \\hat{\\mathbf{x}}_{k - 1} + \\mathbf{K}_{k} \\left( y_k - \\mathbf{H}_k \\hat{\\mathbf{x}}_{k - 1} \\right), \\end{align} \\] <p>where \\(\\mathbf{K}_k\\) is the estimator gain matrix. Here, we compute \\(\\hat{\\mathbf{x}}_k\\) on the basis of the previous estimate \\(\\hat{\\mathbf{x}}_{k - 1}\\) and the new measurement \\(y_k\\). The correction term \\(y_k - \\mathbf{H}_k \\hat{\\mathbf{x}}_{k - 1}\\) applied to the previous term \\(\\hat{\\mathbf{x}}\\) is called the residual or innovation.</p>"},{"location":"estimation_theory/least_squares_estimator/linear_recursive_least_squares/#solution-to-linear-recursive-least-squares","title":"Solution to Linear Recursive Least Squares","text":"<p>The estimation error after \\(k\\) measurements can be defined as:</p> \\[ \\boldsymbol{\\epsilon}_{\\mathbf{x}, k} = \\mathbf{x} - \\hat{\\mathbf{x}}_k. \\] <p>Then the mean or the expectation of the estimation error is:</p> \\[ \\begin{align} \\mathbb{E} \\left[ \\boldsymbol{\\epsilon}_{\\mathbf{x}, k} \\right] &amp;= \\mathbb{E} \\left[ \\mathbf{x} - \\hat{\\mathbf{x}}_k \\right] \\\\ &amp;= \\mathbb{E} \\left[ \\mathbf{x} - \\hat{\\mathbf{x}}_{k - 1} - \\mathbf{K}_k \\left( y_k - \\mathbf{H}_k \\hat{\\mathbf{x}}_{k - 1} \\right) \\right] \\\\ &amp;= \\mathbb{E} \\left[ \\boldsymbol{\\epsilon}_{\\mathbf{x}, k - 1} - \\mathbf{K}_k \\left(\\mathbf{H}_k \\mathbf{x} + v_k - \\mathbf{H}_k \\hat{\\mathbf{x}}_{k - 1} \\right) \\right] \\\\ &amp;= \\mathbb{E}\\left[ \\boldsymbol{\\epsilon}_{\\mathbf{x}, k - 1} - \\mathbf{K}_k \\mathbf{H}_k( \\mathbf{x} - \\hat{\\mathbf{x}}_{k - 1}) - \\mathbf{K}_k v_k \\right] \\\\ &amp;= \\left( \\mathbf{I} - \\mathbf{K}_k \\mathbf{H}_k \\right) \\mathbb{E}(\\boldsymbol{\\epsilon}_{\\mathbf{x}, k-1}) - \\mathbf{K}_k \\mathbb{E}(v_k). \\end{align} \\] <p>Unbiased Estimator</p> <p>If the measurement noise \\(v_k\\) is zero mean for all \\(k\\), and if the initial estimate of \\(\\mathbf{x}\\) is set to the expected value of \\(\\mathbf{x}\\) (i.e., \\(\\hat{\\mathbf{x}}_0 = \\mathbb{E}\\left[ \\mathbf{x} \\right]\\)), then the expected value of \\(\\hat{\\mathbf{x}}_k\\) will be equal to \\(\\mathbf{x}\\) for all \\(k\\) (\\(\\mathbb{E}\\left[\\boldsymbol{\\epsilon}_{\\mathbf{x}, k}\\right] = \\mathbf{0}\\)). This is called an unbiased estimator.</p> <p>The cost function can be defined as the sum of the variances of the estimation errors at time \\(k\\):</p> \\[ \\begin{align} \\mathbf{J}_k &amp;= \\mathbb{E} \\left[(x_1 - \\hat{x}_{1, k})^2 \\right] + \\cdots + \\mathbb{E} \\left[(x_n - \\hat{x}_{n, k})^2 \\right] \\\\ &amp;= \\mathbb{E} \\left[\\epsilon^2_{x1, k} + \\cdots + \\epsilon^2_{xn, k} \\right] \\\\ &amp;= \\mathbb{E} \\left[\\boldsymbol{\\epsilon}^T_{\\mathbf{x}, k} \\boldsymbol{\\epsilon}_{\\mathbf{x}, k} \\right] \\\\ &amp;= \\mathbf{E} \\left [ \\text{Tr} \\left(\\boldsymbol{\\epsilon}^T_{\\mathbf{x}, k} \\boldsymbol{\\epsilon}_{\\mathbf{x}, k}   \\right) \\right] \\\\ &amp;= \\text{Tr} \\mathbf{P}_k, \\end{align} \\] <p>where \\(\\mathbf{P}_k\\) is the estimation-error covariance at time \\(k\\) and can be found as follows:</p> \\[ \\begin{align} \\mathbf{P}_k &amp;= \\mathbb{E} \\left[\\boldsymbol{\\epsilon}^T_{\\mathbf{x}, k} \\boldsymbol{\\epsilon}_{\\mathbf{x}, k} \\right] \\\\ &amp;= \\mathbb{E} \\left[ \\left( \\mathbf{x} - \\hat{\\mathbf{x}}_k \\right) \\left( \\mathbf{x} - \\hat{\\mathbf{x}}_k \\right)^T \\right] \\\\ &amp;= \\mathbb{E} \\left[ \\left(\\mathbf{x} - \\mathbf{\\hat{x}}_{k - 1} - \\mathbf{K}_k (\\mathbf{H}_k \\mathbf{x} + v_k - \\mathbf{H}_k \\hat{\\mathbf{x}}_{k - 1}) \\right) \\left( \\cdots \\right)^T \\right] \\\\ &amp;= \\mathbb{E} \\left[ \\left( \\boldsymbol{\\epsilon}_{\\mathbf{x}, k - 1} - \\mathbf{K}_k \\mathbf{H}_k \\boldsymbol{\\epsilon}_{\\mathbf{x}, k - 1} + \\mathbf{K}_k v_k \\right) \\left( \\cdots \\right)^T \\right] \\\\ &amp;= \\mathbb{E} \\left[ \\left(  (\\mathbf{I} - \\mathbf{K}_k \\mathbf{H}_k)\\boldsymbol{\\epsilon}_{\\mathbf{x}, k - 1} + \\mathbf{K}_k  \\right) \\left( \\cdots \\right)^T \\right] \\\\ &amp;= \\left( \\mathbf{I} - \\mathbf{K}_k \\mathbf{H}_k \\right) \\mathbb{E} \\left[ \\boldsymbol{\\epsilon}_{\\mathbf{x}, k - 1} \\boldsymbol{\\epsilon}^T_{\\mathbf{x}, k - 1} \\right] \\left( \\mathbf{I} - \\mathbf{K}_k \\mathbf{H}_k \\right)^T \\\\ &amp;\\quad - \\mathbf{K}_k \\mathbb{E} \\left[v_k \\boldsymbol{\\epsilon}^T_{\\mathbf{x}, k - 1}  \\right] \\left( \\mathbf{I} - \\mathbf{K}_k \\mathbf{H}_k \\right)^T \\\\ &amp;\\quad - \\left( \\mathbf{I} - \\mathbf{K}_k \\mathbf{H}_k \\right) \\mathbb{E} \\left[ \\boldsymbol{\\epsilon}_{\\mathbf{x}, k - 1} v^T_k \\ \\right] \\mathbf{K}^T_k \\\\ &amp;\\quad + \\mathbf{K}_k \\mathbb{E}\\left[v_k v^T_k \\right] \\mathbf{K}^T_k. \\end{align} \\] <p>The estimation error at time \\(k - 1\\), \\(\\boldsymbol{\\epsilon}_{\\mathbf{x}, k}\\), is independent of the measurement noise at time \\(k\\), \\(v_k\\):</p> \\[ \\mathbb{E}\\left[ v_k \\boldsymbol{\\epsilon}^T_{\\mathbf{x}, k - 1} \\right] = \\mathbb{E}\\left[ v_k \\right] \\mathbb{E} \\left[ \\boldsymbol{\\epsilon}^T_{\\mathbf{x}, k - 1} \\right] = \\mathbf{0}. \\] <p>Hence, the estimation-error covariance is:</p> \\[ \\mathbf{P}_k = \\left( \\mathbf{I} - \\mathbf{K}_k \\mathbf{H}_k \\right) \\mathbf{P}_{k - 1} \\left( \\mathbf{I} - \\mathbf{K}_k \\mathbf{H}_k \\right)^T + \\mathbf{K}_k \\mathbf{R}_k \\mathbf{K}^T_k, \\] <p>where \\(\\mathbf{R}_k\\) is the covariance of \\(v_k\\).</p> <p>To optimality condition is:</p> \\[ \\frac{ \\partial \\mathbf{J}_k}{ \\partial \\mathbf{K}_k} = 2 \\left( \\mathbf{I} - \\mathbf{K}_k \\mathbf{H}_k \\right) \\mathbf{P}_{k - 1} \\left( - \\mathbf{H}^T_k \\right) + 2 \\mathbf{K}_k \\mathbf{R}_k = \\mathbf{0}, \\] <p>since:</p> \\[ \\frac{\\partial \\text{Tr}(\\mathbf{A} \\mathbf{B} \\mathbf{A}^T)}{\\partial \\mathbf{A}} = 2 \\mathbf{A} \\mathbf{B}, \\] <p>given \\(\\mathbf{B}\\) is symmetric. Hence, the recursive least squares update equations are:</p> \\[ \\begin{align} \\mathbf{K}_k &amp;= \\mathbf{P}_{k - 1} \\mathbf{H}^T_k \\left( \\mathbf{H}_k \\mathbf{P}_{k - 1} \\mathbf{H}^T + \\mathbf{R}_k \\right)^{-1} \\\\ \\hat{\\mathbf{x}}_k &amp;= \\hat{\\mathbf{x}}_{k - 1} + \\mathbf{K}_k \\left(y_k - \\mathbf{H}_k \\hat{\\mathbf{x}}_{k - 1} \\right) \\\\ \\mathbf{P}_k &amp;= \\left( \\mathbf{I} - \\mathbf{K}_k \\mathbf{H}_k \\right) \\mathbf{P}_{k - 1} \\left( \\mathbf{I} - \\mathbf{K}_k \\mathbf{H}_k \\right)^T + \\mathbf{K}_k \\mathbf{R}_k \\mathbf{K}^T_k \\\\ &amp;= \\left( \\mathbf{I} - \\mathbf{K}_k \\mathbf{H}_k \\right) \\mathbf{P}_{k - 1}. \\end{align} \\]"},{"location":"estimation_theory/least_squares_estimator/linear_weighted_least_squares/","title":"Linear Weighted Least Squares","text":""},{"location":"estimation_theory/least_squares_estimator/linear_weighted_least_squares/#problem-statement","title":"Problem Statement","text":"<p>Consider a problem of estimating a constant but unknown \\(\\mathbf{x} \\in \\mathbb{R}^n\\) given \\(m\\) measurements, \\(\\mathbf{y} \\in \\mathbb{R}^m\\) where \\(m &gt; n\\). Assume that the measurement model is linear:</p> \\[ \\mathbf{y} = \\mathbf{H} \\mathbf{x} + \\boldsymbol{v} \\label{least_squares_main}, \\] <p>where \\(\\mathbf{H} \\in \\mathbb{R}^{m \\times n}\\) is the linear observation matrix and \\(\\boldsymbol{v} \\in \\mathbb{R}^m\\) is the measurement noise. Assume that the noise for each measurement is zero-mean and independent:</p> \\[ \\mathbb{E} \\left[v^2_i \\right] = \\sigma^2_i, \\quad i = 1, \\ldots, m. \\] <p>The measurement covariance matrix is:</p> \\[ \\begin{align} \\mathbf{R} &amp;= E(\\boldsymbol{v} \\boldsymbol{v}^T) \\\\ &amp;= \\left[ \\begin{array}{ccc} \\sigma^2_1 &amp; \\ldots &amp; 0 \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; \\ldots &amp; \\sigma^2_m \\end{array} \\right] \\end{align} \\] <p>The measurement residual is defined as:</p> \\[ \\boldsymbol{\\epsilon}_{\\mathbf{y}} = \\mathbf{y} - \\mathbf{H} \\hat{\\mathbf{x}}, \\] <p>where \\(\\hat{\\mathbf{x}}\\) is the \"best\" estimate of \\(\\mathbf{x}\\).</p>"},{"location":"estimation_theory/least_squares_estimator/linear_weighted_least_squares/#solution-to-linear-weighted-least-squares","title":"Solution to Linear Weighted Least Squares","text":"<p>We will define the cost function as a weighted sum of squares of the residuals:</p> \\[ \\begin{align} \\mathbf{J} &amp;= \\boldsymbol{\\epsilon}^T_{\\mathbf{y}} \\mathbf{R}^{-1} \\boldsymbol{\\epsilon}_{\\mathbf{y}} \\\\ &amp;= \\left[ \\begin{array}{ccc} \\epsilon_{y1} &amp; \\ldots &amp; \\epsilon_{ym} \\end{array} \\right] \\left[ \\begin{array}{ccc} 1/\\sigma^2_1 &amp; \\ldots &amp; 0 \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; \\ldots &amp; 1/\\sigma^2_m \\end{array} \\right] \\left[ \\begin{array}{c} \\epsilon_{y1} \\\\ \\vdots \\\\ \\epsilon_{ym} \\end{array} \\right] \\\\ &amp;= \\epsilon^2_{y1} / \\sigma^2_1 + \\ldots + \\epsilon^2_{ym} / \\sigma^2_{m}. \\end{align} \\] <p>Hence, the weighted least squares problem can be formulated as:</p> \\[ \\begin{align} \\arg \\min_{\\hat{\\mathbf{x}}} \\quad \\mathbf{R}^{-1} || \\mathbf{H} \\hat{\\mathbf{x}} - \\mathbf{y} ||^2_2 = \\arg \\min_{\\hat{\\mathbf{x}}} \\quad \\mathbf{R}^{-1} \\sqrt{\\sum^m_{i = 1} \\left( \\mathbf{h}^T_i \\hat{\\mathbf{x}} - y_i \\right)^2}. \\end{align} \\] <p>Rewrite the objective function in terms of the optimization variable as:</p> \\[ \\begin{align} \\mathbf{J} &amp;= \\boldsymbol{\\epsilon}^T_{\\mathbf{y}} \\mathbf{R}^{-1} \\boldsymbol{\\epsilon}_{\\mathbf{y}} \\\\ &amp;= (\\mathbf{y} - \\mathbf{H} \\hat{\\mathbf{x}})^T \\mathbf{R}^{-1} (\\mathbf{y} - \\mathbf{H} \\hat{\\mathbf{x}}) \\\\ &amp;= (\\mathbf{y}^T \\mathbf{R}^{-1} - \\hat{\\mathbf{x}}^T \\mathbf{H}^T \\mathbf{R}^{-1}) (\\mathbf{y} - \\mathbf{H} \\hat{\\mathbf{x}}) \\\\ &amp;= \\mathbf{y}^T \\mathbf{R}^{-1} \\mathbf{y} - \\mathbf{y}^T \\mathbf{R}^{-1} \\mathbf{H} \\hat{\\mathbf{x}} - \\hat{\\mathbf{x}}^T \\mathbf{H}^T \\mathbf{R}^{-1} \\mathbf{y} +  \\hat{\\mathbf{x}}^T \\mathbf{H}^T \\mathbf{R}^{-1} \\mathbf{H} \\hat{\\mathbf{x}}. \\end{align} \\] <p>The optimization variable is \\(\\hat{\\mathbf{x}}\\) and \\(\\mathbf{J}\\) is a quadratic convex function. Hence, the optimality condition is:</p> \\[ \\nabla_{\\hat{\\mathbf{x}}} \\mathbf{J} = -2\\mathbf{y}^T \\mathbf{R}^{-1} \\mathbf{H} + 2 \\hat{\\mathbf{x}}^T \\mathbf{H}^T \\mathbf{R}^{-1} \\mathbf{H} = 0. \\] <p>Solving for \\(\\hat{\\mathbf{x}}\\) yields to:</p> \\[ \\hat{\\mathbf{x}} = \\left( \\mathbf{H}^T \\mathbf{R}^{-1} \\mathbf{H} \\right)^{-1} \\mathbf{H}^T \\mathbf{R}^{-1} \\mathbf{y}. \\]"},{"location":"estimation_theory/least_squares_estimator/nonlinear_least_squares/","title":"Nonlinear Least Squares","text":""},{"location":"estimation_theory/least_squares_estimator/nonlinear_least_squares/#problem-statement","title":"Problem Statement","text":"<p>Consider a problem of estimating a constant but unknown \\(\\mathbf{x} \\in \\mathbb{R}^n\\) given \\(m\\) measurements, \\(\\mathbf{y} \\in \\mathbb{R}^m\\) where \\(m &gt; n\\). Assume that the measurement model is nonlinear scalar functions:</p> \\[ \\mathbf{y} = \\mathbf{h}(\\mathbf{x}) + \\boldsymbol{v}, \\] <p>The optimization problem can be formulated as:</p> \\[ \\min_{\\mathbf{x}} = \\frac{1}{2} ||\\mathbf{h}(\\mathbf{x})||^2_2. \\]"},{"location":"estimation_theory/least_squares_estimator/nonlinear_least_squares/#solution-to-nonlinear-least-squares","title":"Solution to Nonlinear Least Squares","text":"<p>Iterative methods are usually used to solve nonlinear least squares.</p> <p>Nonlinear Least Squares</p> <ol> <li>Set an initial value \\(\\mathbf{x}_0\\).</li> <li> <p>For the \\(k\\)'th iteration, find an incremental value of \\(\\Delta \\mathbf{x}_k\\), such that the objective function:</p> \\[ ||\\mathbf{h}(\\mathbf{x}_k + \\Delta \\mathbf{x}_k)||^2_2, \\] <p>reaches a smaller value.</p> </li> <li> <p>If \\(\\Delta \\mathbf{x}_k\\) is small enough, stop the algorithm.</p> </li> <li>Else, set \\(\\mathbf{x}_{k + 1} = \\mathbf{x}_k + \\Delta \\mathbf{x}_k\\) and repeat from step 2.</li> </ol> <p>The main problem is on how to find \\(\\Delta \\mathbf{x}_k\\).</p>"},{"location":"estimation_theory/least_squares_estimator/nonlinear_least_squares/#first-and-second-order-methods","title":"First and Second-Order Methods","text":"<p>Consider the \\(k\\)-th iteration. Suppose we are at \\(\\mathbf{x}_k\\) and want to find the increment \\(\\Delta \\mathbf{x}_k\\). The second-order Taylor series of the measurement function is:</p> \\[ \\mathbf{h}(\\mathbf{x}_k + \\Delta \\mathbf{x}_k) \\approx \\mathbf{h}(\\mathbf{x}_k) + \\mathbf{J}^T(\\mathbf{x}_k) \\Delta \\mathbf{x}_k + \\frac{1}{2} \\Delta \\mathbf{x}^T_k \\mathbf{H}(\\mathbf{x}_k) \\Delta \\mathbf{x}_k, \\] <p>where \\(\\mathbf{J}(\\mathbf{x}_k)\\) is the Jacobian or and \\(\\mathbf{H}(\\mathbf{x})\\) is the Hessian. Refer to Unconstrained Optimization for more details.</p>"},{"location":"estimation_theory/least_squares_estimator/nonlinear_least_squares/#gauss-newton-method","title":"Gauss-Newton Method","text":"<p>Refer to Gauss-Newon Method.</p>"},{"location":"estimation_theory/least_squares_estimator/nonlinear_least_squares/#levernberg-marquatdt-method","title":"Levernberg-Marquatdt Method","text":"<p>Refer to Levernberg-Marquatdt Method.</p>"},{"location":"estimation_theory/least_squares_estimator/nonlinear_least_squares/#example-curve-fitting","title":"Example - Curve Fitting","text":"<p>Consider a curve with a measurement equation:</p> \\[ y = \\exp \\left\\{ a x^2 + bx + c \\right\\} + w, \\] <p>where \\(a, b, c\\) are parameters to be estimated, and \\(w \\sim \\mathcal{N}(0, \\sigma^2)\\) is a zero-mean Gaussian noise. Suppose we have \\(N\\) observation. The least squares problem can be formulated as:</p> \\[ \\arg \\min_{a, b, c} \\frac{1}{2} \\sum^N_{i = 1} ||y_i - \\exp \\left\\{ a x^2_i + bx_i + c \\right\\}||^2. \\] <p>The residual can be defined as:</p> \\[ e_i = y_i - \\exp \\left\\{ a x^2_i + bx_i + c \\right\\}. \\] <p>The derivative of the residual with respect to the state variables are:</p> \\[ \\begin{align} \\frac{\\partial e_i}{\\partial a} &amp;= -x^2_i \\exp \\left\\{ a x^2_i + bx_i + c \\right\\} \\\\  \\frac{\\partial e_i}{\\partial b} &amp;= -x_i \\exp \\left\\{ a x^2_i + bx_i + c \\right\\} \\\\  \\frac{\\partial e_i}{\\partial c} &amp;= -\\exp \\left\\{ a x^2_i + bx_i + c \\right\\}. \\end{align} \\] <p>The Jacobian for the \\(i\\)-th measurement is then:</p> \\[ \\mathbf{J} = \\left[\\begin{array}{ccc} \\frac{\\partial e_i}{\\partial a} &amp; \\frac{\\partial e_i}{\\partial b} &amp; \\frac{\\partial e_i}{\\partial c} \\end{array} \\right]^T, \\] <p>and the normal equation of the Gauss-Newton method is:</p> \\[ \\biggl( \\sum^N_{i = 1} \\mathbf{J}_i (\\sigma^2)^{-1} \\mathbf{J}^T_i \\biggr) \\Delta \\mathbf{x}_k = \\sum^N_{i = 1} -\\mathbf{J}_i (\\sigma^2)^{-1} e_i. \\] <p>Figure 1 shows the nonlinear least squares estimator using Gauss-Newton method for \\(N = 100\\) points.</p> <p> </p> Curve fitting with nonlinear LSE using Gauss-Newton method"},{"location":"estimation_theory/least_squares_estimator/nonlinear_least_squares/#appendix","title":"Appendix","text":"Direct Gauss Newtong2o <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom numpy.random import normal\n\ndef model(x, a, b, c):\n\n    d = a * x * x + b * x + c\n    y = np.exp(d)\n    return y\n\n# Ground truth values\na_gt, b_gt, c_gt = 1.0, 2.0, 1.0\n\nN = 100\nx = np.zeros((N, ), dtype=np.float64)\ny_gt = np.zeros((N, ), dtype=np.float64)\ny_meas = np.zeros((N, ), dtype=np.float64)\ny_est = np.zeros((N, ), dtype=np.float64)\n\n# Noise properties\nw_sigma = 1.0\ninv_sigma = 1.0 / w_sigma\n\n# Generate N ground truth and noisy measurements\nfor i in range(0, N):\n    x[i] = i / float(N)\n    y_gt[i] = model(x[i], a_gt, b_gt, c_gt)\n    y_meas[i] = y_gt[i] + normal(0, w_sigma)\n\n\n# Gauss-Newton\nnum_iter = 100\ncost, last_cost = 0.0, 0.0\n\na, b, c = 2.0, -1.0, 5.0\n\nfor j in range(0, num_iter):\n    H = np.zeros((3, 3), dtype=np.float64) # Hessian = J^T W^{-1} J\n    bias = np.zeros((3, 1), dtype=np.float64) # bias\n\n    cost = 0.0\n\n    for i in range(0, N):\n        x_i, y_i = x[i], y_meas[i]\n        h_i = model(x_i, a, b, c)\n        r_i = y_i - h_i\n\n        # Compute Jacobian at x_i\n        J = np.zeros((3, 1), dtype=np.float64)\n        J[0] = -x_i * x_i * h_i\n        J[1] = -x_i * h_i\n        J[2] = -h_i\n\n        H += inv_sigma * inv_sigma * J @ J.T\n        bias += -inv_sigma * inv_sigma * r_i * J\n\n        cost += r_i * r_i\n\n    H_pseudo_inv = np.linalg.inv(H.T @ H)\n    dx = H_pseudo_inv @ H.T @ bias\n    if (j &gt; 0 and cost &gt;= last_cost):\n        break\n\n    a += dx[0]\n    b += dx[1]\n    c += dx[2]\n\n    last_cost = cost\n\nfor i in range(0, N):\n    y_est[i] = model(x[i], a, b, c)\n\nfig, ax = plt.subplots()\nax.plot(x, y_gt, \"-r\", label=\"Ground truth\")\nax.plot(x, y_meas, \".b\", label=\"Measurement\")\nax.plot(x, y_est, \".g\", label=\"Estimated\")\nax.set_xlabel(\"x\")\nax.set_ylabel(\"y\")\nax.grid(True)\nax.legend()\nfig.savefig(\"curve_fitting_with_gn.png\", dpi=1000)\n</code></pre> <p>``` python linenums=\"1\"</p>"},{"location":"estimation_theory/least_squares_estimator/nonlinear_least_squares/#include","title":"include  <p>int main() {     omp_set_num_threads(16); // OPTIONAL - Can also use                              // OMP_NUM_THREADS environment variable</p> <pre><code>#pragma omp parallel\n{\n    printf(\"hello, world!\\n\"); // Execute in parallel\n} // Implicity join\nreturn 0;\n</code></pre> <p>}</p>","text":""},{"location":"estimation_theory/statistical_estimators/maximum_likelihood_estimator/","title":"Maximum Likelihood Estimator","text":""},{"location":"estimation_theory/statistical_estimators/maximum_likelihood_estimator/#definition","title":"Definition","text":"<p>Maximum likelihood estimator (MLE) is an estimator for the parameters of an assumed probability distribution, given some observed data. This is achieved by maximizing a likelihood function so that, under the assumed statistical model, the observed data is most probable.</p> <p>Suppose that the sample \\(X_1, \\ldots, X_n\\) comes from a population with distribution \\(f(x | \\theta)\\) indexed by \\(\\theta\\), which could be a scalar or a vector of parameters. Elements of the sample are independent, thus the joint distribution of \\(X_1, \\ldots, X_n\\) is a product of individual densities:</p> \\[ f(x_1, \\ldots, x_n | \\theta) = \\prod^n_{i = 1} f(x_i | \\theta). \\] <p>When the sample is observed, the joint distribution remains dependent upon the parameter:</p> \\[ L(\\theta | X_1, \\ldots, X_n) = \\prod^n_{i = 1} f(X_i | \\theta), \\] <p>and, as a function of the parameter, \\(L\\) is called the likelihood. The value of the parameter \\(\\theta\\) that maximimizes the likelihood \\(L(\\theta | X_1, \\ldots, X_n)\\) is the MLE:</p> \\[ \\hat{\\theta}_{mle} = \\arg \\max_\\theta L(\\theta | X_1, \\ldots, X_n). \\] <p>The solution to the optimization problem can be found as:</p> \\[ \\frac{\\partial \\ell (\\theta | X_1, \\ldots, X_n)}{\\partial \\theta} = 0, \\ \\text{s.t.} \\ \\frac{\\partial^2 \\ell(\\theta | X_1, \\ldots, X_n)}{\\partial \\theta^2} &lt; 0. \\] <p>Intuitively, likelihood refers to \"what observation data may be generated in the current state\". Since we know the observation or the measurement data, the maximum likelihood estimator can be understood as \"under what state, it is most likely to produce the data that is currently being observed?\".</p>"},{"location":"estimation_theory/statistical_estimators/maximum_likelihood_estimator/#log-likelihood","title":"Log-Likelihood","text":"<p>In most cases, maximizing the logarithm of likelihood, log-likelihood, is simpler than maximizing the likelihood directly:</p> \\[ \\ell (\\theta | X_1, \\ldots, X_n) = \\log L (\\theta | X_1, \\ldots, X_n) = \\sum^n_{i = 1} \\log f(X_i | \\theta), \\] <p>and finding an extremum of a sum is simpler. Since the logarithm is a monotonically increasing function, the maxima of \\(L\\) and \\(\\ell\\) are achieved at the same value \\(\\hat{\\theta}_{mle}\\). Figure 1 shows likelihood and log-likelihood for exponential distribution with rate parmater \\(\\lambda\\) when the sample \\(X = [0.4, 0.3, 0.1, 0.5]\\) is observed. The MLE is \\(1 / \\bar{X} = 3.077\\).</p> <p> </p> Figure 1 Likelihood and log-likelihood example"},{"location":"estimation_theory/statistical_estimators/maximum_likelihood_estimator/#example","title":"Example","text":""},{"location":"estimation_theory/statistical_estimators/maximum_likelihood_estimator/#exponential-model","title":"Exponential Model","text":"<p>Consider the MLE of \\(\\lambda\\) in the exponential model, \\(\\text{Exp}(\\lambda)\\). After \\(X_1, \\ldots, X_n\\) are observed, the likelihood becomes:</p> \\[ L(\\lambda | X_1, \\ldots, X_n) = \\prod^n_{i = 1} \\lambda e^{- \\lambda X_i} = \\lambda^n \\exp \\left\\{ -\\lambda \\sum^n_{i = 1} X_i \\right\\}. \\] <p>The likelihood \\(L\\) is obtained as a product of densities \\(f(x_i | \\lambda)\\) where the arguments \\(x_i\\)s are fixed observations \\(X_i\\). The log-lileihood is:</p> \\[ \\ell (\\lambda | X_1, \\ldots, X_n) = n \\log \\lambda - \\lambda \\sum^n_{i = 1} X_i. \\] <p>We have:</p> \\[ \\frac{\\partial \\ell}{\\partial \\lambda} = \\frac{n}{\\lambda} - \\sum^n_{i = 1} X_i = 0, \\] <p>and the solution is \\(\\hat{\\lambda}_{mle} = \\frac{n}{\\sum^n_{i = 1} X_i} = 1 / \\bar{X}\\). The second derivative of the log-likelihood, \\(\\frac{\\partial^2 \\ell}{\\partial \\lambda^2} = -\\frac{n}{\\lambda^2}\\), is always negative; thus, the solution \\(\\hat{\\lambda}_{mle}\\) maximizes \\(\\ell\\).</p> <p>Invariance Property of MLEs</p> <p>Let \\(\\hat{\\theta}_{mle}\\) be an MLE of \\(\\theta\\) and let \\(\\eta = g(\\theta)\\), where \\(g\\) is an arbitrary function. Then \\(\\hat{\\eta}_{mle} = g(\\hat{\\theta}_{mle})\\) is an MLE of \\(\\eta\\).</p> <p>For example, if the MLE for \\(\\lambda\\) in the exponential distribution was \\(1 / \\bar{X}\\), then for a function of the parameter \\(\\eta = \\lambda^2 - \\sin \\lambda\\), the MLE is \\((1 / \\bar{X})^2 - \\sin(1 / \\bar{X})\\).</p>"},{"location":"estimation_theory/statistical_estimators/maximum_likelihood_estimator/#appendix","title":"Appendix","text":""},{"location":"estimation_theory/statistical_estimators/maximum_likelihood_estimator/#plotting-script","title":"Plotting Script","text":"<pre><code>import numpy as np\nfrom matplotlib import pyplot as plt\n\ndef compute_likelihoods(X, lambdas):\n\n    num_samples = X.shape[0]\n\n    ## Likelihood\n    L = np.zeros(lambdas.shape)\n    for j in range(lambdas.shape[0]):\n\n        sum = 0\n        for i in range(num_samples):\n            sum += -lambdas[j] * X[i]\n\n        L[j] = np.power(lambdas[j], num_samples) * np.exp(sum)\n\n    ## Log-likelihood\n    l = np.zeros(lambdas.shape)\n    for j in range(lambdas.shape[0]):\n\n        sum = 0\n        for i in range(num_samples):\n            sum += -lambdas[j] * X[i]\n\n        l[j] = num_samples * np.log(lambdas[j]) + sum\n\n    return L, l\n\n\nrate_params = np.linspace(1, 5)\nX = np.array([0.4, 0.3, 0.1, 0.5], dtype=np.float32)\n\nL, l = compute_likelihoods(X, rate_params)\n\nmax_rate_param = np.array([3.077])\n\nL_mle, l_mle = compute_likelihoods(X, max_rate_param)\n\nfig, ax = plt.subplots()\nax.plot(rate_params, L, label=\"Likelihood\")\nax.plot(rate_params, l, label=\"Log-likelihood\")\nax.plot(max_rate_param, L_mle, \"o\")\nax.plot(max_rate_param, l_mle, \"o\")\nax.axvline(x=max_rate_param, linestyle=\"--\")\nax.set_xlim((1, 5))\nax.set_ylim((-2, 2))\nax.set_box_aspect(1)\nax.set_xlabel(\"Rate param\")\nax.set_ylabel(\"Likelihood\")\nax.grid(True)\nax.legend()\nplt.show()\n\nfig.tight_layout()\nfig.savefig(\"maximum_likelihood.png\", dpi=800, bbox_inches=\"tight\")\n</code></pre>"},{"location":"estimation_theory/statistical_estimators/moment_matching_estimator/","title":"Moment-Matching Estimator","text":""},{"location":"estimation_theory/statistical_estimators/moment_matching_estimator/#definition","title":"Definition","text":"<p>They key idea is to match the theoretical descriptors, most often moments, with their empirical counterparts. The theoretical moments of a random variable \\(X\\) with a density specified up to a parameter, \\(f(x | \\theta)\\), are functions of that parameter:</p> \\[ \\mathbb{E} X^k = h(\\theta). \\] <p>For example, if the measurements have a distribution \\(\\mathcal{Poi}(\\lambda)\\), the second moment \\(\\mathbb{E} X^2\\) is \\(\\lambda + \\lambda^2\\), which is a function of \\(\\lambda\\). Here, \\(h(x) = x + x^2\\).</p> <p>Suppose a sample \\(X_1, X_2, \\ldots, X_n\\) was obtained from \\(f(x | \\theta)\\). The empirical counterpars for theoretical moments \\(\\mathbb{E}X^k\\) are sample moments:</p> \\[ \\bar{X^k} = \\frac{1}{n}\\sum^n_{i = 1} X^k_i. \\] <p>By matching the theoretical and empirical moments, an estimator \\(\\hat{\\theta}\\) is found as a solution of the equation:</p> \\[ \\bar{X^k} = h(\\theta). \\]"},{"location":"estimation_theory/statistical_estimators/moment_matching_estimator/#example","title":"Example","text":""},{"location":"estimation_theory/statistical_estimators/moment_matching_estimator/#exponential-distribution","title":"Exponential Distribution","text":"<p>For the exponential distribution \\(\\text{Exp}(\\lambda)\\), the first theoretical moment is the mean, i.e., \\(\\mathbb{E} X = 1 / \\lambda\\). An estimator for rate parameter \\(\\lambda\\) is obtained by solving the moment-matching equation \\(\\bar{X} = 1 / \\lambda\\), resulting in \\(\\hat{\\lambda}_{mm} = 1 / \\bar{X}\\). </p> <p>Note that the moment-matching estimators are not unique. Different theoretical and sample moments can be matched. For example, the second theoretical moment is \\(\\mathbb{E}X^2 = 2 / \\lambda^2\\), leading to an alternative matching equation:</p> \\[ \\bar{X^2} = 2 / \\lambda^2, \\] <p>with the solution:</p> \\[ \\hat{\\lambda}_{mm} = \\sqrt{\\frac{2}{\\bar{X^2}}} = \\sqrt{\\frac{2n}{\\sum^n_{i = 1} X^2_i}}. \\]"},{"location":"estimation_theory/statistical_estimators/unbiasedness_and_consistency_of_estimators/","title":"Unbiasedness and Error of Estimators","text":""},{"location":"estimation_theory/statistical_estimators/unbiasedness_and_consistency_of_estimators/#estimator-and-sampling-distribution","title":"Estimator and Sampling Distribution","text":"<p>Based on a sample \\(X_1, \\ldots, X_n\\) from a population with distribution \\(f(x | \\theta)\\), let \\(\\hat{\\theta}_n = g(X_1, \\ldots, X_n)\\) be an estimator that estimates the parameter \\(\\theta\\). The estimator \\(\\hat{\\theta}_n\\) as a function of the sample is a random variable. As a random variable, the estimator has an expectation of \\(\\mathbb{E}\\hat{\\theta}_n\\), a variance of \\(\\mathbb{V}\\text{ar}\\hat{\\theta}_n\\), and its own distribution called a sampling distribution.</p>"},{"location":"estimation_theory/statistical_estimators/unbiasedness_and_consistency_of_estimators/#bias","title":"Bias","text":"<p>If \\(\\mathbb{\\hat{\\theta}_n} = \\theta\\), then the estimator \\(\\hat{\\theta}\\) is called unbiased. The expectation is taken with respect to the sampling distribution The quantity:</p> \\[ b(\\theta) = \\mathbb{E}\\hat{\\theta}_n - \\theta, \\] <p>is called the bias of the estimator \\(\\hat{\\theta}\\).</p>"},{"location":"estimation_theory/statistical_estimators/unbiasedness_and_consistency_of_estimators/#mean-squared-error","title":"Mean Squared Error","text":"<p>The error in estimation can be assessed by various measures. The usual measure is the mean squared error (MSE) and is defined as:</p> \\[ MSE(\\hat{\\theta}, \\theta) = \\mathbb{E}(\\hat{\\theta}_n - \\theta)^2. \\] <p>The MSE represents the expected squared deviation of the estimator from the parameter it estimates. This expectation is taken with respect to the sampling distribution of \\(\\hat{\\theta}_n\\). From the definiton:</p> \\[ \\begin{align} \\mathbb{E}(\\hat{\\theta}_n - \\theta)^2 &amp;= \\mathbb{E}(\\hat{\\theta}_n - \\mathbb{E}\\hat{\\theta}_n + \\mathbb{E}\\hat{\\theta}_n - \\theta)^2 \\\\ &amp;= \\mathbb{E}(\\hat{\\theta}_n - \\mathbb{E}\\hat{\\theta}_n)^2 - 2 \\mathbb{E}(\\hat{\\theta}_n - \\mathbb{E} \\hat{\\theta}_n) (\\mathbb{E}\\hat{\\theta}_n - \\theta) + (\\mathbb{E} \\hat{\\theta}_n - \\theta)^2 \\\\ &amp;= \\mathbb{E}(\\hat{\\theta}_n - \\mathbb{E}\\hat{\\theta}_n)^2 + (\\mathbb{E}\\hat{\\theta}_n - \\theta)^2. \\end{align} \\] <p>MSE can be respresent as:</p> \\[ MSE(\\hat{\\theta}, \\theta) = \\mathbb{V}\\text{ar} \\hat{\\theta} + b(\\theta)^2. \\]"},{"location":"kinematics/acceleration/","title":"Acceleration","text":""},{"location":"kinematics/acceleration/#definition","title":"Definition","text":"<p>Acceleration is defined as the second time derivative of the position of the origin of one frame with respect to the origin and axes of another frame:</p> \\[ \\mathbf{a}^{\\beta}_{\\beta \\alpha} \\triangleq \\ddot{\\mathbf{r}}^{\\beta}_{\\beta \\alpha}. \\label{6.1} \\] <p>The resolving axes can be changed via transformation matrix:</p> \\[ \\mathbf{a}^{\\gamma}_{\\beta \\alpha} = \\mathbf{R}^{\\gamma}_{\\beta} \\ddot{\\mathbf{r}}^{\\beta}_{\\beta \\alpha}. \\label{6.2} \\] <p>Acceleration is the force per unit mass on the object applied from the reference frame. Its magnitude is necessarily independent of the resolving frame. Furthemore, it is  not the same as the time derivative of \\(\\mathbf{v}^{\\gamma}_{\\beta \\alpha}\\) or the second derivative of \\(\\mathbf{r}^{\\gamma}_{\\beta \\alpha}\\) since these depend on the rotation of the resolving frame, \\(F_{\\gamma}\\), with respect to the reference frame, \\(F_\\beta\\):</p> \\[ \\begin{align} \\mathbf{a}^{\\gamma}_{\\beta \\alpha} &amp;\\neq \\dot{\\mathbf{v}}^{\\gamma}_{\\beta \\alpha} \\\\ \\mathbf{a}^{\\gamma}_{\\beta \\alpha} &amp;\\neq \\ddot{\\mathbf{r}}^{\\gamma}_{\\beta \\alpha}. \\\\ \\end{align} \\label{6.3} \\] <p>The above would hold only if there is no rotation between resolving axes and the reference frame. Using the definition of velocity:</p> \\[ \\begin{align} \\dot{\\mathbf{v}}^{\\gamma}_{\\beta \\alpha} &amp;= \\frac{d}{dt} \\left( \\mathbf{R}^{\\gamma}_{\\beta} \\dot{\\mathbf{r}}^{\\beta}_{\\beta \\alpha} \\right)\\\\ &amp;=  \\dot{\\mathbf{R}}^{\\gamma}_{\\beta} \\dot{\\mathbf{r}}^{\\beta}_{\\beta \\alpha} + \\mathbf{R}^{\\gamma}_{\\beta} \\ddot{\\mathbf{r}}^{\\beta}_{\\beta \\alpha} \\\\ &amp;= \\dot{\\mathbf{R}}^{\\gamma}_{\\beta} \\dot{\\mathbf{r}}^{\\beta}_{\\beta \\alpha} + \\mathbf{a}^{\\gamma}_{\\beta \\alpha}. \\label{6.4} \\end{align} \\] <p>Using the definition of Cartesion position and taking the second derivative yields:</p> \\[ \\begin{align} \\ddot{\\mathbf{r}}^{\\gamma}_{\\beta \\alpha} &amp;= \\frac{d^2}{dt^2} \\left( \\mathbf{R}^{\\gamma}_{\\beta} \\mathbf{r}^{\\beta}_{\\beta \\alpha} \\right) \\\\ &amp;= \\frac{d}{dt} \\left( \\dot{\\mathbf{R}}^{\\gamma}_{\\beta} \\mathbf{r}^{\\beta}_{\\beta \\alpha} + \\mathbf{R}^{\\gamma}_{\\beta} \\dot{\\mathbf{r}}^{\\beta}_{\\beta \\alpha} \\right) \\\\ &amp;= \\ddot{\\mathbf{R}}^{\\gamma}_{\\beta} \\mathbf{r}^{\\beta}_{\\beta \\alpha} + \\dot{\\mathbf{R}}^{\\gamma}_{\\beta} \\dot{\\mathbf{r}}^{\\beta}_{\\beta \\alpha} +  \\dot{\\mathbf{R}}^{\\gamma}_{\\beta} \\dot{\\mathbf{r}}^{\\beta}_{\\beta \\alpha} + \\mathbf{R}^{\\gamma}_{\\beta} \\ddot{\\mathbf{r}}^{\\beta}_{\\beta \\alpha} \\\\ &amp;= \\ddot{\\mathbf{R}}^{\\gamma}_{\\beta} \\mathbf{r}^{\\beta}_{\\beta \\alpha} + \\dot{\\mathbf{R}}^{\\gamma}_{\\beta} \\dot{\\mathbf{r}}^{\\beta}_{\\beta \\alpha}+ \\dot{\\mathbf{v}}^{\\gamma}_{\\beta \\alpha} \\\\ &amp;= \\ddot{\\mathbf{R}}^{\\gamma}_{\\beta} \\mathbf{r}^{\\beta}_{\\beta \\alpha} + 2 \\dot{\\mathbf{R}}^{\\gamma}_{\\beta} \\dot{\\mathbf{r}}^{\\beta}_{\\beta \\alpha} + \\mathbf{a}^{\\gamma}_{\\beta \\alpha}. \\label{6.5} \\end{align} \\] <p>The first term in the last row of equation (\\(\\ref{6.5}\\)) can be expressed by taking the derivative of the equality:</p> \\[ \\dot{\\mathbf{R}}^{\\gamma}_{\\beta} = -\\boldsymbol{\\Omega}^{\\gamma}_{\\beta \\gamma} \\mathbf{R}^{\\gamma}_{\\beta}. \\] <p>The second derivative is:</p> \\[ \\begin{align} \\ddot{\\mathbf{R}}^{\\gamma}_{\\beta} &amp;= \\dot{\\boldsymbol{\\Omega}}^{\\gamma}_{\\beta \\gamma} \\mathbf{R}^{\\gamma}_{\\beta} - \\boldsymbol{\\Omega}^{\\gamma}_{\\beta \\gamma} \\dot{\\mathbf{R}}^{\\gamma}_{\\beta} \\\\ &amp;= -\\dot{\\boldsymbol{\\Omega}}^{\\gamma}_{\\beta \\gamma} \\mathbf{R}^{\\gamma}_{\\beta} + \\boldsymbol{\\Omega}^{\\gamma}_{\\beta \\gamma} \\boldsymbol{\\Omega}^{\\gamma}_{\\beta \\gamma} \\mathbf{R}^{\\gamma}_{\\beta} \\\\ &amp;= \\left( \\boldsymbol{\\Omega}^{\\gamma}_{\\beta \\gamma} \\boldsymbol{\\Omega}^{\\gamma}_{\\beta \\gamma} -  \\dot{\\boldsymbol{\\Omega}}^{\\gamma}_{\\beta \\gamma} \\right) \\mathbf{R}^{\\gamma}_{\\beta}.  \\label{6.6} \\end{align} \\] <p>Substituting back, we get:</p> \\[ \\begin{align} \\ddot{\\mathbf{R}}^{\\gamma}_{\\beta} \\mathbf{r}^{\\beta}_{\\beta \\alpha} &amp;=  \\left( \\boldsymbol{\\Omega}^{\\gamma}_{\\beta \\gamma} \\boldsymbol{\\Omega}^{\\gamma}_{\\beta \\gamma} -  \\dot{\\boldsymbol{\\Omega}}^{\\gamma}_{\\beta \\gamma} \\right) \\mathbf{R}^{\\gamma}_{\\beta} \\mathbf{r}^{\\beta}_{\\beta \\alpha} \\\\ &amp;= \\left( \\boldsymbol{\\Omega}^{\\gamma}_{\\beta \\gamma} \\boldsymbol{\\Omega}^{\\gamma}_{\\beta \\gamma} -  \\dot{\\boldsymbol{\\Omega}}^{\\gamma}_{\\beta \\gamma} \\right) \\mathbf{r}^{\\gamma}_{\\beta \\alpha}. \\label{6.7} \\end{align} \\] <p>Similarly, the second term in the last row of equation \\(\\ref{6.5}\\) can be expressed as:</p> \\[ \\begin{align} \\dot{\\mathbf{R}}^{\\gamma}_{\\beta} \\dot{\\mathbf{r}}^{\\beta}_{\\beta \\alpha} &amp;= -\\boldsymbol{\\Omega}^{\\gamma}_{\\beta \\gamma} \\mathbf{R}^{\\gamma}_{\\beta} \\dot{\\mathbf{r}}^{\\beta}_{\\beta \\alpha} \\\\  &amp;= -\\boldsymbol{\\Omega}^{\\gamma}_{\\beta \\gamma} \\dot{\\mathbf{v}}^{\\gamma}_{\\beta \\alpha} \\\\ &amp;= -\\boldsymbol{\\Omega}^{\\gamma}_{\\beta \\gamma} \\left( \\dot{\\mathbf{r}}^{\\gamma}_{\\beta \\alpha} - \\dot{\\mathbf{R}}^{\\gamma}_{\\beta} \\mathbf{r}^{\\beta}_{\\beta \\alpha} \\right) \\\\ &amp;= -\\boldsymbol{\\Omega}^{\\gamma}_{\\beta \\gamma} \\boldsymbol{\\Omega}^{\\gamma}_{\\beta \\gamma} \\mathbf{r}^{\\gamma}_{\\beta \\alpha} - \\boldsymbol{\\Omega}^{\\gamma}_{\\beta \\gamma} \\dot{\\mathbf{r}}^{\\gamma}_{\\beta \\alpha}. \\label{6.8} \\end{align} \\] <p>Substituting equations (\\(\\ref{6.7}\\)) and (\\(\\ref{6.8}\\)) into (\\(\\ref{6.5}\\)):</p> \\[ \\ddot{\\mathbf{r}}^{\\gamma}_{\\beta \\alpha} = -\\boldsymbol{\\Omega}^{\\gamma}_{\\beta \\gamma} \\boldsymbol{\\Omega}^{\\gamma}_{\\beta \\gamma} \\mathbf{r}^{\\gamma}_{\\beta \\alpha}  - 2 \\boldsymbol{\\Omega}^{\\gamma}_{\\beta \\gamma} \\dot{\\mathbf{r}}^{\\gamma}_{\\beta \\alpha} - \\dot{\\boldsymbol{\\Omega}}^{\\gamma}_{\\beta \\alpha} \\mathbf{r}^{\\gamma}_{\\beta \\alpha} + \\mathbf{a}^{\\gamma}_{\\beta \\alpha}. \\label{6.9} \\] <p>The first three terms are related to the centrifugal, Coriolis, and Euler pseudo-forces. They are called centripetal, Coriolis, and angular accelerations.</p> <p>Addition is not valid if the reference frames are rotating with respect to each other:</p> \\[ \\mathbf{a}^{\\gamma}_{\\beta \\alpha} \\neq \\mathbf{a}^{\\gamma}_{\\beta \\delta} + \\mathbf{a}^{\\gamma}_{\\delta \\alpha}. \\label{6.10} \\] <p>Finally, resolving axes can be changed via transformation matrix:</p> \\[ \\mathbf{a}^{\\gamma}_{\\beta \\alpha} = \\mathbf{R}^{\\gamma}_{\\delta} \\mathbf{a}^{\\delta}_{\\beta \\alpha}. \\label{6.11} \\]"},{"location":"kinematics/acceleration/#rotating-reference-frame","title":"Rotating Reference Frame","text":"<p>Consider an object frame, \\(F_\\alpha\\), that is stationary with respect to a reference frame, \\(F_\\beta\\), that is rotating at a constant rate, \\(\\omega_{ i \\beta}\\) , with respect to an inertial frame, \\(F_i\\).  An observer in inertial frame will see the object moving in circle centered about the axis of rotation of the rotating frame. The position of the object with respect to the inertial frame resolved in inertial frame axes is:</p> \\[ \\begin{align} x^{i}_{i \\alpha}(t) &amp;= r \\text{cos} \\left(\\omega_{i \\beta}t \\right) \\\\ y^{i}_{i \\alpha}(t) &amp;= r \\text{sin} \\left(\\omega_{i \\beta}t \\right). \\label{6.12} \\end{align} \\] <p>Acceleration is:</p> \\[ \\begin{align} \\ddot{x}^{i}_{i \\alpha} (t) &amp;= -\\omega^2_{i \\beta} r \\text{cos} \\left( \\omega_{i \\beta} t \\right) = -\\omega^2_{i \\beta} x^{i}_{i \\alpha} \\\\ \\ddot{y}^{i}_{i \\alpha} (t) &amp;= -\\omega^2_{i \\beta} r \\text{sin} \\left( \\omega_{i \\beta} t \\right) = -\\omega^2_{i \\beta} y^{i}_{i \\alpha}. \\label{6.13} \\\\ \\end{align} \\] <p>Equation (\\(\\ref{6.13}\\)) is the centripetal acceleration due to centripetal force and the acceleration is towards the axis of rotation. An object on a rotating dish must be subject to a  centripetal force in order to remain on the dish.  With respect to the rotating reference frame, the acceleration of the object is zero. The centripetal force is still present, hence, from the perspective of the rotating frame, there must be another force that is equal and opposite to the centripetal force. This is the centrifugal force (pseudo-force).</p> <p>Consider now the object on the rotating dish starts moving towards the axis of rotation at a constant velocity. With respect to the rotating frame, the object is moving at a constant velocity in a straight line, so the acceleration must be zero. With respect to the inertial frame, the object is moving in a curved path and must therefore be accelerating. The object's velocity, with respect to the inertial frame, along the direction of rotation reduces as it approaches the axis of rotation. Therefore, it mut be subject to another force along the direction of opposing rotation as well as to the centripetal force. This force is called Coriolis force. The centrifugal and Coriolis pseudo-accelerations sum to the centripetal acceleration required to describe the object's motion with respect to the rotating frame.</p> <p>Consider the motion of an object frame, \\(F_\\alpha\\), with respect to a rotating reference frame, \\(F_\\beta\\). The pseudo-acceleration, \\(\\mathbf{a}^{P \\beta}_{\\beta \\alpha}\\) is:</p> \\[ \\begin{align} \\mathbf{a}^{P\\beta}_{\\beta \\alpha} &amp;= \\mathbf{a}^{\\beta}_{\\beta \\alpha} - \\left( \\mathbf{a}^{\\beta}_{i \\alpha} - \\mathbf{a}^{\\beta}_{i \\beta} \\right) \\\\ &amp;= \\ddot{\\mathbf{r}}^{\\beta}_{\\beta \\alpha} - \\mathbf{R}^{\\beta}_{i} \\left( \\ddot{\\mathbf{r}}^{i}_{i \\alpha} - \\ddot{\\mathbf{r}}^{i}_{i \\beta}  \\right) \\\\ &amp;= \\ddot{\\mathbf{r}}^{\\beta}_{\\beta \\alpha} - \\mathbf{R}^{\\beta}_{i} \\ddot{\\mathbf{r}}^{i}_{\\beta \\alpha} \\\\ &amp;= -\\boldsymbol{\\Omega}^{\\beta}_{i \\beta} \\boldsymbol{\\Omega}^{\\beta}_{i \\beta} \\mathbf{r}^{\\beta}_{\\beta \\alpha} - 2 \\boldsymbol{\\Omega}^{\\beta}_{i \\beta} \\dot{\\mathbf{r}}^{\\beta}_{\\beta \\alpha} - \\dot{\\boldsymbol{\\Omega}}^{\\beta}_{i \\beta} \\mathbf{r}^{\\beta}_{\\beta \\alpha}. \\label{6.14} \\end{align} \\] <p>The first term is the centrifugal acceleration, the second term is the Coriolis acceleration, and the final term is the Euler acceleration. The Euler force is the third pseudo-force that arises when the reference frame has angular acceleration with respect to the inertial frame. The Coriolis acceleration is always in direction perpendicular to the object's velocity with respect to the rotating reference frame.</p>"},{"location":"kinematics/cartesian_position/","title":"Cartesian Position","text":""},{"location":"kinematics/cartesian_position/#definition-and-properties","title":"Definition and Properties","text":"Figure 1 Cartesian position vector (Groves, p47) <p>As shown in Figure 1, Cartesian position of an origin of frame \\(F_\\alpha\\) with respect to an origin of frame \\(F_\\beta\\) resolved about the axes of frame \\(F_\\gamma\\) is denoted as:</p> \\[ \\mathbf{r}^{\\gamma}_{\\beta \\alpha} =  \\left[ \\begin{array}{ccc} x^{\\gamma}_{\\beta \\alpha} &amp; y^{\\gamma}_{\\beta \\alpha} &amp; z^{\\gamma}_{\\beta \\alpha} \\end{array} \\right]^T. \\] Properties Inverse \\(\\mathbf{r}^{\\gamma}_{\\beta \\alpha} = -\\mathbf{r}^{\\gamma}_{\\alpha \\beta}\\) Addition \\(\\mathbf{r}^{\\gamma}_{\\beta \\alpha} = \\mathbf{r}^{\\gamma}_{\\delta \\alpha} - \\mathbf{r}^{\\gamma}_{\\delta \\beta} = \\mathbf{r}^{\\gamma}_{\\beta \\delta} + \\mathbf{r}^{\\gamma}_{\\delta \\alpha}\\) Resolving Axes Transformation \\(\\begin{align*}\\mathbf{r}^{\\gamma}_{\\beta \\alpha} &amp;= \\mathbf{R}^{\\gamma}_{\\delta} \\mathbf{r}^{\\delta}_{\\beta \\alpha} \\\\ \\mathbf{r}^{\\beta}_{\\beta \\alpha} &amp;= \\mathbf{R}^{\\beta}_{\\delta} \\left( \\mathbf{r}^{\\delta}_{\\beta \\delta} + \\mathbf{r}^{\\delta}_{\\delta \\alpha} \\right) \\\\ &amp;= \\mathbf{r}^{\\beta}_{\\beta \\delta} + \\mathbf{R}^{\\beta}_{\\delta} \\mathbf{r}^{\\delta}_{\\delta \\alpha} \\end{align*}\\)"},{"location":"kinematics/references/","title":"References","text":"<p>Contents are from:</p> <ol> <li>Szeliski, R., Computer Vision: Algorithms and Applications, 2nd Edition</li> <li>Groves, P., Principles of GNSS, Inertial, and Multisensor Integrated Navigation Systems, Second Edition</li> <li>Bernstein D., Geometry, Kinematics, Statics, and Dynamics</li> <li>Barfoot, T., State Estimation for Robotics</li> <li>Gao, X., Introduction to Visual SLAM: From Theory to Practice</li> <li>Eade, E., Lie Groups for 2D and 3D Transformations</li> <li>Hartley, R., Zisserman, A., Multiple View Geometry in Computer Vision, Second Edition</li> <li>Sola, J., Quaternion Kinematics for the Error-State Kalman Filter</li> </ol>"},{"location":"kinematics/velocity/","title":"Velocity","text":""},{"location":"kinematics/velocity/#definition","title":"Definition","text":"<p>Velocity is defined as the rate of change of the position of the origin of an object frame, \\(F_\\alpha\\) with respect to the origin of a reference frame, \\(F_\\beta\\), resolved around the axes of \\(F_\\beta\\):</p> \\[ \\mathbf{v}^{\\beta}_{\\beta \\alpha} \\triangleq \\dot{\\mathbf{r}}^{\\beta}_{\\beta \\alpha}. \\label{5.1} \\] <p>This may, in turn, be resolved about the axes of a third frame, \\(F_\\gamma\\) using the rotation matrix:</p> \\[ \\mathbf{v}^{\\gamma}_{\\beta \\alpha} = \\mathbf{R}^{\\gamma}_{\\beta} \\dot{\\mathbf{r}}^{\\beta}_{\\beta \\alpha} = \\mathbf{R}^{\\gamma}_{\\beta} \\mathbf{v}^\\beta_{\\beta \\alpha}.\\label{5.2} \\] <p>Transport Theorem</p> <p>Velocity, \\(\\mathbf{v}^{\\gamma}_{\\beta \\alpha}\\), is not equal to the time derivative of \\(\\mathbf{r}^{\\gamma}_{\\beta \\alpha}\\) when there is a  rotation of the resolving frame \\(F_\\gamma\\), with respect to the reference frame \\(F_\\beta\\). The time derivative of \\(\\mathbf{r}^{\\gamma}_{\\beta \\alpha}\\) is:</p> \\[ \\begin{align} \\dot{\\mathbf{r}}^{\\gamma}_{\\beta \\alpha} &amp;= \\frac{d}{dt} \\left( \\mathbf{R}^{\\gamma}_{\\beta} \\mathbf{r}^{\\beta}_{\\beta \\alpha} \\right) \\\\ &amp;= \\dot{\\mathbf{R}}^{\\gamma}_{\\beta} \\mathbf{r}^{\\beta}_{\\beta \\alpha} + \\mathbf{R}^{\\gamma}_{\\beta} \\dot{\\mathbf{r}}^{\\beta}_{\\beta \\alpha} \\\\ &amp;= \\dot{\\mathbf{R}}^{\\gamma}_{\\beta} \\mathbf{r}^{\\beta}_{\\beta \\alpha} + \\mathbf{v}^{\\gamma}_{\\beta \\alpha} \\\\ &amp;= \\mathbf{v}^{\\gamma}_{\\beta \\alpha} + \\boldsymbol{\\Omega}^{\\gamma}_{\\gamma \\beta} \\mathbf{R}^\\gamma_\\beta \\mathbf{r}^\\beta_{\\beta \\alpha} \\\\ &amp;= \\mathbf{v}^{\\gamma}_{\\beta \\alpha} + \\boldsymbol{\\Omega}^{\\gamma}_{\\gamma \\beta} \\mathbf{r}^\\gamma_{\\beta \\alpha}. \\label{5.3} \\end{align} \\] <p>which is called the transport theorem. </p>"},{"location":"kinematics/velocity/#velocity-registry","title":"Velocity Registry","text":"<p>Figure 1 shows types of motion that can cause a velocity to register.</p> <p> </p> Figure 1 Motion causing a velocity to register (Groves, p49) <p>Velocity is registered when:</p> <ol> <li>The object frame, \\(F_\\alpha\\), moves with respect to the origin of reference frame, \\(F_\\beta\\)</li> <li>The reference frame, \\(F_\\beta\\), moves with respect to the origin of object frame, \\(F_\\alpha\\)</li> <li>The reference frame, \\(F_\\beta\\), rotates with respect to the origin of object frame, \\(F_\\alpha\\)</li> </ol> <p>Velocity is not registered when:</p> <ol> <li>The object frame, \\(F_\\alpha\\), rotates with respect to the origin of reference frame, \\(F_\\beta\\)</li> </ol>"},{"location":"kinematics/velocity/#properties","title":"Properties","text":"<p>Direction reversal and velocity addition doesn't hold unless there is no rotational motion between the object and the reference frame:</p> \\[ \\begin{align} \\mathbf{v}^{\\gamma}_{\\beta \\alpha} &amp; \\neq \\mathbf{v}^{\\gamma}_{\\beta \\delta} + \\mathbf{v}^{\\gamma}_{\\delta \\alpha} \\\\ \\mathbf{v}^{\\gamma}_{\\alpha \\beta} &amp; \\neq - \\mathbf{v}^{\\gamma}_{\\beta \\alpha}.  \\label{5.4} \\end{align} \\] <p>The correct relationship is:</p> \\[ \\mathbf{v}^{\\gamma}_{\\alpha \\beta} = -\\mathbf{v}^{\\gamma}_{\\beta \\alpha} - \\mathbf{R}^{\\gamma}_{\\alpha} \\dot{\\mathbf{R}}^{\\alpha}_{\\beta} \\mathbf{r}^{\\beta}_{\\beta \\alpha}, \\label{5.5} \\] <p>although:</p> \\[ \\left. \\mathbf{v}^\\gamma_{\\alpha \\beta} \\right|_{\\dot{\\mathbf{R}}^\\alpha_\\beta = 0} =  - \\mathbf{v}^{\\gamma}_{\\beta \\alpha}. \\] <p>Velocity may be transformed from one resolving frame to another using the appropriate coordinate transformation matrix:</p> \\[ \\mathbf{v}^{\\delta}_{\\beta \\alpha} = \\mathbf{R}^\\delta_\\gamma \\mathbf{v}^{\\gamma}_{\\beta \\alpha}. \\] <p>Speed is the magnitude of the velocity and is independent of the resolving axes, so \\(v_{\\beta \\alpha} = |\\mathbf{v}^\\gamma_{\\beta \\alpha}|\\). However, the magnitude of the time derivative of velocity, \\(|\\dot{\\mathbf{v}^\\gamma_{\\beta \\alpha}}|\\), is dependent on the choice of the resolving frame.</p>"},{"location":"kinematics/jacobians_of_rotations_and_poses/perturbed_poses_via_rotation_vector/","title":"Perturbed Poses via Rotation Vector","text":""},{"location":"kinematics/jacobians_of_rotations_and_poses/perturbed_poses_via_rotation_vector/#definition","title":"Definition","text":"<p>Suppose a point \\(\\mathbf{v}\\) is transformed by \\(\\mathbf{T} \\in SE(3)\\) with corresponding Lie algebra vector \\(\\boldsymbol{\\xi}\\), and the result is \\(\\mathbf{T} \\mathbf{v}\\). Note that \\(\\mathbf{v}\\) is in homogeneous coordinates. Left perturb \\(\\mathbf{T}\\) with \\(\\Delta \\mathbf{T} = \\exp \\left[ \\Delta \\boldsymbol{\\xi} \\right]_\\times\\) with Lie algebra vector \\(\\Delta \\boldsymbol{\\xi} = \\left[ \\begin{array}{cc} \\Delta \\boldsymbol{\\ell} &amp; \\Delta \\boldsymbol{\\rho} \\end{array} \\right]^T\\). We have:</p> \\[ \\begin{align} \\frac{\\partial \\left( \\mathbf{T} \\mathbf{v} \\right)}{\\partial \\Delta \\boldsymbol{\\xi}} &amp;= \\lim_{\\Delta \\boldsymbol{\\xi} \\rightarrow \\mathbf{0}} \\frac{\\exp \\left[ \\Delta \\boldsymbol{\\xi} \\right]_\\times \\exp \\left[ \\boldsymbol{\\xi} \\right]_\\times \\mathbf{v} - \\exp\\left[\\boldsymbol{\\xi} \\right]_\\times \\mathbf{v}}{\\Delta \\boldsymbol{\\xi}} \\\\ &amp;= \\lim_{\\Delta \\boldsymbol{\\xi} \\rightarrow \\mathbf{0}} \\frac{\\left( \\mathbf{I} + \\left[ \\Delta \\boldsymbol{\\xi} \\right]_\\times \\right) \\exp \\left[ \\boldsymbol{\\xi} \\right]_\\times \\mathbf{v} - \\exp \\left[ \\boldsymbol{\\xi} \\right]_\\times \\mathbf{v}}{\\Delta \\boldsymbol{\\xi}} \\\\ &amp;= \\lim_{\\Delta \\boldsymbol{\\xi} \\rightarrow \\mathbf{0}} \\frac{\\left[ \\Delta \\boldsymbol{\\xi} \\right]_\\times \\exp \\left[ \\boldsymbol{\\xi} \\right]_\\times \\mathbf{v}}{\\Delta \\boldsymbol{\\xi}} \\\\ &amp;= \\lim_{\\Delta \\boldsymbol{\\xi} \\rightarrow \\mathbf{0}} \\frac{\\left[ \\begin{array}{cc} \\left[ \\Delta \\boldsymbol{\\rho} \\right]_\\times &amp; \\Delta \\boldsymbol{\\ell} \\\\ \\mathbf{0}^T &amp; 0 \\end{array} \\right] \\left[\\begin{array}{c} \\mathbf{R} \\mathbf{v} + \\mathbf{t} \\\\ 1 \\end{array} \\right]}{\\Delta \\boldsymbol{\\xi}} \\\\ &amp;= \\lim_{\\Delta \\boldsymbol{\\xi} \\rightarrow \\mathbf{0}} \\frac{\\left[ \\begin{array}{cc} \\left[\\Delta \\boldsymbol{\\rho}  \\right]_\\times \\left( \\mathbf{R} \\mathbf{v} + \\mathbf{t} \\right) + \\Delta \\boldsymbol{\\ell} \\\\ \\mathbf{0}^T \\end{array} \\right]}{\\left[ \\begin{array}{cc} \\Delta \\boldsymbol{\\ell} &amp; \\Delta \\boldsymbol{\\rho} \\end{array} \\right]^T} \\\\ &amp;= \\left[ \\begin{array}{cc} \\mathbf{I} &amp; -\\left[ \\mathbf{R} \\mathbf{v} + \\mathbf{t} \\right]_\\times \\\\ \\mathbf{0}^T &amp; \\mathbf{0}^T \\end{array} \\right]. \\end{align} \\]"},{"location":"kinematics/jacobians_of_rotations_and_poses/perturbed_rotations_via_euler_angles/","title":"Perturbed Rotations via Euler Angles","text":""},{"location":"kinematics/jacobians_of_rotations_and_poses/perturbed_rotations_via_euler_angles/#general-perturbation-theory","title":"General Perturbation Theory","text":"<p>Given a scalar function, \\(f(\\mathbf{x}) \\in \\mathbb{R}\\) of some vector variable, \\(\\mathbf{x} \\in \\mathbb{R}^n\\), perturbing \\(\\mathbf{x}\\) slightly from its nominal value, \\(\\bar{\\mathbf{x}}\\), by an amount \\(\\delta \\mathbf{x}\\) will result a change in the function. Consider a standard Taylor series expansion of \\(f(\\mathbf{x})\\) around its nominal value, \\(\\bar{\\mathbf{x}}\\):</p> \\[ f(\\mathbf{x}) \\approx \\left. f(\\mathbf{x}) \\right|_{\\mathbf{x} = \\bar{\\mathbf{x}}} + \\left. \\nabla^T f(\\mathbf{x}) \\right|_{\\mathbf{x} = \\bar{\\mathbf{x}}} \\left( \\mathbf{x} - \\bar{\\mathbf{x}} \\right) + \\frac{1}{2} \\left( \\mathbf{x} - \\bar{\\mathbf{x}} \\right)^T \\nabla^2 \\left. f(\\mathbf{x}) \\right|_{\\mathbf{x} = \\bar{\\mathbf{x}}} \\left(\\mathbf{x} - \\bar{\\mathbf{x}} \\right) + \\ldots. \\] <p>For convergence, we need \\(\\mathbf{x} - \\bar{\\mathbf{x}}\\) to be small in magnitude. Let \\(\\delta \\mathbf{x} = \\mathbf{x} - \\bar{\\mathbf{x}}\\) (or equivalently \\(\\mathbf{x} = \\bar{\\mathbf{x}} + \\delta \\mathbf{x}\\)). Substituting back and considering only the first-order approxmation yields to:</p> \\[ f(\\bar{\\mathbf{x}} + \\delta \\mathbf{x}) \\approx f(\\bar{\\mathbf{x}}) + \\left. \\frac{\\partial f(\\mathbf{x})}{\\partial \\mathbf{x}} \\right|_{\\mathbf{x} = \\bar{\\mathbf{x}}} \\delta \\mathbf{x}. \\]"},{"location":"kinematics/jacobians_of_rotations_and_poses/perturbed_rotations_via_euler_angles/#perturbing-a-rotation-matrix-via-euler-angles","title":"Perturbing a Rotation Matrix via Euler Angles","text":"<p>Most of the rotation representations involve constraints and thus are not easily perturbed (without enforcing the constraint). The notable exceptions are the Euler angle sets. Euler angles representation contains exactly three parameters, and thus each can be varied independently.</p> <p>Consider perturbing \\(\\mathbf{R}(\\boldsymbol{\\theta}) \\mathbf{v}\\) with respect to Euler angles \\(\\boldsymbol{\\theta}\\), where \\(\\mathbf{v}\\) is an arbitrary constant vector. Let \\(\\bar{\\boldsymbol{\\theta}} = (\\bar{\\theta}_1, \\bar{\\theta}_2. \\bar{\\theta}_3)\\) be the nominal Euler angles and \\(\\delta \\boldsymbol{\\theta} = \\left(\\delta \\theta_1, \\delta \\theta_2, \\delta \\theta_3 \\right)\\) be the perturbation angles. Applying a first-order Taylor-series approximation and using the previously derived Jacobian:</p> \\[ \\begin{align} \\mathbf{R}(\\bar{\\boldsymbol{\\theta}} + \\delta{\\boldsymbol{\\theta}}) \\mathbf{v} &amp;\\approx \\mathbf{R}(\\bar{\\boldsymbol{\\theta}}) \\mathbf{v}+ \\left.\\frac{\\partial (\\mathbf{R}(\\boldsymbol{\\theta})\\mathbf{v})}{\\partial \\boldsymbol{\\theta}} \\right|_{\\bar{\\boldsymbol{\\theta}}} \\delta \\boldsymbol{\\theta} \\\\ &amp;= \\mathbf{R}(\\bar{\\boldsymbol{\\theta}}) \\mathbf{v} + \\biggl. \\biggl( \\left[ \\mathbf{R}(\\boldsymbol{\\theta}) \\mathbf{v} \\right]_\\times \\mathbf{S} \\left( \\theta_2, \\theta_3 \\right) \\biggr) \\biggr|_{\\bar{\\boldsymbol{\\theta}}} \\ \\delta \\boldsymbol{\\theta} \\\\ &amp;= \\mathbf{R}(\\bar{\\boldsymbol{\\theta}}) \\mathbf{v} + \\left[ \\mathbf{R}(\\bar{\\boldsymbol{\\theta}}) \\mathbf{v} \\right]_\\times \\mathbf{S}(\\bar{\\theta}_2, \\bar{\\theta}_3) \\delta \\boldsymbol{{\\theta}} \\\\ &amp;= \\mathbf{R}(\\bar{\\boldsymbol{\\theta}}) \\mathbf{v} - \\left[ \\mathbf{S}(\\bar{\\theta}_2, \\bar{\\theta}_3) \\delta \\boldsymbol{{\\theta}} \\right]_\\times \\left(\\mathbf{R}(\\bar{\\boldsymbol{\\theta}}) \\mathbf{v} \\right) \\\\ &amp;= \\biggl( \\mathbf{I} - \\left[ \\mathbf{S}(\\bar{\\theta}_2, \\bar{\\theta}_3) \\delta \\boldsymbol{\\theta} \\right]_\\times \\biggr) \\mathbf{R}(\\bar{\\boldsymbol{\\theta}}) \\mathbf{v}. \\end{align} \\] <p>Since \\(\\mathbf{v}\\) is arbitrary, it can be dropped from both sides:</p> \\[ \\begin{align} \\mathbf{R}(\\bar{\\boldsymbol{\\theta}} + \\delta \\boldsymbol{\\theta}) &amp;\\approx \\underbrace{\\biggl( \\mathbf{I} - \\left[ \\mathbf{S}(\\bar{\\theta}_2, \\bar{\\theta}_3) \\delta \\boldsymbol{\\theta} \\right]_\\times \\biggr)}_{\\text{infinitesimal rotation matrix}} \\mathbf{R}(\\bar{\\boldsymbol{\\theta}}) \\\\ &amp;= \\left( \\mathbf{I} - \\left[\\delta \\boldsymbol{\\phi} \\right]_\\times \\right) \\mathbf{R}(\\bar{\\boldsymbol{\\theta}}), \\end{align} \\] <p>where:</p> \\[ \\delta \\boldsymbol{\\phi} = \\mathbf{S}(\\bar{\\theta}_2, \\bar{\\theta}_3) \\delta \\boldsymbol{\\theta}. \\] <p>This is a perturbation of a rotation matrix (in terms of perturbations to its Euler angles) expressed as a linearized rotation.</p>"},{"location":"kinematics/jacobians_of_rotations_and_poses/perturbed_rotations_via_euler_angles/#example","title":"Example","text":"<p>Let \\(J\\) be a scalar function:</p> \\[ J(\\boldsymbol{\\theta}) = \\mathbf{u}^T \\mathbf{R}(\\boldsymbol{\\theta}) \\mathbf{v}, \\] <p>where \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\) are arbitrary vectors. Linearizing the rotation yields to:</p> \\[ J(\\bar{\\boldsymbol{\\theta}} + \\delta \\boldsymbol{\\theta}) \\approx \\mathbf{u}^T \\left( \\mathbf{I} - \\left[\\delta \\boldsymbol{\\phi} \\right]_\\times \\right) \\mathbf{R}(\\bar{\\boldsymbol{\\theta}}) \\mathbf{v} =  \\underbrace{\\mathbf{u}^T \\mathbf{R}(\\bar{\\boldsymbol{\\theta}}) \\mathbf{v}}_{J(\\bar{\\boldsymbol{\\theta}})} + \\underbrace{\\mathbf{u}^T \\biggl[\\mathbf{R}(\\bar{\\boldsymbol{\\theta}}) \\mathbf{v} \\biggr]_\\times \\delta \\boldsymbol{\\phi}}_{\\delta J(\\delta \\boldsymbol{\\theta})}, \\] <p>so that the linearized function is:</p> \\[ \\delta J(\\delta \\boldsymbol{\\theta}) = \\underbrace{\\biggl( \\mathbf{u}^T \\left[ \\mathbf{R}(\\bar{\\boldsymbol{\\theta}}) \\mathbf{v} \\right]_\\times \\mathbf{S}(\\bar{\\theta}_2, \\bar{\\theta}_3) \\biggr) \\delta \\boldsymbol{\\theta}}_{\\text{const}}, \\] <p>where the factor in front of \\(\\delta \\boldsymbol{\\theta}\\) is constant; in fact, it is \\(\\left. \\frac{\\partial J}{\\partial \\boldsymbol{\\theta}} \\right|_{\\bar{\\boldsymbol{\\theta}}}\\), the Jacobian of J with respect to \\(\\boldsymbol{\\theta}\\).</p>"},{"location":"kinematics/jacobians_of_rotations_and_poses/perturbed_rotations_via_rotation_vector/","title":"Perturbed Rotations via Rotation Vector","text":""},{"location":"kinematics/jacobians_of_rotations_and_poses/perturbed_rotations_via_rotation_vector/#definition","title":"Definition","text":"<p>Perturbation via rotation vector provides a new way of computing the Jacobian of a rotation matrix with respect to the rotation vector. The previous derivation requires to compute the left Jacobian which could be complicated.</p> <p>Consider a left perturbation of a rotation matrix \\(\\mathbf{R}\\) with Lie algebra vector \\(\\boldsymbol{\\rho}\\) by \\(\\Delta \\mathbf{R}\\) with Lie algebra vector \\(\\Delta \\boldsymbol{\\rho}\\).  The change of result relative to this disturbance for a vector \\(\\mathbf{v} \\in \\mathbb{R}^3\\) is:</p> \\[ \\begin{align} \\frac{\\partial \\left(\\mathbf{R} \\mathbf{v}\\right)}{\\partial \\Delta \\boldsymbol{\\rho}} &amp;= \\lim_{\\Delta \\boldsymbol{\\rho} \\rightarrow \\mathbf{0}} \\frac{\\exp \\left[\\Delta \\boldsymbol{\\rho} \\right]_\\times \\exp \\left[ \\boldsymbol{\\rho}\\right]_\\times \\mathbf{v} - \\exp \\left[ \\boldsymbol{\\rho} \\right]_\\times \\mathbf{v}}{\\Delta \\boldsymbol{\\rho}} \\\\ &amp;= \\lim_{\\Delta \\boldsymbol{\\rho} \\rightarrow \\mathbf{0}} \\frac{\\left(\\mathbf{I} + \\left[\\Delta \\boldsymbol{\\rho} \\right]_\\times \\right) \\exp \\left[ \\boldsymbol{\\rho} \\right]_\\times \\mathbf{v} - \\exp \\left[ \\boldsymbol{\\rho} \\right]_\\times \\mathbf{v}}{\\Delta \\boldsymbol{\\rho}} \\\\ &amp;= \\lim_{\\Delta \\boldsymbol{\\rho} \\rightarrow \\mathbf{0}} \\frac{\\left[\\Delta \\boldsymbol{\\rho} \\right]_\\times \\mathbf{R} \\mathbf{v}}{\\Delta \\boldsymbol{\\rho}} \\\\ &amp;= \\lim_{\\Delta \\boldsymbol{\\rho} \\rightarrow \\mathbf{0}} \\frac{-\\left[ \\mathbf{R} \\mathbf{v} \\right]_\\times \\Delta \\boldsymbol{\\rho}}{\\Delta \\boldsymbol{\\rho}} \\\\ &amp;= -\\left[ \\mathbf{R} \\mathbf{v} \\right]_\\times. \\end{align} \\] <p>Note that the calculation of a left Jacobian, \\(\\mathbf{J}_l\\) is omitted compared to the direct Lie algebra's derivation. This makes perturbation model much more practical.</p>"},{"location":"kinematics/lie_group_and_lie_algebra/derivative_and_perturbation_definitions/","title":"Derivative and Perturbation Definitions","text":""},{"location":"kinematics/lie_group_and_lie_algebra/derivative_and_perturbation_definitions/#definitions","title":"Definitions","text":"<p>There are four types of derivative and perturbation definitions as summarized in the table below.</p> Function Type Conditions Derivative and Perturbation Vector Space to Vector Space Given a function \\(f \\ : \\ \\mathbb{R}^m \\rightarrow \\mathbb{R}^n\\) with operator \\(\\left\\{+, - \\right\\}\\) and \\(\\mathbf{x} \\in \\mathbb{R}^m\\) \\(\\begin{align*} \\frac{\\partial f(\\mathbf{x})}{\\partial \\mathbf{x}} &amp;\\triangleq \\lim_{\\delta \\mathbf{x} \\rightarrow \\mathbf{0}} \\frac{f(\\mathbf{x} + \\delta \\mathbf{x}) - f(\\mathbf{x})}{\\delta \\mathbf{x}} \\in \\mathbb{R}^{n \\times m} \\\\ f(\\mathbf{x} + \\Delta \\mathbf{x}) &amp;\\approx f(\\mathbf{x}) + \\frac{\\partial f(\\mathbf{x})}{\\partial \\mathbf{x}} \\Delta \\mathbf{x} \\in \\mathbb{R}^n \\end{align*}\\) \\(SO(3)\\) to \\(SO(3)\\) Given a function \\(f \\ : \\ SO(3) \\rightarrow SO(3)\\) with operator \\(\\left\\{ \\oplus, \\ominus \\right\\}\\), \\(\\mathbf{R} \\in SO(3)\\) and a local, small angular variation \\(\\boldsymbol{\\theta} \\in \\mathbb{R}^3\\) \\(\\begin{align*}\\frac{\\partial f(\\mathbf{R})}{\\partial \\boldsymbol{\\theta}} &amp;\\triangleq \\lim_{\\delta \\boldsymbol{\\theta} \\rightarrow \\mathbf{0}} \\frac{f(\\mathbf{R} \\oplus \\delta \\boldsymbol{\\theta}) \\ominus f(\\mathbf{R})}{\\delta \\boldsymbol{\\theta}} \\\\ &amp;= \\lim_{\\delta \\boldsymbol{\\theta} \\rightarrow \\mathbf{0}} \\frac{\\left[ \\ln \\left( f^{-1}(\\mathbf{R}) f(\\mathbf{R} \\exp \\left[ \\delta \\boldsymbol{\\theta} \\right]_\\times ) \\right) \\right]_{-\\times}}{\\delta \\boldsymbol{\\theta}} \\in \\mathbb{R}^{3 \\times 3} \\\\ f(\\mathbf{R} \\oplus \\Delta \\boldsymbol{\\theta}) &amp;\\approx f(\\mathbf{R}) \\oplus \\frac{\\partial f(\\mathbf{R})}{\\partial \\boldsymbol{\\theta}} \\Delta \\boldsymbol{\\theta} \\\\ &amp;\\triangleq f(\\mathbf{R}) \\exp \\left[ \\frac{\\partial f(\\mathbf{R})}{\\partial \\boldsymbol{\\theta}} \\Delta \\boldsymbol{\\theta} \\right]_\\times \\in SO(3) \\end{align*}\\) Vector Space to \\(SO(3)\\) Given a function \\(f \\ : \\ \\mathbb{R}^m \\rightarrow SO(3)\\) with operator \\(\\left\\{+, \\ominus \\right\\}\\) and \\(\\mathbf{x} \\in \\mathbb{R}^m\\) \\(\\begin{align*} \\frac{\\partial f(\\mathbf{x})}{\\partial \\mathbf{x}} &amp;\\triangleq \\lim_{\\delta \\mathbf{x} \\rightarrow \\mathbf{0}} \\frac{f(\\mathbf{x} + \\delta \\mathbf{x}) \\ominus f(\\mathbf{x})}{\\delta \\mathbf{x}} \\\\ &amp;= \\lim_{\\delta \\mathbf{x} \\rightarrow \\mathbf{0}} \\frac{\\left[ \\ln \\left(f^{-1}(\\mathbf{x}) f(\\mathbf{x + \\delta \\mathbf{x}}) \\right) \\right]_{-\\times}}{\\delta \\mathbf{x}} \\in \\mathbb{R}^{3 \\times m} \\\\ f(\\mathbf{x} + \\Delta \\mathbf{x}) &amp;\\approx f(\\mathbf{x}) \\oplus \\frac{\\partial f(\\mathbf{x})}{\\partial \\mathbf{x}} \\Delta \\mathbf{x} \\triangleq f(\\mathbf{x}) \\exp \\left( \\left[ \\frac{\\partial f(\\mathbf{x})}{\\partial \\mathbf{x}} \\Delta \\mathbf{x} \\right]_\\times \\right) \\in SO(3) \\end{align*}\\) \\(SO(3)\\) to Vector Space Given \\(f \\ : \\ SO(3) \\rightarrow \\mathbb{R}^n\\) with operator \\(\\left\\{\\oplus, - \\right\\}\\) and \\(\\boldsymbol{\\theta} \\in \\mathbb{R}^3, \\ \\mathbf{R} \\in SO(3)\\) \\(\\begin{align*} \\frac{\\partial f(\\mathbf{R})}{\\partial \\boldsymbol{\\theta}} &amp;\\triangleq \\lim_{\\delta \\boldsymbol{\\theta} \\rightarrow \\mathbf{0}} \\frac{f(\\mathbf{R} \\oplus \\boldsymbol {\\theta}) - f(\\mathbf{R})}{\\delta \\boldsymbol{\\theta}} \\\\ &amp;= \\lim_{\\delta \\boldsymbol{\\theta} \\rightarrow \\mathbf{0}} \\frac{f(\\mathbf{R} \\exp \\left[ \\delta \\boldsymbol{\\theta} \\right]_\\times) - f(\\mathbf{R})}{\\delta \\boldsymbol{\\theta}} \\in \\mathbb{R}^{n \\times 3} \\\\ f(\\mathbf{R} \\oplus \\Delta \\boldsymbol{\\theta}) &amp;\\approx f(\\mathbf{R}) + \\frac{\\partial f(\\mathbf{R})}{\\partial \\boldsymbol{\\theta}} \\Delta \\boldsymbol{\\theta} \\\\ &amp;\\triangleq f(\\mathbf{R}) + \\exp \\left[ \\frac{\\partial f(\\mathbf{R})}{\\partial \\boldsymbol{\\theta}} \\Delta \\boldsymbol{\\theta} \\right]_\\times \\in \\mathbb{R}^n \\end{align*}\\)"},{"location":"kinematics/lie_group_and_lie_algebra/derivative_and_perturbation_definitions/#references","title":"References","text":"<ol> <li>Barfoot, T., State Estimation for Robotics</li> <li>Sol\u00e0, J., Quaternion Kinematics for the Error-State Kalman Filter, 2017</li> </ol>"},{"location":"kinematics/lie_group_and_lie_algebra/difference_interpolation_and_perturbation/","title":"Difference, Interpolation, and Perturbation","text":""},{"location":"kinematics/lie_group_and_lie_algebra/difference_interpolation_and_perturbation/#definition","title":"Definition","text":"Special Orthogonal Group Special Euclidean Group Difference Given \\(\\mathbf{R}_1, \\mathbf{R}_2, \\mathbf{R}_{12} \\in SO(3)\\), where \\(\\mathbf{R}_{12}\\) is the attitude difference between \\(\\mathbf{R}_1\\) and \\(\\mathbf{R}_2\\), we have:  \\(\\begin{align*} &amp;\\mathbf{R}_1 \\mathbf{R}_{12} = \\mathbf{R}_2 \\\\ &amp;\\boldsymbol{\\rho}_{12} = \\left[ \\ln \\mathbf{R}_{12} \\right]_{-\\times} = \\left[ \\ln \\mathbf{R}^T_1 \\mathbf{R}_2  \\right]_{-\\times} \\end{align*}\\) Perturbation on Lie Group Let \\(\\mathbf{R}, \\Delta \\mathbf{R} \\in SO(3)\\) and \\(\\boldsymbol{\\rho}, \\Delta \\boldsymbol{\\rho} \\in \\mathfrak{so}(3)\\) the corresponding Lie algebras. Then:  \\(\\begin{align*} \\Delta \\mathbf{R} \\mathbf{R} &amp;= \\exp\\left(\\left[\\Delta\\boldsymbol{\\rho} \\right]_\\times \\right) \\exp\\left(\\left[\\boldsymbol{\\rho} \\right]_\\times \\right) \\\\ &amp;= \\exp \\bigl( \\left[ \\boldsymbol{\\rho} + \\mathbf{J}^{-1}_l (\\boldsymbol{\\rho}) \\Delta \\boldsymbol{\\rho} \\right]_\\times \\bigr) \\end{align*}\\) Perturbation on Lie Algebra If we do an addition on Lie algebra vector \\(\\boldsymbol{\\rho}\\) by perturbing it with \\(\\Delta \\boldsymbol{\\rho}\\), we can approximate the multiplication on the Lie group as:  \\(\\begin{align*} \\exp \\left( \\left[\\boldsymbol{\\rho} + \\Delta \\boldsymbol{\\rho} \\right]_\\times \\right) &amp;= \\exp \\left( \\left[ \\mathbf{J}_l \\Delta \\boldsymbol{\\rho} \\right]_\\times \\right) \\exp \\left( \\left[ \\boldsymbol{\\rho} \\right]_\\times \\right) \\\\ &amp;= \\exp \\left( \\left[\\boldsymbol{\\rho} \\right]_\\times \\right) \\exp \\left(\\left[ \\mathbf{J}_r \\Delta \\boldsymbol{\\rho} \\right]_\\times \\right). \\end{align*}\\)"},{"location":"kinematics/lie_group_and_lie_algebra/jacobians/","title":"Jacobians","text":""},{"location":"kinematics/lie_group_and_lie_algebra/jacobians/#definition","title":"Definition","text":"<p>Consider a rotation matrix \\(\\mathbf{R} \\in SO(3)\\) with Lie algebra \\(\\left[ \\boldsymbol{\\rho} \\right]_\\times = \\left[ \\phi \\mathbf{u} \\right]_\\times\\) where \\(\\phi \\in \\mathbb{R}\\) is the angle of rotation and \\(\\mathbf{u} \\in \\mathbb{R}^3\\) is the unit axis of rotation vector. Multiple Jacobians can be derived in this setting:</p> Jacobian Supplementary Jacobian with respect to the rotated vector, \\(\\mathbf{x}\\) \\(\\begin{align*} \\frac{\\partial \\left(\\mathbf{R} \\mathbf{x} \\right)}{\\partial \\mathbf{x}} = \\frac{\\partial \\left( \\mathbf{q} \\otimes \\mathbf{x} \\otimes \\mathbf{q} \\right)}{\\partial \\mathbf{x}} = \\mathbf{R} \\in SO(3) \\end{align*}\\) Jacobian with respect to the angle of rotation, \\(\\phi\\) Using Rodrigues' formula \\(\\mathbf{R} = \\cos \\phi \\mathbf{I} + \\left( 1- \\cos \\phi \\right) \\hat{\\mathbf{e}} \\hat{\\mathbf{e}}^T - \\sin \\phi \\left[ \\hat{\\mathbf{e}} \\right]_\\times\\), we have:  \\(\\begin{align*} \\frac{ \\partial \\mathbf{R}}{\\partial \\phi} &amp;= - \\sin \\phi \\mathbf{I} + \\sin \\phi \\hat{\\mathbf{e}} \\hat{\\mathbf{e}}^T - \\cos \\phi \\left[ \\hat{\\mathbf{e}} \\right]_\\times \\\\  &amp;= \\sin \\phi \\underbrace{\\left( -\\mathbf{I} + \\hat{\\mathbf{e}} \\hat{\\mathbf{e}}^T \\right)}_{\\left[ \\hat{\\mathbf{e}} \\right]^2_\\times} - \\cos \\phi \\left[ \\hat{\\mathbf{e}} \\right]_\\times \\\\ &amp;= -\\cos \\phi \\left[ \\hat{\\mathbf{e}} \\right]_\\times -  (1 - \\cos \\phi) \\underbrace{\\left[ \\hat{\\mathbf{e}} \\right]_\\times \\hat{\\mathbf{e}}}_{\\mathbf{0}}  \\hat{\\mathbf{e}}^T + \\sin \\phi \\left[ \\hat{\\mathbf{e}} \\right]^2_\\times \\\\ &amp;= -\\left[ \\hat{\\mathbf{e}} \\right]_\\times \\underbrace{\\left(\\cos \\phi \\mathbf{I} + (1 - \\cos \\phi) \\hat{\\mathbf{e}} \\hat{\\mathbf{e}}^T - \\sin \\phi \\left[ \\hat{\\mathbf{e}} \\right]_\\times \\right)}_{\\mathbf{R}} \\\\ &amp;= - \\left[ \\hat{\\mathbf{e}} \\right]_\\times \\mathbf{R} \\end{align*}\\) Jacobian with respect to the rotation vector, \\(\\boldsymbol{\\rho}\\) Consider a rotation of an arbitrary vector \\(\\mathbf{x} \\in \\mathbb{R}^3\\). We have:  \\(\\begin{align*} \\frac{\\partial \\left( \\mathbf{R} \\mathbf{x} \\right)}{\\partial \\boldsymbol  {\\rho}} &amp;= \\lim_{\\delta \\boldsymbol{\\rho} \\rightarrow 0}  \\frac{\\exp \\left( \\left[ \\boldsymbol{\\rho} + \\delta \\boldsymbol{\\rho} \\right]_\\times \\right) \\mathbf{x} - \\exp \\left(\\left[ \\boldsymbol{\\rho} \\right]_\\times \\right) \\mathbf{x}}{\\delta \\boldsymbol{\\rho}} \\\\ &amp;= \\lim_{\\delta \\boldsymbol{\\rho} \\rightarrow \\mathbf{0}}  \\frac{\\exp \\left( \\left[ \\mathbf{J}_l \\delta \\boldsymbol{\\rho} \\right]_\\times \\right) \\exp \\left(\\left[ \\boldsymbol{\\rho} \\right]_\\times\\right) \\mathbf{x} - \\exp \\left(\\left[ \\boldsymbol{\\rho} \\right]_\\times\\right) \\mathbf{x}}{\\delta \\boldsymbol{\\rho}} \\\\ &amp;= \\lim_{\\delta \\boldsymbol{\\rho} \\rightarrow \\mathbf{0}}  \\frac{\\left(\\mathbf{I} + \\left[ \\mathbf{J}_l \\delta \\boldsymbol{\\rho} \\right]_\\times \\right) \\exp \\left( \\left[ \\boldsymbol{\\rho} \\right]_\\times\\right) \\mathbf{x} - \\exp \\left(\\left[ \\boldsymbol{\\rho} \\right]_\\times\\right) \\mathbf{x}}{\\delta \\boldsymbol{\\rho}} \\\\ &amp;= \\lim_{\\delta \\boldsymbol{\\rho} \\rightarrow \\mathbf{0}}  \\frac{\\left[ \\mathbf{J}_l \\delta \\boldsymbol{\\rho} \\right]_\\times  \\exp \\left(\\left[ \\boldsymbol{\\rho} \\right]_\\times\\right) \\mathbf{x}}{\\delta \\boldsymbol{\\rho}} \\\\ &amp;= \\lim_{\\delta \\boldsymbol{\\rho} \\rightarrow \\mathbf{0}}  \\frac{-\\left[ \\exp \\left(\\left[ \\boldsymbol{\\rho} \\right]_\\times\\right) \\mathbf{x} \\right]_\\times \\mathbf{J}_l \\delta \\boldsymbol{\\rho}}{\\delta \\boldsymbol{\\rho}} \\\\ &amp;= - \\left[ \\mathbf{R} \\mathbf{x} \\right]_\\times \\mathbf{J}_l(\\boldsymbol{\\rho}) \\\\ &amp;= -\\mathbf{R} \\left[ \\mathbf{x} \\right]_\\times \\mathbf{R}^T \\mathbf{R} \\mathbf{J}_r (\\boldsymbol{\\rho}) = -\\mathbf{R} \\left[ \\mathbf{x} \\right]_\\times \\mathbf{J}_r (\\boldsymbol{\\rho}) \\end{align*}\\) Per Barfoot, the directional derivatives (along the \\(i\\)'th axes \\(\\mathbf{I}\\), denoted as \\(\\mathbf{I}_i\\)) with respect to \\(\\rho_i\\) is:  \\(\\begin{align*} \\frac{\\partial \\left( \\mathbf{R} \\mathbf{x} \\right)}{\\partial \\rho_i} = \\lim_{h \\rightarrow 0} \\frac{\\exp \\left( \\left[ \\boldsymbol{\\rho} + h \\mathbf{I}_i \\right]_\\times \\right) \\mathbf{x} - \\exp \\left(\\left[ \\boldsymbol{\\rho} \\right]_\\times \\right) \\mathbf{x}}{h} \\end{align*}\\)  Since we are interested in the limit of \\(h\\) infinitely small, using the BCH formula, we get:  \\(\\begin{align*} \\exp \\left( \\left[ \\boldsymbol{\\rho} + h \\mathbf{I}_i \\right]_\\times \\right) &amp;\\approx \\exp \\left( \\left[ \\mathbf{J}_l h \\mathbf{I}_i \\right]_\\times \\right) \\exp \\left( \\left[ \\boldsymbol{\\rho} \\right]_\\times \\right) \\\\ &amp;\\approx \\left(1 + h \\left[ \\mathbf{J}_l \\mathbf{I}_i \\right]_\\times \\right) \\exp \\left( \\left[ \\boldsymbol{\\rho} \\right]_\\times \\right) \\end{align*}\\)  Finally, we have:  \\(\\begin{align*} \\frac{\\partial \\left( \\mathbf{R} \\mathbf{x} \\right)}{\\partial \\rho_i} = \\left[ \\mathbf{J}_l \\mathbf{I}_i \\right]_\\times \\mathbf{R} \\mathbf{x} = - \\left[\\mathbf{R} \\mathbf{x} \\right]_\\times \\mathbf{J}_l \\mathbf{I}_i \\end{align*}\\)  Stacking the three directional derivatives alongside one another yields to the desired Jacobian. If \\(\\mathbf{R} \\mathbf{x}\\) appears inside another scalar function, \\(u(\\mathbf{y})\\), with \\(\\mathbf{y} = \\mathbf{R} \\mathbf{x}\\), we can use the chain rule:  \\(\\begin{align*} \\frac{\\partial u}{ \\partial \\boldsymbol{\\rho}} = \\frac{\\partial u}{ \\partial \\mathbf{y}} \\frac{\\partial \\mathbf{y}}{ \\partial \\boldsymbol{\\rho}}= \\frac{\\partial u}{\\partial \\mathbf{y}} \\left[ \\mathbf{R} \\mathbf{x} \\right]_\\times \\mathbf{J}_l \\end{align*}\\) Jacobian with respect to the Euler Angles, \\((\\theta_1, \\theta_2, \\theta_3)\\) Consider the 1-2-3 Euler angles and denote it as \\(\\boldsymbol{\\theta} = \\left( \\theta_1, \\theta_2, \\theta_3 \\right)\\) corresponding to the roll, pitch, and yaw angles. The rotation matrix can be represented as:  \\(\\begin{align*} \\mathbf{R}(\\boldsymbol{\\theta}) &amp;= \\mathbf{R}_3 (\\theta_3) \\mathbf{R}_2(\\theta_2) \\mathbf{R}_1(\\theta_1) \\end{align*}\\)  We have (see proofs):  \\(\\begin{align*} \\frac{\\partial \\left(\\mathbf{R}(\\boldsymbol{\\theta}) \\mathbf{v} \\right)}{ \\partial \\boldsymbol{\\theta}} &amp;= \\left[ \\begin{array}{ccc} \\frac{\\partial \\left(\\mathbf{R}(\\boldsymbol{\\theta}) \\mathbf{v} \\right)}{\\partial \\theta_1} &amp; \\frac{\\partial \\left(\\mathbf{R}(\\boldsymbol{\\theta}) \\mathbf{v} \\right)}{\\partial \\theta_2} &amp; \\frac{\\partial \\left(\\mathbf{R}(\\boldsymbol{\\theta}) \\mathbf{v} \\right)}{\\partial \\theta_3} &amp; \\end{array} \\right] \\\\ &amp;= \\left[ \\mathbf{R} (\\boldsymbol{\\theta}) \\mathbf{v} \\right]_\\times \\underbrace{\\left[ \\begin{array}{ccc} \\mathbf{R}_3(\\theta_3) \\mathbf{R}_2 (\\theta_2) \\mathbf{I}_1 &amp; \\mathbf{R}_3(\\theta_3) \\mathbf{I}_2 &amp; \\mathbf{I}_3  \\end{array} \\right]}_{\\mathbf{S}(\\theta_2, \\theta_3)} \\\\ &amp;= \\left[ \\mathbf{R}(\\boldsymbol{\\theta}) \\mathbf{v} \\right]_\\times \\mathbf{S}(\\theta_2, \\theta_3) \\end{align*}\\)"},{"location":"kinematics/lie_group_and_lie_algebra/jacobians/#proofs","title":"Proofs","text":"Jacobian with respect to Euler Angles <p>Consider the 1-2-3 Euler angles and denote it as \\(\\boldsymbol{\\theta} = \\left( \\theta_1, \\theta_2, \\theta_3 \\right)\\) corresponding to the roll, pitch, and yaw angles. The rotation matrix can be represented as:</p> \\[ \\begin{align*} \\mathbf{R}(\\boldsymbol{\\theta}) &amp;= \\mathbf{R}_3 (\\theta_3) \\mathbf{R}_2(\\theta_2) \\mathbf{R}_1(\\theta_1). \\end{align*} \\] <p>Taking the derivative of the rotation matrix with respect to the Euler angles yields to:</p> \\[ \\begin{alignat*}{2} \\frac{\\partial \\mathbf{R}(\\boldsymbol{\\theta})}{\\partial \\theta_3} &amp;= \\frac{\\partial \\left( \\mathbf{R}_3 (\\theta_3) \\mathbf{R}_2(\\theta_2) \\mathbf{R}_1(\\theta_1) \\right)}{\\partial \\theta_3} &amp;&amp;= -\\left[ \\mathbf{I}_3 \\right]_\\times \\mathbf{R}(\\boldsymbol{\\theta}) \\\\ \\frac{\\partial \\mathbf{R}(\\boldsymbol{\\theta})}{\\partial \\theta_2} &amp;= \\frac{\\partial \\left( \\mathbf{R}_3 (\\theta_3) \\mathbf{R}_2(\\theta_2) \\mathbf{R}_1(\\theta_1) \\right)}{\\partial \\theta_2} &amp;&amp;= -\\mathbf{R}_3(\\theta_3) \\left[ \\mathbf{I}_2 \\right]_\\times \\mathbf{R}_2 (\\theta_2) \\mathbf{R}_1 (\\theta_1) \\\\ \\frac{\\partial \\mathbf{R}(\\boldsymbol{\\theta})}{\\partial \\theta_1} &amp;= \\frac{\\partial \\left( \\mathbf{R}_3 (\\theta_3) \\mathbf{R}_2(\\theta_2) \\mathbf{R}_1(\\theta_1) \\right)}{\\partial \\theta_1} &amp;&amp;= -\\mathbf{R}_3(\\theta_3) \\mathbf{R}_2 (\\theta_2) \\left[ \\mathbf{I}_1 \\right]_\\times \\mathbf{R}_1. \\\\ \\end{alignat*} \\] <p>If we take the derivative of the rotated vector with repect to the Euler angles:</p> \\[ \\begin{align*} \\frac{\\partial \\left( \\mathbf{R}(\\boldsymbol{\\theta}) \\mathbf{v} \\right)}{\\partial \\theta_3} &amp;= -\\left[\\mathbf{I}_3 \\right]_\\times \\mathbf{R}_3(\\theta_3) \\mathbf{R}_2(\\theta_2) \\mathbf{R}_1(\\theta_1) \\mathbf{v} \\\\ &amp;= -\\left[ \\mathbf{I}_3 \\right]_\\times \\mathbf{R}(\\boldsymbol{\\theta}) \\mathbf{v} \\\\ &amp;= \\left[ \\mathbf{R}(\\boldsymbol{\\theta}) \\mathbf{v} \\right]_\\times \\mathbf{I}_3 \\\\ \\frac{\\partial \\left( \\mathbf{R}(\\boldsymbol{\\theta}) \\mathbf{v} \\right)}{\\partial \\theta_2} &amp;=  -\\mathbf{R}_3(\\theta_3) \\left[\\mathbf{I}_2 \\right]_\\times \\mathbf{R}_2(\\theta_2) \\mathbf{R}_1 (\\theta_1)\\mathbf{v} \\\\ &amp;= -\\mathbf{R}_3 (\\theta_3) \\left[ \\mathbf{I}_2 \\right]_\\times \\mathbf{R}^T_3(\\theta_3) \\mathbf{R}_3(\\theta_3) \\mathbf{R}_2(\\theta_2) \\mathbf{R}_1(\\theta_1) \\mathbf{v} \\\\ &amp;= -\\left[ \\mathbf{R}_3(\\theta_3) \\mathbf{I}_2 \\right]_\\times \\mathbf{R}(\\boldsymbol{\\theta}) \\mathbf{v} \\\\ &amp;= \\left[\\mathbf{R}(\\boldsymbol{\\theta}) \\mathbf{v} \\right]_\\times \\mathbf{R}_3(\\theta_3) \\mathbf{I}_2 \\\\ \\frac{\\partial \\left( \\mathbf{R}(\\boldsymbol{\\theta}) \\mathbf{v} \\right)}{\\partial \\theta_1} &amp;= -\\mathbf{R}_3(\\theta_3) \\mathbf{R}_2(\\theta_2) \\left[ \\mathbf{I}_1 \\right]_\\times \\mathbf{R}_1(\\theta_1) \\mathbf{v} \\\\ &amp;= -\\mathbf{R}_3(\\theta_3) \\mathbf{R}_2(\\theta_2) \\left[ \\mathbf{I}_1 \\right]_\\times \\mathbf{R}^T_2(\\theta_2) \\mathbf{R}^T_3(\\theta_3) \\mathbf{R}_3(\\theta_3) \\mathbf{R}_2(\\theta_2) \\mathbf{R}_1(\\theta_1) \\mathbf{v} \\\\ &amp;= -\\left[ \\mathbf{R}_3 (\\theta_3) \\mathbf{R}_2 (\\theta_2) \\mathbf{I}_1 \\right]_\\times \\mathbf{R}(\\boldsymbol{\\theta}) \\mathbf{v} \\\\ &amp;= \\left[ \\mathbf{R}(\\boldsymbol{\\theta}) \\mathbf{v} \\right]_\\times \\mathbf{R}_3(\\theta_3) \\mathbf{R}_2(\\theta_2) \\mathbf{I}_1. \\end{align*} \\] <p>Summarizing the result, we have:</p> \\[ \\begin{align*} \\frac{\\partial \\left(\\mathbf{R}(\\boldsymbol{\\theta}) \\mathbf{v} \\right)}{ \\partial \\boldsymbol{\\theta}} &amp;= \\left[ \\begin{array}{ccc} \\frac{\\partial \\left(\\mathbf{R}(\\boldsymbol{\\theta}) \\mathbf{v} \\right)}{\\partial \\theta_1} &amp; \\frac{\\partial \\left(\\mathbf{R}(\\boldsymbol{\\theta}) \\mathbf{v} \\right)}{\\partial \\theta_2} &amp; \\frac{\\partial \\left(\\mathbf{R}(\\boldsymbol{\\theta}) \\mathbf{v} \\right)}{\\partial \\theta_3} &amp; \\end{array} \\right] \\\\ &amp;= \\left[ \\mathbf{R} (\\boldsymbol{\\theta}) \\mathbf{v} \\right]_\\times \\underbrace{\\left[ \\begin{array}{ccc} \\mathbf{R}_3(\\theta_3) \\mathbf{R}_2 (\\theta_2) \\mathbf{I}_1 &amp; \\mathbf{R}_3(\\theta_3) \\mathbf{I}_2 &amp; \\mathbf{I}_3  \\end{array} \\right]}_{\\mathbf{S}(\\theta_2, \\theta_3)} \\\\ &amp;= \\left[ \\mathbf{R}(\\boldsymbol{\\theta}) \\mathbf{v} \\right]_\\times \\mathbf{S}(\\theta_2, \\theta_3), \\end{align*} \\] <p>which is true regardless of the choice of Euler set.</p> Principle Rotation Matrix Derivatives <p>The principle rotation matrices are:</p> \\[ \\begin{align*} \\mathbf{R}_1(\\theta_1) &amp;= \\left[ \\begin{array}{ccc} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; \\cos \\theta_1 &amp; \\sin \\theta_1 \\\\ 0 &amp; -\\sin \\theta_1 &amp; \\cos \\theta_1 \\end{array} \\right] \\\\ \\mathbf{R}_2(\\theta_2) &amp;= \\left[ \\begin{array}{ccc} \\cos \\theta_2 &amp; 0 &amp; -\\sin \\theta_2 \\\\ 0 &amp; 1 &amp; 0 \\\\ \\sin \\theta_2 &amp; 0 &amp; \\cos \\theta_2 \\end{array} \\right] \\\\ \\mathbf{R}_3(\\theta_3) &amp;= \\left[ \\begin{array}{ccc} \\cos \\theta_3 &amp; \\sin \\theta_3 &amp; 0 \\\\ -\\sin \\theta_3 &amp; \\cos \\theta_3 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{array} \\right]. \\end{align*} \\] <p>The derivatives of the principle rotation matrices with respect to their angle of rotations are:</p> \\[ \\begin{alignat*}{2} \\frac{\\partial \\mathbf{R}_1(\\theta_1)}{ \\partial \\theta_1} &amp;= \\left[ \\begin{array}{ccc} 0 &amp; 0 &amp; 0 \\\\ 0 &amp; -\\sin \\theta_1 &amp; \\cos \\theta_1 \\\\ 0 &amp; -\\cos \\theta_1 &amp; -\\sin \\theta_1 \\end{array} \\right] &amp;&amp;= -\\left[\\mathbf{I}_1 \\right]_\\times \\mathbf{R}_1 (\\theta_1) \\\\ \\frac{\\partial \\mathbf{R}_2(\\theta_2)}{ \\partial \\theta_2} &amp;= \\left[ \\begin{array}{ccc} -\\sin \\theta_2 &amp; 0 &amp; -\\cos \\theta_2 \\\\ 0 &amp; 0 &amp; 0\\\\ \\cos \\theta_2 &amp; 0 &amp; -\\sin \\theta_2 \\end{array} \\right] &amp;&amp;= -\\left[\\mathbf{I}_2 \\right]_\\times \\mathbf{R}_2 (\\theta_2) \\\\ \\frac{\\partial \\mathbf{R}_3(\\theta_3)}{ \\partial \\theta_3} &amp;= \\left[ \\begin{array}{ccc} -\\sin \\theta_3 &amp; \\cos \\theta_3 &amp; 0 \\\\ -\\cos \\theta_3 &amp; -\\sin \\theta_3 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\end{array} \\right] &amp;&amp;= -\\left[\\mathbf{I}_3\\right]_\\times \\mathbf{R}_3 (\\theta_3). \\end{alignat*} \\] <p>Note that this property holds regardless if it is passive or active rotation.</p> General Derivative of a Rotation Matrix <p>In general, given a rotation vector \\(\\boldsymbol{\\rho} = \\phi \\mathbf{u}\\) and the Rodrigues' formula:</p> \\[ \\begin{align*} \\mathbf{R}(\\boldsymbol{\\rho}) = \\mathbf{I} + \\frac{\\sin \\theta}{ \\theta} \\left[ \\boldsymbol{\\rho} \\right]_\\times + \\frac{1 - \\cos \\theta}{\\theta^2} \\left[ \\boldsymbol{\\rho} \\right]^2_\\times, \\end{align*} \\] <p>the derivative of the rotation matrix with respect to a variable of interest (e.g., time or the rotation vector component etc.) can be expressed as:</p> \\[ \\begin{align*} \\frac{\\partial \\left( \\mathbf{R} \\right)}{\\partial x} = \\left[ \\mathbf{J}_r(\\boldsymbol{\\rho}) \\frac{\\partial \\boldsymbol{\\rho}}{\\partial x} \\right]_\\times \\mathbf{R}. \\end{align*} \\]"},{"location":"kinematics/lie_group_and_lie_algebra/jacobians/#references","title":"References","text":"<ol> <li>Barfoot, T., State Estimation for Robotics</li> <li>Sol\u00e0, J., Quaternion Kinematics for the Error-State Kalman Filter, 2017</li> <li>Sol\u00e0 et al. A Micro Lie Theory for State Estimation in Robotics, 2021</li> </ol>"},{"location":"kinematics/lie_group_and_lie_algebra/matrix_groups_and_lie_theory/","title":"Matrix Groups and Lie Theory","text":""},{"location":"kinematics/lie_group_and_lie_algebra/matrix_groups_and_lie_theory/#group-definition","title":"Group Definition","text":"<p>A group is a set \\(G\\) with an operation \"\\(\\circ\\)\" on the elmenets of \\(G\\) such that it satisfies:</p> <ol> <li>Closure: \\(\\forall g_1, g_2 \\in G, g_1 \\circ g_2 \\in G\\).</li> <li>Associativity: \\(\\forall g_1, g_2, g_3 \\in G, g_1 \\circ (g_2 \\circ g_3) = (g_1 \\circ g_2) \\circ g_3 = g_1 \\circ g_2 \\circ g_3\\).</li> <li>Identity: \\(\\exists g_0 \\in G, \\ \\text{s.t.} \\ \\forall g \\in G, g_0 \\circ g = g \\cdot g_0 = g\\).</li> <li>Invertibility: \\(\\forall g \\in G, \\exists g^{-1} \\in G, \\ \\text{s.t.} \\ g \\circ g^{-1} = g_0\\).</li> </ol> <p>An example group is \\(G = (\\mathbb{Z}, +)\\).</p>"},{"location":"kinematics/lie_group_and_lie_algebra/matrix_groups_and_lie_theory/#matrix-groups","title":"Matrix Groups","text":"<p>Group Relationships</p> \\[ \\begin{align*} SO(n) \\subset O(n) \\subset GL(n), \\quad SE(n) \\subset E(n) \\subset A(n) \\subset GL(n + 1) \\end{align*} \\] Group Name Definition General Linear Group, \\(GL(n)\\) Let \\(\\mathcal{M}(n)\\) be a set of all real \\(n \\times n\\) matrices. The general linear group, \\(GL(n)\\), consists of all \\(\\mathbf{A} \\in \\mathcal{M}(n)\\) for which \\(\\text{det}(\\mathbf{A}) \\neq 0.\\) In order words, the set of all \\(n \\times n\\) non-singular (real) matrices with matrix multiplication is \\(GL(n)\\). Special Linear Group, \\(SL(n)\\) All matrices \\(\\mathbf{A} \\in GL(n)\\) for which \\(\\text{det}(\\mathbf{A}) = 1\\) form a group called the special linear group \\(SL(n)\\). Note that the inverse of \\(\\mathbf{A}\\) is also in this group since \\(\\text{det}(\\mathbf{A}^{-1}) = \\text{det}(\\mathbf{A})^{-1}\\). Affine Group, \\(A(n)\\) An affine transformation \\(L \\ : \\ \\mathbb{R}^n \\rightarrow \\mathbb{R}^n\\) is defined jointly by a matrix \\(\\mathbf{A} \\in GL(n)\\) and a vector \\(\\mathbf{b} \\in \\mathbb{R}^n\\) such that \\(L(\\mathbf{x}) = \\mathbf{A} \\mathbf{x} + \\mathbf{b}.\\) The set of all such affine transformations is called the affine group of dimension \\(n\\) and is denoted by \\(A(n)\\). Note that \\(L\\) defined above is not a linear map unless \\(\\mathbf{b} = \\mathbf{0}\\). Orthogonal Group, \\(O(n)\\) A matrix \\(\\mathbf{A} \\in \\mathcal{M}(n)\\) is called orthogonal if it preserves the inner product, i.e. \\(\\langle \\mathbf{A} \\mathbf{x}, \\mathbf{A} \\mathbf{y} \\rangle = \\langle \\mathbf{x}, \\mathbf{y} \\rangle, \\quad \\forall \\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^n.\\) The set of all orthogonal matrices forms the orthogonal group \\(O(n)\\), which is a subgroup of \\(GL(n)\\). For an orthogonal matrix \\(\\mathbf{R}\\), we have \\(\\langle \\mathbf{R} \\mathbf{x}, \\mathbf{R} \\mathbf{y} \\rangle = \\mathbf{x}^T \\mathbf{R}^T \\mathbf{R} \\mathbf{y} = \\mathbf{x}^T \\mathbf{y}, \\quad \\forall \\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^n,\\) which suggests that \\(\\mathbf{R}^T \\mathbf{R} = \\mathbf{R} \\mathbf{R}^T = \\mathbf{I}\\), or equivalently \\(O(n) = \\left\\{ \\mathbf{R} \\in GL(n) \\ \\| \\ \\mathbf{R}^T \\mathbf{R} = \\mathbf{I} \\right\\}.\\) The above shows that for any orthogonal matrix \\(\\mathbf{R}\\), we have \\(\\text{det}(\\mathbf{R}^T \\mathbf{R}) = \\left(\\text{det}(\\mathbf{R}) \\right)^2 = \\text{det}(\\mathbf{I}) = 1\\), such that \\(\\text{det}(\\mathbf{R}) \\in \\left\\{ \\pm 1 \\right\\}\\). Special Orthogonal Group, \\(SO(3)\\) The subgroup of \\(O(n)\\) with \\(\\text{det}(\\mathbf{R}) = +1\\) is called the special orthogonal group \\(SO(n)\\). Note that \\(SO(n) = O(n) \\cap SL(n)\\). \\(SO(3)\\) is a Lie group and represents rotations. Euclidean Group, \\(E(n)\\) A Euclidean transformation \\(L\\) from \\(\\mathbb{R}^n \\rightarrow \\mathbb{R}^n\\) is defined by an orthogonal matrix \\(\\mathbf{R} \\in O(n)\\) and a vector \\(\\mathbf{t} \\in \\mathbf{R}^n\\) such that: \\(L \\ : \\ \\mathbb{R}^n \\rightarrow \\mathbb{R}^n; \\quad \\mathbf{x} \\rightarrow \\mathbf{R} \\mathbf{x} + \\mathbf{t}\\). The set of all such transformations is called the Euclidean group \\(E(n)\\). It is a subgroup of the affine group \\(A(n)\\). Embedded by homogeneous coordinates, we have \\(E(n) = \\left\\{\\left(\\begin{array}{cc}\\mathbf{R} &amp; \\mathbf{t} \\\\\\mathbf{0} &amp; 1\\end{array}\\right) \\ \\|\\ \\mathbf{R} \\in O(n), \\mathbf{t} \\in \\mathbb{R}^n\\right\\}.\\) Special Euclidean Group, \\(SE(n)\\) For \\(E(n)\\), if \\(\\mathbf{R} \\in SO(n)\\), we have the special Euclidean group \\(SE(n)\\). \\(SE(3)\\) is a Lie group and represents poses."},{"location":"kinematics/lie_group_and_lie_algebra/matrix_groups_and_lie_theory/#lie-group-and-lie-algebra","title":"Lie Group and Lie Algebra","text":"<p>Lie group refer to a group with smooth manifold properties. Smoothness implies that we can use differential calculus on the manifold; or roughly, if we change the input to any group operation by a little bit, the output will only change by a little bit. With every matrix Lie group is associated a Lie algebra, which consists of a vector space \\(\\mathbb{V}\\) over some field \\(\\mathbb{F}\\), and a binary operation \\(\\left[\\cdot, \\cdot \\right]\\), called the Lie bracket. The following properties are satisfied for Lie Algebra \\((\\mathbb{V}, \\mathbb{F}, \\left[\\cdot, \\cdot\\right])\\):</p> <ol> <li>Closure: \\(\\forall \\mathbf{X}, \\mathbf{Y} \\in \\mathbb{V}; \\ \\left[ \\mathbf{X}, \\mathbf{Y} \\right] \\in \\mathbb{V}\\).</li> <li> <p>Bilinearity: \\(\\forall \\mathbf{X}, \\mathbf{Y}, \\mathbf{Z} \\in \\mathbb{V}; \\ a,b \\in \\mathbb{F}\\), we have:</p> \\[ \\begin{align} &amp;\\left[a \\mathbf{X} + b \\mathbf{Y}, \\mathbf{Z} \\right] = a \\left[\\mathbf{X}, \\mathbf{Z} \\right] + b \\left[ \\mathbf{Y}, \\mathbf{Z} \\right] \\\\ &amp;\\left[\\mathbf{Z}, a \\mathbf{X} + b \\mathbf{Y} \\right] = a \\left[ \\mathbf{Z}, \\mathbf{X} \\right] + b \\left[ \\mathbf{Z}, \\mathbf{Y} \\right]. \\end{align} \\] </li> <li> <p>Alternating: \\(\\forall \\mathbf{X} \\in \\mathbb{V}; \\ \\left[ \\mathbf{X}, \\mathbf{X} \\right] = 0\\).</p> </li> <li>Jacobi identity: \\(\\forall \\mathbf{X}, \\mathbf{Y}, \\mathbf{Z} \\in \\mathbb{V}; \\ \\left[ \\mathbf{X}, \\left[ \\mathbf{Y}, \\mathbf{Z} \\right] \\right] + \\left[ \\mathbf{Z}, \\left[ \\mathbf{X}, \\mathbf{Y} \\right] \\right] + \\left[ \\mathbf{Y}, \\left[ \\mathbf{Z}, \\mathbf{X} \\right] \\right] = 0\\).</li> </ol> <p>The vector space of a Lie algebra is the tangent space of the associated Lie group at the identity element of the group, and it completely captures the local structure of the group.</p>"},{"location":"kinematics/lie_group_and_lie_algebra/matrix_groups_and_lie_theory/#references","title":"References","text":"<ol> <li>Barfoot, T., State Estimation for Robotics</li> <li>Ma., Y., An Invitation to 3-D Vision: From Images to Models, 2001</li> </ol>"},{"location":"kinematics/lie_group_and_lie_algebra/perturbations/","title":"Perturbations","text":""},{"location":"kinematics/lie_group_and_lie_algebra/special_orthogonal_and_special_euclidean_groups/","title":"Special Orthogonal and Special Euclidean Groups","text":""},{"location":"kinematics/lie_group_and_lie_algebra/special_orthogonal_and_special_euclidean_groups/#definition","title":"Definition","text":"Figure 1 Relationship between Lie group and Lie algebra <p>\\(SO(3)\\) is a Lie group that consists of orthogonal matrices (orthonormal rows and columns) that provide distance-preserving transformations of a Euclidean space. \\(SE(3)\\) is a Lie group that represents poses.</p> Group Properties Special Orthogonal Group Special Euclidean Group Lie Group \\(SO(3) = \\left\\{ \\mathbf{R} \\in \\mathbb{R}^{3 \\times 3} \\ \\| \\ \\mathbf{R} \\mathbf{R}^T = \\mathbf{R}^T \\mathbf{R} = \\mathbf{I}, \\ \\text{det}(\\mathbf{R}) = 1 \\right\\}\\) \\(SE(3) = \\left\\{ \\mathbf{T} = \\left[ \\begin{array}{cc} \\mathbf{R} &amp; \\mathbf{t} \\\\\\mathbf{0}^T &amp; 1 \\end{array} \\right] \\in \\mathbb{R}^{4  \\times 4} \\ \\big\\| \\ \\mathbf{R} \\in SO(3), \\ \\mathbf{t} \\in \\mathbb{R}^3 \\right\\}\\) Inverse \\(\\mathbf{R}^{-1} = \\mathbf{R}^T \\in SO(3)\\) \\(\\begin{align*} \\mathbf{T}^{-1} = \\left[ \\begin{array}{cc} \\mathbf{R}^T &amp; -\\mathbf{R}^T \\mathbf{t} \\\\ \\mathbf{0}^T &amp; 1 \\end{array} \\right] \\in SE(3) \\end{align*}\\) Lie Algebra Set of skew-symmetrics matrices, \\(\\left[ \\boldsymbol{\\rho} \\right]_\\times\\) with \\(\\boldsymbol{\\rho} \\in \\mathbb{R}^3\\) \\(\\begin{align*} \\text{Vector space: } &amp;\\mathfrak{so}(3) = \\left\\{ \\boldsymbol{P} = \\left[ \\boldsymbol{\\rho} \\right]_{\\times} \\in \\mathbb{R}^{3 \\times 3} \\ \\| \\ \\boldsymbol{\\rho} \\in \\mathbb{R}^3 \\right\\} \\\\ \\text{Field: } &amp;\\mathbb{R} \\\\ \\text{Lie bracket: } &amp;\\left[ \\boldsymbol{P}_1, \\boldsymbol{P}_2  \\right] = \\boldsymbol{P}_1 \\boldsymbol{P}_2 - \\boldsymbol{P}_2 \\boldsymbol{P}_1. \\end{align*}\\) \\(\\begin{align*} \\text{Vector space: } &amp;\\mathfrak{se}(3) = \\left\\{ \\boldsymbol{\\Xi} = \\left[ \\boldsymbol{\\xi} \\right]_\\times \\in \\mathbb{R}^{4 \\times 4} \\ \\| \\ \\boldsymbol{\\xi} \\in \\mathbb{R}^6  \\right\\} \\\\ \\text{Field: } &amp;\\mathbb{R} \\\\ \\text{Lie bracket: } &amp;\\left[\\boldsymbol{\\Xi}_1, \\boldsymbol{\\Xi}_2 \\right] = \\boldsymbol{\\Xi}_1 \\boldsymbol{\\Xi}_2 - \\boldsymbol{\\Xi}_2 \\boldsymbol{\\Xi}_1, \\\\ \\end{align*}\\) where \\(\\begin{align*} \\boldsymbol{\\xi} = \\left[ \\begin{array}{c} \\boldsymbol{\\ell} \\\\ \\boldsymbol{\\rho} \\end{array} \\right] \\in \\mathbb{R}^{6}, \\ \\boldsymbol{\\ell}, \\boldsymbol{\\rho} \\in \\mathbb{R}^3, \\ \\left[ \\boldsymbol{\\xi} \\right]_\\times = \\left[ \\begin{array}{cc} \\left[ \\boldsymbol{\\rho} \\right]_\\times &amp; \\boldsymbol{\\ell} \\\\ \\mathbf{0}^T &amp; 0 \\end{array} \\right] \\in \\mathbb{R}^{4 \\times 4}, \\\\ \\end{align*}\\) \\(\\boldsymbol{\\ell}\\) is the \"translation part\" (note that this is different from the translation in the matrix), \\(\\boldsymbol{\\rho}\\) is the rotation part. Here \\(\\left[ \\ \\cdot \\ \\right]_\\times\\) has an extended meaning since in \\(\\mathfrak{se}(3)\\), a six-dimensional vector is converted to a four-dimensional matrix using the \\(\\left[ \\ \\cdot \\ \\right]_\\times\\) operator, but it is no longer a skew-symmetric matrix. However, the meaning is still \"vector-to-matrix\" operation Exponential Map \\(\\begin{align*} \\mathbf{R} = e^{\\left[\\boldsymbol{\\rho} \\right]_\\times} &amp;= e^{ \\left[ \\theta \\hat{\\mathbf{e}} \\right]_\\times} = \\sum^{\\infty}_{k = 0} \\frac{1}{k!} \\left(\\theta \\left[\\hat{\\mathbf{e}} \\right]_\\times \\right)^k \\\\ &amp;= \\mathbf{I} + \\theta \\left[ \\hat{\\mathbf{e}} \\right]_\\times + \\frac{\\theta^2}{2} \\left[ \\hat{\\mathbf{e}} \\right]^2_\\times +  \\frac{\\theta^3}{3!} \\left[ \\hat{\\mathbf{e}} \\right]^2_\\times + \\ldots \\\\ &amp;= \\mathbf{I} + \\left( \\theta - \\frac{\\theta^3}{3!} + \\ldots \\right) \\left[ \\hat{\\mathbf{e}} \\right]_\\times + \\left( \\frac{\\theta^2}{2} - \\frac{\\theta^4}{4!} + \\ldots \\right) \\left[ \\hat{\\mathbf{e}} \\right]^2_\\times \\\\ &amp;= \\mathbf{I} + \\sin \\theta \\left[ \\hat{\\mathbf{e}} \\right]_\\times + \\left(1 - \\cos \\theta \\right) \\left[ \\hat{\\mathbf{e}} \\right]^2_\\times \\\\ &amp;= \\cos \\theta \\mathbf{I} + \\left(1 - \\cos \\theta \\right) \\hat{\\mathbf{e}} \\hat{\\mathbf{e}}^T + \\sin \\theta \\left[ \\hat{\\mathbf{e}} \\right]_\\times \\end{align*}\\) \\(\\begin{align*} \\mathbf{T} = \\exp \\left\\{ \\boldsymbol{ \\left[\\xi \\right]_\\times} \\right\\} &amp;= \\sum^\\infty_{n = 0} \\frac{1}{n!} \\left[\\boldsymbol{\\xi} \\right]^n_\\times \\\\ \\mathbf{e}^{\\left[ \\boldsymbol{\\xi} \\right]_\\times} &amp;= \\sum^\\infty_{n = 0} \\frac{1}{n!} \\left(\\left[ \\boldsymbol{\\xi} \\right]_\\times \\right)^n \\\\ &amp;= \\sum^\\infty_{n = 0} \\frac{1}{n!} \\left( \\left[ \\begin{array}{c} \\boldsymbol{\\ell} \\\\ \\boldsymbol{\\rho} \\end{array} \\right]_\\times \\right)^n \\\\ &amp;= \\sum^\\infty_{n = 0} \\frac{1}{n!} \\left[ \\begin{array}{cc} \\left[\\boldsymbol{\\rho} \\right]_\\times &amp; \\boldsymbol{\\ell} \\\\ \\mathbf{0}^T &amp; 0 \\end{array} \\right]^n \\\\ &amp;= \\left[ \\begin{array}{cc} \\sum^{\\infty}_{n = 0} \\frac{1}{n!} \\left( \\left[ \\boldsymbol{\\rho} \\right]_\\times \\right)^n &amp; \\left(\\sum^{\\infty}_{n = 0} \\frac{1}{(n + 1)!} \\left( \\left[ \\boldsymbol{\\rho} \\right]_\\times \\right)^n \\right) \\boldsymbol{\\ell} \\\\ \\mathbf{0}^T &amp; 1 \\end{array} \\right] \\\\ &amp;\\triangleq \\underbrace{ \\left[ \\begin{array}{cc} \\mathbf{R} &amp; \\mathbf{J} \\boldsymbol{\\ell} \\\\ \\mathbf{0}^T &amp; 1 \\end{array} \\right]}_\\mathbf{T} \\in SE(3), \\end{align*}\\) Jacobian The Jacobian plays an important role in allowing us to convert the translation component of pose in \\(\\mathfrak{se}(3)\\) into the translation component of pose in \\(SE(3)\\) through \\(\\mathbf{t} = \\mathbf{J} \\boldsymbol{\\ell}\\). Let \\(\\boldsymbol{\\rho} = \\theta \\hat{\\mathbf{e}}\\). Then we can obtain closed-form solutions for the left Jacobian matrix \\(\\mathbf{J}\\) and its inverse \\(\\begin{align*} \\mathbf{J}_l &amp;\\triangleq \\sum^{\\infty}_{n = 0} \\frac{1}{(n + 1)!} \\left( \\left[ \\boldsymbol{\\rho} \\right]_\\times \\right)^n \\\\ &amp;= \\mathbf{I} + \\frac{1}{2!}\\theta \\left[ \\hat{\\mathbf{e}} \\right]_\\times + \\frac{1}{3!}\\theta^2 \\left[ \\hat{\\mathbf{e}} \\right]^2_\\times + \\frac{1}{4!}\\theta^3 \\left[ \\hat{\\mathbf{e}} \\right]^3_\\times \\ldots \\\\ &amp;= \\frac{1}{\\theta} \\left( \\frac{1}{2!}\\theta^2 - \\frac{1}{4!}\\theta^4 \\ldots \\right) \\left[ \\hat{\\mathbf{e}} \\right]_\\times + \\frac{1}{\\theta} \\left(\\frac{1}{3!} \\theta^3 - \\frac{1}{5}\\theta^5 + \\ldots \\right) \\left[ \\hat{\\mathbf{e}} \\right]^2_\\times + \\mathbf{I} \\\\ &amp;= \\frac{1}{\\theta} (1 - \\cos \\theta) \\left[ \\hat{\\mathbf{e}} \\right]_\\times +  \\frac{\\theta - \\sin \\theta}{\\theta} (\\hat{\\mathbf{e}} \\hat{\\mathbf{e}}^T - \\mathbf{I}) + \\mathbf{I} \\\\  &amp;= \\frac{\\sin \\theta}{\\theta} \\mathbf{I} + \\left(1 - \\frac{\\sin \\theta}{\\theta} \\right) \\hat{\\mathbf{e}} \\hat{\\mathbf{e}}^T +  \\frac{1 - \\cos \\theta}{\\theta} \\left[ \\hat{\\mathbf{e}} \\right]_\\times \\\\  \\mathbf{J}^{-1}_l &amp;\\triangleq \\frac{\\theta}{2} \\cot \\frac{\\theta}{2} \\mathbf{I} +  \\left(1 - \\frac{\\theta}{2} \\cot \\frac{\\theta}{2} \\right) \\hat{\\mathbf{e}} \\hat{\\mathbf{e}}^T - \\frac{\\theta}{2} \\left[ \\hat{\\mathbf{e}} \\right]_\\times \\\\ \\mathbf{R} &amp;= \\mathbf{I} + \\left[ \\boldsymbol{\\rho} \\right]_\\times \\mathbf{J}_l. \\end{align*}\\)  The left and right Jacobians are related as  \\(\\begin{align*} \\mathbf{J}_l (\\boldsymbol{\\rho}) = \\mathbf{R} \\mathbf{J}_r (\\boldsymbol{\\rho}) \\\\ \\mathbf{J}_r (\\boldsymbol{\\rho}) = \\mathbf{J}_l (-\\boldsymbol{\\rho}) \\end{align*}\\) The left and right Jacobians of \\(SE(3)\\) are  \\(\\begin{align*} \\boldsymbol{\\mathcal{J}}_r \\left(\\boldsymbol{\\xi} \\right) &amp;= \\left[ \\begin{array}{cc} \\mathbf{J}_r &amp; \\mathbf{Q}_r \\\\ \\mathbf{0} &amp; \\mathbf{J}_r \\end{array} \\right] \\\\ \\boldsymbol{\\mathcal{J}}_l \\left(\\boldsymbol{\\xi} \\right) &amp;= \\left[ \\begin{array}{cc} \\mathbf{J}_l &amp; \\mathbf{Q}_l \\\\ \\mathbf{0} &amp; \\mathbf{J}_l \\end{array} \\right]. \\end{align*}\\)  See Barfoot \\((8.91)\\) for definition Jacobian Properties Per the derivative definitions, the right Jacobian of \\(SO(3)\\) has the following properties, for any \\(\\boldsymbol{\\theta}\\) and small \\(\\delta \\boldsymbol{\\theta}\\):  \\(\\begin{align*} \\exp \\left[\\boldsymbol{\\theta} + \\delta \\boldsymbol{\\theta} \\right]_\\times &amp;\\approx \\exp \\left[\\boldsymbol{\\theta} \\right]_\\times \\exp \\left[\\mathbf{J}_r(\\boldsymbol{\\theta}) \\delta \\boldsymbol{\\theta} \\right]_\\times \\\\ \\exp \\left[\\boldsymbol{\\theta} \\right]_\\times \\exp \\left[ \\delta \\boldsymbol{\\theta} \\right]_\\times &amp;\\approx \\exp \\left[ \\boldsymbol{\\theta} + \\mathbf{J}^{-1}_r (\\boldsymbol{\\theta}) \\delta \\boldsymbol{\\theta} \\right]_\\times \\\\ \\left[ \\ln \\left( \\exp \\left[ \\boldsymbol{\\theta} \\right]_\\times \\exp \\left[ \\delta \\boldsymbol{\\theta} \\right]_\\times \\right) \\right]_{-\\times} &amp;\\approx \\boldsymbol{\\theta} + \\mathbf{J}^{-1}_r (\\boldsymbol{\\theta}) \\delta \\boldsymbol{\\theta} \\end{align*}\\) Logarithm Map \\(\\begin{align*} \\theta &amp;= \\arccos \\left( \\frac{\\text{tr}(\\mathbf{R}) - 1}{2} \\right) \\\\ \\ln (\\mathbf{R}) &amp;= \\frac{\\theta}{2 \\sin \\theta} \\left( \\mathbf{R} - \\mathbf{R}^T \\right) \\\\ \\boldsymbol{\\rho} &amp;= \\left[ \\ln \\left( \\mathbf{R} \\right) \\right]_{-\\times} \\end{align*}\\) \\(\\begin{align*} \\boldsymbol{\\xi} &amp;= \\left[ \\ln \\left(  \\mathbf{T} \\right) \\right]_{-\\times} \\\\ \\boldsymbol{\\ell} &amp;= \\mathbf{J}^{-1} \\mathbf{t} \\end{align*}\\) Adjoint The adjoint of a Lie group is a way of describing the elements of that group as linear transformations of its Lie algebra, which is a vector space. For \\(SO(3)\\), the adjoint representation is the same as the group itself \\(\\text{Adj}_{\\mathbf{R}} = \\mathbf{R}.\\) Then we have  \\(\\begin{align*} &amp;\\mathbf{R} \\ \\exp \\left( \\left[ \\boldsymbol{\\rho} \\right]_\\times \\right) = \\exp \\left( \\text{Adj}_{\\mathbf{R}} \\cdot \\left[ \\boldsymbol{\\rho} \\right]_\\times \\right) \\mathbf{R} \\ \\Rightarrow \\\\ &amp;\\exp \\left( \\text{Adj}_{\\mathbf{R}} \\cdot \\left[ \\boldsymbol{\\rho} \\right]_\\times \\right) = \\mathbf{R} \\ \\exp \\left( \\left[ \\boldsymbol{\\rho} \\right]_\\times \\right) \\mathbf{R}^{-1}. \\end{align*}\\)  In order words, rotating a tangent vector by an element \"moves\" it from the tangent space on the right side of the element to the tangent space on the left The adjoint map of \\(SE(3)\\) transforms an element \\(\\left[ \\mathbf{x} \\right]_{\\times} \\in \\mathfrak{se}(3)\\) to another element of \\(\\mathfrak{se}(3)\\) via conjugation \\(\\text{Ad}_{\\mathbf{T}} \\left[ \\mathbf{x} \\right]_\\times = \\mathbf{T} \\left[  \\mathbf{x} \\right]_\\times \\mathbf{T}^{-1} = \\left[\\boldsymbol{\\mathcal{T}} \\mathbf{x} \\right]_\\times\\), where \\(\\boldsymbol{\\mathcal{T}}\\) is the adjoint representation of \\(SE(3)\\) \\(\\begin{align*} \\boldsymbol{\\mathcal{T}} = \\text{Ad}\\left( \\mathbf{T} \\right) = \\text{Ad} \\left[ \\begin{array}{cc} \\mathbf{R} &amp; \\mathbf{t} \\\\ \\mathbf{0}^T &amp; 1 \\end{array} \\right] = \\left[ \\begin{array}{cc} \\mathbf{R} &amp; \\left[ \\mathbf{t} \\right]_\\times \\mathbf{R} \\\\ \\mathbf{0} &amp; \\mathbf{R} \\end{array} \\right] \\end{align*}\\) Compounding via BCH Let \\(\\mathbf{R}_1 = \\exp \\left( \\left[ \\boldsymbol{\\rho}_1 \\right]_\\times \\right)\\) and \\(\\mathbf{R}_2 \\\\ = \\exp \\left( \\left[ \\boldsymbol{\\rho}_2 \\right]_\\times \\right)\\). Then \\(\\begin{align*} \\boldsymbol{\\rho}_3 &amp;= \\left[  \\ln \\mathbf{R}_3 \\right]_{-\\times} = \\left[ \\ln \\left( \\mathbf{R}_1 \\mathbf{R}_2 \\right) \\right]_{-\\times} \\\\ &amp;= \\left[ \\ln \\bigl( \\exp(\\left[ \\boldsymbol{\\rho}_1 \\right]_\\times) \\exp\\left( \\left[ \\boldsymbol{\\rho}_2 \\right]_\\times \\right) \\bigr) \\right]_{-\\times} \\\\ &amp;= \\boldsymbol{\\rho}_1 + \\boldsymbol{\\rho}_2 + \\frac{1}{2} \\left[ \\boldsymbol{\\rho}_1 \\right]_\\times \\boldsymbol{\\rho}_2 + \\frac{1}{12} \\left[ \\boldsymbol{\\rho}_1 \\right]_\\times \\left[ \\boldsymbol{\\rho}_1 \\right]_\\times \\boldsymbol{\\rho}_2 + \\frac{1}{12} \\left[ \\boldsymbol{\\rho}_2 \\right]_\\times \\left[ \\boldsymbol{\\rho}_2 \\right]_\\times \\boldsymbol{\\rho}_1 + \\ldots \\\\ &amp;\\approx  \\begin{cases} \\mathbf{J}_l^{-1} \\left( \\boldsymbol{\\rho}_2 \\right) \\boldsymbol{\\rho}_1 + \\boldsymbol{\\rho} _2, \\quad \\text{if } \\boldsymbol{\\rho}_1 \\ \\text{is a small} \\\\ \\mathbf{J}_r^{-1} \\left( \\boldsymbol{\\rho}_1 \\right) \\boldsymbol{\\rho}_2 + \\boldsymbol{\\rho}_1, \\quad \\text{if } \\boldsymbol{\\rho}_2 \\ \\text{is a small}, \\end{cases} \\end{align*}\\) \\(\\begin{align*} \\boldsymbol{\\xi}_3 &amp;= \\left[ \\ln \\left( \\mathbf{T}_1 \\mathbf{T}_2 \\right) \\right]_{-\\times} \\\\ &amp;= \\left[ \\ln \\bigl( \\exp(\\left[ \\xi_1 \\right]_\\times) \\exp(\\left[ \\xi_2 \\right]_\\times)  \\bigr) \\right]_{-\\times} \\\\ &amp;\\approx \\begin{cases} \\boldsymbol{\\mathcal{J}}_l \\left( \\boldsymbol{\\xi}_2 \\right)^{-1} \\boldsymbol{\\xi}_1 + \\boldsymbol{\\xi}_2, \\quad \\text{if } \\boldsymbol{\\xi}_1 \\ \\text{is a small} \\\\ \\boldsymbol{\\mathcal{J}}_r \\left( \\boldsymbol{\\xi}_1 \\right)^{-1} \\boldsymbol{\\xi}_2 + \\boldsymbol{\\xi}_1, \\quad \\text{if } \\boldsymbol{\\xi}_2 \\ \\text{is a small}. \\end{cases} \\end{align*}\\)"},{"location":"kinematics/lie_group_and_lie_algebra/special_orthogonal_and_special_euclidean_groups/#references","title":"References","text":"<ol> <li>Barfoot, T., State Estimation for Robotics</li> </ol>"},{"location":"kinematics/optimization_on_smooth_manifolds/difference_of_rotations/","title":"Difference of Rotations","text":""},{"location":"kinematics/optimization_on_smooth_manifolds/difference_of_rotations/#metrics-for-rotations","title":"Metrics for Rotations","text":"<p>Given \\(\\mathbf{R}_1, \\mathbf{R}_2 \\in SO(3)\\), there are two common ways to define the difference of two rotations:</p> \\[ \\begin{align} \\boldsymbol{\\rho}_{12} &amp;= \\left[ \\ln \\mathbf{R}^T_1 \\mathbf{R}_2 \\right]_{-\\times} \\\\ \\boldsymbol{\\rho}_{21} &amp;= \\left[ \\ln \\mathbf{R}_2 \\mathbf{R}^T_1 \\right]_{-\\times}, \\label{metrics} \\end{align} \\] <p>This can be thought of as the right and the left difference between the two rotation matrices. The inner product for \\(\\mathfrak{so}(3)\\) can be defined as:</p> \\[ \\left[ \\boldsymbol{\\rho}_{1} \\right]_\\times \\cdot \\left[ \\boldsymbol{\\rho}_{2} \\right]_\\times = \\frac{1}{2} \\text{tr} \\left( \\left[ \\boldsymbol{\\rho}_{1} \\right]_\\times \\left[ \\boldsymbol{\\rho}_{2} \\right]^T_\\times \\right) = \\boldsymbol{\\rho}^T_{1} \\boldsymbol{\\rho}_{2}. \\label{inner_product} \\] <p>Using Eq (\\(\\ref{inner_product}\\)) as the distance metric:</p> \\[ \\begin{align} |\\boldsymbol{\\rho}_{12}| &amp;= \\sqrt{\\boldsymbol{\\rho}_{12}^T \\boldsymbol{\\rho}_{12}} \\\\ |\\boldsymbol{\\rho}_{21}| &amp;= \\sqrt{\\boldsymbol{\\rho}_{21}^T \\boldsymbol{\\rho}_{21}}. \\\\ \\end{align} \\] <p>This can be viewed as the magnitude of the angle of the rotation difference.</p>"},{"location":"kinematics/optimization_on_smooth_manifolds/difference_of_rotations/#metrics-for-pertubed-rotations","title":"Metrics for Pertubed Rotations","text":"<p>Let \\(\\mathbf{R} = \\exp \\left( \\left[ \\boldsymbol{\\rho} \\right]_\\times \\right) \\in SO(3)\\) be a rotation matrix. Perturbing \\(\\boldsymbol{\\rho}\\) by a little bit results in a new rotation matrix, \\(\\mathbf{R}' = \\exp \\left( \\left[ \\boldsymbol{\\rho} + \\delta \\boldsymbol{\\rho} \\right]_\\times \\right) \\in SO(3)\\).</p> <p>We are interested in quantifying the difference between \\(\\mathbf{R}\\) and \\(\\mathbf{R}'\\). Using Eq (\\(\\ref{metrics}\\)) and the BCH formula, the right difference is:</p> \\[ \\begin{align} \\left[ \\ln \\bigl( \\delta \\mathbf{R}_r \\bigr) \\right]_{-\\times} &amp;= \\left[ \\ln \\bigl( \\mathbf{R}^T \\mathbf{R}' \\bigr) \\right]_{-\\times} \\\\ &amp;= \\left[ \\ln \\bigl( \\mathbf{R}^T \\exp\\left( \\left[ \\boldsymbol{\\rho} + \\delta \\boldsymbol{\\rho} \\right]_\\times \\right) \\bigr) \\right]_{-\\times} \\\\ &amp;\\approx \\left[ \\ln \\bigl( \\mathbf{R}^T \\mathbf{R} \\exp \\left( \\left[ \\mathbf{J}_r \\delta \\boldsymbol{\\rho} \\right]_{\\times} \\right) \\bigr) \\right]_{-\\times} = \\mathbf{J}_r \\delta \\boldsymbol{\\rho}. \\end{align} \\] <p>Similarly, the left difference is:</p> \\[ \\begin{align} \\left[ \\ln \\bigl( \\delta \\mathbf{R}_l \\bigr) \\right]_{-\\times} &amp;= \\left[ \\ln \\bigl( \\mathbf{R}' \\mathbf{R}^T \\bigr) \\right]_{-\\times} \\\\ &amp;= \\left[ \\ln \\bigl( \\exp\\left( \\left[ \\boldsymbol{\\rho} + \\delta \\boldsymbol{\\rho} \\right]_\\times \\right) \\mathbf{R}^T \\bigr) \\right]_{-\\times} \\\\ &amp;\\approx \\left[ \\ln \\bigl( \\exp \\left( \\left[ \\mathbf{J}_l \\delta \\boldsymbol{\\rho} \\right]_{\\times} \\right) \\mathbf{R}^T \\mathbf{R} \\bigr) \\right]_{-\\times} = \\mathbf{J}_l \\delta \\boldsymbol{\\rho}. \\end{align} \\] <p>Note here that \\(\\mathbf{J}_r\\) and \\(\\mathbf{J}_l\\) are evaluated at \\(\\boldsymbol{\\rho}\\).</p>"},{"location":"kinematics/optimization_on_smooth_manifolds/interpolation/","title":"Interpolation","text":""},{"location":"kinematics/optimization_on_smooth_manifolds/interpolation/#lie-group-interpolation","title":"Lie Group Interpolation","text":"<p>The typical linear interpolation scheme:</p> \\[ x = (1 - \\alpha) x_1 + \\alpha x_2, \\quad \\alpha \\in \\left[0, 1 \\right], \\] <p>will not work on \\(SO(3)\\) and \\(SE(3)\\) because this interpolation scheme does not satisfy closure (i.e., the result is no longer in the group):</p> \\[ \\begin{align} (1 - \\alpha) \\mathbf{R}_1 + \\alpha \\mathbf{R}_2 \\notin SO(3) \\\\ (1 - \\alpha) \\mathbf{T}_1 + \\alpha \\mathbf{T}_2 \\notin SE(3), \\\\ \\end{align} \\] <p>for some values of \\(\\alpha \\in \\left[0, 1 \\right]\\), \\(\\mathbf{R}_1, \\mathbf{R}_2 \\in SO(3)\\) and \\(\\mathbf{T}_1, \\mathbf{T}_2 \\in SE(3)\\).s</p>"},{"location":"kinematics/optimization_on_smooth_manifolds/interpolation/#rotation-interpolation","title":"Rotation Interpolation","text":"<p>One of the interpolations schemes is:</p> \\[ \\mathbf{R} = \\left( \\mathbf{R}_2 \\mathbf{R}^T_1 \\right)^\\alpha \\mathbf{R}_1, \\quad \\alpha \\in \\left[0, 1 \\right], \\] <p>where \\(\\mathbf{R}, \\mathbf{R}_1, \\mathbf{R}_2 \\in SO(3)\\). We see that when \\(\\alpha = 0\\), we have \\(\\mathbf{R} = \\mathbf{R}_1\\), and \\(\\mathbf{R} = \\mathbf{R}_2\\) when \\(\\alpha = 1\\). With this definition, we can guarantee close, i.e., \\(\\mathbf{R} \\in SO(3)\\) for all \\(\\alpha \\in \\left[0, 1 \\right]\\).</p> <p>Proof. Let \\(\\mathbf{R}_{21} = \\mathbf{R}_2 \\mathbf{R}^T_1 = \\exp (\\left[ \\boldsymbol{\\rho} \\right]_\\times)\\). Then, we have:</p> \\[ \\mathbf{R}^\\alpha_{21} = \\exp \\left( \\left[ \\boldsymbol{\\rho} \\right]_\\times \\right)^\\alpha = \\exp \\left( \\alpha \\left[ \\boldsymbol{\\rho} \\right]_\\times \\right) \\in SO(3). \\] <p>One way to interepret the interpolation scheme is that it enforces a constant angular velocity, \\(\\boldsymbol{\\omega}\\). If the rotation matrix is a function of time, \\(\\mathbf{R}(t)\\), then the scheme is:</p> \\[ \\mathbf{R}(t) = \\left( \\mathbf{R}(t_2) \\mathbf{R}(t_1)^T \\right)^\\alpha \\mathbf{R}(t_1), \\quad \\alpha = \\frac{t - t_1}{t_2 - t_1}. \\] <p>Defining the constant angular velocity as:</p> \\[ \\boldsymbol{\\omega} = \\frac{1}{t_2 - t_1} \\boldsymbol{\\rho}, \\] <p>we get:</p> \\[ \\mathbf{R}(t) = \\exp((t - t_1) \\left[ \\boldsymbol{\\omega} \\right]_\\times) \\mathbf{R}(t_1), \\] <p>which is the solution to the Poisson's equation:</p> \\[ \\dot{\\mathbf{R}}(t) = \\left[ \\boldsymbol{\\omega} \\right]_\\times \\mathbf{R}(t). \\]"},{"location":"kinematics/rotations/angular_velocity/","title":"Angular Velocity","text":""},{"location":"kinematics/rotations/angular_velocity/#definition","title":"Definition","text":"<p>The angular velocity vector, \\(\\boldsymbol{\\omega}^{\\gamma}_{\\beta \\alpha}\\), is the rate of rotation of the frame \\(F_\\alpha\\) axes with respect to the frame \\(F_\\beta\\) axes, resolved about the frame \\(F_\\gamma\\) axes. The rotation is within the plane perpendicular to the angular rate vector, and  the angular rate vector direction follows the right-hand rule.</p> Properties of Angular Velocity Reverse Angular Rate \\(\\boldsymbol{\\omega}^{\\gamma}_{\\beta \\alpha} = -\\boldsymbol{\\omega}^{\\gamma}_{\\alpha \\beta}\\) Addition \\(\\boldsymbol{\\omega}^{\\gamma}_{\\beta \\alpha} = \\boldsymbol{\\omega}^{\\gamma}_{\\beta \\delta} + \\boldsymbol{\\omega}^{\\gamma}_{\\delta \\alpha}\\) Resolving Axes Transform \\(\\boldsymbol{\\omega}^{\\gamma}_{\\beta \\alpha} = \\mathbf{R}^{\\gamma}_{\\delta} \\boldsymbol{\\omega}^{\\delta}_{\\beta \\alpha}\\) Skew Symmetric Form \\(\\boldsymbol{\\Omega}^{\\gamma}_{\\beta \\alpha} = \\left[ \\boldsymbol{\\omega}^{\\gamma}_{\\beta \\alpha} \\right]_\\times = \\left[ \\begin{array}{ccc} 0 &amp; -\\omega^{\\gamma}_{\\beta \\alpha, 3} &amp; \\omega^{\\gamma}_{\\beta \\alpha, 2} \\\\ \\omega^{\\gamma}_{\\beta \\alpha, 3} &amp; 0 &amp; -\\omega^{\\gamma}_{\\beta \\alpha, 1} \\\\ -\\omega^{\\gamma}_{\\beta \\alpha, 2} &amp; \\omega^{\\gamma}_{\\beta \\alpha, 1} &amp; 0 \\\\ \\end{array} \\right]\\) Skew Form Axes Transformation \\(\\boldsymbol{\\Omega}^{\\gamma}_{\\beta \\alpha} = \\mathbf{R}^{\\gamma}_{\\delta} \\boldsymbol{\\Omega}^{\\delta}_{\\beta \\alpha} \\mathbf{R}^{\\delta}_{\\gamma}\\)"},{"location":"kinematics/rotations/angular_velocity/#references","title":"References","text":"<ol> <li>Groves, P., Principles of GNSS, Inertial, and Multisensor Integrated Navigation Systems, Second Edition, pp. 44-45</li> </ol>"},{"location":"kinematics/rotations/axis_angle/","title":"Axis-Angle","text":""},{"location":"kinematics/rotations/axis_angle/#definition","title":"Definition","text":"<p>Rotation can be respresented by a unit vector, \\(\\hat{\\mathbf{e}} \\in \\mathbb{R}^3\\) and a rotation angle \\(\\theta \\in \\mathbb{R}\\). Let \\(\\boldsymbol{\\rho} = \\theta \\hat{\\mathbf{e}} \\in \\mathbb{R}^3\\), with \\(\\left[ \\boldsymbol{\\rho} \\right]_\\times \\in \\mathfrak{so}(3)\\). </p> <p>Given frames \\(F_\\alpha\\) and \\(F_\\beta\\), \\(\\boldsymbol{\\rho}_{\\beta \\alpha} = \\theta_{\\beta \\alpha} \\hat{\\mathbf{e}}_{\\beta \\alpha}\\) denotes the rotation vector from \\(F_\\beta\\) to \\(F_\\alpha\\). It does not matter in which frame \\(\\hat{\\mathbf{e}}\\) is expressed in since \\(\\mathbf{R} \\hat{\\mathbf{e}} = \\hat{\\mathbf{e}}\\).</p> Axis-Angle Representation Rodrigues' Formula \\(\\begin{align*} \\mathbf{R}^{\\alpha}_{\\beta} &amp;= \\exp{\\left( \\left[ \\boldsymbol{\\rho}_{\\beta \\alpha} \\right]_\\times \\right)} \\\\ &amp;= \\mathbf{I} + \\sin \\theta \\left[ \\hat{\\mathbf{e}} \\right]_\\times + \\left(1 - \\cos \\theta \\right) \\left[ \\hat{\\mathbf{e}} \\right]^2_\\times \\\\ &amp;= \\cos \\theta \\mathbf{I} + \\left(1 - \\cos \\theta \\right) \\hat{\\mathbf{e}} \\hat{\\mathbf{e}}^T + \\sin \\theta \\left[ \\hat{\\mathbf{e}} \\right]_\\times \\end{align*}\\) Logarithmic Mapping \\(\\begin{align*} \\left[ \\boldsymbol{\\rho}_{\\beta \\alpha} \\right]_\\times &amp;= \\ln \\left( \\mathbf{R}^\\alpha_{\\beta} \\right) = \\sum^{\\infty}_{k=0} \\frac{(-1)^k}{k + 1} \\left( \\mathbf{R}^{\\alpha}_{\\beta} - \\mathbf{I} \\right)^{k + 1}  \\end{align*}\\) Closed-Form Rotation Angle \\(\\begin{align*} \\theta_{\\beta \\alpha} &amp;= \\text{arccos} \\left( \\frac{\\text{tr} \\left( \\mathbf{R}^{\\alpha}_{\\beta}\\right) - 1}{2} \\right) \\\\ &amp;= \\text{arccos} \\left( \\frac{1}{2} \\left( \\mathbf{R}^{\\alpha}_{\\beta \\ 1,1} + \\mathbf{R}^{\\alpha}_{\\beta \\ 2, 2} + \\mathbf{R}^{\\alpha}_{\\beta \\ 1,1} - 1\\right) \\right) \\end{align*}\\) Closed-Form Rotation Vector \\(\\begin{align*} \\boldsymbol{\\rho}_{\\alpha \\beta} &amp;= \\frac{\\theta_{\\beta \\alpha}}{2 \\text{sin} (\\theta_{\\beta \\alpha})} \\left[ \\begin{array}{c} \\mathbf{R}^{\\beta}_{\\alpha \\ 2,3} - \\mathbf{R}^{\\beta}_{\\alpha \\ 3,2} \\\\ \\mathbf{R}^{\\beta}_{\\alpha \\ 3,1} - \\mathbf{R}^{\\beta}_{\\alpha \\ 1,3} \\\\ \\mathbf{R}^{\\alpha}_{\\beta \\ 1,2} - \\mathbf{R}^{\\alpha}_{\\beta \\ 2,1} \\end{array} \\right]. \\end{align*}\\) Infinitesimal Rotations \\(\\begin{align*} \\mathbf{R^{\\alpha}_{\\beta}}=  e^{\\left[\\boldsymbol{\\rho}_{\\beta \\alpha} \\right]_{\\times}} \\approx  \\sum^{\\infty}_{k=0} \\frac{\\left[\\boldsymbol{\\rho}_{\\beta \\alpha} \\right]^k_{\\times}}{k!} \\approx \\mathbf{I}_3 + \\left[\\boldsymbol{\\rho}_{\\beta \\alpha} \\right]_{\\times} \\end{align*}\\) <p>Note that rotation vector and Euler angles are identical for small perturbation.</p>"},{"location":"kinematics/rotations/axis_angle/#proofs","title":"Proofs","text":"Rodrigues' Formula <p>Let \\(F_\\alpha\\) and \\(F_\\beta\\) be two frames. A rotation can be represented by a rotation axis \\(\\hat{\\mathbf{e}}\\) and an angle \\(\\theta\\) (from \\(F_\\beta\\) to \\(F_\\alpha\\)), or equivalently by a 3D vector \\(\\boldsymbol{\\rho} = \\theta \\hat{\\mathbf{e}}\\). The rotation matrix can be computed via exponential mapping:</p> \\[ \\begin{align} \\mathbf{R}^\\alpha{\\beta} =e^{\\left[\\boldsymbol{\\rho} \\right]_\\times} &amp;= e^{ \\left[ \\theta \\hat{\\mathbf{e}} \\right]_\\times} = \\sum^{\\infty}_{k = 0} \\frac{1}{k!} \\left(\\theta \\left[\\hat{\\mathbf{e}} \\right]_\\times \\right)^k \\\\ &amp;= \\mathbf{I} + \\theta \\left[ \\hat{\\mathbf{e}} \\right]_\\times + \\frac{\\theta^2}{2} \\left[ \\hat{\\mathbf{e}} \\right]^2_\\times +  \\frac{\\theta^3}{3!} \\left[ \\hat{\\mathbf{e}} \\right]^2_\\times + \\ldots \\\\ &amp;= \\mathbf{I} + \\left( \\theta - \\frac{\\theta^3}{3!} + \\ldots \\right) \\left[ \\hat{\\mathbf{e}} \\right]_\\times + \\left( \\frac{\\theta^2}{2} - \\frac{\\theta^4}{4!} + \\ldots \\right) \\left[ \\hat{\\mathbf{e}} \\right]^2_\\times \\\\ &amp;= \\mathbf{I} + \\sin \\theta \\left[ \\hat{\\mathbf{e}} \\right]_\\times + \\left(1 - \\cos \\theta \\right) \\left[ \\hat{\\mathbf{e}} \\right]^2_\\times \\\\ &amp;= \\cos \\theta \\mathbf{I} + \\left(1 - \\cos \\theta \\right) \\hat{\\mathbf{e}} \\hat{\\mathbf{e}}^T + \\sin \\theta \\left[ \\hat{\\mathbf{e}} \\right]_\\times, \\end{align} \\] <p>or simply:</p> \\[ \\mathbf{R} = \\cos \\theta \\mathbf{I} + \\left(1 - \\cos \\theta \\right) \\hat{\\mathbf{e}} \\hat{\\mathbf{e}}^T + \\sin \\theta \\left[ \\hat{\\mathbf{e}} \\right]_{\\times}. \\label{rodrigues_formula} \\]"},{"location":"kinematics/rotations/axis_angle/#references","title":"References","text":"<ol> <li>Groves, P., Principles of GNSS, Inertial, and Multisensor Integrated Navigation Systems, Second Edition</li> <li>Sola, J., Quaternion Kinematics for the Error-State Kalman Filter</li> <li>Ma., Y., An Invitation to 3-D Vision: From Images to Models, 2001</li> </ol>"},{"location":"kinematics/rotations/euler_angles/","title":"Euler Angles","text":""},{"location":"kinematics/rotations/euler_angles/#definition","title":"Definition","text":"<p>Figiure 1 shows a 321 rotation of reference frame \\(F_\\beta\\) to object frame \\(F_\\alpha\\) with roll \\(\\phi_{\\beta \\alpha}\\), pitch \\(\\theta_{\\beta \\alpha}\\), and yaw \\(\\psi_{\\beta \\alpha}\\) Euler angles.</p> <p> </p> Figure 1 321 rotation from left to right (Groves, p34) <p>The properties table drops the subscripts for simplicity, e.g., \\(\\phi_{\\beta \\alpha} \\triangleq \\phi\\).</p> Properties 321 123 Definition 1. Rotation through the yaw angle \\(\\psi\\) about the common \\(z\\) axis of the \\(F_\\beta\\) frame and the first intermediate frame  2. Rotation through the pitch angle \\(\\theta\\) about the common \\(y\\) axis of the first and second intermediate frame  3. Rotation through the roll angle \\(\\phi\\) about the common \\(x\\) axis of the second frame and the \\(F_\\alpha\\) frame Type Intrinsic Intrinsic Euler Rotation Vector Rotation from \\(F_\\beta\\) to \\(F_\\alpha\\):  \\(\\begin{align*}\\boldsymbol{\\Psi}_{\\beta \\alpha} = \\left[ \\begin{array}{c} \\phi \\\\ \\theta \\\\ \\psi \\\\ \\end{array} \\right] \\end{align*}\\) Rotation Composition \\(\\mathbf{R}^{\\alpha}_{\\beta} = \\mathbf{R}^{\\alpha}_{\\theta} \\mathbf{R}^{\\theta}_{\\psi} \\mathbf{R}^{\\psi}_{\\beta} = \\mathbf{R}_1(\\phi) \\mathbf{R}_2(\\theta) \\mathbf{R}_3(\\psi)\\) \\(\\mathbf{R}^{\\alpha}_\\beta = \\mathbf{R}_3(\\psi) \\mathbf{R}_2(\\theta) \\mathbf{R}_1 (\\phi)\\) Euler to Rotation Matrix \\(\\mathbf{R}^{\\beta}_{\\alpha} = \\left[ \\begin{array}{ccc} c\\theta c\\psi &amp; \\left( \\begin{array}{c} -c\\phi s\\psi + \\\\ s\\phi s\\theta c\\psi \\\\ \\end{array} \\right) &amp;  \\left( \\begin{array}{c} s\\phi s\\psi + \\\\ c\\phi s\\theta c\\psi \\\\ \\end{array} \\right) \\\\ c\\theta s\\psi &amp; \\left(\\begin{array}{c} c\\phi c\\psi + \\\\ s\\phi s\\theta s\\psi \\\\ \\end{array} \\right) &amp; \\left( \\begin{array}{c} -s\\phi c\\psi + \\\\ c\\phi s\\theta s\\psi \\\\ \\end{array} \\right) \\\\ -s\\theta &amp; s\\phi c\\theta &amp; c\\phi c\\theta \\\\ \\end{array} \\right]\\) \\(\\mathbf{R}^\\beta_\\alpha = \\left[ \\begin{array}{ccc} c\\psi c\\theta &amp; -s\\psi c\\theta &amp; s\\theta \\\\ \\left(\\begin{array}{c} s\\psi c\\phi + \\\\ c\\psi s\\theta s\\phi \\end{array} \\right) &amp; \\left(\\begin{array}{c} c\\psi c\\phi - \\\\ s\\psi s\\theta s\\phi \\end{array} \\right) &amp; -c\\theta s\\phi \\\\ \\left(\\begin{array}{c} s\\psi s\\phi - \\\\ c\\psi s\\theta c\\phi \\end{array} \\right) &amp; \\left(\\begin{array}{c} c\\psi s\\phi + \\\\ s\\psi s\\theta c\\phi \\end{array} \\right) &amp; c\\theta c\\phi \\end{array} \\right]\\) Rotation Matrix to Euler \\(\\begin{align*} \\phi &amp;= \\text{arctan}_2 \\left( \\mathbf{R}^{\\beta}_{\\alpha \\ 3,2}, \\mathbf{R}^{\\beta}_{\\alpha \\ 3,3} \\right) \\\\ \\theta &amp;= -\\text{arcsin}\\left( \\mathbf{R}^{\\beta}_{\\alpha \\ 3,1}\\right) \\\\ \\psi &amp;= \\text{arctan}_2 \\left( \\mathbf{R}^{\\beta}_{\\alpha \\ 2,1}, \\mathbf{R}^{\\beta}_{\\alpha \\ 1,1} \\right) \\end{align*}\\) Infinitesimal Rotations \\(\\begin{align*} \\mathbf{R^{\\beta}_{\\alpha}} &amp;= \\left[ \\begin{array}{ccc} 1 &amp; -\\psi &amp; \\theta \\\\ \\psi &amp; 1 &amp; -\\phi \\\\ -\\theta &amp; \\phi &amp; 1 \\end{array} \\right] = \\mathbf{I}_{3} + \\left[\\boldsymbol{\\Psi}_{\\beta \\alpha} \\right]_{\\times} \\\\ \\mathbf{R}^{\\alpha}_{\\beta} &amp;= \\mathbf{I}_3 - \\left[ \\boldsymbol{\\Psi}_{\\beta \\alpha} \\right]_\\times \\end{align*}\\)"},{"location":"kinematics/rotations/euler_angles/#euler-rates","title":"Euler Rates","text":"<p>From Poisson's equation:</p> \\[ \\begin{alignat}{2} \\boldsymbol{\\Omega}^\\alpha_{\\alpha \\beta} &amp;= \\dot{\\mathbf{R}}^\\alpha_\\beta \\mathbf{R}^\\beta_\\alpha, \\quad \\boldsymbol{\\Omega}^\\alpha_{\\beta \\alpha} &amp;&amp;= -\\dot{\\mathbf{R}}^\\alpha_\\beta \\mathbf{R}^\\beta_\\alpha \\\\ \\boldsymbol{\\Omega}^\\beta_{\\alpha \\beta} &amp;= \\mathbf{R}^\\beta_\\alpha \\dot{\\mathbf{R}}^\\alpha_\\beta, \\quad \\boldsymbol{\\Omega}^\\beta_{\\beta \\alpha} &amp;&amp;= - \\mathbf{R}^\\beta_\\alpha \\dot{\\mathbf{R}}^\\alpha_\\beta. \\end{alignat} \\] <p>Then we have:</p> \\[ \\begin{align} \\left[ \\boldsymbol{\\omega}^\\alpha_{\\beta \\alpha} \\right]_\\times &amp;= -\\dot{\\mathbf{R}}^\\alpha_\\beta \\left( \\mathbf{R}^\\alpha_\\beta \\right)^{-1} \\\\ &amp;= -\\dot{\\mathbf{R}}^\\alpha_\\beta \\left( \\mathbf{R}^\\alpha_\\beta \\right)^{T}. \\label{1} \\end{align} \\] <p>For each rotation about a principle axis, we have:</p> \\[ \\begin{align} -\\dot{\\mathbf{R}}_3 \\mathbf{R}^T_3 &amp;= \\left[\\mathbf{I}_3 \\right]_\\times \\dot{\\psi}_{\\beta \\alpha}, \\\\ -\\dot{\\mathbf{R}}_2 \\mathbf{R}^T_2 &amp;= \\left[\\mathbf{I}_2 \\right]_\\times \\dot{\\theta}_{\\beta \\alpha}, \\\\ -\\dot{\\mathbf{R}}_1 \\mathbf{R}^T_1 &amp;= \\left[\\mathbf{I}_1 \\right]_\\times \\dot{\\phi}_{\\beta \\alpha}, \\end{align} \\] <p>where \\(\\mathbf{I}_i\\) os column \\(i\\) of \\(\\mathbf{I}_{3 \\times 3}\\).</p> Proof <p>The principle rotation matrix about the third axis is given as:</p> \\[ \\mathbf{R}_3 =  \\left[ \\begin{array}{ccc} \\cos \\psi &amp; \\sin \\psi &amp; 0 \\\\ -\\sin \\psi &amp; \\cos \\psi &amp; 0 \\\\ 0 &amp; 0 &amp; 1. \\end{array} \\right] \\] <p>The time derivative of \\(\\mathbf{R}_3\\) is:</p> \\[ \\dot{\\mathbf{R}}_3 =  \\left[ \\begin{array}{ccc} -\\dot{\\psi} \\sin \\psi &amp; \\dot{\\psi} \\cos \\psi &amp; 0 \\\\ -\\dot{\\psi} \\cos \\psi &amp; - \\dot{\\psi} \\sin \\psi &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\end{array} \\right]. \\] <p>Then:</p> \\[ -\\dot{\\mathbf{R}}_3 \\mathbf{R}^T_3 = \\left[ \\mathbf{I}_3 \\right]_\\times \\dot{\\psi}. \\] <p>Consider the 3-2-1 Euler angle sequence for frames, \\(F_\\alpha\\) and \\(F_\\beta\\), and its associated rotation matrix:</p> \\[ \\mathbf{R}^\\alpha_\\beta = \\mathbf{R}^\\alpha_\\theta \\mathbf{R}^\\theta_\\psi \\mathbf{R}^\\psi_\\beta = \\mathbf{R}_1 \\mathbf{R}_2 \\mathbf{R}_3. \\] <p>Eq (\\(\\ref{1}\\)) can be written as:</p> \\[ \\begin{align} \\left[ \\boldsymbol{\\omega}^\\alpha_{\\beta \\alpha} \\right]_\\times &amp;= -\\overbrace{\\mathbf{R}^\\alpha_\\theta \\mathbf{R}^\\theta_\\psi \\mathbf{R}^\\psi_\\beta}^\\cdot \\left( \\mathbf{R}^\\alpha_\\theta \\mathbf{R}^\\theta_\\psi \\mathbf{R}^\\psi_\\beta \\right)^T \\\\ &amp;= -\\left[\\dot{\\mathbf{R}}^\\alpha_\\theta \\mathbf{R}^\\theta_\\psi \\mathbf{R}^\\psi_\\beta + \\mathbf{R}^\\alpha_\\theta \\dot{\\mathbf{R}}^\\theta_\\psi \\mathbf{R}^\\psi_\\beta + \\mathbf{R}^\\alpha_\\theta \\mathbf{R}^\\theta_\\psi \\dot{\\mathbf{R}}^\\psi_\\beta \\right] \\mathbf{R}^\\beta_\\psi \\mathbf{R}^\\psi_\\theta \\mathbf{R}^\\theta_\\alpha \\\\ &amp;= -\\mathbf{R}^\\alpha_\\theta \\mathbf{R}^\\theta_\\psi \\dot{\\mathbf{R}}^\\psi_\\beta \\mathbf{R}^\\beta_\\psi \\mathbf{R}^\\psi_\\theta \\mathbf{R}^\\theta_\\alpha - \\mathbf{R}^\\alpha_\\theta \\dot{\\mathbf{R}}^\\theta_\\psi \\mathbf{R}^\\psi_\\theta \\mathbf{R}^\\theta_\\alpha - \\dot{\\mathbf{R}}^\\alpha_\\theta \\mathbf{R}^\\theta_\\alpha \\\\ &amp;= -\\mathbf{R}_1 \\mathbf{R}_2 \\dot{\\mathbf{R}}_3 \\mathbf{R}^T_3 \\mathbf{R}^T_2 \\mathbf{R}^T_1 - \\mathbf{R}_1 \\dot{\\mathbf{R}}_2 \\mathbf{R}^T_2 \\mathbf{R}^T_1 - \\dot{\\mathbf{R}}_1 \\mathbf{R}^T_1 \\\\ &amp;= \\mathbf{R}_1 \\mathbf{R}_2 \\left[\\mathbf{I}_3 \\right]_\\times \\dot{\\psi}_{\\beta \\alpha} \\mathbf{R}^T_2 \\mathbf{R}^T_1 + \\mathbf{R}_1 \\left[\\mathbf{I}_2 \\right]_\\times \\dot{\\theta}_{\\beta \\alpha} \\mathbf{R}^T_1 + \\left[\\mathbf{I}_1 \\right]_\\times \\dot{\\phi}_{\\beta \\alpha}. \\label{2} \\end{align} \\] <p>Given:</p> \\[ \\left[ \\mathbf{R} \\mathbf{r} \\right]_\\times = \\mathbf{R} \\left[ \\mathbf{r} \\right]_\\times \\mathbf{R}^T, \\] <p>for any vector \\(\\mathbf{r} \\in \\mathbb{R}^3\\), eq (\\(\\ref{2}\\)) becomes:</p> \\[ \\begin{align} \\left[ \\boldsymbol{\\omega}^\\alpha_{\\beta \\alpha} \\right]_\\times &amp;= \\left[ \\mathbf{R}_1 \\mathbf{R}_2 \\mathbf{I}_3 \\dot{\\psi}_{\\beta \\alpha} \\right]_\\times + \\left[ \\mathbf{R}_1 \\mathbf{I}_2 \\dot{\\theta}_{\\beta \\alpha} \\right]_\\times + \\left[ \\mathbf{I}_1 \\dot{\\phi}_{\\beta \\alpha} \\right]_\\times, \\end{align} \\] <p>which can be simplified to:</p> \\[ \\begin{align} \\boldsymbol{\\omega}^\\alpha_{\\beta \\alpha} &amp;= \\underbrace{\\left[ \\begin{array}{ccc} \\mathbf{I}_1 &amp; \\mathbf{R}_1 \\mathbf{I}_2 &amp; \\mathbf{R}_1 \\mathbf{R}_2 \\mathbf{I}_3 \\end{array} \\right]}_{\\mathbf{S}(\\phi_{\\beta \\alpha}, \\theta_{\\beta \\alpha})} \\left[ \\begin{array}{c} \\dot{\\phi}_{\\beta \\alpha} \\\\ \\dot{\\theta}_{\\beta \\alpha} \\\\ \\dot{\\psi}_{\\beta \\alpha} \\end{array} \\right] \\\\ &amp;= \\mathbf{S}(\\phi_{\\beta \\alpha}, \\theta_{\\beta \\alpha}) \\dot{\\boldsymbol{\\Psi}}_{\\beta \\alpha}, \\end{align} \\] <p>which gives the angular velocity in terms of Euler rates. The matrix \\(\\mathbf{S}\\) is:</p> \\[ \\mathbf{S}(\\phi_{\\beta \\alpha}, \\theta_{\\beta \\alpha}) = \\left[ \\begin{array}{ccc} 1 &amp; 0 &amp; -\\sin \\theta_{\\beta \\alpha} \\\\ 0 &amp; \\cos \\phi_{\\beta \\alpha} &amp; \\sin \\phi_{\\beta \\alpha} \\cos \\theta_{\\beta \\alpha} \\\\ 0 &amp; -\\sin \\phi_{\\beta \\alpha} &amp; \\cos \\phi_{\\beta \\alpha} \\cos \\theta_{\\beta \\alpha} \\end{array} \\right]. \\] <p>The inverse relationship is:</p> \\[ \\begin{align} \\left[ \\begin{array}{c} \\dot{\\phi}_{\\beta \\alpha} \\\\ \\dot{\\theta}_{\\beta \\alpha} \\\\ \\dot{\\psi}_{\\beta \\alpha} \\end{array} \\right] &amp;= \\left[ \\begin{array}{ccc} 1 &amp; \\sin \\phi_{\\beta \\alpha} \\tan \\theta_{\\beta \\alpha} &amp; \\cos \\phi_{\\beta \\alpha} \\tan \\theta_{\\beta \\alpha} \\\\ 0 &amp; \\cos \\phi_{\\beta \\alpha} &amp; -\\sin \\phi_{\\beta \\alpha} \\\\ 0 &amp; \\sin \\phi_{\\beta \\alpha} / \\cos \\theta_{\\beta \\alpha} &amp; \\cos \\phi_{\\beta \\alpha} / \\cos \\theta_{\\beta \\alpha} \\end{array} \\right] \\boldsymbol{\\omega}^\\alpha_{\\beta \\alpha}. \\end{align} \\] <p>Note that \\(\\mathbf{S}^{-1}\\) does not exist at \\(\\theta_{\\beta \\alpha} = \\pi / 2\\), which is the singularity associasted with Euler series.</p>"},{"location":"kinematics/rotations/euler_angles/#proofs","title":"Proofs","text":"Proof <p>From Figure 1, the first rotation will be through the yaw angle \\(\\psi_{\\beta \\alpha}\\) about the common \\(z\\) axis of the \\(\\beta\\) frame to yield the first intermediate axes \\((x^\\psi, y^\\psi, z^\\psi)\\):</p> \\[ \\begin{align} &amp; x^{\\psi} = x^{\\beta} c(\\psi_{\\beta \\alpha}) + y^{\\beta} s(\\psi_{\\beta \\alpha}) \\\\ &amp; y^{\\psi} = -x^{\\beta} s(\\psi_{\\beta \\alpha}) + y^{\\beta} c(\\psi_{\\beta \\alpha}) \\\\ &amp; z^{\\psi} = z^{\\beta}, \\end{align} \\] <p>which yields to a rotation matrix:</p> \\[ \\mathbf{R}^{\\psi}_{\\beta} = \\left[ \\begin{array}{ccc} c(\\psi_{\\beta \\alpha}) &amp; s(\\psi_{\\beta \\alpha}) &amp; 0 \\\\ -s(\\psi_{\\beta \\alpha}) &amp; c(\\psi_{\\beta \\alpha}) &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{array} \\right]. \\] <p>The second rotation will be through the pitch angle \\(\\theta_{\\beta \\alpha}\\) about the common \\(y\\) axis of the first and second intermediate frames:</p> \\[ \\begin{align} &amp; x^{\\theta} = x^{\\psi} c(\\theta_{\\beta \\alpha}) - z^{\\psi} s(\\theta_{\\beta \\alpha}) \\\\ &amp; y^{\\theta} = y^{\\psi} \\\\ &amp; z^{\\theta} = x^{\\psi} s(\\theta_{\\beta \\alpha}) + z^{\\psi} c(\\theta_{\\beta \\alpha}), \\end{align} \\] <p>which yields to a rotation matrix:</p> \\[ \\mathbf{R}^{\\theta}_{\\psi} = \\left[ \\begin{array}{ccc} c(\\theta_{\\beta \\alpha}) &amp; 0 &amp; -s(\\theta_{\\beta \\alpha}) \\\\ 0 &amp; 1 &amp; 0 \\\\ s(\\theta_{\\beta \\alpha}) &amp; 0 &amp; c(\\theta_{\\beta \\alpha}) \\end{array} \\right]. \\] <p>The third and the last rotation will be through the roll angle \\(\\phi_{\\beta \\alpha}\\) about the common \\(x\\) axis of the second frame and the \\(\\alpha\\) frame:</p> \\[ \\begin{align} &amp; x^{\\alpha} = x^{\\theta} \\\\ &amp; y^{\\alpha} = y^{\\theta} c(\\phi_{\\beta \\alpha}) + z^{\\theta} s(\\phi_{\\beta \\alpha}) \\\\ &amp; z^{\\alpha} = -y^{\\theta} s(\\phi_{\\beta \\alpha}) + z^{\\theta} c(\\phi_{\\beta \\alpha}), \\end{align} \\] <p>which yields to a rotation matrix:</p> \\[ \\mathbf{R}^{\\alpha}_{\\theta} = \\left[ \\begin{array}{ccc} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; c(\\phi_{\\beta \\alpha}) &amp; s(\\phi_{\\beta \\alpha}) \\\\ 0 &amp; -s(\\phi_{\\beta \\alpha}) &amp; c(\\phi_{\\beta \\alpha}) \\end{array} \\right]. \\]"},{"location":"kinematics/rotations/quaternions/","title":"Quaternions","text":""},{"location":"kinematics/rotations/quaternions/#definition","title":"Definition","text":"<p>There are two quaternion conventions commonly in use, Hamilton quaternions and JPL quaternions. The set of Hamilton quaternions, \\(\\mathbb{H}\\), and the set of JPL quaternions, \\(\\mathbb{S}\\) are defined as:</p> \\[ \\begin{alignat}{3} \\mathbb{H} &amp;= \\mathbb{C} + \\mathbb{C}j, &amp;&amp;\\quad k \\triangleq ij = -ji, \\quad &amp;&amp;&amp;i^2 = j^2 = k^2 = ijk = -1 \\\\ \\mathbb{S} &amp;= \\mathbb{C} - \\mathbb{C}j, &amp;&amp;\\quad k \\triangleq ji = -ij, \\quad &amp;&amp;&amp;i^2 = j^2 = k^2 = ijk = -1. \\end{alignat} \\] <p>Elements of \\(\\mathbb{H}\\) and \\(\\mathbb{S}\\) are of the form:</p> \\[ \\begin{align} \\mathbf{q}_{\\mathbb{H}} &amp;= q_w + q_x \\mathbf{i} + q_y \\mathbf{j} + q_z \\mathbf{k} = q_w + \\mathbf{q}_v \\in \\mathbb{H} \\\\ \\mathbf{q}_{\\mathbb{S}} &amp;= q_x \\mathbf{i} + q_y \\mathbf{j} + q_z \\mathbf{k} + q_w = \\mathbf{q}_v + q_w \\in \\mathbb{S}. \\end{align} \\] <p>Note that we can conclude \\(\\mathbf{q}_{\\mathbb{S}} = \\mathbf{q}_{\\mathbb{H}}\\), but the equality is only present in the quaternion values and the two quaternions, when employed in formulas, mean and represent different things. The Hamilton notation (right-handed) and JPL notation (left-handed) are related by:</p> \\[ \\mathbf{q}_{\\mathbb{S}} = \\mathbf{q}^*_{\\mathbb{H}}. \\] Quaternion Type Hamilton JPL Definition \\(\\mathbf{q} =  \\left[ \\begin{array}{cc} q_w &amp; \\mathbf{q}_v \\end{array} \\right]^T\\) \\(\\mathbf{q} =  \\left[ \\begin{array}{cc} \\mathbf{q}_v &amp; q_w \\end{array} \\right]^T\\) Conjugate \\(\\mathbf{q}^{*} = \\left[ \\begin{array}{cc} q_w &amp; - \\mathbf{q}_v \\end{array} \\right]^T\\) \\(\\mathbf{q}^{*} = \\left[ \\begin{array}{cc} -\\mathbf{q}_v &amp; q_w \\end{array} \\right]^T\\) Inverse \\(\\mathbf{q}^{-1} = \\mathbf{q}^* / \\left\\|\\mathbf{q}\\right\\|^2\\) Attitude Representation Constraint \\(\\mathbf{q}^{-1} = \\mathbf{q}^*\\) with \\(\\left\\|\\mathbf{q} \\right\\| = \\sqrt{\\mathbf{q} \\otimes \\mathbf{q}^*} = 1\\) Multiplication \\(\\mathbf{q}\\otimes \\mathbf{p} = \\left[ \\mathbf{q} \\right]_L \\mathbf{p} = \\left[ \\mathbf{p}\\right]_R \\mathbf{q}\\) \\(\\mathbf{q} \\otimes \\mathbf{p} = \\left[ \\mathbf{q} \\right]_L \\mathbf{p} = \\left[ \\mathbf{p} \\right]_R \\mathbf{q}\\) Left Product Matrix \\(\\left[ \\mathbf{q} \\right]_L = \\left[ \\begin{array}{cccc} q_w &amp; -q_x &amp; -q_y &amp; -q_z \\\\ q_x &amp; q_w &amp; - q_z &amp; q_y \\\\ q_y &amp; q_z &amp; q_w &amp; -q_x \\\\ q_z &amp; -q_y &amp; q_x &amp; q_w \\end{array}\\right]\\) \\(\\left[ \\mathbf{q} \\right]_L = \\left[ \\begin{array}{cccc} q_w &amp; q_z &amp; -q_y &amp; q_x \\\\ -q_z &amp; q_w &amp; q_x &amp; q_y \\\\ q_y &amp; -q_x &amp; q_w &amp; q_z \\\\ -q_x &amp; -q_y &amp; -q_z &amp; q_w \\end{array}\\right]\\) Right Product Matrix \\(\\left[\\mathbf{q} \\right]_R= \\left[ \\begin{array}{cccc} q_w &amp; -q_x &amp; -q_y &amp; -q_z \\\\ q_x &amp; q_w &amp; q_z &amp; -q_y \\\\ q_y &amp; -q_z &amp; q_w &amp; q_x \\\\ q_z &amp; q_y &amp; -q_x &amp; q_w \\end{array}\\right]\\) \\(\\left[\\mathbf{q} \\right]_R= \\left[ \\begin{array}{cccc} q_w &amp; -q_z &amp; q_y &amp; q_x \\\\ q_z &amp; q_w &amp; -q_x &amp; q_y \\\\ -q_y &amp; q_x &amp; q_w &amp; q_z \\\\ -q_x &amp; -q_y &amp; -q_z &amp; q_w \\end{array}\\right]\\) Rotation Type Passive Passive Rotation Vector \\(\\mathbf{q}^g_l = \\cos(\\phi / 2) + \\mathbf{u} \\sin(\\phi / 2)\\) \\(\\begin{align*} \\mathbf{q}^l_g &amp;= \\mathbf{u} \\sin (\\phi / 2) + \\cos (\\phi / 2) \\\\ &amp;= \\left[ \\begin{array}{1} \\mathbf{u} \\sin(\\phi / 2) \\\\ \\cos (\\phi / 2) \\end{array} \\right] \\end{align*}\\), where \\(\\mathbf{u}\\) is expressed in \\(F_l\\) Rotation Representation Local-to-Global, i.e., \\(\\mathbf{q} \\triangleq \\mathbf{q}^g_l\\) Global-to-Local, i.e., \\(\\mathbf{q} \\triangleq \\mathbf{q}^l_g\\) Default Operation \\(\\mathbf{x}^g_{a  b} = \\mathbf{q} \\otimes \\mathbf{x}^{l}_{a  b} \\otimes \\mathbf{q}^*\\) \\(\\begin{align*}\\left[ \\begin{array}{c}\\mathbf{x}^l_{a  b} \\\\ 0 \\end{array} \\right]= \\mathbf{q} \\otimes \\left[ \\begin{array}{c} \\mathbf{x}^{g}_{a  b} \\\\ 0 \\end{array} \\right] \\otimes \\mathbf{q}^*\\end{align*}\\) Corresponding Rotation Matrix \\(\\begin{align*}\\mathbf{R}^g_l &amp;= \\left[ \\begin{array}{ccc} q^2_w + q^2_x - q^2_y - q^2_z &amp; 2(q_x q_y - q_w q_z) &amp; 2(q_x q_z + q_w q_y) \\\\ 2(q_x q_y + q_w q_z) &amp; q^2_w - q^2_x + q^2_y - q^2_z &amp; 2(q_y q_z - q_w q_x) \\\\ 2(q_x q_z - q_w q_y) &amp; 2(q_y q_z + q_w q_x) &amp; q^2_w - q^2_x - q^2_y + q^2_z  \\end{array}\\right] \\\\ &amp;= \\left(q^2_w - \\mathbf{q}^T_v \\mathbf{q}_v \\right)\\mathbf{I} + 2 \\mathbf{q}_v \\mathbf{q}^T_v + 2 q_w \\left[ \\mathbf{q}_v \\right]_\\times \\end{align*}\\) \\(\\begin{align*} \\mathbf{R}^l_g &amp;= \\left[ \\begin{array}{ccc} q^2_x - q^2_y - q^2_z + q^2_w &amp; 2(q_x q_y + q_z q_w) &amp; 2(q_x q_z - q_y q_w) \\\\ 2(q_x q_y - q_z q_w) &amp; -q^2_x + q^2_y - q^2_z + q^2_w &amp; 2(q_y q_z + q_x q_w) \\\\ 2(q_x q_z + q_y q_w) &amp; 2(q_y q_z - q_x q_w) &amp; -q^2_x - q^2_y + q^2_z + q^2_w \\end{array} \\right] \\\\ &amp;= \\left(2q^2_w - 1 \\right) \\mathbf{I} - 2q_w \\left[ \\mathbf{q}_v \\right]_\\times + 2 \\mathbf{q}_v \\mathbf{q}^T_v  \\\\ &amp;= \\exp \\left( -\\left[ \\mathbf{u} \\right]_\\times \\phi \\right)  \\end{align*}\\) Rotation Matrix Properties \\(\\begin{align*} \\mathbf{R}\\left\\{ -\\mathbf{q} \\right\\} &amp;= \\mathbf{R}\\left\\{\\mathbf{q} \\right\\} \\\\ \\mathbf{R}\\left\\{ \\mathbf{q}^* \\right\\} &amp;= \\mathbf{R}\\left\\{ \\mathbf{q} \\right\\}^T \\\\ \\mathbf{R}\\left\\{ \\mathbf{q} \\otimes \\mathbf{p} \\right\\} &amp;= \\mathbf{R}\\left\\{ \\mathbf{q} \\right\\} \\mathbf{R} \\left\\{ \\mathbf{p} \\right\\}\\end{align*}\\) Perturbation Perturbation is in the local vector space \\(\\delta \\boldsymbol{\\phi}\\):  \\(\\begin{align*} \\delta \\mathbf{q}^g_l &amp;= \\left[ \\begin{array}{c} \\delta q_w \\\\ \\delta \\mathbf{q}_v \\end{array} \\right] \\\\ &amp;= \\left[ \\begin{array}{c} \\cos \\left( \\delta \\phi / 2 \\right) \\\\  \\mathbf{u} \\sin \\left( \\delta \\phi / 2 \\right) \\end{array} \\right] \\\\ &amp;\\approx \\left[ \\begin{array}{c} 1 \\\\ \\frac{1}{2} \\delta \\phi  \\end{array} \\right] \\\\ \\mathbf{R}^g_l \\left\\{ \\delta \\mathbf{q}^g_l \\right\\} &amp;= \\mathbf{I}_3 + \\left[\\delta \\boldsymbol{\\phi} \\right]_\\times \\end{align*}\\) Perturbation is in the global vector space \\(\\delta \\boldsymbol{\\phi}\\):  \\(\\begin{align*} \\delta \\mathbf{q}^l_g &amp;= \\left[ \\begin{array}{c} \\delta \\mathbf{q}_v \\\\ \\delta q_w \\end{array} \\right] \\\\ &amp;= \\left[ \\begin{array}{c} \\mathbf{u} \\sin \\left( \\delta \\phi / 2 \\right) \\\\ \\cos \\left( \\delta \\phi / 2 \\right) \\end{array} \\right] \\\\ &amp;\\approx \\left[ \\begin{array}{c} \\frac{1}{2} \\delta \\boldsymbol{\\phi} \\\\ 1 \\end{array} \\right] \\\\ \\mathbf{R}^l_g\\left\\{ \\delta \\mathbf{q}^l_g \\right\\} &amp;\\approx \\mathbf{I}_3 - \\left[ \\delta \\boldsymbol{\\phi} \\right]_\\times  \\end{align*}\\)"},{"location":"kinematics/rotations/quaternions/#cross-relations-to-rotation-matrix","title":"Cross-Relations to Rotation Matrix","text":"<p>Let \\(\\boldsymbol{\\phi} = \\phi \\mathbf{u}\\) be a rotation vector representing a rotation of \\(\\phi\\) radians around the axis of \\(\\mathbf{u}\\) which is expressed in the local frame.</p> Rotation Matrix, \\(\\mathbf{R}^g_l\\) Hamilton, \\(\\mathbf{q}^g_l\\) JPL, \\(\\mathbf{q}^l_g\\) ODE \\(\\begin{align*}\\dot{\\mathbf{R}}^g_l &amp;= \\mathbf{R}^g_l \\left[ \\boldsymbol{\\omega}^l_{g  l} \\right]_\\times \\\\ &amp;= \\left[ \\boldsymbol{\\omega}^g_{g  l}  \\right]_\\times \\mathbf{R}^g_l \\end{align*}\\) \\(\\begin{align*} \\dot{\\mathbf{q}}^g_l &amp;= \\frac{1}{2} \\mathbf{q}^g_l \\otimes \\boldsymbol{\\omega}^l_{g  l} \\\\ &amp;= \\frac{1}{2} \\boldsymbol{\\Omega}^l_{g  l} \\mathbf{q}^g_l \\\\ &amp;= \\frac{1}{2} \\left[ \\begin{array}{cccc} 0 &amp; -w_x &amp; -w_y &amp; -w_z \\\\ w_x &amp; 0 &amp; w_z &amp; -w_y \\\\ w_y &amp; -w_z &amp; 0 &amp; w_x \\\\ w_z &amp; w_y &amp; -w_x &amp; 0 \\end{array}\\right] \\mathbf{q}^g_l \\end{align*}\\) \\(\\begin{align*} \\dot{\\mathbf{q}}^l_g &amp;= \\frac{1}{2} \\boldsymbol{\\omega}^l_{g  l} \\otimes \\mathbf{q}^l_g \\\\ &amp;= \\frac{1}{2} \\boldsymbol{\\Omega}^l_{g  l} \\mathbf{q}^l_g \\\\ &amp;= \\frac{1}{2} \\left[ \\begin{array}{cccc} 0 &amp; w_z &amp; -w_y &amp; w_x \\\\ -w_z &amp; 0 &amp; w_x &amp; w_y \\\\ w_y &amp; - w_x &amp; 0 &amp; w_z \\\\ -w_x &amp; -w_y &amp; -w_z &amp; 0  \\end{array} \\right] \\mathbf{q}^l_g \\end{align*}\\) Exponential Map \\(\\mathbf{R}^g_l = \\exp \\left( \\left[ \\phi \\mathbf{u} \\right]_\\times \\right)\\) \\(\\mathbf{q}^g_l = \\exp \\left( \\left[ \\phi \\mathbf{u} / 2 \\right]_\\times \\right)\\) \\(\\mathbf{q}^l_g = \\exp \\left( \\left[ -\\phi \\mathbf{u} / 2 \\right]_\\times \\right)\\) Logarithmic Map \\(\\log \\left( \\mathbf{R}^g_l \\right) = \\left[ \\phi \\mathbf{u} \\right]_\\times\\) \\(\\log \\left( \\mathbf{q}^g_l \\right) = \\phi \\mathbf{u} / 2\\) \\(\\log (\\mathbf{q}^l_g) = -\\phi \\mathbf{u} / 2\\) Rotation Operator \\(\\mathbf{R}^g_l = \\mathbf{I} + \\sin \\phi \\left[ \\mathbf{u} \\right]_\\times + (1 - \\cos \\phi) \\left[ \\mathbf{u} \\right]^2_\\times\\) \\(\\mathbf{q}^g_l = \\cos \\phi / 2 + \\mathbf{u} \\sin \\phi / 2\\) \\(\\mathbf{q}^l_g = -\\mathbf{u} \\sin \\phi / 2 + \\cos \\phi / 2\\) Rotation Action \\(\\mathbf{x}^g_{a  b} = \\mathbf{R}^g_l \\mathbf{x}^l_{a  b}\\) \\(\\mathbf{x}^g_{a  b} = \\mathbf{q}^g_l \\otimes \\mathbf{x}^l_{a  b} \\otimes \\left( \\mathbf{q}^g_l \\right)^*\\) \\(\\mathbf{x}^l_{a  b} = \\mathbf{q}^l_g \\otimes \\mathbf{x}^g_{a  b} \\otimes \\left( \\mathbf{q}^l_g \\right)^*\\) Rotation Composition \\(\\mathbf{R}^a_c = \\mathbf{R}^a_b \\mathbf{R}^b_c\\) \\(\\mathbf{q}^a_{c} = \\mathbf{q}^a_b \\otimes \\mathbf{q}^b_c\\) Interpolation \\(\\begin{align*} \\mathbf{R}(t) &amp;= \\mathbf{R}_0 (\\mathbf{I} + \\sin (t \\Delta \\phi) \\left[ \\mathbf{u} \\right]_\\times + (1 - \\cos( t  \\Delta \\phi)) \\left[ \\mathbf{u} \\right]^2_\\times ) \\\\ &amp;= \\mathbf{R}_0 (\\mathbf{R}^T_0 \\mathbf{R}_1)^t \\end{align*}\\) \\(\\begin{align*}\\mathbf{q}(t) &amp;= \\mathbf{q}_0 \\otimes \\left[ \\begin{array}{c} \\cos(t \\Delta \\phi / 2) \\\\ \\mathbf{u} \\sin (t \\Delta \\phi / 2) \\end{array} \\right] \\\\ &amp;= \\mathbf{q}_0 \\otimes \\left( \\mathbf{q}^*_0 \\otimes \\mathbf{q}_1 \\right)^t \\end{align*}\\)"},{"location":"kinematics/rotations/quaternions/#references","title":"References","text":"<ol> <li>Sola, J., Quaternion Kinematics for the Error-State Kalman Filter</li> <li>Trawny, N., et al. Indirect Kalman Filter for 3D Attitude Estimation, 2005</li> </ol>"},{"location":"kinematics/rotations/rotation_matrix/","title":"Rotation Matrix","text":""},{"location":"kinematics/rotations/rotation_matrix/#definition","title":"Definition","text":"<p>Consider an arbitrary vector \\(\\mathbf{x} \\in \\mathbb{R}^3\\) and two frames \\(F_\\alpha\\) and \\(F_\\beta\\) with a common origin. \\(\\mathbf{R}^{\\beta}_{\\alpha} \\in SO(3)\\) represents a rotation matrix from \\(F_\\alpha\\) to \\(F_\\beta\\).</p> Representation Attitude Rotation Rotation Function Passive, i.e., the function of the rotation operator is on the frames Active, i.e., the function of the rotation operator is on the vectors Rotation Operator \\(\\mathbf{x}^\\beta = \\mathbf{R}^\\beta_\\alpha \\mathbf{x}^\\alpha\\) \\(\\mathbf{x}' = \\mathbf{R} \\mathbf{x}\\) Cross Relationship \\(\\mathbf{R}_{\\text{active}} = \\mathbf{R}^T_{\\text{passive}}\\) Inverse Transformation \\(\\mathbf{R}^{\\alpha}_{\\beta} = \\left(\\mathbf{R}^{\\beta}_{\\alpha} \\right)^T = \\left(\\mathbf{R}^{\\beta}_{\\alpha} \\right)^{-1}\\) Composition \\(\\mathbf{R}^{\\gamma}_{\\alpha} = \\mathbf{R}^{\\gamma}_{\\beta} \\mathbf{R}^{\\beta}_{\\alpha}\\) Resolving Axes Transformation Given a linear transformation matrix \\(\\mathbf{M}\\), \\(\\mathbf{M}^{\\beta} = \\mathbf{R}^{\\beta}_{\\alpha} \\mathbf{M}^{\\alpha} \\mathbf{R}^{\\alpha}_{\\beta}\\) Principal Rotation Matrices Given an angle \\(\\left( \\cdot \\right) = \\left( \\cdot \\right)_{\\beta \\alpha}\\) which is the angle from \\(F_\\beta\\) to \\(F_\\alpha\\) around a specific principle axis, the principal rotation matrices describing the rotation \\(\\mathbf{R}^\\alpha_\\beta\\) are \\(\\begin{align*} \\mathbf{R}_3(\\psi) &amp;= \\left[ \\begin{array}{ccc} \\text{cos}(\\psi) &amp; \\text{sin}(\\psi) &amp; 0 \\\\ -\\text{sin}(\\psi) &amp; \\text{cos}(\\psi) &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{array} \\right] \\\\ \\mathbf{R}_2(\\theta) &amp;= \\left[ \\begin{array}{ccc} \\text{cos}(\\theta) &amp; 0 &amp; -\\text{sin}(\\theta) \\\\ 0 &amp; 1 &amp; 0 \\\\ \\text{sin}(\\theta) &amp; 0 &amp; \\text{cos}(\\theta) \\end{array} \\right] \\\\ \\mathbf{R}_1(\\phi) &amp;= \\left[ \\begin{array}{ccc} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; \\text{cos}(\\phi) &amp; \\text{sin}(\\phi) \\\\ 0 &amp; -\\text{sin}(\\phi) &amp; \\text{cos}(\\phi) \\end{array} \\right] \\\\ \\end{align*}\\) Time Derivative \\(\\begin{align*} \\dot{\\mathbf{R}}^\\alpha_\\beta(t) &amp;= - \\mathbf{R}^\\alpha_\\beta \\boldsymbol{\\Omega}^\\beta_{\\beta \\alpha} = \\mathbf{R}^\\alpha_\\beta \\boldsymbol{\\Omega}^\\beta_{\\alpha \\beta} \\\\ &amp;= -\\boldsymbol{\\Omega}^\\alpha_{\\beta \\alpha} \\mathbf{R}^\\alpha_\\beta = \\boldsymbol{\\Omega}^\\alpha_{\\alpha \\beta} \\mathbf{R}^\\alpha_\\beta \\end{align*}\\)"},{"location":"kinematics/rotations/rotation_matrix/#covariance-transformation","title":"Covariance Transformation","text":"<p>Consider a state vector \\(\\mathbf{x} \\in \\mathbb{R}^6\\) with a covariance matrix \\(\\mathbf{P} \\in \\mathbb{R}^{6 \\times 6}\\). The covariance is defined as:</p> \\[ \\mathbf{P} = \\mathbb{E}\\left[ \\mathbf{x} \\mathbf{x}^T \\right] - \\mathbb{E}\\left[ \\mathbf{x} \\right] \\mathbb{E}\\left[ \\mathbf{x}^T \\right]. \\] <p>If there has been a state transformation such that:</p> \\[ \\mathbf{x}' = \\mathbf{M} \\mathbf{x}, \\] <p>with \\(\\mathbf{M} \\in \\mathbb{R}^{6 \\times 6}\\), then the transformed covariance becomes:</p> \\[ \\begin{align} \\mathbf{M}' &amp;= \\mathbb{E}\\left[ \\mathbf{x}' \\left(\\mathbf{x}' \\right)^T \\right] - \\mathbb{E}\\left[ \\mathbf{x}' \\right] \\mathbb{E}\\left[\\left(\\mathbf{x}' \\right)^T \\right] \\\\ &amp;= \\mathbb{E} \\left[ \\mathbf{M} \\mathbf{x} \\mathbf{x}^T \\mathbf{M}^T \\right] - \\mathbb{E}\\left[ \\mathbf{M} \\mathbf{x} \\right] \\mathbb{E}\\left[ \\mathbf{x}^T \\mathbf{M}^T \\right] \\\\ &amp;= \\mathbf{M} \\mathbb{E}\\left[ \\mathbf{x} \\mathbf{x}^T \\right] \\mathbf{M}^T - \\mathbf{M} \\mathbb{E}\\left[ \\mathbf{x} \\right] \\mathbb{E}\\left[ \\mathbf{x}^T \\right] \\mathbf{M}^T \\\\ &amp;= \\mathbf{M} \\left( \\mathbb{E}\\left[ \\mathbf{x} \\mathbf{x}^T \\right] - \\mathbb{E}\\left[ \\mathbf{x} \\right] \\mathbb{E} \\left[ \\mathbf{x}^T \\right] \\right) \\mathbf{M}^T \\\\ &amp;= \\mathbf{M} \\mathbf{P} \\mathbf{M}^T. \\end{align} \\]"},{"location":"kinematics/rotations/rotation_matrix/#proofs","title":"Proofs","text":"Proof - Principle Rotations <p>Let the coordinates of the vector \\(\\mathbf{p}\\) be \\(\\left[\\begin{array}{ccc} x^\\beta &amp; y^\\beta &amp; z^\\beta \\end{array} \\right]^T\\) in \\(F_\\beta\\) and \\(\\left[\\begin{array}{ccc} x^\\alpha &amp; y^\\alpha &amp; z^\\alpha \\end{array} \\right]^T\\) in \\(F_\\alpha\\). Consider a case when \\(F_\\alpha\\) is rotated by \\(\\psi\\) about the principle 3-axis and a point \\(P\\) as shown in Figure 1.</p> <p> Figure 1 Active rotation about 3-axis </p> <p>In \\(F_\\beta\\) and \\(F_\\alpha\\), the coordinates of \\(P\\) are:</p> \\[ \\begin{align} x^\\beta &amp;= r \\cos \\gamma \\\\ y^\\beta &amp;= r \\sin \\gamma \\\\ x^\\alpha &amp;= r \\cos (\\gamma - \\psi) \\\\ &amp;= r \\left(\\cos \\gamma \\cos \\psi + \\sin \\gamma \\sin \\psi \\right) \\\\ &amp;= x^\\beta \\cos \\psi + y^\\beta \\sin \\psi \\\\ y^\\alpha &amp;= r \\sin (\\gamma - \\psi) \\\\ &amp;= r \\left( \\sin \\gamma \\cos \\psi - \\cos \\gamma \\sin \\psi \\right) \\\\ &amp;= y^\\beta \\cos \\psi - x^\\beta \\sin \\psi. \\end{align} \\] <p>Hence, the relationship between the two coordinate frames is:</p> \\[ \\begin{align} \\left[ \\begin{array}{c} x^\\beta \\\\ y^\\beta \\\\ z^\\beta \\\\ \\end{array} \\right] &amp;= \\left[ \\begin{array}{ccc} \\cos \\psi &amp; -\\sin \\psi &amp; 0 \\\\ \\sin \\psi &amp; \\cos \\psi &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{array} \\right] \\left[ \\begin{array}{c} x^\\alpha \\\\ y^\\alpha \\\\ z^\\alpha \\\\ \\end{array} \\right]. \\end{align} \\] Proof - Poisson \\[ \\dot{\\mathbf{R}}^{\\alpha}_{\\beta}(t) = \\lim_{\\delta t \\rightarrow 0} \\left( \\frac{\\mathbf{R}^{\\alpha}_{\\beta}(t + \\delta t) - \\mathbf{R}^{\\alpha}_{\\beta} (t)}{\\delta t} \\right). \\label{3.6} \\] <p>If \\(F_{\\alpha}\\) is rotating with respect to a stationary reference frame, \\(F_\\beta\\), then:</p> \\[ \\mathbf{R}^{\\alpha}_{\\beta}(t + \\delta t) = \\mathbf{R}^{\\alpha(t + \\delta t)}_{\\alpha(t)} \\mathbf{R}^{\\alpha}_{\\beta}(t). \\label{3.7} \\] <p>Since the rotation of \\(F_{\\alpha}\\) from \\(t\\) to \\(t + \\delta t\\) is infinitesimal, using small angle approximation and assuming \\(\\boldsymbol{\\omega}^{\\alpha}_{\\beta \\alpha}\\) is constant:</p> \\[ \\begin{align} \\mathbf{R}^{\\alpha}_{\\beta} (t + \\delta t) &amp;= (\\mathbf{I}_3 - \\left[ \\boldsymbol{\\rho}_{\\alpha(t) \\alpha(t + \\delta t)}  \\right]_\\times) \\mathbf{R}^{\\alpha}_{\\beta}(t) \\\\  &amp;= (\\mathbf{I}_3 - \\delta t \\left[\\boldsymbol{\\omega}^{\\alpha}_{\\beta \\alpha} \\right]_\\times) \\mathbf{R}^{\\alpha}_{\\beta}(t) \\\\ &amp;= \\left(\\mathbf{I}_3 - \\delta t \\boldsymbol{\\Omega}^{\\alpha}_{\\beta \\alpha} \\right) \\mathbf{R}^{\\alpha}_{\\beta}(t). \\label{3.8} \\end{align} \\] <p>Substituting equation (\\(\\ref{3.8}\\)) into equation (\\(\\ref{3.6}\\)), we get:</p> \\[ \\begin{align} \\dot{\\mathbf{R}}^{\\alpha}_{\\beta}(t) &amp;= \\lim_{\\delta t \\rightarrow 0} \\left( \\frac{ \\left(\\mathbf{I}_3 - \\delta t \\boldsymbol{\\Omega}^{\\alpha}_{\\beta \\alpha} \\right) \\mathbf{R}^{\\alpha}_{\\beta}(t) - \\mathbf{R}^{\\alpha}_{\\beta}(t)}{\\delta t} \\right) \\\\  &amp;= - \\boldsymbol{\\Omega}^{\\alpha}_{\\beta \\alpha} \\mathbf{R}^{\\alpha}_{\\beta} (t) \\\\ &amp;= -\\mathbf{R}^{\\alpha}_{\\beta} (t) \\boldsymbol{\\Omega}^{\\alpha}_{\\beta \\alpha}, \\end{align} \\label{3.9} \\] <p>which is the Poisson's equation.</p> <p>Note that if the above steps are repeated under the assumption that \\(F_\\beta\\) is rotating and \\(F_\\alpha\\) is stionary, the result  \\(\\dot{\\mathbf{R}}^\\alpha_\\beta = -\\mathbf{R}^\\alpha_\\beta \\boldsymbol{\\Omega}^\\beta_{\\beta \\alpha}\\) is obtained. However, the results are equivalent.</p>"},{"location":"kinematics/rotations/rotation_matrix/#references","title":"References","text":"<ol> <li>Groves, P., Principles of GNSS, Inertial, and Multisensor Integrated Navigation Systems, Second Edition</li> </ol>"},{"location":"kinematics/rotations/time_derivative_of_axes/","title":"Time Derivative of Axes","text":"<p>Let \\(F_\\alpha\\) and \\(F_\\beta\\) be defined as:</p> \\[ F_\\alpha = \\left[ \\begin{array}{ccc} \\hat{i}_\\alpha &amp; \\hat{j}_\\alpha &amp; \\hat{k}_\\alpha \\end{array} \\right], \\quad F_\\beta =  \\left[ \\begin{array}{ccc} \\hat{i}_\\beta &amp; \\hat{j}_\\beta &amp; \\hat{k}_\\beta \\end{array} \\right]. \\] <p>Denote the vector time derivative as seen in \\(F_\\alpha\\) by \\(\\left. \\dot{\\left( \\ \\right)} \\right|_\\alpha\\) (or simply just resolved about the axes of \\(F_\\alpha\\)) and that seen in \\(F_\\beta\\) by \\(\\left. \\dot{\\left( \\ \\right)} \\right|_\\beta\\). Then:</p> \\[ \\left. \\dot{F}_\\alpha \\right|_\\alpha = \\mathbf{0}, \\quad \\left. \\dot{F}_\\beta \\right|_\\beta = \\mathbf{0}. \\] <p>Let frame \\(F_\\beta\\) rotate with respect to frame \\(F_\\alpha\\) with \\(\\boldsymbol{\\omega}^\\alpha_{\\alpha \\beta}\\). Then:</p> \\[ \\begin{align} F^T_\\beta &amp;= \\mathbf{R}^\\beta_\\alpha F^T_\\alpha, \\\\ \\left. \\dot{F}^T_\\beta \\right|_\\alpha &amp;= \\dot{\\mathbf{R}}^\\beta_\\alpha F^T_\\alpha + \\mathbf{R}^\\beta_\\alpha \\underbrace{\\left. \\dot{F}^T_\\alpha \\right|_\\alpha}_\\mathbf{0} \\\\ &amp;= -\\boldsymbol{\\Omega}^\\alpha_{\\beta \\alpha} \\mathbf{R}^\\beta_\\alpha  F^T_\\alpha  \\\\ &amp;= \\boldsymbol{\\Omega}^\\alpha_{\\alpha \\beta} F^T_\\beta \\\\ &amp;= \\left[ \\boldsymbol{\\omega}^\\alpha_{\\alpha \\beta} \\right]_\\times F^T_\\beta \\\\ &amp;= \\boldsymbol{\\omega}^\\alpha_{\\alpha \\beta} \\times F^T_\\beta. \\end{align} \\] <p>In order words:</p> \\[ \\left[ \\begin{array}{ccc} \\left. \\dot{\\hat{i}}_\\beta \\right|_\\alpha &amp; \\left. \\dot{\\hat{j}}_\\beta \\right|_\\alpha &amp; \\left. \\dot{\\hat{k}}_\\beta \\right|_\\alpha \\end{array} \\right] = \\boldsymbol{\\omega}^\\alpha_{\\alpha \\beta} \\times \\left[ \\begin{array}{ccc} \\hat{i}_\\beta &amp; \\hat{j}_\\beta &amp; \\hat{k}_\\beta \\end{array} \\right], \\] <p>or equivalently:</p> \\[ \\begin{align} \\left. \\dot{\\hat{i}} \\right|_\\alpha &amp;= \\boldsymbol{\\omega}^\\alpha_{\\alpha \\beta} \\times \\hat{i}_\\beta, \\\\ \\left. \\dot{\\hat{j}} \\right|_\\alpha &amp;= \\boldsymbol{\\omega}^\\alpha_{\\alpha \\beta} \\times \\hat{j}_\\beta, \\\\ \\left. \\dot{\\hat{k}} \\right|_\\alpha &amp;= \\boldsymbol{\\omega}^\\alpha_{\\alpha \\beta} \\times \\hat{k}_\\beta. \\end{align} \\]"},{"location":"kinematics/rotations/time_derivative_of_rotation_matrix/","title":"Time Derivative of Rotation Matrix and Angular Velocity","text":""},{"location":"kinematics/rotations/time_derivative_of_rotation_matrix/#angular-velocity","title":"Angular Velocity","text":"<p>The angular velocity vector, \\(\\boldsymbol{\\omega}^{\\gamma}_{\\beta \\alpha}\\), is the rate of rotation of the frame \\(F_\\alpha\\) axes with respect to the frame \\(F_\\beta\\) axes, resolved about the frame \\(F_\\gamma\\) axes. The rotation is within the plane perpendicular to the angular rate vector, and  the angular rate vector direction follows the right-hand rule. </p>"},{"location":"kinematics/rotations/time_derivative_of_rotation_matrix/#angular-velocity-properties","title":"Angular Velocity Properties","text":"<p>Reversing the sign of the angular rate vector results in rotation of the frame \\(F_\\beta\\) with respect to frame \\(F_\\alpha\\) resolved about the frame \\(F_\\gamma\\) axes:</p> \\[ \\boldsymbol{\\omega}^{\\gamma}_{\\beta \\alpha} = -\\boldsymbol{\\omega}^{\\gamma}_{\\alpha \\beta}. \\label{3.1} \\] <p>Angular rates resolved about the same axes can be added given the object frame of one angular rate is the same as the reference frame of the other:</p> \\[ \\boldsymbol{\\omega}^{\\gamma}_{\\beta \\alpha} = \\boldsymbol{\\omega}^{\\gamma}_{\\beta \\delta} + \\boldsymbol{\\omega}^{\\gamma}_{\\delta \\alpha}.\\label{3.2} \\] <p>The resolving axes can be changed by using the rotation matrix:</p> \\[ \\boldsymbol{\\omega}^{\\gamma}_{\\beta \\alpha} = \\mathbf{R}^{\\gamma}_{\\delta} \\boldsymbol{\\omega}^{\\delta}_{\\beta \\alpha}.\\label{3.3} \\] <p>Given $\\boldsymbol{\\omega}^{\\gamma}_{\\beta \\alpha} $:</p> \\[ \\boldsymbol{\\Omega}^{\\gamma}_{\\beta \\alpha} = \\left[ \\boldsymbol{\\omega}^{\\gamma}_{\\beta \\alpha} \\right]_\\times =  \\left[ \\begin{array}{ccc} 0 &amp; -\\omega^{\\gamma}_{\\beta \\alpha, 3} &amp; \\omega^{\\gamma}_{\\beta \\alpha, 2} \\\\ \\omega^{\\gamma}_{\\beta \\alpha, 3} &amp; 0 &amp; -\\omega^{\\gamma}_{\\beta \\alpha, 1} \\\\ -\\omega^{\\gamma}_{\\beta \\alpha, 2} &amp; -\\omega^{\\gamma}_{\\beta \\alpha, 1} &amp; 0 \\\\ \\end{array} \\right], \\label{3.4} \\] <p>The resolving axes of the skew-symmetric matrix above can be converted via:</p> \\[ \\boldsymbol{\\Omega}^{\\gamma}_{\\beta \\alpha} = \\mathbf{R}^{\\gamma}_{\\delta} \\boldsymbol{\\Omega}^{\\delta}_{\\beta \\alpha} \\mathbf{R}^{\\delta}_{\\gamma}. \\label{3.5} \\]"},{"location":"kinematics/rotations/time_derivative_of_rotation_matrix/#time-derivative-of-rotation-matrix","title":"Time Derivative of Rotation Matrix","text":"<p>Poisson's Equation</p> \\[ \\begin{align} \\dot{\\mathbf{R}}^\\alpha_\\beta(t) &amp;= - \\mathbf{R}^\\alpha_\\beta \\boldsymbol{\\Omega}^\\beta_{\\beta \\alpha} = \\mathbf{R}^\\alpha_\\beta \\boldsymbol{\\Omega}^\\beta_{\\alpha \\beta} \\\\ &amp;= -\\boldsymbol{\\Omega}^\\alpha_{\\beta \\alpha} \\mathbf{R}^\\alpha_\\beta = \\boldsymbol{\\Omega}^\\alpha_{\\alpha \\beta} \\mathbf{R}^\\alpha_\\beta. \\end{align} \\] Proof <p>The time derivative of a coordinate transformation matrix was previously computed when we derived Rodrigues' formula. Using the definition of derivative:</p> \\[ \\dot{\\mathbf{R}}^{\\alpha}_{\\beta}(t) = \\lim_{\\delta t \\rightarrow 0} \\left( \\frac{\\mathbf{R}^{\\alpha}_{\\beta}(t + \\delta t) - \\mathbf{R}^{\\alpha}_{\\beta} (t)}{\\delta t} \\right). \\label{3.6} \\] <p>If \\(F_{\\alpha}\\) is rotating with respect to a stationary reference frame, \\(F_\\beta\\), then:</p> \\[ \\mathbf{R}^{\\alpha}_{\\beta}(t + \\delta t) = \\mathbf{R}^{\\alpha(t + \\delta t)}_{\\alpha(t)} \\mathbf{R}^{\\alpha}_{\\beta}(t). \\label{3.7} \\] <p>Since the rotation of \\(F_{\\alpha}\\) from \\(t\\) to \\(t + \\delta t\\) is infinitesimal, using small angle approximation and assuming \\(\\boldsymbol{\\omega}^{\\alpha}_{\\beta \\alpha}\\) is constant:</p> \\[ \\begin{align} \\mathbf{R}^{\\alpha}_{\\beta} (t + \\delta t) &amp;= (\\mathbf{I}_3 - \\left[ \\boldsymbol{\\rho}_{\\alpha(t) \\alpha(t + \\delta t)}  \\right]_\\times) \\mathbf{R}^{\\alpha}_{\\beta}(t) \\\\  &amp;= (\\mathbf{I}_3 - \\delta t \\left[\\boldsymbol{\\omega}^{\\alpha}_{\\beta \\alpha} \\right]_\\times) \\mathbf{R}^{\\alpha}_{\\beta}(t) \\\\ &amp;= \\left(\\mathbf{I}_3 - \\delta t \\boldsymbol{\\Omega}^{\\alpha}_{\\beta \\alpha} \\right) \\mathbf{R}^{\\alpha}_{\\beta}(t). \\label{3.8} \\end{align} \\] <p>Substituting equation (\\(\\ref{3.8}\\)) into equation (\\(\\ref{3.6}\\)), we get:</p> \\[ \\begin{align} \\dot{\\mathbf{R}}^{\\alpha}_{\\beta}(t) &amp;= \\lim_{\\delta t \\rightarrow 0} \\left( \\frac{ \\left(\\mathbf{I}_3 - \\delta t \\boldsymbol{\\Omega}^{\\alpha}_{\\beta \\alpha} \\right) \\mathbf{R}^{\\alpha}_{\\beta}(t) - \\mathbf{R}^{\\alpha}_{\\beta}(t)}{\\delta t} \\right) \\\\  &amp;= - \\boldsymbol{\\Omega}^{\\alpha}_{\\beta \\alpha} \\mathbf{R}^{\\alpha}_{\\beta} (t) \\\\ &amp;= -\\mathbf{R}^{\\alpha}_{\\beta} (t) \\boldsymbol{\\Omega}^{\\alpha}_{\\beta \\alpha}, \\end{align} \\label{3.9} \\] <p>which is known as the Poisson's equation (derived in Sophus section as well).</p> <p>Note that if the above steps are repeated under the assumption that \\(F_\\beta\\) is rotating and \\(F_\\alpha\\) is stionary, the result  \\(\\dot{\\mathbf{R}}^\\alpha_\\beta = -\\mathbf{R}^\\alpha_\\beta \\boldsymbol{\\Omega}^\\beta_{\\beta \\alpha}\\) is obtained. However, the results are equivalent.</p>"},{"location":"navigation/references/","title":"References","text":"<p>Contents are from:</p> <ol> <li>Groves, P., Principles of GNSS, Inertial, and Multisensor Integrated Navigation Systems, Second Edition, 2013</li> <li>Misra, P., Enge. P, Global Positioning System: Signals, Measurements, and Performance</li> <li>Woodman, O., An Introduction To Inertial Navigation</li> </ol>"},{"location":"navigation/coordinate_frames/coordinate_frames/","title":"Coordinate Frames","text":""},{"location":"navigation/coordinate_frames/coordinate_frames/#eci-frame","title":"ECI Frame","text":"<p>Earth-centered inertial (ECI) coordinate frame, denoted as \\(F_i\\). Refer to Wiki.</p>"},{"location":"navigation/coordinate_frames/coordinate_frames/#ecef-frame","title":"ECEF Frame","text":"<p>Earth-centered Earth-fixed (ECEF) coordinate frame, denoted as \\(F_e\\). Refer to Wiki.</p>"},{"location":"navigation/coordinate_frames/coordinate_frames/#local-navigation-frame","title":"Local Navigation Frame","text":"<p>Local navigation frame denoted as \\(F_n\\). Refer to Wiki</p>"},{"location":"navigation/coordinate_frames/coordinate_frames/#local-tangent-plane-frame","title":"Local Tangent-Plane Frame","text":"<p>Local tangent-plane frame denoted as \\(F_l\\) that has North-East-Down axes and a fixed origin. Refer to Wiki.</p>"},{"location":"navigation/coordinate_frames/coordinate_frames/#body-frame","title":"Body Frame","text":"<p>Body frame, \\(F_b\\), comprises the origin and orientation of the object described by the navigation solution. Its origin coincides with  local navigation frame and the axes remain fixed with respect to the vehicle. \\(x^b\\) is the forward axis, pointing in the usual direction of travel;  \\(z^b\\) is the down axis, pointing in the usual direction of gravity; and \\(y^b\\) is the right axis, completing the orthogonal set. Body frame is shown in Figure 1.</p> <p> </p> Figure 1 Body Frame (Groves, p29)"},{"location":"navigation/geodesy/ecef_to_curvilinear/","title":"ECEF From Curvilinear Conversion","text":"<p>The meridian (or the north-south motion) radius of curvature, \\(R_{N}\\),  varies with latitude and is smallest at the equator, where the geocentric radius is the largest, and largest at the poles:</p> \\[ R_{N}(L) = \\frac{R_0 (1 - e^2)}{(1 - e^2 \\text{sin}^2(L))^{3/2}}, \\] <p>where \\(L\\) is the geodetic latitude in radians, \\(e\\) is the eccentricity of the reference ellipsoid (WGS 84 - 0.0818191908425), \\(R_0\\) is the equatorial radius (WGS 84 - 6,378,137.0m).</p> <p>The radius of curvature for east-west motion, \\(R_E\\) is the vertical plane perpendicular to the meridian plane and is not the plane of constant latitude. It varies with latitude and is smallest at the equator:</p> \\[ R_{E}(L) = \\frac{R_0}{\\sqrt{1 - e^2 \\text{sin}^2(L)}}. \\] <p>The Cartesian ECEF position can be obtained from curvilinear position by:</p> \\[ \\begin{align} \\mathbf{r}^{e}_{eb} =  \\left[ \\begin{array}{c} x^{e}_{eb} \\\\ y^{e}_{eb} \\\\ z^{e}_{eb} \\end{array} \\right] =  \\left[ \\begin{array}{c} \\left( R_E (L_b) + h_b \\right) \\text{cos}L_b \\text{cos} \\lambda_b \\\\ \\left( R_E (L_b) + h_b \\right) \\text{cos}L_b \\text{sin} \\lambda_b \\\\ \\left[ (1 - e^2) R_E (L_b) + h_b \\right] \\text{sin} L_b \\end{array} \\right], \\end{align} \\] <p>where \\(h_b\\) is the geodetic height or altitude (distance from a body to the ellipsoid surface along the normal to that ellipsoid).</p>"},{"location":"navigation/geodesy/ecef_to_curvilinear/#curvilinear-from-ecef-conversion","title":"Curvilinear From ECEF Conversion","text":"<p>Conversion from ECEF position to LLA is given by:</p> \\[ \\begin{align} \\text{tan}L_b &amp;= \\frac{z^{e}_{eb} \\left[R_E(L_b) + h_b \\right]}{\\sqrt{(x^e_{eb})^2 + (y^e_{eb})^2} \\left[(1 - e^2)R_E(L_b) + h_b \\right]} \\\\ \\text{tan}\\lambda_b &amp;= \\frac{y^e_{eb}}{x^{e}_{eb}} \\\\ h_b &amp;= \\frac{\\sqrt{(x^e_{eb})^2 + (y^{e}_{eb})^2}}{\\text{cos} L_b} - R_E(L_b), \\end{align} \\] <p>where a four-quadrant arctangent function must be used for longitude. Also, since \\(R_E\\) is a function of latitude, the latitude and heigh must be solved iteratively. The approximate closed-form latitude solution (accurate to within 1cm for positions close to the Earth's surface) is given by:</p> \\[ \\text{tan}L_b \\approx \\frac{z^e_{eb} \\sqrt{1 - e^2} + e^2 R_0 sin^3 \\zeta_b}{\\sqrt{1 - e^2} (\\sqrt{(x^e_{eb})^2 + (y^e_{eb})^2} - e^2 R_0 \\text{cos}^3 \\zeta_b)}, \\] <p>where</p> \\[ \\text{tan}\\zeta_b = \\frac{z^e_{eb}}{\\sqrt{1-e^2} \\sqrt{(x^e_{eb})^2 + (y^e_{eb})^2}}. \\] <p>\\(1^o\\) of longitude is about 110 km (60 nautical miles) at the equator, and 80 km at \\(45^o\\) latitude.</p>"},{"location":"navigation/geodesy/frame_transformations/","title":"Frame Transformations","text":""},{"location":"navigation/geodesy/frame_transformations/#common-transformations","title":"Common Transformations","text":"<p>Cartesian position, velocity, acceleration, and angular rate referenced to the same frame transform between resolving axes simply by applying the transformation matrix:</p> \\[ \\mathbf{x}^{\\gamma}_{\\beta \\alpha} = \\mathbf{R}^\\gamma_\\delta \\mathbf{x}^{\\delta}_{\\beta \\alpha} \\ \\ \\  \\mathbf{x} \\in \\mathbf{r}, \\mathbf{v}, \\mathbf{a}, \\boldsymbol{\\omega} \\ \\ \\  F_\\gamma, F_\\delta \\in F_i, F_e, F_n, F_l, F_b. \\label{3.8.1} \\] <p>The attitude of a body with respect to a reference frame is described by:</p> \\[ \\mathbf{R}^{\\beta}_b, \\mathbf{R}^b_\\beta \\ \\ \\ F_\\beta \\in F_i, F_e, F_n, F_l. \\label{3.8.2} \\] <p>The body attitude with respect to a new reference frame can be obtained by multiplying by the transformation matrix between the two reference frames:</p> \\[ \\mathbf{R}^{\\delta}_b = \\mathbf{R}^\\delta_\\beta \\mathbf{R}^\\beta_b, \\ \\ \\  \\mathbf{R}^{b}_\\delta = \\mathbf{R}^b_\\beta \\mathbf{R}^\\beta_\\delta \\ \\ \\ F_\\beta, F_\\delta \\in F_i, F_e, F_n, F_l. \\label{3.8.3} \\] <p>Transforming Euler, quaternion, or rotation vector attitude to a new reference frame should be done via converting to transformation matrix representation, transform the reference, and then convert back.</p>"},{"location":"navigation/geodesy/frame_transformations/#eci-and-ecef-frames","title":"ECI and ECEF Frames","text":"<p>Since the \\(z\\) axis is common between ECI and ECEF, the transformation between the two frames can be described  by rotation around the common \\(z\\) axis:</p> \\[ \\begin{align} \\mathbf{R}^e_i &amp;= \\left[ \\begin{array}{ccc} \\text{cos} \\omega_{ie} (t - t_0) &amp; \\text{sin} \\omega_{ie} (t - t_0) &amp; 0 \\\\ -\\text{sin} \\omega_{ie} (t - t_0) &amp; \\text{cos} \\omega_{ie} (t - t_0) &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{array} \\right] \\\\ \\\\ \\mathbf{R}^i_e &amp;= \\left[ \\begin{array}{ccc} \\text{cos} \\omega_{ie} (t - t_0) &amp; -\\text{sin} \\omega_{ie} (t - t_0) &amp; 0 \\\\ \\text{sin} \\omega_{ie} (t - t_0) &amp; \\text{cos} \\omega_{ie} (t - t_0) &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{array} \\right], \\label{3.8.4} \\end{align} \\] <p>where \\(w_{it} (t-t_0)\\) is the rotation angle since the time of coincidence between the two frames at \\(t_0\\).</p> <p>Since a position of body referenced to the two frames are the same, only the resolving axes need to be transformed:</p> \\[ \\mathbf{r}^e_{eb} = \\mathbf{R}^e_i \\mathbf{r}^i_{eb} = \\mathbf{R}^e_i \\mathbf{r}^i_{ib}, \\ \\ \\ \\mathbf{r}^i_{ib} = \\mathbf{R}^i_e \\mathbf{r}^e_{ib} =\\mathbf{R}^i_e \\mathbf{r}^e_{eb}. \\tag{3.8.5} \\label{3.8.5} \\] <p>Since ECEF is rotating with respect to ECI, the velocity transformation is:</p> \\[ \\begin{align} \\mathbf{v}^e_{eb} &amp;= \\dot{\\mathbf{r}}^e_{eb} \\\\ &amp;= \\dot{\\mathbf{R}}^e_i \\mathbf{r}^i_{ib} + \\mathbf{R}^e_i \\dot{\\mathbf{r}}^i_{ib} \\\\ &amp;= -\\boldsymbol{\\Omega}^e_{ie} \\mathbf{R}^e_i \\mathbf{r}^i_{ib} + \\mathbf{v}^e_{ib}\\\\  &amp;= \\mathbf{v}^e_{ib} - \\boldsymbol{\\Omega}^e_{ie} \\mathbf{r}^e_{ib} \\\\ &amp;= \\mathbf{R}^e_i \\mathbf{v}^i_{ib} - \\mathbf{R}^e_i \\boldsymbol{\\Omega}^i_{ie} \\mathbf{R}^i_e \\mathbf{r}^e_{ib} \\\\ &amp;= \\mathbf{R}^e_i \\left( \\mathbf{v}^i_{ib} - \\boldsymbol{\\Omega}^i_{ie} \\mathbf{r}^i_{ib} \\right) \\label{3.8.6} \\end{align}, \\] <p>and:</p> \\[ \\begin{align} \\mathbf{v}^i_{ib} &amp;= \\dot{\\mathbf{r}}^i_{ib} \\\\ &amp;= \\dot{\\mathbf{R}}^i_e \\mathbf{r}^e_{eb} + \\mathbf{R}^i_e \\dot{\\mathbf{r}}^e_{eb} \\\\ &amp;= \\boldsymbol{\\Omega}^{i}_{ie} \\mathbf{R}^i_e \\mathbf{r}^e_{eb} + \\mathbf{R}^i_e \\mathbf{v}^e_{eb} \\\\ &amp;= \\mathbf{R}^i_e \\mathbf{R}^e_i \\boldsymbol{\\Omega}^{i}_{ie} \\mathbf{R}^i_e \\mathbf{r}^e_{eb} + \\mathbf{R}^i_e \\mathbf{v}^e_{eb} \\\\  &amp;= \\mathbf{R}^i_e \\left( \\mathbf{v}^e_{eb} + \\boldsymbol{\\Omega}^{e}_{ie} \\mathbf{r}^e_{eb} \\right). \\label{3.8.7} \\end{align} \\] <p>Similarly, acceleration is:</p> \\[ \\begin{align} \\mathbf{a}^e_{eb} &amp;= \\mathbf{R}^e_i \\left( \\mathbf{a}^i_{ib} - 2 \\boldsymbol{\\Omega}^i_{ie} \\mathbf{v}^i_{ib} +  \\boldsymbol{\\Omega}^i_{ie} \\boldsymbol{\\Omega}^i_{ie} \\mathbf{r}^i_{ib} \\right) \\\\  \\mathbf{a}^i_{ib} &amp;= \\mathbf{R}^i_e \\left( \\mathbf{a}^e_{eb} + 2 \\boldsymbol{\\Omega}^e_{ie} \\mathbf{v}^e_{eb} +  \\boldsymbol{\\Omega}^e_{ie} \\boldsymbol{\\Omega}^e_{ie} \\mathbf{r}^e_{ib} \\right). \\label{3.8.8} \\\\  \\end{align} \\] <p>For angular rates, we know that:</p> \\[ \\boldsymbol{\\omega}^i_{ie} = \\boldsymbol{\\omega}^e_{ie} =  \\left[ \\begin{array}{c} 0 \\\\ 0 \\\\ \\omega_{ie} \\end{array} \\right]. \\label{3.8.9} \\] <p>Then:</p> \\[ \\begin{align} \\boldsymbol{\\omega}^e_{eb} &amp;= \\boldsymbol{\\omega}^e_{ib} - \\boldsymbol{\\omega}^e_{ie} = \\mathbf{R}^e_i \\left( \\boldsymbol{\\omega}^i_{ib} - \\boldsymbol{\\omega}^i_{ie} \\right) \\\\  \\boldsymbol{\\omega}^i_{ib} &amp;= \\boldsymbol{\\omega}^i_{eb} + \\boldsymbol{\\omega}^i_{ie} = \\mathbf{R}^i_e \\left( \\boldsymbol{\\omega}^e_{eb} + \\boldsymbol{\\omega}^e_{ie} \\right). \\label{3.8.10} \\end{align} \\]"},{"location":"navigation/geodesy/frame_transformations/#ecef-and-local-navigation-frames","title":"ECEF and Local Navigation Frames","text":"<p>ECEF frame to local navigation frame (NED) would require \\(z\\) axis rotation by the amount of longitude,  \\(\\lambda_b\\) and intermediate \\(y\\) axis rotation by \\(-\\frac{\\pi}{2} -  L_b\\), where \\(L_b\\) is the latitude. This yields to:</p> \\[ \\begin{align} \\mathbf{R}^e_n &amp;=  \\left[ \\begin{array}{ccc} \\text{cos}(-\\frac{\\pi}{2} - L_b) &amp; 0 &amp; -\\text{sin}(- \\frac{\\pi}{2} - L_b) \\\\  0 &amp; 1 &amp; 0 \\\\ \\text{sin}(-\\frac{\\pi}{2} - L_b) &amp; 0 &amp; \\text{cos}(-\\frac{\\pi}{2} - L_b) \\\\ \\end{array} \\right] \\left[ \\begin{array}{ccc} \\text{cos}\\lambda_b &amp; \\text{sin}\\lambda_b &amp; 0 \\\\ -\\text{sin}\\lambda_b &amp; \\text{cos}\\lambda_b &amp; 0 \\\\ 0 &amp; 0 &amp; 1\\\\ \\end{array} \\right] \\\\  &amp;=  \\left[ \\begin{array}{ccc} -\\text{sin}L_b &amp; 0 &amp; \\text{cos}L_b \\\\  0 &amp; 1 &amp; 0 \\\\ -\\text{cos}L_b &amp; 0 &amp; -\\text{sin}L_b \\\\ \\end{array} \\right] \\left[ \\begin{array}{ccc} \\text{cos}\\lambda_b &amp; \\text{sin}\\lambda_b &amp; 0 \\\\ -\\text{sin}\\lambda_b &amp; \\text{cos}\\lambda_b &amp; 0 \\\\ 0 &amp; 0 &amp; 1\\\\ \\end{array} \\right] \\\\  &amp;=  \\left[ \\begin{array}{ccc} -\\text{sin}L_b \\text{cos}\\lambda_b &amp; -\\text{sin}L_b \\text{sin}\\lambda_b &amp; \\text{cos}L_b \\\\ -\\text{sin}\\lambda_b &amp; \\text{cos}\\lambda_b &amp; 0 \\\\ -\\text{cos}L_b \\text{cos}\\lambda_b &amp; -\\text{cos}L_b \\text{sin}\\lambda_b &amp; -\\text{sin}L_b \\end{array} \\right], \\label{3.8.11} \\end{align} \\] <p>and:</p> \\[ \\begin{align} \\mathbf{R}^n_e &amp;=  \\left[ \\begin{array}{ccc} -\\text{sin}L_b \\text{cos}\\lambda_b &amp; -\\text{sin}\\lambda_b &amp; -\\text{cos}L_b \\text{cos}\\lambda_b \\\\ -\\text{sin}L_b \\text{sin}\\lambda_b &amp; \\text{cos}\\lambda_b &amp; -\\text{cos}L_b \\text{sin}\\lambda_b  \\\\ \\text{cos}L_b &amp; 0 &amp; -\\text{sin}L_b \\\\ \\end{array} \\right].  \\label{3.8.12} \\end{align} \\] <p>The latitude and longitude can be obtained from the transformation matrices by:</p> \\[ \\begin{align} L_b &amp;= \\text{arctan}\\left(\\frac{-R^n_{e3, 3}}{R^n_{e1, 3}} \\right) = \\text{arctan}\\left(\\frac{-R^e_{n3, 3}}{R^e_{n3, 1}} \\right) \\\\ \\lambda_b &amp;= \\text{arctan}_2 \\left( -R^n_{e2, 1}, -R^n_{e2, 2} \\right) = \\text{arctan}_2 \\left( -R^e_{n1, 2}, -R^e_{n2, 2} \\right) \\\\ \\end{align} \\] <p>Position, velocity, and acceleration referenced to local navigation frame are meaningless since the origin coincides with \\(F_b\\). The resolving axes of Earth-referenced position, velocity and acceleration are:</p> \\[ \\begin{align} \\mathbf{r}^n_{eb} &amp;= \\mathbf{R}^n_e \\mathbf{r}^e_{eb}, \\ \\ \\ \\mathbf{r}^e_{eb} = \\mathbf{R}^e_n \\mathbf{r}^n_{eb} \\\\ \\mathbf{v}^n_{eb} &amp;= \\mathbf{R}^n_e \\mathbf{v}^e_{eb}, \\ \\ \\ \\mathbf{v}^e_{eb} = \\mathbf{R}^e_n \\mathbf{v}^n_{eb} \\\\ \\mathbf{a}^n_{eb} &amp;= \\mathbf{R}^n_e \\mathbf{a}^e_{eb}, \\ \\ \\ \\mathbf{a}^e_{eb} = \\mathbf{R}^e_n \\mathbf{a}^n_{eb} \\label{3.8.13} \\\\ \\end{align} \\] <p>Angular rates transform as:</p> \\[ \\begin{align} \\boldsymbol{\\omega}^n_{nb} &amp;= \\mathbf{R}^n_e \\left( \\boldsymbol{\\omega}^e_{eb} - \\boldsymbol{\\omega}^e_{en} \\right) = \\mathbf{R}^n_e \\boldsymbol{\\omega}^e_{eb} - \\boldsymbol{\\omega}^n_{en} \\\\  \\boldsymbol{\\omega}^e_{eb} &amp;= \\mathbf{R}^e_n \\left( \\boldsymbol{\\omega}^n_{nb} + \\boldsymbol{\\omega}^n_{en} \\right) \\label{3.8.14} \\end{align}  \\]"},{"location":"navigation/geodesy/frame_transformations/#inertial-and-local-navigation-frames","title":"Inertial and Local Navigation Frames","text":"<p>We can compute the transform matrix from equations (\\(\\ref{3.8.4}\\)) and (\\(\\ref{3.8.12}\\)):</p> \\[ \\begin{align} \\mathbf{R}^n_i &amp;= \\mathbf{R}^e_i \\mathbf{R}^n_e = \\left[ \\begin{array}{ccc} -\\text{sin}L_b \\text{cos}(\\lambda_b + \\omega_{ie}(t - t_0)) &amp; -\\text{sin}L_b \\text{sin}(\\lambda_b + \\omega_{ie}(t - t_0)) &amp; \\text{cos}L_b \\\\ -\\text{sin}(\\lambda_b + \\omega_{ie}(t - t_0)) &amp; \\text{cos}(\\lambda_b + \\omega_{ie} (t - t_0)) &amp; 0 \\\\ -\\text{cos}L_b \\text{cos}(\\lambda_b + \\omega_{ie}(t - t_0)) &amp; -\\text{cos}L_b \\text{sin}(\\lambda_b + \\omega_{ie}(t-t_0)) &amp; -\\text{sin}L_b \\end{array} \\right] \\\\ \\\\ \\mathbf{R}^i_n &amp;= \\left[ \\begin{array}{ccc} -\\text{sin}L_b \\text{cos}(\\lambda_b + \\omega_{ie}(t - t_0)) &amp; -\\text{sin}(\\lambda_b + \\omega_{ie}(t - t_0)) &amp; -\\text{cos}L_b \\text{cos}(\\lambda_b + \\omega_{ie}(t - t_0)) \\\\ -\\text{sin}L_b \\text{sin}(\\lambda_b + \\omega_{ie}(t - t_0)) &amp; \\text{cos}(\\lambda_b + \\omega_{ie} (t - t_0)) &amp; -\\text{cos}L_b \\text{sin}(\\lambda_b + \\omega_{ie}(t-t_0)) \\\\ \\text{cos}L_b &amp; 0 &amp; -\\text{sin}L_b \\\\  \\end{array} \\right] \\label{3.8.15} \\end{align} \\] <p>Earth-referenced velocity and acceleration in navigation frame axes transform to and from their ECI reference counterparts as:</p> \\[ \\begin{align} \\mathbf{v}^n_{eb} &amp;= \\mathbf{R}^n_i (\\mathbf{v}^i_{ib} + \\boldsymbol{\\Omega}^i_{ie} \\mathbf{r}^i_{ib}) \\\\ \\mathbf{v}^i_{ib} &amp;= \\mathbf{R}^i_n \\mathbf{v}^n_{eb} + \\mathbf{R}^i_e \\boldsymbol{\\Omega}^e_{ie} \\mathbf{r}^e_{eb} \\\\ \\mathbf{a}^n_{eb} &amp;= \\mathbf{R}^n_i (\\mathbf{a}^i_{ib} - 2 \\boldsymbol{\\Omega}^i_{ie} \\mathbf{v}^i_{ib} + \\boldsymbol{\\Omega}^i_{ie} \\boldsymbol{\\Omega}^i_{ie} \\mathbf{r}^i_{ib}) \\\\ \\mathbf{a}^i_{ib} &amp;= \\mathbf{R}^i_n (\\mathbf{a}^n_{eb} + 2 \\boldsymbol{\\Omega}^n_{ie} \\mathbf{v}^n_{eb}) + \\mathbf{R}^i_e \\boldsymbol{\\Omega}^e_{ie} \\boldsymbol{\\Omega}^e_{ie} \\mathbf{r}^e_{eb}. \\label{3.8.16} \\end{align}  \\] <p>Angular rates transform as:</p> \\[ \\begin{align} \\boldsymbol{w}^n_{nb} &amp;= \\mathbf{R}^n_i (\\boldsymbol{\\omega}^i_{ib} - \\boldsymbol{\\omega}^i_{in}) = \\mathbf{R}^n_i (\\boldsymbol{\\omega}^i_{ib} - \\boldsymbol{\\omega}^i_{ie}) - \\boldsymbol{\\omega}^n_{en} \\\\ \\boldsymbol{w}^i_{ib} &amp;= \\mathbf{R}^i_n (\\boldsymbol{\\omega}^n_{nb} + \\boldsymbol{\\omega}^n_{in}) = \\mathbf{R}^i_n (\\boldsymbol{\\omega}^n_{nb} + \\boldsymbol{\\omega}^n_{en}) + \\boldsymbol{\\omega}^i_{ie}. \\label{3.8.17} \\end{align} \\]"},{"location":"navigation/geodesy/frame_transformations/#earth-and-local-tangent-plane-frames","title":"Earth and Local Tangent-Plane Frames","text":"<p>The transformation matrix is similar to ECEF and navigation frame conversions:</p> \\[ \\begin{align} \\mathbf{R}^l_e &amp;= \\left[ \\begin{array}{ccc} -\\text{sin}L_l \\text{cos}\\lambda_l &amp; -\\text{sin}L_l \\text{sin}\\lambda_l &amp; \\text{cos}L_l \\\\ -\\text{sin}\\lambda_l &amp; \\text{cos}\\lambda_l &amp; 0 \\\\ -\\text{cos}L_l \\text{cos}\\lambda_l &amp; -\\text{cos}L_l \\text{sin}\\lambda_l &amp; -\\text{sin}L_l \\end{array} \\right] \\\\ \\\\ \\mathbf{R}^e_l &amp;=  \\left[ \\begin{array}{ccc} -\\text{sin}L_l \\text{cos}\\lambda_l &amp; -\\text{sin}\\lambda_l &amp; -\\text{cos}L_l \\text{cos}\\lambda_l \\\\ -\\text{sin}L_l \\text{sin}\\lambda_l &amp; \\text{cos}\\lambda_l &amp; -\\text{cos}L_l \\text{sin}\\lambda_l  \\\\ \\text{cos}L_l &amp; 0 &amp; -\\text{sin}L_l \\\\ \\end{array} \\right]. \\label{3.8.18} \\end{align} \\] <p>Note that the origin and orientation of a local tangent-plane frame with respect to an ECEF frame are constant. Therefore, the velocity, acceleration, and angular rate can be transformed by rotating the resolving axes:</p> \\[ \\begin{align} \\mathbf{v}^l_{lb} &amp;= \\mathbf{R}^l_e \\mathbf{v}^e_{eb}, \\ \\ \\ \\mathbf{v}^e_{eb} = \\mathbf{R}^e_l \\mathbf{v}^l_{lb} \\\\ \\mathbf{a}^l_{lb} &amp;= \\mathbf{R}^l_e \\mathbf{a}^e_{eb}, \\ \\ \\ \\mathbf{a}^e_{eb} = \\mathbf{R}^e_l \\mathbf{a}^l_{lb} \\\\ \\mathbf{w}^l_{lb} &amp;= \\mathbf{R}^l_e \\mathbf{w}^e_{eb}, \\ \\ \\ \\mathbf{w}^e_{eb} = \\mathbf{R}^e_l \\mathbf{w}^l_{lb} \\label{3.8.19} \\\\ \\end{align} \\] <p>The Cartesian position transforms as:</p> \\[ \\begin{align} \\mathbf{r}^l_{lb} &amp;= \\mathbf{R}^l_e \\left( \\mathbf{r}^e_{eb} - \\mathbf{r}^e_{el} \\right) \\\\ \\mathbf{r}^e_{eb} &amp;= \\mathbf{r}^e_{el} + \\mathbf{R}^e_l \\mathbf{r}^l_{lb} \\label{3.8.20} \\end{align}, \\] <p>where \\(\\mathbf{r}^e_{el}\\) is the Cartesoam ECEF position of the local tangent-plane origin.</p>"},{"location":"navigation/geodesy/frame_transformations/#enu-and-ned","title":"ENU and NED","text":"<p>Considering some authors use East-North-Up, \\(F_{ENU}\\) and Groves use North-East-Down, \\(F_{NED}\\), the transformation matrix between the two is derived here. ENU to NED can be achieved by rotating about the \\(z\\) axis 90 degrees anti-clockwise and 180 degrees anti-clockwise about the \\(x\\) axis:</p> \\[ \\begin{align} \\mathbf{R}^{NED}_{ENU} &amp;= \\left[ \\begin{array}{ccc} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; \\text{cos}(180^o) &amp; \\text{sin}(180^o) \\\\  0 &amp; -\\text{sin}(180^o) &amp; \\text{cos}(180^o) \\end{array} \\right] \\left[ \\begin{array}{ccc} \\text{cos}(90^o) &amp; \\text{sin}(90^o) &amp;  0 \\\\ -\\text{sin}(90^o) &amp; \\text{cos}(90^o) &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{array} \\right] \\\\ &amp;=  \\left[ \\begin{array}{ccc} 0 &amp; 1 &amp; 0 \\\\ 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; -1 \\end{array} \\right] \\label{3.8.21} \\end{align} \\]"},{"location":"navigation/geodesy/gravity_models/","title":"Gravity Models","text":""},{"location":"navigation/geodesy/gravity_models/#specific-force-and-gravity-models","title":"Specific Force and Gravity Models","text":"<p>Specific force is defined as the non-gravitational force per unit mass and is measured in meters per seconds squared. Specific force is the quantity measured by accelerometers and is defined as:</p> \\[ \\mathbf{f}^{b}_{ib} = \\mathbf{a}^b_{ib} - \\boldsymbol{\\gamma}^{b}_{ib}, \\label{3.7.1} \\] <p>where \\(\\mathbf{f}\\) is the specific force, \\(\\mathbf{a}\\) is the acceleration, and \\(\\mathbf{\\gamma}\\) is the acceleration due to the gravitaitonal force. </p> <p>Consider an object that is stationary with respect to ECEF frame. Then:</p> \\[ \\begin{align} \\mathbf{v}^e_{eb} &amp;= \\dot{\\mathbf{r}}^{e}_{eb} = \\dot{\\mathbf{r}}^{e}_{ib} = 0 \\\\  \\mathbf{a}^e_{eb} &amp;= \\ddot{\\mathbf{r}}^{e}_{eb} = \\ddot{\\mathbf{r}}^{e}_{ib} = 0. \\label{3.7.2} \\\\  \\end{align} \\] <p>The inertially referenced acceleration resolved about ECEF would be:</p> \\[ \\begin{align} \\mathbf{a}^{e}_{ib} &amp;= \\ddot{\\mathbf{r}}^{e}_{ib} + \\boldsymbol{\\Omega}^{e}_{ib} \\boldsymbol{\\Omega}^{e}_{ib} \\mathbf{r}^{e}_{ib} + 2 \\boldsymbol{\\Omega}^{e}_{ib} \\dot{\\mathbf{r}^{e}_{ib}} + \\dot{\\boldsymbol{\\Omega}}^{e}_{ib} \\mathbf{r}^{e}_{ib} \\\\ &amp;= \\boldsymbol{\\Omega}^{e}_{ib} \\boldsymbol{\\Omega}^{e}_{ib} \\mathbf{r}^{e}_{ib}. \\label{3.7.3} \\end{align} \\] <p>Substituting equation (\\(\\ref{3.7.3}\\)) into (\\(\\ref{3.7.1}\\)) and using the identity  \\(\\mathbf{r}^\\gamma_{eb} = \\mathbf{r}^\\gamma_{ib}\\) yields to:</p> \\[ \\mathbf{f}^{e}_{ib} = \\boldsymbol{\\Omega}^{e}_{ib} \\boldsymbol{\\Omega}^{e}_{ib} \\mathbf{r}^{e}_{eb} - \\boldsymbol{\\gamma}^{e}_{ib}. \\label{3.7.4} \\] <p>The specific force sensed when an object is stationary with respect to ECEF frame is the reaction to what is known as the acceleration due to gravity:</p> \\[ \\begin{align} \\mathbf{g}^e_b &amp;= \\left. -f^{e}_{ib} \\right|_{\\mathbf{v}^e_{eb}=0, \\ \\mathbf{a}^{e}_{eb} = 0} \\\\ &amp;= \\boldsymbol{\\gamma}^{e}_{ib} - \\boldsymbol{\\Omega}^{e}_{ib} \\boldsymbol{\\Omega}^{e}_{ib} \\mathbf{r}^{e}_{eb} \\\\ &amp;= \\boldsymbol{\\gamma}^{e}_{ib} + \\omega^2_{ie}  \\left[ \\begin{array}{ccc} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\end{array} \\right] \\mathbf{r}^e_{eb}. \\label{3.7.5} \\end{align} \\] <p>In navigation frame:</p> \\[ \\begin{align} \\mathbf{g}^n_b &amp;= \\boldsymbol{\\gamma}^{n}_{ib} + \\boldsymbol{\\Omega}^{n}_{ib} \\boldsymbol{\\Omega}^{n}_{ib} \\mathbf{r}^{n}_{eb} \\\\ &amp;=  \\boldsymbol{\\gamma}^{n}_{ib} + \\mathbf{R}^{n}_e \\boldsymbol{\\Omega}^{e}_{ib} \\mathbf{R}^{e}_n \\mathbf{R}^{n}_e \\boldsymbol{\\Omega}^{e}_{ib} \\mathbf{R}^{e}_n \\mathbf{r}^{n}_{eb} \\\\ &amp;= \\boldsymbol{\\gamma}^{n}_{ib} + \\mathbf{R}^{n}_e \\boldsymbol{\\Omega}^{e}_{ib} \\boldsymbol{\\Omega}^{e}_{ib} \\mathbf{R}^{e}_n \\mathbf{r}^{n}_{eb} \\\\ &amp;= \\boldsymbol{\\gamma}^{n}_{ib} + \\omega^2_{ie}  \\mathbf{R}^{n}_e  \\left[ \\begin{array}{ccc} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\end{array} \\right]  \\mathbf{R}^{e}_n \\mathbf{r}^{n}_{eb} \\\\ &amp;= \\boldsymbol{\\gamma}^{n}_{ib} + \\omega^2_{ie} \\left[ \\begin{array}{ccc} \\text{sin}^2 L_b &amp; 0 &amp; \\text{cos} L_b \\text{sin} L_b \\\\ 0 &amp; 1 &amp; 0 \\\\ \\text{cos}L_b \\text{sin}L_b &amp; 0 &amp; \\text{cos}^2 L_b \\end{array} \\right] \\mathbf{r}^n_{eb}. \\label{3.7.6} \\end{align} \\] <p>The first term is the gravitational acceleration or the acceleration due to gravitational force. The second term is the  outward centrifugal acceleration due to the Earth's rotation. Figure 3.7.1 illustrates this.</p> <p> </p> Fig 3.7.1 Gravity, gravitational acceleration, centrifugal acceleration (Groves, p71) <p>At earth's surface, the total acceleration due to gravity is about \\(\\mathbf{g} = 9.8\\) m/s^2, with centrifugal component contributing up to 0.034 m/s^2. </p> <p>When working with  ECI, only the gravitation acceleration is required and can be directly calculated as:</p> \\[ \\begin{align} \\boldsymbol{\\gamma}^i_{ib} &amp;=  -\\frac{\\mu}{|\\mathbf{r}^i_{ib}|^3}  \\left\\{ \\mathbf{r}^i_{ib} + \\frac{3}{2}J_2 \\frac{R_0^2}{|\\mathbf{r}^i_{ib}|^2}  \\left\\{ \\begin{array}{c} \\left[ 1 - 5(r^i_{ib,z} / |\\mathbf{r}^i_{ib}|)^2 \\right] r^i_{ib, x} \\\\ \\left[ 1 - 5(r^i_{ib,z} / |\\mathbf{r}^i_{ib}|)^2 \\right] r^i_{ib, y} \\\\ \\left[ 3 - 5(r^i_{ib,z} / |\\mathbf{r}^i_{ib}|)^2 \\right] r^i_{ib, z} \\end{array} \\right\\} \\right\\} \\\\ \\boldsymbol{\\gamma}^e_{ib} &amp;=  -\\frac{\\mu}{|\\mathbf{r}^e_{eb}|^3}  \\left\\{ \\mathbf{r}^e_{eb} + \\frac{3}{2}J_2 \\frac{R_0^2}{|\\mathbf{r}^e_{eb}|^2}  \\left\\{ \\begin{array}{c} \\left[ 1 - 5(r^e_{eb,z} / |\\mathbf{r}^e_{eb}|)^2 \\right] r^e_{eb, x} \\\\ \\left[ 1 - 5(r^e_{eb,z} / |\\mathbf{r}^e_{eb}|)^2 \\right] r^e_{eb, y} \\\\ \\left[ 3 - 5(r^e_{eb,z} / |\\mathbf{r}^e_{eb}|)^2 \\right] r^e_{eb, z} \\end{array} \\right\\} \\right\\} \\label{3.7.7} \\\\ \\end{align}, \\] <p>where \\(J_2\\) is the Earth's second harmonic gravitational constant and is equal to \\(1.082627 \\times 10^{-3}\\) and  \\(\\mu\\) is the Earth's gravitational constant and its WGS 84 value is \\(3.986004418 \\times 10^{14} \\ m^3 s^{-2}\\). </p>"},{"location":"navigation/geodesy/orthometric_height/","title":"Orthometric Height","text":""},{"location":"navigation/geodesy/orthometric_height/#mean-sea-level-and-orthometric-height","title":"Mean Sea Level and Orthometric Height","text":"<p>Mean sea level (MSL) is an average surface level of one or more among Earth's coastal bodies of water from which height can be measured. It maintains a surface of approximately equal gravity potential, i.e., potential energy required to overcome gravity. Gravitational force is a vector, with magnitude and direction. In order to characterize the gravity field, it is simpler to specirfy the gravitational potential, a scalar quantity, defined so that its spacial gradient (i.e., a vector specifying the rate of change along three orthogonal directions) equals the gravity vector at that point.</p> <p>The geoid is a model of the Earth's equipotential surface. An equipotential surface is a closed, smooth surface surrounding the earth to which the direction of gravity is perpendicular at each point. It is a surface with a constant gravity potential. The geoid is usually within 1 meter of MSL. Physical surface of the Earth, known as terrain, is generally above the geoid. The gravity vector at any point on the Earth's surface is perpendicular to the geoid, not the ellipsoid or the terrain, although, in practice, the difference is small.</p> <p>Height above MSL is a measure of the vertical distance of a location in reference to a historic mean sea level taken as a vertical datum (geoid model). This is known as  orthometric height, \\(H\\), or altitude above MSL (AMSL):</p> \\[ H_b \\approx h_b - N(L_b, \\lambda_b), \\] <p>where \\(N\\) is the height of the geoid (also known as undulation) with respect to the ellipsoid (WGS 84 - 4,730,400m). The approximation is due to the geodetic height is measured normal to the ellipsoid, whereas the orthometric heigh is measured normal to the geoid. The following figure shows the various height illustrations.</p> <p> </p> Geoid and Orthometric Height (Groves, p65) <p>The heights shown on topographic maps, for example, are orthometric heights. Calculation of the orthometric height of a point from GPS measurements is a two-step process:</p> <ol> <li>Determine the ellipsoidal/geodetic/curvilinear coordinates \\((\\phi, \\lambda, h)\\) from GPS measurements.</li> <li>Determine the geoidal/geoid height from a data base, and subtract it from the ellipsoidal/geodetic height, \\(h\\). The most accurate geoid model available at present is the WGS 84 geoid.</li> </ol>"},{"location":"navigation/geodesy/primer/","title":"Primer on Geodesy","text":"<ol> <li>Geodesy</li> <li>Geodetic Coordinates</li> <li>Mercator Projection</li> </ol>"},{"location":"navigation/geodesy/rotation_of_earth/","title":"Rotation of Earth","text":"<p>The Earth-rotation vector resolved in an ECI or ECEF frame is:</p> \\[ \\boldsymbol{\\omega}^i_{ie} = \\boldsymbol{\\omega}^e_{ie} =  \\left[ \\begin{array}{c} 0 \\\\  0 \\\\ \\omega_{ie} \\end{array} \\right]. \\] <p>Resolving the Earth-rotation vector into local navigation frame axes yields to:</p> \\[ \\boldsymbol{\\omega}^{n}_{ie} =  \\left[ \\begin{array}{c} \\omega_{ie} \\text{cos}L_b \\\\  0 \\\\ -\\omega_{ie} \\text{sin}L_b \\end{array} \\right]. \\] <p>For navigation, a constant rotation rate is assumed and the WGS 84 value of the Earth's angular rate is  \\(\\omega_{ie} = 7.292115 \\times 10^{-5}\\) rad/s, which is about 15 degrees per hour.</p>"},{"location":"navigation/gps/gps_receiver/","title":"GPS Receiver","text":""},{"location":"navigation/gps/gps_receiver/#signal-acquisition-and-tracking","title":"Signal Acquisition and Tracking","text":"<p>The basic functions of a GPS receiver are:</p> <ol> <li>To capture the RF signals transmitted by the satellites spread out in the sky. The signals are gathered by a hemispherical antenna.</li> <li>To separate the signals from satellites in view. Given a recent almanac and a rough idea of the user location, the receiver determines which satellites are in view.</li> <li>To perform measurements of signal transmit time and Doppler shift. Given the satellite ID, the receiver knows the structure of the C/A-code being transmitted by it, and attempts to \"tune\" to it to acquire the signal, and from then on track changes in it continously. To acquire a signal, the receiver generates a replica of the known C/A-code, and attempts to align it with the incoming code by sliding the replica in time and computing the correlation. From the auto-correlation property of the signal, the correlation function exhibitis a sharp peak when the code replica is aligned with the code received from the satellite. Code tracking is implemented as a feedback control loop, called a delay lock loop, which continuously adjusts the replica code to keep it aligned with the code in the incoming signal. The time shift required to align the receiver-generated code replica and the signal received from the satellite is the apparent transmit time of the signal modulo 1 ms. The PRN code chips are generated at the satellite at precisely known instants in accordance with the satellite clock and, therefore, the receiver can \"read\" the satellite clock time time to determine when a chip was generated. </li> <li>To decode the navigation message to determine the satellite position, velocity, and clock parameters. After the alignmnet is accomplished, the PRN code is removed from the signal, leaving the carrier modulated by the navigation message. This signal is now tracked with another feedback control loop called a phase lock loop. Essentially, the receiver generates a sinusoidal signal to match the frequency and phase of the incoming signal, and in the process extracts the navigation message. </li> <li>To estimate the user PVT. The quality of PVT estimates obtained by a user from GPS depends on two factors: (i) numer of satellites in view and their spatial distribution in the sky, and (ii) quality of the range and range rate measurements. The spatial distribution of the satellites relative to the user is referred to as satellite geometry. Roughtl speaking, the geometry is good if the satellites are on all sides of the user, some high in the sky and several low. </li> </ol> <p>The second factor determining the quality of the PVT estimates is the quality of the peudorange and Doppler measurements which may be due to:</p> <ol> <li>Errors in the navigation message parameters which specify satellite position and signal transmission time introduce errors in the pseudorange measurements. These are referred as signal-in-space (SIS) errors.</li> <li>Propagation delays in the ionosphere and the troposphere, signal distortion due to multipath, and receiver noise also introduce measurement errors. </li> </ol>"},{"location":"navigation/gps/gps_signals/","title":"GPS Signals","text":""},{"location":"navigation/gps/gps_signals/#signals","title":"Signals","text":"<p>In legacy architecture, each GPS satellite transmits continuously using two radio frequencies in the L-band referred to as Link 1 (L1) and Link 2 (L2). The L-band covers frequencies between 1 GHz and 2 GHz, and is a subset of the UHF band. The center frequencies are are:</p> \\[ L1: \\ f_{L1} = 1575.42 MHz, \\ and \\ L2: \\ f_{L2} = 1227.60 MHz. \\] <p>The GPS signals are well below the background RF noise level sensed by an antenna. It is the knowledge of the signal structure (i.e., PRN code) that allows a receiver to extract the signal buried in noise and make precise measurements.</p>"},{"location":"navigation/gps/gps_signals/#signal-structure","title":"Signal structure","text":"<p>Refer to ICD for full description. In general, each GPS signal consists of three components:</p> <ol> <li>Carrier, \\(f(t)\\): RF sinusoidal signal with frequency \\(f_{L1}\\) or \\(f_{L2}\\).</li> <li> <p>Ranging code, \\(C(t)\\): Associated with each service (i.e., SPS and PPS) is a family of     binary codes called pseudo-random noise (PNR) sequences or PRN codes. The PRN codes    have special mathematical properties which allow all satellites to transmit at the same frequency without interfering with each other. These codes allow precise range measurements, and mitigate the deleterious effects of reflected and interfering signals received by a GPS antenna. The SPS codes are called coarse/acquisition codes (C/A-codes) and PPS codes are referred to as precision (encrypted codes), or P(Y)-codes. Each satellite transmits a unique C/A-code on L1 and unique P(Y)-codes on both L1 and L2. Each C/A-code is a unique sequence of 1023 bits, called chips, which is repeated each millisecond.  P-code on the other hand is a unique segment of an extremely long (\\(\\approx 10^14\\) chips) PRN sequence. The chipping rate is ten times of C/A code and the chip width is about 30 meters which is about ten times smaller than C/A. The smaller wavelength results in greater precision in the range measurements than C/A-codes.</p> </li> <li> <p>Navigation data, \\(D(T)\\): A binary-coded message consisting of data on the satellite health status, ephemeris (satellite position and velocity), clock bias parameters, and an almanac giving reduced-precision ephemeris data on all satellites in the constellation. The navigation message is transmitted at a leisurely 50 bits per second (bps), with a bit duration of 20 ms. It takes 12.5 minutes for the entire message to be received.  </p> </li> </ol>"},{"location":"navigation/gps/time/","title":"Time","text":""},{"location":"navigation/gps/time/#overview","title":"Overview","text":"<p>There are two epochs in UTC that are relevant to GPS and overall software implementation:</p> <ol> <li>Unix Time - Number of seconds since January 1st, 1970 at 00:00 UTC (Thursday).</li> <li>GPS Time (GPST) - Number of seconds since January 6th, 1980 at 00:00 UTC (The first week in 1980, Sunday).</li> </ol> <p>The difference between the two epochs is exactly 315964800 seconds (two leap years).</p> <p>The conversion between the two is:</p> <p>$$ \\begin{align}</p> <p>\\end{align} $$</p>"},{"location":"navigation/gps/time/#clock","title":"Clock","text":"<p>A clock is a generator of periodic events (frequency source or resonator) and a counting mechanism (counter or integrator) for the events. The accuracy of such a clock to measure time would depend upon (i) erro in the initial frequency setting (accuracy), and (ii) ability to maintain the rate of the periodic process (frequency stability).</p> <p>Frequency stability is a measure of the ability of a frequency source to operate at the specified frequency over a period of interest. The stability of a clock is commonly specified in terms of relative frequency deviation. </p>"},{"location":"navigation/gps/time/#solar-and-sidereal-times","title":"Solar and Sidereal Times","text":"<p>A complete revolution of the earth with respect to the sun (i.e., time between two successive transits of the sun across a local meridian plane) defines an apparent solar day. Due to the fact that no two apparent solar days are precisely the same length, mean solar time was introduced which corresponds to the earth in a hypothetical circular orbit around the sun with the same period, and its axis of rotation perpendicular to the orbital plane. The mean solar time at the Greenwich meridian is called the Greenwich Mean Time (GMT). </p> <p>A sidereal day, or twenty-four hours of sidereal time, is defined as the time the earth takes to rotate once on its axis relative to an inertial frame. The earth revolves once around the sun in a year (365.25 mean solar days), and there is one extra rotation of the earth to account for. Mean solar day is approximately four minutes longer than a sidereal day. The orbital period of a GPS satellite is one-half sidereal day. After two revolutions around the earth, each satellite rises at the same spot on the horizon relative to each observer, but four minutes earlier than the day before by the observer's watch. </p>"},{"location":"navigation/gps/time/#international-atomic-time-tai","title":"International Atomic Time (TAI)","text":"<p>The System of Units (SI) second is defined as \"the duration of 9,192,631,770\" periods of the radiation corresponding to the transition between the two hyperfine levels of the ground state of the cesium-133 atom\". The continuous time scale based on this definition of atomic second is called International Atomic Time (TAI). (SI day = 86,400 SI seconds). TAI is a precise and uniform time scale which is not tied to the earth's rotation on its axis or its revolution around the sun.</p>"},{"location":"navigation/gps/time/#coordinated-universal-time-utc","title":"Coordinated Universal Time (UTC)","text":"<p>It is estimated that in about four thousand years. the earth could lose about twelve hours, or half a day, and the sun would be high in the sky while local time based on a TAI clock indicates midnight [Allan, Ashby, and Hodge (1997)]. The result has been a compromise time scale called the Coordinated Universal Time (UTC). The definition of the UTC second is the same as that for atomic time, and is based on the cesium atom. UTC is the scale for public time throughout the world and is the new GMT. </p> <p>UTC was set to agree with UT1 at 00 hours on January 1, 1958. At first, the two time scales were kept close by introducing 0.1-second steps in UTC, as needed. Since 1972, changes in the earth's spin rate have been accommodated by introducing leap seconds in UTC. Hence, UTC and TAI differ by an integer number of seconds. The difference between TAI and UTC is:</p> \\[ TAI - UTC = 33 \\ s. \\]"},{"location":"navigation/gps/time/#gps-time","title":"GPS Time","text":"<p>GPS defines a time reference of its own called GPS Time (GPST) and keeps track of the offset between GPST and the international civil standard, UTC. Like UTC, GPST is a composite time kept by a \"paper clock\". There are two important differences between GPST and UTC:</p> <ol> <li>GPST is defined in real time.</li> <li>GPST is a continuous time scale (no leap seconds).</li> </ol> <p>The relationship between GPST and UTC is:</p> \\[ GPST = UTC + 18 \\ s. \\] <p>A time epoch in GPST is defined in terms of the week number and number of seconds of the week (or seconds into the week). The GPS Week field in the navigation message is modulo 1024. The first GPS cycle of 1024 weeks began at the Standard Epoch of GPS: midnight of the transition between Saturday, 5 January 1980, and Sunday, 6 January 1980 (00:00:00 UTC, 6 January 1980, Julian Day 2,444,244.500). The number of seconds of the week is measured since the previous midnight (GPS Time) marking the transition between Saturday and Sunday. There are 604,800 seconds in a GPS week. </p>"},{"location":"navigation/imu_and_gravity_models/imu_error_models/","title":"IMU Error Models","text":""},{"location":"navigation/imu_and_gravity_models/imu_error_models/#error-sources","title":"Error Sources","text":"<p>MEMS IMUs measure specific force, \\(\\tilde{\\mathbf{f}}^b_{ib}\\), and rotation rate of the sensor with respect to an inertial frame, \\(\\tilde{\\boldsymbol{\\omega}}^b_{i b}\\). All types of IMUs exhibit biases, scale factor and cross-coupling errors, and random noise. </p> Error Type Cause Model Biases Most dominant error term and consists of static and dynamic biases. The static bias is due to manufacturing and calibration errors. The dynamic bias is usually due to the temperature and is typically about 10% of the static bias. \\(\\begin{align*} \\mathbf{b}_a &amp;= \\mathbf{b}_{as} + \\mathbf{b}_{ad} \\\\ \\mathbf{b}_g &amp;= \\mathbf{b}_{gs} + \\mathbf{b}_{gd}  \\end{align*}\\) Scale Factor and Cross-coupling Errors Scale factor error arises due to IO conversion of the instrument. Cross-coupling error arises from the misalignment of the sensitive axes of the sensors with respect to the orthogonal axes of the body frame due to manufacturing errors. \\(\\begin{align*} \\mathbf{M}_a &amp;= \\left[ \\begin{array}{ccc} s_{a, x} &amp; m_{a, xy} &amp; m_{a, xz} \\\\ m_{a, yx} &amp; s_{a, y} &amp; m_{a, yz} \\\\ m_{a, zx} &amp; m_{a, zy} &amp; s_{a, z} \\end{array} \\right] \\\\ \\mathbf{M}_g &amp;= \\left[ \\begin{array}{ccc} s_{g, x} &amp; m_{g, xy} &amp; m_{g, xz} \\\\ m_{g, yx} &amp; s_{g, y} &amp; m_{g, yz} \\\\ m_{g, zx} &amp; m_{g, zy} &amp; s_{g, z} \\end{array} \\right] \\end{align*}\\) Random Noise Due to electrical noise, vibration, etc. Usually modelled as a random walks. <p>IMU errors are always expressed in body frame axes so the superscript \\(b\\) is omitted.</p>"},{"location":"navigation/imu_and_gravity_models/imu_error_models/#measurement-model","title":"Measurement Model","text":"\\[ \\begin{align} \\tilde{\\mathbf{f}}^b_{ib} &amp;= \\mathbf{b}_a + \\left( \\mathbf{I}_3 + \\mathbf{M}_a \\right) \\mathbf{f}^b_{ib} + \\mathbf{w}_a \\\\ \\tilde{\\boldsymbol{\\omega}}^b_{ib} &amp;= \\mathbf{b}_g + \\left( \\mathbf{I}_3 + \\mathbf{M}_g \\right) \\boldsymbol{\\omega}^b_{ib} + \\mathbf{w}_g \\\\ \\end{align}, \\]"},{"location":"navigation/imu_and_gravity_models/imu_error_models/#evaluating-imu","title":"Evaluating IMU","text":"<p>Allen deviation quantifies the sensor bias and bias instability by analyzing the variance of the sensor errors in a static position.</p>"},{"location":"navigation/imu_and_gravity_models/imu_measurements/","title":"IMU Measurements","text":""},{"location":"navigation/imu_and_gravity_models/imu_measurements/#gravity-model","title":"Gravity Model","text":"Figure 1 Gravity, gravitational acceleration, centrifugal acceleration (Groves, p71) <p>Figure 1 shows that the net acceleration due to gravity, \\(\\mathbf{g}\\), is the sum of gravitational acceleration, \\(\\boldsymbol{\\gamma}\\), (due to the mass distribution within Earth) and the outward centrifugal acceleration (due to the Earth's rotation). The algebraic representation in frame \\(F_{\\gamma}\\) for the body \\(b\\) is:</p> \\[ \\mathbf{g}^\\gamma_{b} = \\boldsymbol{\\gamma}^{\\gamma}_{ib} - \\boldsymbol{\\Omega}^\\gamma_{i e} \\boldsymbol{\\Omega}^\\gamma_{i e} \\mathbf{r}^\\gamma_{eb}. \\] <p>Depending on the resolving frame as well as the gravity model being used, the formulation of net acceleration can differ. The following table is from Groves.</p> Resolving Frame Gravity Model ECI When working in an ECI, it is common to neglegt Earth's rotation rate. Refer to Sola for more information.  \\(\\begin{align*} \\mathbf{g}^i_{b} &amp;= \\boldsymbol{\\gamma}^i_{ib} \\\\ \\boldsymbol{\\gamma}^i_{ib} &amp;=  -\\frac{\\mu}{\\left\\|\\mathbf{r}^i_{ib}\\right\\|^3} \\left\\{ \\mathbf{r}^i_{ib} + \\frac{3}{2}J_2 \\frac{R_0^2}{\\left\\|\\mathbf{r}^i_{ib}\\right\\|^2} \\left\\{ \\begin{array}{c} \\left[ 1 - 5(r^i_{ib,z} / \\left\\|\\mathbf{r}^i_{ib}\\right\\|)^2 \\right] r^i_{ib, x} \\\\ \\left[1 - 5(r^i_{ib,z} / \\left\\|\\mathbf{r}^i_{ib}\\right\\|)^2 \\right] r^i_{ib, y} \\\\ \\left[ 3 - 5(r^i_{ib,z} \\ \\left\\|\\mathbf{r}^i_{ib}\\right\\|)^2 \\right] r^i_{ib, z} \\end{array} \\right\\} \\right\\} \\end{align*}\\) ECEF \\(\\begin{align*} \\mathbf{g}^e_{b} &amp;= \\boldsymbol{\\gamma}^e_{ib} + \\boldsymbol{\\omega}^2_{ie} \\left[ \\begin{array}{ccc} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\end{array}\\right] \\mathbf{r}^e_{eb} \\\\ \\boldsymbol{\\gamma}^e_{ib} &amp;= -\\frac{\\mu}{\\left\\|\\mathbf{r}^e_{eb}\\right\\|^3} \\left\\{ \\mathbf{r}^e_{eb} + \\frac{3}{2}J_2 \\frac{R_0^2}{\\left\\|\\mathbf{r}^e_{eb}\\right\\|^2}  \\left\\{ \\begin{array}{c} \\left[ 1 - 5(r^e_{eb,z} / \\left\\|\\mathbf{r}^e_{eb}\\right\\|)^2 \\right] r^e_{eb, x} \\\\ \\left[ 1 - 5(r^e_{eb,z} / \\left\\|\\mathbf{r}^e_{eb}\\right\\|)^2 \\right] r^e_{eb, y} \\\\ \\left[ 3 - 5(r^e_{eb,z} / \\left\\|\\mathbf{r}^e_{eb}\\right\\|)^2 \\right] r^e_{eb, z} \\end{array} \\right\\} \\right\\} \\end{align*}\\) NED \\(\\begin{align*} \\mathbf{g}^n_b &amp;= \\boldsymbol{\\gamma}^{n}_{ib} + \\boldsymbol{\\Omega}^{n}_{ib} \\boldsymbol{\\Omega}^{n}_{ib} \\mathbf{r}^{n}_{eb} \\\\ &amp;= \\boldsymbol{\\gamma}^{n}_{ib} + \\mathbf{R}^{n}_e \\boldsymbol{\\Omega}^{e}_{ib} \\mathbf{R}^{e}_n \\mathbf{R}^{n}_e \\boldsymbol{\\Omega}^{e}_{ib} \\mathbf{R}^{e}_n \\mathbf{r}^{n}_{eb} \\\\ &amp;= \\boldsymbol{\\gamma}^{n}_{ib} + \\mathbf{R}^{n}_e \\boldsymbol{\\Omega}^{e}_{ib} \\boldsymbol{\\Omega}^{e}_{ib} \\mathbf{R}^{e}_n \\mathbf{r}^{n}_{eb} \\\\ &amp;= \\boldsymbol{\\gamma}^{n}_{ib} + \\boldsymbol{\\omega}^2_{ie} \\mathbf{R}^{n}_{e} \\left[ \\begin{array}{ccc} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\end{array} \\right] \\mathbf{R}^{e}_n \\mathbf{r}^{n}_{eb} \\\\ &amp;= \\boldsymbol{\\gamma}^{n}_{ib} + \\boldsymbol{\\omega}^2_{ie} \\left[ \\begin{array}{ccc} \\text{sin}^2 L_b &amp; 0 &amp; \\text{cos} L_b \\text{sin} L_b \\\\ 0 &amp; 1 &amp; 0 \\\\ \\text{cos}L_b \\text{sin}L_b &amp; 0 &amp; \\text{cos}^2 L_b \\end{array} \\right] \\mathbf{r}^n_{eb} \\end{align*}\\) <p>\\(J_2\\) is the Earth's second harmonic gravitational constant and is equal to \\(1.082627 \\times 10^{-3}\\) and  \\(\\mu\\) is the Earth's gravitational constant and its WGS 84 value is \\(3.986004418 \\times 10^{14} \\ m^3 s^{-2}\\).</p>"},{"location":"navigation/imu_and_gravity_models/imu_measurements/#accelerometer","title":"Accelerometer","text":"<p>Accelerometers measure specific force which is the non-gravity acceleration. This is equivalent to the total acceleration with respect to an inertial frame (\\(\\mathbf{a}^b_{ib}\\)) minus the net acceleration due to gravity defined previously along its input axis. Depending on how the sensor frame is defined, accelerometer triad should measure about \\(+1\\mathbf{g}\\) at rest if the input axis is up, and about \\(-1\\mathbf{g}\\) if the input axis is down (if the input axis is up, the total acceleration along the input axis is zero and the gravitational component along the input axis is \\(-1\\mathbf{g}\\)).</p> <p>If we let the sensor frame align with the body frame, the accelerometer measurement is:</p> \\[ \\begin{align} \\tilde{\\mathbf{f}}^{b}_{ib} &amp;= \\mathbf{a}^b_{ib} - \\mathbf{g}_b. \\end{align} \\]"},{"location":"navigation/imu_and_gravity_models/imu_measurements/#gyroscope","title":"Gyroscope","text":"<p>Gyro triad measures the angular rate of the IMU body with respect to the inertial frame in the body axes, i.e., \\(\\tilde{\\boldsymbol{\\omega}}^b_{ib}\\).</p>"},{"location":"navigation/imu_and_gravity_models/imu_measurements/#integrated-imu-measurements","title":"Integrated IMU Measurements","text":"<p>Some IMUs integrate the specific force and angular rate over the sampling interval, \\(\\tau_i\\) producing the so-called \"delta-\\(v\\)\"s and \"delta-\\(\\theta\\)\"s:</p> \\[ \\begin{align} \\tilde{\\boldsymbol{v}}^b_{ib} &amp;= \\int^t_{t - \\tau_i} \\tilde{\\mathbf{f}}^b_{ib}(t')dt' \\\\ \\tilde{\\boldsymbol{\\alpha}}^b_{ib} &amp;= \\int^t_{t - \\tau_i} \\tilde{\\boldsymbol{\\omega}}^b_{ib}(t')dt'. \\end{align} \\]"},{"location":"navigation/inertial_navigation/imu/","title":"IMU","text":""},{"location":"navigation/inertial_navigation/imu/#overview","title":"Overview","text":"<p>Typical MEMS IMU schematic is shown in Figure 1.</p> <p> </p> Fig 1 IMU schematic (Groves, 148) <p>Accelerometer triad contained in an IMU measures the specific force of the IMU body with respect to inertial space in body axes, i.e., \\(\\mathbf{f}^b_{ib}\\). Gyro triad contained IMU measures the angular rate of the IMU body with respect to inertial space in the body axes, i.e., \\(\\boldsymbol{\\omega}^b_{ib}\\). Many IMUs integrate the specific force and angular rate over the sampling interval, \\(\\tau_i\\), producing:</p> \\[ \\begin{align} \\mathbf{v}^b_{ib} &amp;= \\int^t_{t - \\tau_i} \\mathbf{f}^b_{ib}(t')dt' \\\\ \\boldsymbol{\\alpha}^b_{ib} &amp;= \\int^t_{t - \\tau_i} \\boldsymbol{\\omega}^b_{ib}(t')dt'. \\end{align} \\] <p>These are referred as \"delta-v\"s and \"delta-\\(\\theta\\)\"s, which are specific force and attitude increments. The IMUs outputs specific forces and angular rates, or their integrals. Output rates typically range from 100 to 1000Hz.</p>"},{"location":"navigation/inertial_navigation/imu/#error-model","title":"Error Model","text":"<p>Accelerometer and gyro outputs can be modelled as:</p> \\[ \\begin{align} \\tilde{\\mathbf{f}}^b_{ib} &amp;= \\mathbf{b}_a + \\left( \\mathbf{I}_3 + \\mathbf{M}_a \\right) \\mathbf{f}^b_{ib} + \\mathbf{w}_a \\\\ \\tilde{\\boldsymbol{\\omega}}^b_{ib} &amp;= \\mathbf{b}_g + \\left( \\mathbf{I}_3 + \\mathbf{M}_g \\right) \\boldsymbol{\\omega}^b_{ib} + \\mathbf{w}_g \\\\ \\end{align}, \\] <p>where \\(\\mathbf{b_{a|g}}\\), \\(\\mathbf{M}_{a|g}\\), and \\(\\mathbf{w}_{a|g}\\) are accelorometer and gyro biases, scale factor and cross-coupling errors matrices, random noises respectively. \\(\\mathbf{f}^b_{ib}\\) and  \\(\\boldsymbol{\\omega}^b_{ib}\\) are the true specific force and angular velocity values. \\(\\tilde{\\mathbf{f}}^b_{ib}\\) and \\(\\tilde{\\boldsymbol{\\omega}}^b_{ib}\\) are the measurements we receive from the sensors.</p>"},{"location":"navigation/inertial_navigation/imu/#bias","title":"Bias","text":"<p>In most cases, bias is the dominant term in the overall error of an inertial instrument. Bias consists of static component, \\(\\mathbf{b}_{as}\\) and \\(\\mathbf{b}_{gs}\\), and dynamic component, \\(\\mathbf{b}_{ad}\\) and \\(\\mathbf{b}_{gd}\\), where:</p> \\[ \\begin{align} \\mathbf{b}_a &amp;= \\mathbf{b}_{as} + \\mathbf{b}_{ad} \\\\ \\mathbf{b}_g &amp;= \\mathbf{b}_{gs} + \\mathbf{b}_{gd} \\\\ \\end{align} \\] <p>The static component is called fixed-bias, turn-on bias, or bias repeatability. It is constant within the run (IMU operating period), but varies from run to run.  It comprises of run-to-run variation of each instrument bias plus the residual fixed bias remaining after the sensor calibration. The static component can be computed by averating the IMU output over long period of time while the IMU is static. Once this is know, the static component can be subtracted from the output.</p> <p>The dynamic component is called in-run bias variation or bias instability. It is time-varying (order of a minute) and also incorporates the residual temperature-dependent bias remaining after sensor calibration. The dynamic bias is usually about 10% of the static bias.</p> <p>Units of milli-g (mg) or micro-g (\\(\\mu\\)g), where 1g = \\(9.80665 \\ \\text{ms}^{-2}\\), are used for accelerometer biases. For gyro biases, degree per hour (\\(^o\\text{hr}^{-1}\\)) are used where  \\(1 \\ ^o \\text{hr}^{-1} = 4.848 \\times 10^{-6} \\ \\text{rad/s}\\).</p>"},{"location":"navigation/inertial_navigation/imu/#scale-factor-and-cross-coupling-errors","title":"Scale Factor and Cross-Coupling Errors","text":"<p>The scale factor error is the departure of the input-output gradient of the instrument from unity following unit conversion by the IMU. The accelerometer output error due to the scale factor error is proportional to the true specific force along the sensitive axis, while the gyro output error due to the scale factor error is proportional to the true angular rate about the sensitive axis. The scale factor errors for accelerometer and gyro are denoted as \\(\\mathbf{s}_a = (s_{a,x}, s_{a,y}, s_{a,z})\\) and \\(\\mathbf{s}_g = (s_{g,x}, s_{g,y}, s_{g,z})\\) respectively.</p> <p>Cross-coupling errors or misalignment errors arise from the misalignment of the sensitive axes of the inertial sensors with respect to the orthogonal axes of the body frame due to manufacturing limitations. These make each accelerometer sensitive to the specific force along the axes orthogonal to its sensitive axes and end each gyro sensitive to the angular rate about the axes orthogonal to its sensitive axis. \\(m_{a, \\alpha \\beta}\\) denotes the cross-copuling coefficient of \\(\\beta\\)-axis specific force sensed by the \\(\\alpha\\)-axis accelerometer, while \\(m_{g, \\alpha \\beta}\\) denotes the coefficient of \\(\\beta\\)-axis angular rate sensed by the \\(\\alpha\\)-axis gyro. </p> <p>Scale factor and cross-coupling errors can be expressed as:</p> \\[ \\begin{align} \\mathbf{M}_a &amp;= \\left[ \\begin{array}{ccc} s_{a, x} &amp; m_{a, xy} &amp; m_{a, xz} \\\\ m_{a, yx} &amp; s_{a, y} &amp; m_{a, yz} \\\\ m_{a, zx} &amp; m_{a, zy} &amp; s_{a, z} \\end{array} \\right] \\\\ \\\\ \\mathbf{M}_g &amp;= \\left[ \\begin{array}{ccc} s_{g, x} &amp; m_{g, xy} &amp; m_{g, xz} \\\\ m_{g, yx} &amp; s_{g, y} &amp; m_{g, yz} \\\\ m_{g, zx} &amp; m_{g, zy} &amp; s_{g, z} \\end{array} \\right]. \\\\ \\end{align} \\] <p>Both are unitless and typically expressed in parts per million (ppm) or as a percentage.</p>"},{"location":"navigation/inertial_navigation/imu/#random-noise","title":"Random Noise","text":"<p>All IMUs exhibit random noise from number of sources. Electrical noise limits the resolution of inertial sensors, particularly MEMS sensors, where  the signal is very weak. Another source is thermo-mechanical fluctuations within the sensors. The random noise on each IMU sample is denoted by \\(\\mathbf{w}_a = (w_{a, x}, w_{a, y}, w_{a, z})\\) and \\(\\mathbf{w}_g = (w_{g, x}, w_{g, y}, w_{g, z})\\).</p> <p>The spectrum of accelerometer and gyro noise for frequencies below 1Hz is approximately white, so the  standard deviation of the average specific force and angular rate noise varies in inverse proportion to the  square root of the averating time. Inertial sensor noise is thus usually quoted in termos of the root PSD.  The units are \\(\\mu \\text{g}/ \\sqrt{\\text{Hz}}\\) for accelerometer  random noise, where  \\(1\\mu \\text{g} / \\sqrt{\\text{Hz}} = 9.80665 \\times 10^{-6} \\text{ms}^{-1.5}\\),  and \\(^o / \\sqrt{\\text{hr}}\\) or \\(^o / \\sqrt{\\text{Hz}}\\) for gyro random noise, where  \\(1 ^o / \\sqrt{\\text{hr}} = 2.909 \\times 10^{-4}\\text{rads}^{-0.5}\\) and  \\(1^o / \\sqrt{\\text{Hz}} = 4.848 \\times 10^{-6} \\text{rads}^{-0.5}\\).</p> <p>The accelerometer and gyro random noise are sometimes desibred as random walks.  Random noise on the specific force measurements is integrated to produce a random-walk error on the  intertial velocity solution. Similarly, random noise on the angular rate measurements is integrated to  produce an attitude random-walk error. The standard deviation of a random-walk process is proportional to the square root of the integration time.</p>"},{"location":"navigation/inertial_navigation/inertial_navigation_ECEF/","title":"Navigation Equations in ECEF Frame","text":""},{"location":"navigation/inertial_navigation/inertial_navigation_ECEF/#overview","title":"Overview","text":"<p>ECEF frame is commonly used as a reference frame and resolving axes for application such as satellite navigation solutions or airbone photogrammetry. ECEF frame navigation equations block diagram is shown in Figure 1. The suffixes (-) and (+) are used to denote a priori (at time \\(t\\)) and a posteriori values (at time \\(t + \\tau_i\\)).</p> <p> </p> Figure 1 ECEF-frame navigation (Groves, p173)"},{"location":"navigation/inertial_navigation/inertial_navigation_ECEF/#attitude-update","title":"Attitude Update","text":"<p>To track the attitude change, we must track the rotation matrix through time. Consider the attitude change over time interval \\(t\\) to \\(t + \\tau_i\\). The time derivative of the trasnformation matrix is:</p> \\[ \\begin{align} \\dot{\\mathbf{R}}^e_b &amp;= \\mathbf{R}^e_b \\boldsymbol{\\Omega}^b_{eb} \\\\ &amp;= \\mathbf{R}^e_b  \\left( \\boldsymbol{\\Omega}^b_{ib} - \\boldsymbol{\\Omega}^b_{ie} \\right) \\\\  &amp;= \\mathbf{R}^e_b \\boldsymbol{\\Omega}^b_{ib} - \\mathbf{R}^e_b \\boldsymbol{\\Omega}^b_{ie} \\\\ &amp;= \\mathbf{R}^e_b \\boldsymbol{\\Omega}^b_{ib} - \\mathbf{R}^e_b \\mathbf{R}^b_e \\boldsymbol{\\Omega}^e_{ie}  \\mathbf{R}^e_b \\\\ &amp;= \\mathbf{R}^e_b \\boldsymbol{\\Omega}^b_{ib} - \\boldsymbol{\\Omega}^e_{ie}  \\mathbf{R}^e_b, \\label{4.3.1} \\end{align} \\] <p>where \\(\\boldsymbol{\\Omega}^b_{ib}\\) is the skew-symmetric matrix of the IMU's angular-rate measurement and \\(\\boldsymbol{\\Omega}^e_{ie}\\) is the  skew-symmetric matrix of the Earth-rotation vector defined in section &gt;Rotation of Earth. Hence, the rotation of  the Earth must be accounded for in updating the attitude.</p> <p>Since this is a first-order matrix ordinary differential equation, assuming \\(\\boldsymbol{\\Omega}^e_{ie}\\) is constant:</p> \\[ \\begin{align} \\mathbf{R}^e_b(t + \\tau_i) &amp;\\approx \\mathbf{R}^e_b(t) \\exp\\left( \\boldsymbol{\\Omega}^b_{eb} \\tau_i \\right) \\\\ &amp;= \\mathbf{R}^e_b(t) \\exp \\left( \\boldsymbol{\\Omega}^b_{ib} \\tau_i - \\boldsymbol{\\Omega}^e_{ie} \\tau_i \\right) \\\\ &amp;= \\mathbf{R}^e_b(t) \\exp\\left(\\boldsymbol{\\Omega}^b_{ib} \\tau_i \\right) - \\mathbf{R}^e_b(t) \\left[ \\exp\\left( \\boldsymbol{\\Omega}^b_{ie} \\tau_i \\right) - \\mathbf{I}_3 \\right] \\\\ &amp;= \\mathbf{R}^e_b(t) \\exp\\left( \\left[ \\boldsymbol{\\alpha}^b_{ib} \\right]_\\times \\right) - \\left[ \\exp\\left( \\boldsymbol{\\Omega}^e_{ie} \\tau_i \\right) - \\mathbf{I}_3 \\right] \\mathbf{R}^e_b(t) \\\\ \\label{4.3.2} \\end{align} \\] <p>Applying small angle approximation and truncating the power series expansion at the first order yields to:</p> \\[ \\mathbf{R}^e_b(+) \\approx \\mathbf{R}^e_b(-) \\left( \\mathbf{I}_3 + \\boldsymbol{\\Omega}^b_{ib} \\tau_i \\right) - \\boldsymbol{\\Omega}^e_{ie} \\mathbf{R}^e_b(-) \\tau_i. \\label{4.3.3} \\] <p>Since the rotation of the Earth is much slower compared to the angular rate measurements from the IMU, this small angle approximation is always valid for the  Earth rate term of the attitude update equation. </p>"},{"location":"navigation/inertial_navigation/inertial_navigation_ECEF/#precision-attitude-update","title":"Precision Attitude Update","text":"<p>We can replace the first order approximation in eq (\\(\\ref{4.3.3}\\)) with the attitude update matrix:</p> \\[ \\begin{align} \\mathbf{R}^e_b(+) &amp;=  \\left[  \\begin{array}{ccc} \\text{cos}\\omega_{ie} \\tau_i &amp; \\text{sin}\\omega_{ie} \\tau_i &amp; 0 \\\\ -\\text{sin}\\omega_{ie} \\tau_i &amp; \\text{cos}\\omega_{ie} \\tau_i &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{array} \\right] \\mathbf{R}^e_b(-) \\mathbf{R}^{b-}_{b+} \\\\ &amp;\\approx \\mathbf{R}^e_b(-)\\mathbf{R}^{b-}_{b+} - \\boldsymbol{\\Omega}^e_{ie} \\mathbf{R}^e_b(-) \\tau_i, \\label{4.3.4} \\end{align} \\] <p>where the attidude update matrix is given by the Rodrigues's formula:</p> \\[ \\begin{align} \\mathbf{R}^{b-}_{b+} &amp;= \\mathbf{I}_3 + \\frac{\\text{sin}|\\boldsymbol{\\alpha}^b_{ib}|}{|\\boldsymbol{\\alpha}^b_{ib}|}  \\left[ \\boldsymbol{\\alpha}^b_{ib} \\right]_\\times + \\frac{1 - \\text{cos}|\\boldsymbol{\\alpha}^b_{ib}|}{|\\boldsymbol{\\alpha}^b_{ib}|^2} \\left[ \\boldsymbol{\\alpha}^b_{ib} \\right]^2_\\times. \\label{4.3.5} \\end{align} \\]"},{"location":"navigation/inertial_navigation/inertial_navigation_ECEF/#specific-force-frame-transformation","title":"Specific-Force Frame Transformation","text":"<p>The IMU measures specific force along the body-frame resolving axe. Applying the transform matrix similar to ECI yields:</p> \\[ \\mathbf{f}^e_{ib}(t) = \\mathbf{R}^e_b(t) \\mathbf{f}^b_{ib}(t). \\label{4.3.6} \\] <p>Since the specific-force measurement is an average over time \\(t\\) to \\(t + \\tau_i\\), the transformation matrix should be similarly averaged. Assuming a constant angular rate:</p> \\[ \\mathbf{f}^e_{ib} \\approx \\frac{1}{2} \\left( \\mathbf{R}^e_b(-) + \\mathbf{R}^e_b(+) \\right) \\mathbf{f}^b_{ib}. \\label{4.3.7} \\] <p>However, the mean of two transformation matrices does not precisely produce the mean of the two attitudes. The less the attitude varies over the time interval, the smaller the errors introduced by this approximation.</p>"},{"location":"navigation/inertial_navigation/inertial_navigation_ECEF/#precision-specific-force-frame-transformation","title":"Precision Specific-Force Frame Transformation","text":"<p>Retaining the first-order approximation for the Earth-rate term, the prcecise transformation of the specific force to ECEF-frame axes is:</p> \\[ \\mathbf{f}^e_{ib} = \\bar{\\mathbf{R}}^e_b \\mathbf{f}^b_{ib}, \\quad \\bar{\\mathbf{R}}^e_b = \\mathbf{R}^e_b(-) \\mathbf{R}^{b-}_{\\bar{b}} - \\frac{1}{2} \\boldsymbol{\\Omega}^e_{ie} \\mathbf{R}^e_b(-) \\tau_i, \\label{4.3.8} \\] <p>where:</p> \\[ \\begin{align} \\mathbf{R}^{b-}_{\\bar{b}} &amp;= \\mathbf{I}_3 +  \\frac{1 - \\text{cos}|\\boldsymbol{\\alpha^b_{ib}}|}{|\\boldsymbol{\\alpha^b_{ib}}|^2} \\left[ \\boldsymbol{\\alpha}^b_{ib} \\right]_\\times +  \\frac{1}{|\\boldsymbol{\\alpha^b_{ib}}|^2} \\left( 1 - \\frac{\\text{sin}|\\boldsymbol{\\alpha^b_{ib}}|}{|\\boldsymbol{\\alpha^b_{ib}}|} \\right) \\left[ \\boldsymbol{\\alpha}^b_{ib} \\right]^2_\\times. \\label{4.3.9} \\end{align} \\]"},{"location":"navigation/inertial_navigation/inertial_navigation_ECEF/#velocity-update","title":"Velocity Update","text":"<p>Similar to ECI frame implementation, since the reference frame and resolving axes are the same:</p> \\[ \\dot{\\mathbf{v}}^e_{eb} = \\mathbf{a}^e_{eb} = \\ddot{\\mathbf{r}}^e_{eb}. \\label{4.3.10} \\] <p>Since:</p> \\[ \\begin{align} \\mathbf{r}^e_{eb} &amp;= \\mathbf{r}^e_{ib} - \\mathbf{r}^e_{ie} \\\\  &amp;= \\mathbf{r}^e_{ib}, \\label{4.3.11} \\end{align} \\] <p>we get:</p> \\[ \\dot{\\mathbf{v}}^e_{eb} = \\ddot{\\mathbf{r}}^e_{ib}. \\label{4.3.12} \\] <p>From acceleration section in Kinematics, we have:</p> \\[ \\begin{align} \\mathbf{v}^e_{eb} &amp;= -\\boldsymbol{\\Omega}^e_{ie} \\boldsymbol{\\Omega}^e_{ie} \\mathbf{r}^e_{ib} - 2 \\boldsymbol{\\Omega}^e_{ie} \\dot{\\mathbf{r}}^e_{eb} + \\mathbf{a}^e_{ib} \\\\ &amp;= -\\boldsymbol{\\Omega}^e_{ie} \\boldsymbol{\\Omega}^e_{ie} \\mathbf{r}^e_{ib} - 2 \\boldsymbol{\\Omega}^e_{ie} \\mathbf{v}^e_{eb} + \\mathbf{a}^e_{ib}. \\label{4.3.13} \\end{align} \\] <p>The equation shows that the rate of change of velocity resolved about the ECEF axes incorporates a centrifugal and a Coriolis term due to the rotation of the resolving axes. From the section on gravity models, we know that the applied acceleration \\(\\mathbf{a}^e_{ib}\\) is the sum of the measured specific force, \\(\\mathbf{f}^e_{ib}\\), and the acceleration due to the gravitation force, \\(\\boldsymbol{\\gamma}^e_{ib}\\). Furthermore, the acceleration due to gravity, \\(\\mathbf{g}^e_b\\), is the sum of the gravitational and centrifugal accelerations. Hence:</p> \\[ \\dot{\\mathbf{v}}^e_{eb} = \\mathbf{f}^e_{ib} + \\mathbf{g}^e_b(\\mathbf{r}^e_{eb}) - 2 \\boldsymbol{\\Omega}^e_{ie} \\mathbf{v}^e_{eb}. \\label{4.3.14} \\] <p>Since the Coriolis term is much smaller than the specific-force and gravity terms (except for space applications), it is reasonable approximation to neglegt the variation of the Coriolis term over the integration interval. Hence:</p> \\[ \\begin{align} \\mathbf{v}^e_{eb}(+) &amp; \\approx \\mathbf{v}^e_{eb}(-) + \\left( \\mathbf{f}^e_{ib}  + \\mathbf{g}^e_b(\\mathbf{r}^e_{eb}(-)) - 2 \\boldsymbol{\\Omega}^e_{ie} \\mathbf{v}^e_{eb}(-) \\right) \\tau_i \\\\  &amp;= \\mathbf{v}^e_{eb}(-) + \\boldsymbol{v}^e_{ib} + \\left(  \\mathbf{g}^e_b(\\mathbf{r}^e_{eb}(-)) - 2 \\boldsymbol{\\Omega}^e_{ie} \\mathbf{v}^e_{eb}(-) \\right) \\tau_i. \\label{4.3.15} \\end{align} \\]"},{"location":"navigation/inertial_navigation/inertial_navigation_ECEF/#position-update","title":"Position Update","text":"<p>In ECEF frame implementation of the navigation equations, the time derivative of the Cartesian position is simply velocity as the reference frame and resolving axes are the same:</p> \\[ \\dot{\\mathbf{r}}^e_{eb} = \\mathbf{v}^e_{eb}. \\label{4.3.16} \\] <p>Integrating this gives:</p> \\[ \\begin{align} \\mathbf{r}^e_{eb}(+) &amp;= \\mathbf{r}^e_{eb}(-) + \\left( \\mathbf{v}^e_{eb}(-) + \\mathbf{v}^e_{eb}(+) \\right) \\frac{\\tau_i}{2} \\\\ &amp;\\approx \\mathbf{r}^e_{eb}(-) + \\mathbf{v}^e_{eb}(-)\\tau_i + \\left( \\mathbf{f}^e_{ib} + \\mathbf{g}^e_b (\\mathbf{r}^e_{eb}(-)) - 2 \\boldsymbol{\\Omega}^e_{ie} \\mathbf{v}^e_{eb}(-) \\right) \\frac{\\tau^2_i}{2}. \\label{4.3.17} \\end{align} \\]"},{"location":"navigation/inertial_navigation/inertial_navigation_ECEF/#precision-velocity-and-position-update","title":"Precision Velocity and Position Update","text":"<p>Exact evaluation of the Coriolis and transport-rate terms require knowledge of the velocity at the end of the update interval, requiring recursive solution. A good but processor-intensive solution is a two-step recursive method.</p>"},{"location":"navigation/inertial_navigation/inertial_navigation_ECI/","title":"Navigation Equations in ECI Frame","text":""},{"location":"navigation/inertial_navigation/inertial_navigation_ECI/#overview","title":"Overview","text":"<p>ECI-frame navigation equations block diagram is shown in Figure 1. The suffixes (-) and (+) are used to denote a priori (at time \\(t\\)) and a posteriori values (at time \\(t + \\tau_i\\)).</p> <p> </p> Figure 1 ECI-frame navigation (Groves, p169)"},{"location":"navigation/inertial_navigation/inertial_navigation_ECI/#attitude-update","title":"Attitude Update","text":"<p>To track the attitude change, we must track the rotation matrix through time. Consider an attitude change over time interval \\(t\\) to \\(t + \\tau_i\\). The time derivative of the rotation matrix is:</p> \\[ \\dot{\\mathbf{R}}^i_b(t) = \\mathbf{R}^i_b(t) \\boldsymbol{\\Omega}^b_{ib}. \\label{4.2.1} \\] <p>Since this is a first-order matrix ordinary differential equation, we know the solution over the interval \\(t\\) to \\(t + \\tau_i\\) is:</p> \\[ \\mathbf{R}^i_b(t + \\tau_i) = \\mathbf{R}^i_b(t) \\left[ \\lim_{n \\rightarrow \\infty}\\prod^n_{i=1} \\exp \\left( \\boldsymbol{\\Omega}^b_{ib} \\left( t + \\frac{n - i}{n} \\tau_i \\right) \\frac{\\tau_i}{n} \\right)  \\right]. \\label{4.2.2} \\] <p>If the angular rate is assumed to be constant over the attitude integration interval, then:</p> \\[ \\begin{align} \\mathbf{R}^i_b(t + \\tau_i) &amp;\\approx \\mathbf{R}^i_b (t) \\exp \\left(\\boldsymbol{\\Omega}^b_{ib} \\tau_i \\right) \\\\ &amp;= \\mathbf{R}^i_b (t) \\exp \\left(\\left[ \\boldsymbol{\\omega}^b_{ib} \\right]_\\times \\tau_i \\right) \\\\ &amp;= \\mathbf{R}^i_b (t) \\exp \\left( \\left[ \\boldsymbol{\\alpha}^b_{ib} \\right]_\\times \\right). \\label{4.2.3} \\end{align} \\] <p>This assumption is often made where the attiude integration is performed at the IMU output rate. The matrix exponential can be expressed as a power series:</p> \\[ \\mathbf{R}^i_b (t + \\tau_i) = \\mathbf{R}^i_b(t) \\sum_{n = 0} \\frac{1}{n!} \\left[ \\boldsymbol{\\alpha}^b_{ib} \\right]^n_\\times. \\label{4.2.4} \\] <p>Using small angle approximation, we can truncate the power-series expansion to the first order:</p> \\[ \\mathbf{R}^i_b(+) \\approx \\mathbf{R}^i_b(-) \\left( \\mathbf{I}_3 + \\left[ \\boldsymbol{\\alpha}^b_{ib} \\right]_\\times \\right). \\label{4.2.5} \\] <p>When the angular rate is assumed to be constant over the attitude integration interval, \\(\\boldsymbol{\\alpha}^b_{ib} \\approx \\boldsymbol{\\omega}^b_{ib} \\tau_i\\). Then:</p> \\[ \\mathbf{R}^i_b(+) \\approx \\mathbf{R}^i_b (-) \\left( \\mathbf{I}_3 + \\boldsymbol{\\Omega}^b_{ib} \\tau_i \\right). \\label{4.2.6} \\] <p>This truncation of the power-series introduces errors in the attitude integration. Precision may be improved by including higher-order terms in the power series,  breaking down the attitude update into smaller steps, or performing the exact attitude update. </p>"},{"location":"navigation/inertial_navigation/inertial_navigation_ECI/#precision-attitude-update","title":"Precision Attitude Update","text":"<p>It is convenient to define the attitude update matrix as the transformation matrix from the body frame at the end of the attitude update step of the navigation equations to that at the beginning, \\(\\mathbf{R}^{b-}_{b+}\\):</p> \\[ \\begin{align} \\mathbf{R}^i_b(+) &amp;= \\mathbf{R}^i_b(-) \\mathbf{R}^{b-}_{b+} \\\\ \\mathbf{R}^{b-}_{b+} &amp;= \\mathbf{R}^b_i(-)\\mathbf{R}^i_b(+). \\label{4.2.7} \\end{align} \\] <p>Then from \\(\\ref{4.2.4}\\), the attitude update matrix will be:</p> \\[ \\mathbf{R}^{b-}_{b+} = \\mathbf{R}^{b(t)}_{b(t + \\tau_i)} = \\exp\\left[ \\boldsymbol{\\alpha} \\right]_\\times =  \\sum^{\\infty}_{k = 0} \\frac{\\left[ \\boldsymbol{\\alpha}^b_{ib} \\right]^k_\\times}{k!}, \\label{4.2.8} \\] <p>where a constant angular rate is assumed. The third and fourth powers of a skew-symmetric  matrix have the following properties:</p> \\[ \\begin{align} \\left[ \\mathbf{x} \\right]^3_\\times &amp;= -|\\mathbf{x}|^2 \\left[ \\mathbf{x} \\right]_\\times \\\\ \\left[ \\mathbf{x} \\right]^4_\\times &amp;= -|\\mathbf{x}|^2 \\left[ \\mathbf{x} \\right]^2_\\times. \\label{4.2.9} \\end{align} \\] <p>Using this, the attitude update matrix becomes:</p> \\[ \\begin{align} \\mathbf{R}^{b-}_{b+} &amp;=  \\mathbf{I}_3 + \\left( \\sum^{\\infty}_{k = 0} (-1)^k \\frac{|\\boldsymbol{\\alpha}^b_{ib}|^{2k}}{(2k + 1)!} \\right) \\left[ \\boldsymbol{\\alpha}^b_{ib} \\right]_\\times + \\left( \\sum^{\\infty}_{k = 0} (-1)^k \\frac{|\\boldsymbol{\\alpha}^b_{ib}|^{2k}}{(2k + 2)!} \\right) \\left[ \\boldsymbol{\\alpha}^b_{ib} \\right]^2_\\times \\\\ &amp;= \\mathbf{I}_3 + \\frac{\\text{sin}|\\boldsymbol{\\alpha}^b_{ib}|}{|\\boldsymbol{\\alpha}^b_{ib}|}  \\left[ \\boldsymbol{\\alpha}^b_{ib} \\right]_\\times + \\frac{1 - \\text{cos}|\\boldsymbol{\\alpha}^b_{ib}|}{|\\boldsymbol{\\alpha}^b_{ib}|^2} \\left[ \\boldsymbol{\\alpha}^b_{ib} \\right]^2_\\times,  \\label{4.2.10} \\end{align} \\] <p>which is the Rodrigues's formula derived in Kinematics. To avoid division by zero, ensure to replace with the approximate version when \\(|\\boldsymbol{\\alpha}^b_{ib}|\\) is very small. The attitude increment vector can be computed in terms of the attitude update matrix:</p> \\[ \\begin{align} \\boldsymbol{\\alpha}^b_{ib} &amp;= \\frac{\\mu_{b+b-}}{2 \\text{sin}\\mu_{b+b-}} \\left[  \\begin{array}{cc} \\mathbf{R}^{b-}_{b+,3,2} - \\mathbf{R}^{b-}_{b+,2,3} \\\\ \\mathbf{R}^{b-}_{b+,1,3} - \\mathbf{R}^{b-}_{b+,3,1} \\\\ \\mathbf{R}^{b-}_{b+,2,1} - \\mathbf{R}^{b-}_{b+,1,2} \\end{array} \\right] \\\\ \\\\ \\mu_{b+b-} &amp;= \\text{arccos}  \\left( \\frac{\\text{tr}\\left(\\mathbf{R}^{b-}_{b+} - 1 \\right)}{2} \\right).  \\label{4.2.11} \\end{align} \\]"},{"location":"navigation/inertial_navigation/inertial_navigation_ECI/#specific-force-frame-transformation","title":"Specific-Force Frame Transformation","text":"<p>The IMU measures specific force along the body-frame resolving axe. Applying the transform matrix yields:</p> \\[ \\mathbf{f}^i_{ib}(t) = \\mathbf{R}^i_b(t) \\mathbf{f}^b_{ib}(t). \\label{4.2.12} \\] <p>Since the specific-force measurement is an average over time \\(t\\) to \\(t + \\tau_i\\), the transformation matrix should be similarly averaged. Assuming a constant angular rate:</p> \\[ \\mathbf{f}^i_{ib} \\approx \\frac{1}{2} \\left( \\mathbf{R}^i_b(-) + \\mathbf{R}^i_b(+) \\right) \\mathbf{f}^b_{ib}. \\label{4.2.13} \\] <p>However, the mean of two transformation matrices does not precisely produce the mean of the two attitudes. The less the attitude varies over the time interval, the smaller the errors introduced by this approximation.</p>"},{"location":"navigation/inertial_navigation/inertial_navigation_ECI/#precision-specific-force-frame-transformation","title":"Precision Specific-Force Frame Transformation","text":"<p>Let the average coordinate transfromation matrix over the time interval be \\(\\bar{\\mathbf{R}}^i_b\\) such that:</p> \\[ \\mathbf{f}^i_{ib} = \\bar{\\mathbf{R}}^i_b \\mathbf{f}^b_{ib}, \\label{4.2.14} \\] <p>where:</p> \\[ \\begin{align} \\bar{\\mathbf{R}}^i_b &amp;= \\frac{1}{\\tau_i} \\int^{t + \\tau_i}_t \\mathbf{R}^i_b(t')dt' \\\\ &amp;= \\frac{1}{\\tau_i} \\mathbf{R}^i_b(-) \\int^{t + \\tau_i}_0 \\sum^{\\infty}_{k = 0} \\frac{ \\left\\{ (t' / \\tau_i) \\left[ \\boldsymbol{\\alpha}^b_{ib} \\right]_\\times \\right\\}^k }{k!}dt' \\\\ &amp;= \\mathbf{R}^i_b(-) \\sum^{\\infty}_{k = 0} \\frac{\\left[ \\boldsymbol{\\alpha}^b_{ib} \\right]^k_\\times}{(k + 1)!}. \\label{4.2.15} \\end{align} \\] <p>Applying eq (\\(\\ref{4.2.10}\\)) gives:</p> \\[ \\begin{align} \\bar{\\mathbf{R}}^i_b &amp;= \\mathbf{R}^i_b(-) \\mathbf{R}^{b-}_{\\bar{b}} \\\\ \\mathbf{R}^{b-}_{\\bar{b}} &amp;= \\mathbf{I}_3 +  \\frac{1 - \\text{cos}|\\boldsymbol{\\alpha^b_{ib}}|}{|\\boldsymbol{\\alpha^b_{ib}}|^2} \\left[ \\boldsymbol{\\alpha}^b_{ib} \\right]_\\times +  \\frac{1}{|\\boldsymbol{\\alpha^b_{ib}}|^2} \\left( 1 - \\frac{\\text{sin}|\\boldsymbol{\\alpha^b_{ib}}|}{|\\boldsymbol{\\alpha^b_{ib}}|} \\right) \\left[ \\boldsymbol{\\alpha}^b_{ib} \\right]^2_\\times. \\label{4.2.16} \\end{align} \\] <p>To avoid division by zero, ensure to replace with the approximate version when \\(|\\boldsymbol{\\alpha}^b_{ib}|\\) is very small.</p>"},{"location":"navigation/inertial_navigation/inertial_navigation_ECI/#velocity-update","title":"Velocity Update","text":"<p>From section on gravity models, inertially referenced acceleration is obtained by adding the garvitational acceleration to the specific force:</p> \\[ \\mathbf{a}^i_{ib} = \\mathbf{f}^i_{ib} + \\boldsymbol{\\gamma}^i_{ib}(\\mathbf{r}^i_{ib}). \\label{4.2.17} \\] <p>Strictly, the position should be averaged over the interval \\(t\\) to \\(t + \\tau_i\\), but this would require recursive navigation equations, and the gravitaional-field varies slowly with position. Hence, it is generally sufficient to use \\(\\mathbf{r}^i_{ib}(-)\\).</p> <p>When the reference frame and resolving axes are the same, the time derivative of velocity is simply acceleration:</p> \\[ \\dot{\\mathbf{v}}^i_{ib} = \\dot{\\mathbf{a}}^i_{ib}. \\label{4.2.18} \\] <p>Integrating this gives:</p> \\[ \\begin{align} \\mathbf{v}^i_{ib}(+) = \\mathbf{v}^i_{ib}(-) + \\mathbf{a}^i_{ib} \\tau_i = \\mathbf{v}^i_{ib}(-) + \\mathbf{f}^i_{ib} \\tau_i + \\boldsymbol{\\gamma}^i_{ib} \\tau_i =  \\mathbf{v}^i_{ib}(-) + \\mathbf{a}^i_{ib} \\tau_i = \\mathbf{v}^i_{ib}(-) + \\boldsymbol{v}^i_{ib} + \\boldsymbol{\\gamma}^i_{ib} \\tau_i.  \\label{4.2.19} \\end{align} \\]"},{"location":"navigation/inertial_navigation/inertial_navigation_ECI/#position-update","title":"Position Update","text":"<p>In the inertial-frame implementation of the navigation equations, the time derivative of the Cartesian position is simply velocity as the reference frame and resolving axes are the same:</p> \\[ \\dot{\\mathbf{r}}^i_{ib} = \\mathbf{v}^i_{ib}. \\label{4.2.20} \\] <p>Integrating this gives:</p> \\[ \\begin{align} \\mathbf{r}^i_{ib}(+) &amp;= \\mathbf{r}^i_{ib}(-) + \\left( \\mathbf{v}^i_{ib}(-) + \\mathbf{v}^i_{ib}(+) \\right) \\frac{\\tau_i}{2} \\\\ &amp;= \\mathbf{r}^i_{ib}(-) + \\mathbf{v}^i_{ib}(-) \\tau_i + \\mathbf{a}^i_{ib} \\frac{\\tau^2_i}{2} \\\\ &amp;= \\mathbf{r}^i_{ib}(-) + \\mathbf{v}^i_{ib}(+) \\tau_i - \\mathbf{a}^i_{ib} \\frac{\\tau^2_i}{2} \\label{4.2.21} \\end{align} \\]"},{"location":"navigation/inertial_navigation/inertial_navigation_ECI/#precision-velocity-and-position-updates","title":"Precision Velocity and Position Updates","text":"<p>The velocity and position updates presented in eqs (\\(\\ref{4.2.19}\\)) and (\\(\\ref{4.2.21}\\)) are exact when the navigation equations are iterated at the IMU output rate and constant acceleration is assumed excluding the variation in gravitation over the update interval (which is negligible).</p>"},{"location":"navigation/inertial_navigation/inertial_navigation_architecture/","title":"Inertial Navigation Architecture","text":"<p>Figure 1 shows a schematic of an inertial navigation processor. IMU outputs are integrated to produce an updated position, velocity,  and attitude solution in four steps:</p> <ol> <li>Attitude update</li> <li>Transformation of specific-force resolving axes from the IMU body frame to the  coordinate frame used to resolve the position and velocity solutions</li> <li>Velocity update, including transformation of specific force into accelration using gravity or gravitation model</li> <li>Position update</li> </ol> <p> </p> Fig 1 Inertial Navigation Processor (Groves, p167) <p>Continuous-time navigation equations physicall describe a body's modion. Discrete-time navigation equations, also known as mechanization equations, provide a means of updating a navigation solution over a discrete time interval.</p>"},{"location":"navigation/inertial_navigation/inertial_navigation_local_tangent_plane/","title":"Navigation Equations in Local Tangent-Plane Frame","text":""},{"location":"navigation/inertial_navigation/inertial_navigation_local_tangent_plane/#navigation-equations-in-local-tanget-plane-frame","title":"Navigation Equations in Local Tanget-Plane Frame","text":"<p>Local-tangent plane frame is used for navigation within a localized area. Since the frame is Earth fixed, the navigation equations have similar form to the navigation equations in ECEF-frame.</p>"},{"location":"navigation/inertial_navigation/inertial_navigation_local_tangent_plane/#attitude-update","title":"Attitude Update","text":"<p>To track the attitude change, we must track the transformation matrix through time. Consider the attitude change over time interval \\(t\\) to \\(t + \\tau_i\\). The time derivative of the trasnformation matrix is:</p> \\[ \\begin{align} \\dot{\\mathbf{R}}^l_b &amp;= \\mathbf{R}^l_b \\boldsymbol{\\Omega}^b_{lb} \\\\ &amp;= \\mathbf{R}^l_b  \\left( \\boldsymbol{\\Omega}^b_{ib} - \\boldsymbol{\\Omega}^b_{il} \\right) \\\\  &amp;= \\mathbf{R}^l_b \\boldsymbol{\\Omega}^b_{ib} - \\mathbf{R}^l_b \\boldsymbol{\\Omega}^b_{il} \\\\ &amp;= \\mathbf{R}^l_b \\boldsymbol{\\Omega}^b_{ib} - \\mathbf{R}^l_b \\mathbf{R}^b_l \\boldsymbol{\\Omega}^l_{il}  \\mathbf{R}^l_b \\\\ &amp;= \\mathbf{R}^l_b \\boldsymbol{\\Omega}^b_{ib} - \\boldsymbol{\\Omega}^l_{il}  \\mathbf{R}^l_b, \\label{4.4.1} \\end{align} \\] <p>where \\(\\boldsymbol{\\Omega}^b_{ib}\\) is the skew-symmetric matrix of the IMU's angular-rate measurement and \\(\\boldsymbol{\\Omega}^e_{il}\\) is equivalent to:</p> \\[ \\boldsymbol{\\Omega}^l_{il} = \\mathbf{R}^l_e  \\boldsymbol{\\Omega}^e_{ie} \\mathbf{R}^e_l. \\label{4.4.2} \\] <p>Hence, the rotation of the Earth must be accounded for in updating the attitude. Note that \\(\\mathbf{R}^l_e\\) is constant since both frames are Earth fixed.</p> <p>Since this is a first-order matrix ordinary differential equation, assuming \\(\\boldsymbol{\\Omega}^e_{ie}\\) is constant:</p> \\[ \\begin{align} \\mathbf{R}^l_b(t + \\tau_i) &amp;\\approx \\mathbf{R}^l_b(t) \\exp\\left( \\boldsymbol{\\Omega}^b_{lb} \\tau_i \\right) \\\\ &amp;= \\mathbf{R}^l_b(t) \\exp \\left( \\boldsymbol{\\Omega}^b_{ib} \\tau_i - \\boldsymbol{\\Omega}^l_{il} \\tau_i \\right) \\\\ &amp;= \\mathbf{R}^l_b(t) \\exp\\left(\\boldsymbol{\\Omega}^b_{ib} \\tau_i \\right) - \\mathbf{R}^l_b(t) \\left[ \\exp\\left( \\boldsymbol{\\Omega}^b_{il} \\tau_i \\right) - \\mathbf{I}_3 \\right] \\\\ &amp;= \\mathbf{R}^l_b(t) \\exp\\left( \\left[ \\boldsymbol{\\alpha}^b_{ib} \\right]_\\times \\right) - \\left[ \\exp\\left( \\boldsymbol{\\Omega}^l_{il} \\tau_i \\right) - \\mathbf{I}_3 \\right] \\mathbf{R}^l_b(t). \\\\ \\label{4.4.3} \\end{align} \\] <p>Applying small angle approximation and truncating the power series expansion at the first order yields to:</p> \\[ \\mathbf{R}^l_b(+) \\approx \\mathbf{R}^l_b(-) \\left( \\mathbf{I}_3 + \\boldsymbol{\\Omega}^b_{ib} \\tau_i \\right) - \\boldsymbol{\\Omega}^l_{il} \\mathbf{R}^l_b(-) \\tau_i. \\label{4.4.4} \\] <p>Since the rotation of the Earth is much slower compared to the angular rate measurements from the IMU, this small angle approximation is always valid for the Earth rate term of the attitude update equation.</p>"},{"location":"navigation/inertial_navigation/inertial_navigation_local_tangent_plane/#precision-attitude-update","title":"Precision Attitude Update","text":"<p>We can replace the first order approximation in eq (\\(\\ref{4.4.4}\\)) with the attitude update matrix:</p> \\[ \\begin{align} \\mathbf{R}^l_b(+) &amp;=  \\left[  \\begin{array}{ccc} \\text{cos}\\omega_{ie} \\tau_i &amp; \\text{sin}\\omega_{ie} \\tau_i &amp; 0 \\\\ -\\text{sin}\\omega_{ie} \\tau_i &amp; \\text{cos}\\omega_{ie} \\tau_i &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{array} \\right] \\mathbf{R}^l_b(-) \\mathbf{R}^{b-}_{b+} \\\\ &amp;\\approx \\mathbf{R}^l_b(-)\\mathbf{R}^{b-}_{b+} - \\boldsymbol{\\Omega}^l_{il} \\mathbf{R}^l_b(-) \\tau_i, \\label{4.4.5} \\end{align} \\] <p>where the attidude update matrix is given by the Rodrigues's formula:</p> \\[ \\begin{align} \\mathbf{R}^{b-}_{b+} &amp;= \\mathbf{I}_3 + \\frac{\\text{sin}|\\boldsymbol{\\alpha}^b_{ib}|}{|\\boldsymbol{\\alpha}^b_{ib}|}  \\left[ \\boldsymbol{\\alpha}^b_{ib} \\right]_\\times + \\frac{1 - \\text{cos}|\\boldsymbol{\\alpha}^b_{ib}|}{|\\boldsymbol{\\alpha}^b_{ib}|^2} \\left[ \\boldsymbol{\\alpha}^b_{ib} \\right]^2_\\times. \\label{4.4.6} \\end{align} \\]"},{"location":"navigation/inertial_navigation/inertial_navigation_local_tangent_plane/#specific-force-frame-transformation","title":"Specific-Force Frame Transformation","text":"<p>The IMU measures specific force along the body-frame resolving axe. Applying the transform matrix similar to ECEF yields:</p> \\[ \\mathbf{f}^l_{ib}(t) = \\mathbf{R}^l_b(t) \\mathbf{f}^b_{ib}(t). \\label{4.4.7} \\] <p>Since the specific-force measurement is an average over time \\(t\\) to \\(t + \\tau_i\\), the transformation matrix should be similarly averaged. Assuming a constant angular rate:</p> \\[ \\mathbf{f}^l_{ib} \\approx \\frac{1}{2} \\left( \\mathbf{R}^l_b(-) + \\mathbf{R}^l_b(+) \\right) \\mathbf{f}^b_{ib}. \\label{4.4.8} \\] <p>However, the mean of two transformation matrices does not precisely produce the mean of the two attitudes. The less the attitude varies over the time interval, the smaller the errors introduced by this approximation.</p>"},{"location":"navigation/inertial_navigation/inertial_navigation_local_tangent_plane/#precision-specific-force-frame-transformation","title":"Precision Specific-Force Frame Transformation","text":"<p>Retaining the first-order approximation for the Earth-rate term, the prcecise transformation of the specific force to local tangent-plane frame axes is:</p> \\[ \\mathbf{f}^l_{ib} = \\bar{\\mathbf{R}}^l_b \\mathbf{f}^b_{ib}, \\quad \\bar{\\mathbf{R}}^l_b = \\mathbf{R}^l_b(-) \\mathbf{R}^{b-}_{\\bar{b}} - \\frac{1}{2} \\boldsymbol{\\Omega}^l_{il} \\mathbf{R}^l_b(-) \\tau_i, \\label{4.4.9} \\] <p>where:</p> \\[ \\begin{align} \\mathbf{R}^{b-}_{\\bar{b}} &amp;= \\mathbf{I}_3 +  \\frac{1 - \\text{cos}|\\boldsymbol{\\alpha^b_{ib}}|}{|\\boldsymbol{\\alpha^b_{ib}}|^2} \\left[ \\boldsymbol{\\alpha}^b_{ib} \\right]_\\times +  \\frac{1}{|\\boldsymbol{\\alpha^b_{ib}}|^2} \\left( 1 - \\frac{\\text{sin}|\\boldsymbol{\\alpha^b_{ib}}|}{|\\boldsymbol{\\alpha^b_{ib}}|} \\right) \\left[ \\boldsymbol{\\alpha}^b_{ib} \\right]^2_\\times. \\label{4.4.10} \\end{align} \\]"},{"location":"navigation/inertial_navigation/inertial_navigation_local_tangent_plane/#velocity-update","title":"Velocity Update","text":"<p>Similar to ECI/ECEF frame implementation, since the reference frame and resolving axes are the same:</p> \\[ \\dot{\\mathbf{v}}^l_{lb} = \\mathbf{a}^l_{lb} = \\ddot{\\mathbf{r}}^l_{lb}. \\label{4.4.11} \\] <p>Since:</p> \\[ \\begin{align} \\mathbf{r}^l_{lb} &amp;= \\mathbf{r}^l_{ib} - \\mathbf{r}^l_{il} \\\\  &amp;= \\mathbf{r}^l_{ib}, \\end{align} \\label{4.4.12} \\] <p>we get:</p> \\[ \\dot{\\mathbf{v}}^l_{lb} = \\ddot{\\mathbf{r}}^l_{ib}. \\label{4.4.13} \\] <p>From the section on acceleration in Kinematics, we get:</p> \\[ \\begin{align} \\mathbf{v}^l_{lb} &amp;= -\\boldsymbol{\\Omega}^l_{il} \\boldsymbol{\\Omega}^l_{il} \\mathbf{r}^l_{ib} - 2 \\boldsymbol{\\Omega}^l_{il} \\dot{\\mathbf{r}}^l_{lb} + \\mathbf{a}^l_{ib} \\\\ &amp;= -\\boldsymbol{\\Omega}^l_{il} \\boldsymbol{\\Omega}^l_{il} \\mathbf{r}^l_{ib} - 2 \\boldsymbol{\\Omega}^l_{il} \\mathbf{v}^l_{lb} + \\mathbf{a}^l_{ib}. \\label{4.4.14} \\end{align} \\] <p>The equation shows that the rate of change of velocity resolved about the local tangent-plane frame axes incorporates a centrifugal and a Coriolis term due to the rotation of the resolving axes. From the section on gravity models, we know that the applied acceleration \\(\\mathbf{a}^l_{ib}\\) is the sum of the measured specific force, \\(\\mathbf{f}^l_{ib}\\), and the acceleration due to the gravitation force, \\(\\boldsymbol{\\gamma}^l_{ib}\\).</p> <p>Furthermore, the acceleration due to gravity, \\(\\mathbf{g}^e_b\\), is the sum of the gravitational and centrifugal accelerations. Hence:</p> \\[ \\dot{\\mathbf{v}}^l_{lb} = \\mathbf{f}^l_{ib} + \\mathbf{R}^l_e \\mathbf{g}^e_b(\\mathbf{r}^e_{eb}) - 2 \\boldsymbol{\\Omega}^l_{il} \\mathbf{v}^l_{lb}, \\label{4.4.15} \\] <p>where:</p> \\[ \\begin{align} \\mathbf{r}^l_{lb} &amp;= \\mathbf{R}^l_e \\left( \\mathbf{r}^e_{eb} - \\mathbf{r}^e_{el} \\right) \\\\ \\mathbf{r}^e_{eb} &amp;= \\mathbf{r}^e_{el} + \\mathbf{R}^e_l \\mathbf{r}^l_{lb}. \\end{align} \\] <p>Since the Coriolis term is much smaller than the specific-force and gravity terms (except for space applications), it is reasonable approximation to neglegt the variation of the Coriolis term over the integration interval. Hence:</p> \\[ \\begin{align} \\mathbf{v}^l_{lb}(+) &amp; \\approx \\mathbf{v}^l_{lb}(-) + \\left( \\mathbf{f}^l_{ib}  + \\mathbf{R}^l_e \\mathbf{g}^e_b(\\mathbf{r}^e_{eb}(-)) - 2 \\boldsymbol{\\Omega}^l_{il} \\mathbf{v}^l_{lb}(-) \\right) \\tau_i \\\\  &amp;= \\mathbf{v}^l_{lb}(-) + \\boldsymbol{v}^l_{ib} + \\left(  \\mathbf{R}^l_e \\mathbf{g}^e_b(\\mathbf{r}^e_{eb}(-)) - 2 \\boldsymbol{\\Omega}^l_{il} \\mathbf{v}^l_{lb}(-) \\right) \\tau_i. \\label{4.4.16} \\end{align} \\]"},{"location":"navigation/inertial_navigation/inertial_navigation_local_tangent_plane/#position-update","title":"Position Update","text":"<p>In local-tangent plane frame implementation of the navigation equations, the time derivative of the Cartesian position is simply velocity as the reference frame and resolving axes are the same:</p> \\[ \\dot{\\mathbf{r}}^l_{lb} = \\mathbf{v}^l_{lb}. \\label{4.4.17} \\] <p>Integrating this gives:</p> \\[ \\begin{align} \\mathbf{r}^l_{lb}(+) &amp;= \\mathbf{r}^l_{lb}(-) + \\left( \\mathbf{v}^l_{lb}(-) + \\mathbf{v}^l_{lb}(+) \\right) \\frac{\\tau_i}{2} \\\\ &amp;\\approx \\mathbf{r}^l_{lb}(-) + \\mathbf{v}^l_{lb}(-)\\tau_i + \\left( \\mathbf{f}^l_{ib} + \\mathbf{R}^l_e \\mathbf{g}^e_b (\\mathbf{r}^e_{eb}(-)) - 2 \\boldsymbol{\\Omega}^l_{il} \\mathbf{v}^l_{lb}(-) \\right) \\frac{\\tau^2_i}{2}. \\label{4.4.18} \\end{align} \\]"},{"location":"navigation/inertial_navigation/inertial_navigation_local_tangent_plane/#precision-velocity-and-position-update","title":"Precision Velocity and Position Update","text":"<p>Exact evaluation of the Coriolis and transport-rate terms require knowledge of the velocity at the end of the update interval, requiring recursive solution. A good but processor-intensive solution is a two-step recursive method.</p>"},{"location":"navigation/radio_positioning/ranging/position_determination_from_ranging/","title":"Position determination from ranging","text":""},{"location":"navigation/radio_positioning/ranging/position_determination_from_ranging/#overview","title":"Overview","text":"<p>A positioning algorithm may be single-epoch or filtered. Single-epoch or snapshot positioning uses only current measurements, whereas filtered positioning uses the current and previous measurements. A filtered position solution is less noisy but can exhibit a lag in response to dynamics. </p>"},{"location":"navigation/radio_positioning/ranging/position_determination_from_ranging/#single-epoch-or-snapshot","title":"Single-Epoch or Snapshot","text":""},{"location":"navigation/radio_positioning/ranging/positioning_from_passive_ranging/","title":"Positioning from Passive Ranging","text":"<p>In passive ranging or time of arrival (TOA) measurement, the receiver measures the time of arrival, \\(t^t_{sa, a}\\), at receive antenna \\(a\\) of a particular feature of the signal that was transmitted at a known time, \\(t^t_{st, a}\\), from transmit antenna \\(t\\). The transmission time can be a predetermined feature of the system or may be modulated onto the signal. By neglegting the error sources, the range can be obtained by:</p> \\[ r_{at} = r_{ta} = \\left( t^t_{sa, a} - t^t_{st, a} \\right) c, \\] <p>where \\(c\\) is the speed of light which is \\(299, 792, 478 \\ ms^{-1}\\) in free space.</p> <p>The time of signal arrival is measured using the receiver clock, while the time of signal transmission is determined using the transmitter clock. These two clocks are not synchronized. </p> <p>If the receiver clock is ahead by \\(\\delta t^a_c\\) and the transmitter clock is ahead by \\(\\delta t^t_c\\), the range measurement will be (neglegting other error sources):</p> \\[ \\begin{align} \\rho^t_a &amp;= \\left( \\tilde{t}^t_{sa, a} - \\tilde{t}^t_{st, a} \\right) c \\\\  &amp;= \\left( t^t_{sa, a} + \\delta t^a_c - t^t_{sa, a} - \\delta t^t_c \\right) c \\\\ &amp;= r_{at} + \\left( \\delta t^a_c - \\delta t^t_c \\right) c, \\end{align} \\] <p>where \\(\\rho^t_a\\) is called the pseudo-range to distinguish it from the range measured in the absence of clock errors. Note that this pseudo-range is from the transmitter antenna, \\(t\\), to the receiver antenna, \\(a\\). Unlike goemetric range, pseudo-range depends on the direction of transmission. The pseudo-range for a signal transmitted from \\(a\\) to \\(t\\) is:</p> \\[ \\begin{align} \\rho^a_t &amp;= r_{ta} + \\left( \\delta t^t_c - \\delta t^a_c \\right) c \\\\  &amp;= r_{at} + \\left( \\delta t^t_c - \\delta t^a_c \\right) c \\\\ &amp;= \\rho^t_a - 2 \\left( \\delta t^a_c - \\delta t ^t_c \\right)c. \\end{align} \\] <p>Figure 1 illustrates the effect of unsynchronized transmitter and receiver clocks on range measurement.</p> <p> </p> Figure 1 Effect of clock bias in ranging (Groves, p263)"},{"location":"navigation/radio_positioning/ranging/tof_methods/","title":"Ranging","text":"<p>Time of Flight Methods</p> <p>The object's position can be determined by measuring the range to a number of objects at known locations. Range is usually obtained by measuring the signal's time of flight (TOF), but may also be estimated frmo the received signal strength (RSSI).</p> <p>Types</p> <p>There are five types of time of flight (TOF) based ranging measurements from which a position solution may be determined:</p> <ol> <li>Passive ranging or time of arrival (TOA).</li> <li>Time difference of arrival (TDOA) across transmitters or hyperbolic ranging.</li> <li>Differential ranging or TDOA across receivers.</li> <li>Double-differenced ranging across transmitters and receivers.</li> <li>Two-way ranging.</li> </ol>"},{"location":"navigation/sensors/magnetometer/","title":"Magnetometer","text":""},{"location":"navigation/sensors/magnetometer/#magnetic-inclination-and-declination","title":"Magnetic Inclination and Declination","text":"<p>Magnetic north is located in northern Canada at Ellesmere Island.  Magnetic inclination is the angle between the earth's surface and the magnetic field lines (angle made by compass needle when the compass is held in a vertical orientation). The inclination is positive when the field is pointing downward, into the Earth.</p> <p>Magnetic declination is the angle between the  magnetic north of the compass and the true north (geographic north). The declination is positive when the magnetic north polse is east of true north.</p>"},{"location":"navigation/time/time_of_flight/","title":"Time of flight","text":"<p>There are five types of time of flight (TOF) based ranging measurements from which a position solution may be determined:</p> <ol> <li>Passive ranging or time of arrival (TOA).</li> <li>Time difference of arrival (TDOA) across transmitters or hyperbolic ranging.</li> <li>Differential ranging or TDOA across receivers.</li> <li>Double-differenced ranging across transmitters and receivers.</li> <li>Two-way ranging.</li> </ol>"},{"location":"navigation/time/time_standards/","title":"Time Standards","text":""},{"location":"navigation/time/time_standards/#time","title":"Time","text":"<p>Both GPS time and UTC are derived from the atomic time TAI, a reference used to define the time unit in SI, kept by 400 atomic clocks in the world. Both have time unit in TAI seconds. GPS time and UTC wer equal on January 6th, 1980.</p> <p>Read - https://aviation.stackexchange.com/questions/90839/what-are-satellite-time-gps-time-and-utc-time#:~:text=Defined%20as%20equal%20to%20UTC,18%20seconds%20ahead%20of%20UTC.</p>"},{"location":"navigation/visual_slam/overview/","title":"Overview","text":""},{"location":"navigation/visual_slam/overview/#visual-slam-problem-formulation","title":"Visual SLAM Problem Formulation","text":"<p>Given a discrete motion and observation equations:</p> \\[ \\begin{align} \\mathbf{x}_k &amp;= \\mathbf{f}\\left( \\mathbf{x}_{k - 1}, \\mathbf{u}_k \\right) + \\mathbf{w}_k, \\quad k = 1, \\ldots, K \\\\ \\mathbf{z}_{k, j} &amp;= \\mathbf{h}\\left( \\mathbf{y}_j, \\mathbf{x}_k \\right) + \\mathbf{v}_{k, j}, \\quad \\left(k, j \\right) \\in \\mathcal{O}, \\end{align} \\] <p>where \\(\\mathcal{O}\\) is a set that contains the information at which pose the landmark was observed and:</p> <ol> <li>\\(\\mathbf{x}_k\\) - Pose of the camera at \\(k\\).</li> <li>\\(\\mathbf{u}_k\\) - System input at \\(k\\).</li> <li>\\(\\mathbf{z}_{k, j}\\) - Measurement or observation of a landmark point \\(\\mathbf{y}_j\\) at \\(\\mathbf{x}_k\\).</li> <li>\\(\\mathbf{y}_j\\) - \\(j\\)'th landmark, where \\(j = 1, \\ldots, M\\), for a total of \\(M\\) landmarks of the map.</li> <li>\\(\\mathbf{w}_k\\) and \\(\\mathbf{v}_k\\) - Process and measurement noises at \\(k\\).</li> </ol> <p>The observation equation is given by the pinhole model for VSLAM applications. Assuming an observation of a landmark \\(\\mathbf{y}_j\\) at \\(\\mathbf{x}_k\\):</p> \\[ s \\mathbf{z}_{k, j} = \\mathbf{K} \\left( \\mathbf{R}_k \\mathbf{y}_j + \\mathbf{t}_k \\right), \\] <p>where \\(\\mathbf{K}\\) is the camera intrinsics and \\(s\\) is the distance of pixels, which is also the third element of \\((\\mathbf{R}_k \\mathbf{y}_j + \\mathbf{t}_k)\\). The process and measurement noise can be assumed to be zero mean, Gaussian:</p> \\[ \\mathbf{w}_k \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{Q}_k), \\ \\mathbf{v}_k \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{R}_{k, j}), \\] <p>where \\(\\mathbf{Q}_k\\) and \\(\\mathbf{Q}_{k, j}\\) are process and measurement covariance matrices. </p>"},{"location":"notation_and_nomenclature/notation_and_nomenclature/","title":"Notation and Nomenclature","text":"<p>\\(x \\quad\\quad \\text{Real scalar value}\\)</p> <p>\\(\\mathbf{x} \\quad\\quad \\text{Real column vector}\\)</p> <p>\\(x_i \\quad\\quad i\\text{'th scalar component of column vector } \\mathbf{x}\\)</p> <p>\\(\\mathbf{M} \\quad\\quad \\text{Real matrix}\\)</p> <p>\\(\\mathbf{I} \\quad\\quad \\text{Identity matrix}\\)</p> <p>\\(\\mathbf{I}_i \\quad\\quad i\\text{-th column vector of identity matrix}\\)</p> <p>\\(\\mathbf{F}_{\\alpha} \\quad \\  \\text{ Right-handed coordinate frame } \\alpha\\)</p> <p>\\(\\mathbf{t}^\\gamma_{\\beta \\alpha} \\quad \\text{Vector with reference frame } \\beta \\text{ object frame } \\alpha \\text{ resolved in frame } \\gamma \\text{ axes}\\)</p> <p>\\(\\boldsymbol{\\psi}_{\\beta \\alpha} \\quad \\text{Euler rotation from frame } \\beta \\text{ to frame } \\alpha\\)</p> <p>\\(\\mathbf{t}_{\\beta \\alpha} \\quad \\text{Vector from frame } \\beta \\text{'s origin to frame } \\alpha \\text{'s origin}\\)</p> <p>\\(\\mathbf{R} \\quad\\quad SO(3) \\text{ rotation matrix}\\)</p> <p>\\(\\mathbf{R}^{\\alpha}_\\beta \\quad\\quad \\text{Rotation from } F_\\beta \\text{ to } F_\\alpha\\)</p> <p>\\(\\mathbf{T} \\quad\\quad SE(4) \\text{ transformation matrix}\\)</p> <p>\\(\\mathbf{T}^{\\alpha}_\\beta \\quad\\quad \\text{Transformation from } F_\\beta \\text{ to } F_\\alpha\\)</p> <p>\\(\\left[ \\ \\cdot \\ \\right]_\\times \\quad \\text{Skew matrix operator}\\)</p> <p>\\(\\left[ \\ \\cdot \\ \\right]^{-}_{\\times} \\quad \\text{Inverse skew matrix operator}\\)</p> <p>\\(\\hat{x} \\quad\\quad \\ \\ \\text{Estimated quantity of } x\\)</p> <p>\\(\\tilde{x} \\quad\\quad \\ \\ \\text{Measured quantity of } x\\)</p> <p>\\(|| \\mathbf{x} ||^2_{\\mathbf{A}} \\quad \\text{2-norm of } \\mathbf{x} \\ \\text{weighted by the covariance matrix } \\mathbf{A}. \\ \\text{Equivalent to } \\mathbf{x}^T \\mathbf{A}^{-1} \\mathbf{x}.\\)</p>"},{"location":"optimization/cauchy_schwarz_inequality/","title":"Cauchy schwarz inequality","text":"<p>Refer to Cauchy-Schwarz Inequality.</p>"},{"location":"optimization/duality/","title":"Duality Theory","text":""},{"location":"optimization/duality/#relaxation","title":"Relaxation","text":"<p>Duality theory is at the heart of optimization. The motivation to form the dual problem of a minimization LP \\((P)\\) is to find a lower bound to the optimal cost of \\((P)\\), i.e., find \\(Z\\) such that \\(Z \\leq Z^*_{P}\\), where \\(Z^*_{P}\\) is the optimal cost of the primal problem \\((P)\\). </p> <p>Consider an optimization problem \\((P)\\) defined as:</p> \\[ \\begin{align} (P) \\ \\min \\quad&amp; f(\\mathbf{x}) \\\\ \\text{s.t.} \\quad&amp; \\mathbf{x} \\in P. \\end{align} \\] <p>A problem \\((D)\\) defined as:</p> \\[ \\begin{align} \\min \\quad&amp; \\hat{f}(\\mathbf{x}) \\\\ \\text{s.t.} \\quad&amp; \\mathbf{x} \\in \\hat{P} \\end{align} \\] <p>is a relaxation of \\((P)\\) if:</p> <ol> <li>\\(P \\subseteq \\hat{P}\\).</li> <li>\\(f(\\mathbf{x}) \\geq \\hat{f}(\\mathbf{x}), \\ \\forall \\mathbf{x} \\in P\\).</li> </ol> <p>Relaxation involves:</p> <ol> <li>Finding a new objective function that is always smaller or equal to the original objective function at any feasible point.</li> <li>Find a feasible region that is larger than the feasible region of the original problem.</li> </ol> <p>Combining these two steps yields to a problem of minimizing a function lower than the original objective over a region that is larger than the original one. The optimal objective of the new problem will be a lower bound to the original problem. Clearly, if the relaxation is infeasible, then the original problem is also infeasible. The motivation is then to find the best lower bound among all the possible relaxations and lower bounds. \\((P)\\) and \\((D)\\) are illustrated in Figure 1.</p> <p> </p> Figure 1 Relaxation illustration"},{"location":"optimization/duality/#lagrangian","title":"Lagrangian","text":"<p>Consider an optimization problem \\((P)\\) defined as:</p> \\[ \\begin{align} \\min \\quad &amp; f(\\mathbf{x}) \\\\ \\textrm{s.t.} \\quad &amp; g_i(\\mathbf{x}) \\leq b_i, \\quad i = 1, \\ldots, m \\\\ \\quad &amp; h_j(\\mathbf{x}) = d_j, \\quad j = 1, \\ldots, p \\end{align} \\] <p>with optimization variable \\(\\mathbf{x} \\in \\mathbb{R}^n\\). We define the Lagrangian \\(\\mathcal{L}: \\mathbb{R}^n \\times \\mathbb{R}^m \\times \\mathbb{R}^p \\rightarrow \\mathbb{R}\\) associated with the optimization problem as:</p> \\[ \\mathcal{L}(\\mathbf{x}, \\boldsymbol{\\lambda}, \\boldsymbol{\\mu}) =  f(\\mathbf{x}) +  \\sum^m_{i = 1} \\lambda_i \\left[g_i(\\mathbf{x}) - b_i \\right] +  \\sum^p_{j = 1} \\mu_i \\left[ h_j(\\mathbf{x}) - d_j \\right]. \\] <p>The \\(\\lambda_i \\geq 0\\) and \\(\\mu_j\\) are called the Lagrangian multipliers associated with the  \\(i\\)'th inequality and \\(j\\)'th equality constraints. The vectors \\(\\boldsymbol{\\lambda}\\) and \\(\\boldsymbol{\\mu}\\) are called the dual variables or Lagrange multiplier vectors associated with  the optimization problem. The Lagrangian is less than or equal to the original objective for any primal feasible solution \\(\\mathbf{x}\\).</p>"},{"location":"optimization/duality/#lagrange-dual-function","title":"Lagrange Dual Function","text":"<p>The Lagrange dual function (or just dual function) \\(g: \\mathbb{R}^m \\times \\mathbb{R}^p \\rightarrow \\mathbb{R}\\) is defined as the  minimum value of the Lagrangian over \\(\\mathbf{x} \\in X\\): for \\(\\boldsymbol{\\lambda} \\in \\mathbb{R}^m\\) and \\(\\boldsymbol{\\mu} \\in \\mathbb{R}^p\\):</p> \\[ g(\\boldsymbol{\\lambda}, \\boldsymbol{\\mu}) =  \\inf_{\\mathbf{x} \\in X} \\mathcal{L}(\\mathbf{x}, \\boldsymbol{\\lambda}, \\boldsymbol{\\mu}) =  \\inf_{\\mathbf{x} \\in X} \\left( f(\\mathbf{x}) +  \\sum^m_{i = 1} \\lambda_i \\left[ g_i(\\mathbf{x}) - b_i \\right] + \\sum_{j = 1}^p \\mu_i \\left[h_j(\\mathbf{x}) - d_j \\right] \\right). \\] <p>When the Lagrangian is unbounded below in \\(\\mathbf{x}\\), the dual function takes on the  value \\(-\\infty\\). Since the dual function is the pointwise infimum of a family of affine functions of \\(\\boldsymbol{\\lambda}, \\boldsymbol{\\mu}\\), it is concave.</p> <p>Note that we explicitly didn't use minimum. The minimum is attained, the infimum isn't necessarily. The infimum of a set \\(S\\) is defined as the greatest number that is less than or equal to all elements of \\(S\\). The infimum is also sometimes called the greatest lower bound.</p>"},{"location":"optimization/duality/#lagrange-dual-problem","title":"Lagrange Dual Problem","text":"<p>The dual function yields lower bounds on the optimal value \\(p^*\\) of the optimization problem.  For any \\(\\lambda_i \\geq 0\\) and \\(\\mu_i\\):</p> \\[ g(\\boldsymbol{\\lambda}, \\boldsymbol{\\mu}) \\leq p^*. \\] <p>When the dual function takes \\(-\\infty\\), this inequality becomes vacuous.</p> <p>For each pair \\(\\boldsymbol{\\lambda}, \\boldsymbol{\\mu}\\) with \\(\\boldsymbol{\\lambda} \\geq 0\\), the Lagrange dual functions gives us a lower bound on the optimal value \\(p^*\\) of the  optimization problem. Thus we have a lower bound that depends on some parameters  \\(\\boldsymbol{\\lambda}, \\boldsymbol{\\mu}\\). Then what is the best lower bound that  can be obtained from the Lagrange dual function? This leads to an optimization problem:</p> \\[ \\begin{align} \\max \\quad &amp; g(\\boldsymbol{\\lambda}, \\boldsymbol{\\mu}) \\\\ \\textrm{s.t.} \\quad &amp; \\boldsymbol{\\lambda} \\geq 0. \\\\ \\end{align} \\] <p>This problem is called the Lagrange dual problem associated with the optimization problem.  The term dual feasible refers to the pair \\((\\boldsymbol{\\lambda}, \\boldsymbol{\\mu})\\) with  \\(\\boldsymbol{\\lambda} \\geq 0\\) and \\(g(\\boldsymbol{\\lambda}, \\boldsymbol{\\mu}) &gt; -\\infty\\).</p> <p>The Lagrange dual problem is a convex optimization problem, since the objective to be maximized is  concave and the constraint is convex. This is the case whether the initial optimization problem is convex or not.</p> <p>Notice that the dual of the dual is the primal.</p>"},{"location":"optimization/duality/#general-rules-for-forming-lp-dual","title":"General Rules for Forming LP Dual","text":"<p>Given a standard form LP:</p> \\[ \\begin{align} \\min \\quad&amp; \\mathbf{c}^T \\mathbf{x} \\\\ \\text{s.t.} \\quad&amp; \\mathbf{A} \\mathbf{x} = \\mathbf{b} \\\\ \\quad&amp; \\mathbf{x} \\geq 0, \\end{align} \\] <p>its dual pair will be:</p> \\[ \\begin{align} \\max \\quad&amp; \\mathbf{b}^T \\boldsymbol{\\lambda} \\\\  \\text{s.t.} \\quad&amp; \\boldsymbol{\\lambda}^T \\mathbf{A} \\leq \\mathbf{c}^T \\\\  &amp; \\boldsymbol{\\lambda} \\ \\text{free}. \\end{align} \\] <p>The general rules to formulate the dual problem with Lagrangian multiplier vector \\(\\boldsymbol{\\lambda}\\) are:</p> <ol> <li> <p>Relax the objective</p> <p>\\(\\lambda_i (b_i - \\mathbf{a}^T_i \\mathbf{x}) \\leq 0, \\ \\forall i\\):</p> <ol> <li> <p>If \\(\\mathbf{a}^T_i \\mathbf{x} \\geq b_i\\), then \\(\\lambda_i \\geq 0\\). </p> </li> <li> <p>If \\(\\mathbf{a}^T_i \\mathbf{x} \\leq b_i\\), then \\(\\lambda_i \\leq 0\\). </p> </li> <li> <p>If \\(\\mathbf{a}^T_i \\mathbf{x} = b_i\\), then \\(\\lambda_i\\) is free. </p> </li> </ol> </li> <li> <p>*Solve the Lagrangian relaxation</p> <p>\\(\\left( c_j - \\boldsymbol{\\lambda}^T \\mathbf{A}_j \\right)x_j \\geq 0\\):</p> <ol> <li> <p>If \\(x_j \\geq 0\\), then \\(c_j \\geq \\boldsymbol{\\lambda}^T \\mathbf{A}_j\\), i.e., \\(\\boldsymbol{\\lambda}^T \\mathbf{A}_j \\leq c_j\\).</p> </li> <li> <p>If \\(x_j \\leq 0\\), then \\(c_j \\leq \\boldsymbol{\\lambda}^T \\mathbf{A}_j\\), i.e., \\(\\boldsymbol{\\lambda}^T \\mathbf{A}_j \\geq c_j\\).</p> </li> <li> <p>If \\(x_j\\) is free, then \\(c_j = \\boldsymbol{\\lambda}^T \\mathbf{A}_j\\), i.e., \\(\\boldsymbol{\\lambda}^T \\mathbf{A}_j = c_j\\).</p> </li> </ol> </li> </ol> <p>Using these two rules, given the primal LP:</p> \\[ \\begin{align} \\min \\quad&amp; \\sum^{n}_{j = 1} c_j x_j  \\\\ \\text{s.t.} \\quad&amp; \\sum^{n}_{j = 1} a_{ij} x_j \\geq b_i, \\quad i = 1, \\ldots, m_1 \\\\  \\quad&amp; \\sum^{n}_{j = 1} a_{ij} x_j = b_i, \\quad i = m_1 + 1, \\ldots, m_2 \\\\  \\quad&amp; \\sum^{n}_{j = 1} a_{ij} x_j \\leq b_i, \\quad i = m_2 + 1, \\ldots, m \\\\ \\quad&amp; x_j \\geq 0, \\quad j = 1, \\ldots, n_1 \\\\ \\quad&amp; x_j \\ \\text{free}, \\quad j = n_1 + 1, \\ldots, n_2 \\\\ \\quad&amp; x_j \\leq 0, \\quad j = n_2 + 1, \\ldots, n, \\end{align} \\] <p>The dual is:</p> \\[ \\begin{align} \\max \\quad&amp; \\sum^{m}_{i = 1} b_i \\lambda_i  \\\\ \\text{s.t.} \\quad&amp; \\sum^{m}_{i = 1} a_{ij} \\lambda_i \\leq c_j, \\quad j = 1, \\ldots, n_1 \\\\  \\quad&amp; \\sum^{m}_{i = 1} a_{ij} \\lambda_i = c_j, \\quad j = n_1 + 1, \\ldots, n_2 \\\\  \\quad&amp; \\sum^{m}_{i = 1} a_{ij} \\lambda_i \\geq c_j, \\quad j = n_2 + 1, \\ldots, n \\\\ \\quad&amp; \\lambda_i \\geq 0, \\quad i = 1, \\ldots, m_1 \\\\ \\quad&amp; \\lambda_i \\ \\text{free}, \\quad j = m_1 + 1, \\ldots, m_2 \\\\ \\quad&amp; \\lambda_i \\leq 0, \\quad i = m_2 + 1, \\ldots, m. \\end{align} \\] <p>Again, the dual of the dual is the primal. </p>"},{"location":"optimization/duality/#example-on-lagrangian-dual-problem","title":"Example on Lagrangian Dual Problem","text":""},{"location":"optimization/duality/#primal-to-dual","title":"Primal to Dual","text":"<p>Consider LP \\((P)\\) with an optimal cost of \\(v^*_P\\):</p> \\[ \\begin{align} (P) \\quad \\min \\quad&amp; x_1 + 2x_2 + 3x_3 \\\\ \\text{s.t.} \\quad&amp; x_1 + 5x_2 + 4x_3 \\geq 6 \\\\ \\quad&amp; 2x_1 + 3x_2 - x_3 = 3 \\\\ \\quad&amp; x_1 + x_2 - 2 x_3 \\leq 4 \\\\ \\quad&amp; x_1 \\geq 0, \\ x_2 \\leq 0, x_3 \\ \\text{free}. \\end{align} \\] <p>The Lagrangian, \\(\\mathcal{L}: \\ \\mathbb{R}^3 \\times \\mathbb{R}^2 \\times \\mathbb{R} \\rightarrow \\mathbb{R}\\), should have an objective value that is less than or equal to the primal problem:</p> \\[ \\begin{align} \\mathcal{L} &amp;= x_1 + 2x_2 + 3x_3  \\\\ &amp;+ \\lambda_1 \\left[ 6 - x_1 - 5x_2 - 4x_3 \\right] \\\\ &amp;+ \\mu \\left[ 3 - 2x_1 - 3x_2 + x_3 \\right]  \\\\ &amp;+ \\lambda_2 \\left[ x_1 + x_2 - 2x_3 - 4 \\right], \\end{align} \\] <p>where \\(\\lambda_1, \\lambda_2 \\geq 0\\) and \\(\\mu\\) free.</p> <p>The dual function, \\(g: \\mathbb{R}^2 \\times \\mathbb{R} \\rightarrow \\mathbb{R}\\) is then:</p> \\[ \\begin{align} g(\\lambda_1, \\lambda_2, \\mu) =  \\min \\quad&amp; \\mathcal{L} \\\\ \\text{s.t.} \\quad&amp; x_1 + 5x_2 + 4x_3 \\geq 6 \\\\ \\quad&amp; 2x_1 + 3x_2 - x_3 = 3 \\\\ \\quad&amp; x_1 + x_2 - 2 x_3 \\leq 4 \\\\ \\quad&amp; x_1 \\geq 0, \\ x_2 \\leq 0, x_3 \\ \\text{free}. \\end{align} \\] <p>Since for every feasible \\(x_1, x_2, x_3\\), the objective of the above problem is less than our equal to the original objective of the primal problem, then the optimal cost of the above is less than or equal to the optimal cost of the primal problem.</p> <p>The Lagrangian relaxation problem can be formulated by enlarging the feasible region of the optimization problem by removing constraints:</p> \\[ \\begin{align} g'(\\lambda_1, \\lambda_2, \\mu) =  \\min \\quad&amp; \\mathcal{L} \\\\ \\text{s.t.} \\quad&amp; x_1 \\geq 0, \\ x_2 \\leq 0, x_3 \\ \\text{free}. \\end{align} \\] <p>Here, we have \\(g'(\\lambda_1, \\lambda_2, \\mu) \\leq g(\\lambda_1, \\lambda_2, \\mu) \\leq v^*_P\\) for any \\(\\lambda_1, \\lambda_2 \\geq 0\\) and \\(\\mu\\) free. </p> <p>The Lagrangian relaxation problem can be separated into three independent problems, where each is an LP with a single variable \\(x_j\\) and a sign constraint on \\(x_j\\):</p> \\[ \\begin{align} g'(\\lambda_1, \\lambda_2, \\mu) &amp;= \\min_{x_1: \\ x_1 \\geq 0} \\left\\{ \\left[ 1 - \\lambda_1 - 2\\mu + \\lambda_2 \\right] x_1 \\right\\} \\\\ &amp;+ \\min_{x_2: \\ x_2 \\leq 0} \\left\\{ \\left[ 2 - 5\\lambda_1 - 3\\mu + \\lambda_2 \\right] x_2 \\right\\} \\\\ &amp;+ \\min_{x_3: \\ x_3 \\ \\text{free}} \\left\\{ \\left[ 3 - 4\\lambda_1 - 2\\lambda_2 + \\mu \\right] x_3 \\right\\} \\\\ &amp;+ (6 \\lambda_1 - 4\\lambda_2 + 3\\mu). \\end{align} \\] <p>The three subproblems can be easily solved as:</p> \\[ \\begin{align} &amp;\\min_{x_1: \\ x_1 \\geq 0} \\left\\{ \\left[ 1 - \\lambda_1 - 2\\mu + \\lambda_2 \\right] x_1 \\right\\} =  \\begin{cases}     0,&amp; \\text{if }  1 - \\lambda_1 - 2\\mu + \\lambda_2 \\geq 0 \\\\     -\\infty,              &amp; \\text{otherwise} \\end{cases} \\label{a} \\\\ &amp;\\min_{x_2: \\ x_2 \\leq 0} \\left\\{ \\left[ 2 - 5\\lambda_1 - 3\\mu + \\lambda_2 \\right] x_2 \\right\\} =  \\begin{cases}     0,&amp; \\text{if }  2 - 5\\lambda_1 - 3\\mu + \\lambda_2 \\leq 0 \\\\     -\\infty,              &amp; \\text{otherwise} \\end{cases} \\label{b} \\\\ &amp;\\min_{x_3: \\ x_3 \\ \\text{free}} \\left\\{ \\left[ 3 - 4\\lambda_1 - 2\\lambda_2 + \\mu \\right] x_3 \\right\\} =  \\begin{cases}     0,&amp; \\text{if }  3 - 4\\lambda_1 - 2\\lambda_2 + \\mu = 0 \\\\     -\\infty,              &amp; \\text{otherwise}. \\end{cases} \\label {c} \\\\ \\end{align} \\] <p>Then the Lagrangian relaxation problem is:</p> \\[ \\begin{align} g'(\\lambda_1, \\lambda_2, \\mu) =  \\begin{cases}     6\\lambda_1 - 4\\lambda_2 + 3\\mu, &amp; \\text{if }  \\ref{a}, \\ref{b}, \\ref{c} \\ \\text{holds}\\\\     -\\infty,              &amp; \\text{otherwise}. \\end{cases} \\\\ \\end{align} \\] <p>The Lagrangian dual problem is then:</p> \\[ \\begin{align} (D) \\quad \\max_{\\lambda_1, \\lambda_2, \\mu} \\quad&amp; g'(\\lambda_1, \\lambda_2, \\mu) \\\\ \\text{s.t.} \\quad&amp; \\lambda_1, \\lambda_2 \\geq 0, \\ \\mu \\ \\text{free}, \\end{align} \\] <p>or equivalently:</p> \\[ \\begin{align} (D) \\quad \\max_{\\lambda_1, \\lambda_2, \\mu} \\quad&amp; 6\\lambda_1 - 4\\lambda_2 + 3\\mu \\\\ \\text{s.t.} \\quad&amp; 1 - \\lambda_1 - 2\\mu + \\lambda_2 \\geq 0 \\\\  \\quad&amp; 2 - 5\\lambda_1 - 3\\mu + \\lambda_2 \\leq 0 \\\\ \\quad&amp; 3 - 4\\lambda_1 - 2\\lambda_2 + \\mu \\\\ \\quad&amp; \\lambda_1, \\lambda_2 \\geq 0, \\ \\mu \\ \\text{free}. \\end{align} \\]"},{"location":"optimization/duality/#dual-to-primal","title":"Dual to Primal","text":"<p>The dual of the dual is the primal. The Lagrangian for the dual problem is:</p> \\[ \\begin{align} \\mathcal{L'}(x_1, x_2, x_3, \\lambda_1, \\lambda_2, \\mu) &amp;= (6\\lambda_1 - 4\\lambda_2 + 3\\mu)  \\\\ &amp;+ x_1 \\left[ 1 - \\lambda_1 - 2\\mu + \\lambda_2 \\right] \\\\ &amp;+ x_2 \\left[ 2 - 5\\lambda_1 - 3\\mu + \\lambda_2 \\right] \\\\ &amp;+ x_3 \\left[ 3 - 4\\lambda_1 - 2\\lambda_2 + \\mu \\right], \\\\ \\end{align} \\] <p>where \\(x_1 \\geq 0, x_2 \\leq 0\\), and \\(x_3\\) free. We want the Lagrangian function to provide an upper bound to the original problem \\((D)\\). Hence the Lagrangian relaxation is formed as:</p> \\[ \\begin{align} g_2(x_1, x_2, x_3) = \\max_{\\lambda_1, \\lambda_2, \\mu} \\mathcal{L'} \\\\ \\text{s.t.} \\quad&amp; \\lambda_1, \\lambda_2 \\geq 0, \\ \\mu \\ \\text{free}. \\end{align} \\] <p>This is a separable problem and can be solved by maximizing over each lagrangian multiplier separately as follows:</p> \\[ \\begin{align} g_2(x_1, x_2, x_3) &amp;= (x_1 + 2x_2 + 3x_3) \\\\ &amp;+ \\max_{\\lambda_1: \\ \\lambda_1 \\geq 0} \\left\\{ \\left[ 6 - x_1 - 5x_2 -4x_3 \\right] \\lambda_1 \\right\\} \\\\  &amp;+ \\max_{\\lambda_2: \\ \\lambda_2 \\geq 0} \\left\\{ \\left[ -4 + x_1 + x_2 - 2x_3 \\right] \\lambda_2 \\right\\} \\\\ &amp;+ \\max_{\\mu: \\ \\mu \\ \\text{free}} \\left\\{ \\left[ 3 - 2x_1 - 3x_2 + x_3 \\right] \\mu \\right\\}, \\\\ \\end{align} \\] <p>The subproblems can be solved as:</p> \\[ \\begin{align} &amp;\\max_{\\lambda_1: \\lambda_1 \\geq 0} \\left\\{ \\left[ 6 - x_1 - 5x_2 -4x_3 \\right] \\lambda_1 \\right\\} =  \\begin{cases}     0,&amp; \\text{if }  6 - x_1 - 5x_2 -4x_3 \\leq 0 \\\\     +\\infty,              &amp; \\text{otherwise} \\end{cases} \\label{d} \\\\ &amp;\\max_{\\lambda_2: \\ \\lambda_2 \\geq 0} \\left\\{ \\left[ -4 + x_1 + x_2 - 2x_3 \\right] \\lambda_2 \\right\\} =  \\begin{cases}     0,&amp; \\text{if }  -4 + x_1 + x_2 - 2x_3 \\leq 0 \\\\     +\\infty,              &amp; \\text{otherwise} \\end{cases} \\label{e} \\\\ &amp;\\max_{\\mu: \\ \\mu \\ \\text{free}} \\left\\{ \\left[ 3 - 2x_1 - 3x_2 + x_3 \\right] \\mu \\right\\} =  \\begin{cases}     0,&amp; \\text{if }  3 - 2x_1 - 3x_2 + x_3 = 0 \\\\     +\\infty,              &amp; \\text{otherwise}. \\end{cases} \\label{f} \\\\ \\end{align} \\] <p>Hence, the dual of the dual gives the primal problem \\((P)\\).</p>"},{"location":"optimization/duality/#weak-duality","title":"Weak Duality","text":"<p>Theorem (Linear programming weak duality). If \\(\\mathbf{x}\\) is any feasible solution to the primal minimization LP, and \\(\\boldsymbol{\\lambda}\\) is any feasible solution to the dual maximization LP, then \\(\\mathbf{c}^T \\mathbf{x} \\geq \\mathbf{b}^T \\boldsymbol{\\lambda}\\).</p> <p>In order words, the optimal value of the Lagrange dual problem, \\(v_D^*\\), is by definition, the best lower bound on \\(v_P^*\\) that can be obtained from the Lagrange dual function. We have the simple but important inequality:</p> \\[ v_D^* \\leq v_P^*, \\] <p>which holds even if the original problem is not convex. This property is called  weak duality. The optimal duality gap of the original problem is \\(v_P^* - v_D^*\\) which  is the gap between the optimal value of the optimization problem and the best (i.e., greatest) lower bound on it that can be obtained from the Lagrange dual function. The optimal duality gap is always nonnegative. </p> <p>Weak duality provides some useful properties:</p> <ol> <li>If the optimal cost of the primal minimization problem is \\(-\\infty\\), then the dual maximization problem must be infeasible.</li> <li>If the optimal cost of the dual maximization problem is \\(+\\infty\\), then the primal minimization problem must be infeasible.</li> <li>Let \\(\\mathbf{x}^*\\) be a feasible solution to the primal problem and \\(\\boldsymbol{\\lambda}^*\\) be a feasible solution to the dual problem, and suppose \\(\\mathbf{c}^T \\mathbf{x}^* = \\mathbf{b}^T \\boldsymbol{\\lambda}^*\\). Then \\(\\mathbf{x}^*\\) and \\(\\boldsymbol{\\lambda}^*\\) are optimal solutions to the primal and dual problems respectively.</li> </ol>"},{"location":"optimization/duality/#strong-duality","title":"Strong Duality","text":"<p>Theorem (Linear programming strong duality). If a primal linear program has a finite optimal solution \\(\\mathbf{x}^*\\), then its dual linear program must also have a finite optimal solution \\(\\boldsymbol{\\lambda}^*\\), and the respective optimal objective values are equal, that is \\(\\mathbf{c}^T \\mathbf{x}^* = \\mathbf{b}^T \\boldsymbol{\\lambda}^*\\).</p> <p>In other words, if the equality:</p> \\[ v_D^* = v_P^*, \\] <p>holds, i.e., the optimal duality gap is zero, then strong duality holds. If the optimization  problem is convex, we usually (but not always) have strong duality.</p> <p>Proof. Assume the primal problem is a standard form LP (without loss of generality, we can transform any LP to standard form). Then the primal and dual problems are:</p> \\[ \\begin{align} (P) \\ \\min \\quad&amp; \\mathbf{c}^T \\mathbf{x} \\\\ \\text{s.t.} \\quad&amp; \\mathbf{A} \\mathbf{x} = \\mathbf{b} \\\\ \\quad&amp; \\mathbf{x} \\geq \\mathbf{0}, \\end{align} \\] <p>and</p> \\[ \\begin{align} (D) \\ \\max \\quad&amp; \\mathbf{b}^T \\boldsymbol{\\lambda} \\\\ \\text{s.t.} \\quad&amp; \\boldsymbol{\\lambda}^T \\mathbf{A} \\leq \\mathbf{c}^T \\\\ \\quad&amp; \\boldsymbol{\\lambda} \\ \\text{free}. \\end{align} \\] <p>If the primal problem has a finite optimal solution, then the simplex method with an anti-cycling rule (e.g., Bland's rule) will terminate with an optimal solution \\(\\mathbf{x}^*\\) and the associated basis matrix \\(\\mathbf{B}\\). By the optimality of \\(\\mathbf{x}^*\\), we know the reduced costs are \\(\\bar{\\mathbf{c}}^T = \\mathbf{c}^T - \\mathbf{c}^T_B \\mathbf{B}^{-1} \\mathbf{A} \\geq \\mathbf{0}^T\\). Now let \\(\\left( \\boldsymbol{\\lambda}^* \\right)^T = \\mathbf{c}^T_B \\mathbf{B}^{-1}\\), then the reduced costs condition is the same as \\(\\left( \\boldsymbol{\\lambda}^* \\right)^T \\mathbf{A} \\leq \\mathbf{c}^T\\), i.e., \\(\\boldsymbol{\\lambda}^*\\) is a dual feasible. Also, \\(\\mathbf{b}^T \\boldsymbol{\\lambda}^* = \\mathbf{c}^T_B \\mathbf{B}^{-1} \\mathbf{b} = \\mathbf{c}^T_B \\mathbf{x}_B = \\mathbf{c}^T \\mathbf{x}^*\\). By weak duality, \\(\\boldsymbol{\\lambda}^*\\) is an optimal solution to the dual problem, and the respective optimal objective values of primal and dual are equal. </p> <p>This proof shows that the optimal dual solution \\(\\boldsymbol{\\lambda}^*\\) can be obtained from the output of the Simplex method, i.e., \\(\\boldsymbol{\\lambda}^* = \\left( \\mathbf{c}^T_B \\mathbf{B} \\right)^T\\).</p>"},{"location":"optimization/duality/#feasibility-combinations","title":"Feasibility Combinations","text":"<p>The primal and dual problems can be finite optimal, unbounded optimal, or infeasible. </p> <ol> <li> <p>Primal finite optimal, Dual finite optimal: Possible. Per strong duality, if the primal is finite optimal, then dual must be finite optimal, and vice versa. The strong duality tells us that \\(\\mathbf{c}^T \\mathbf{x}^* = \\mathbf{b}^T \\boldsymbol{\\lambda}^*\\) for primal optimal solution \\(\\mathbf{x}^*\\) and dual optimum \\(\\boldsymbol{\\lambda}^*\\).</p> </li> <li> <p>Primal finite optimal, Dual unbounded: Impossible due to the weak duality. If the dual has unbounded optimum, i.e., \\(+\\infty\\), it cannot be a lower bound for the finite optimal cost of the primal.</p> </li> <li> <p>Primal finite optimal, Dual infeasible: Impossible due to the strong duality, which says if the primal has a finite optimal cost, so does the dual.</p> </li> <li> <p>Primal unbounded, Dual finite optimal: Impossible due to the weak duality. It can also be seen by symmetry with the case primal finite optimal, dual unbounded.</p> </li> <li> <p>Primal unbounded, Dual unbounded: Impossible due to the weak duality. Both unbounded means that primal optimal cost is \\(-\\infty\\), and the dual optimal cost is \\(+\\infty\\), which cannot happen.</p> </li> <li> <p>Primal unbounded, Dual infeasible: Possible due to the weak duality. Primal has \\(-\\infty\\) cost, the dual cannot have any feasible solution, otherwise, the feasible solution would give a lower bound to \\(-\\infty\\) by weak duality. In order words, if the primal is unbounded, the dual must be infeasible.</p> </li> <li> <p>Primal infeasible, Dual finite optimal: Impossible by using the result of primal finite optimal, dual infeasible.</p> </li> <li> <p>Primal infeasible, Dual unbounded: Possible by using the result of primal unbounded, dual infeasible. Notice that if the primal is infeasible, then the dual may not necessarily be unbounded. </p> </li> <li> <p>Primal infeasible, Dual infeasible: Possible.</p> </li> </ol> <p>In summary:</p> Finite Optimum Unbounded Infeasible Finite Optimum Possible Impossible Impossible Unbounded Impossible Impossible Possible Infeasible Impossible Possible Possible"},{"location":"optimization/duality/#complementary-slackness","title":"Complementary Slackness","text":"<p>Theorem (Complementary Slackness). Let \\(\\mathbf{x}\\) and \\(\\boldsymbol{\\lambda}\\) be feasible solutions to the primal and dual problem, respectively. Then \\(\\mathbf{x}\\) and \\(\\boldsymbol{\\lambda}\\) are optimal solutions for the two problems if and only if they satisfy the following conditions:</p> <p>Primal Complementary Slackness: \\(\\lambda_i \\left( \\mathbf{a}^T_i \\mathbf{x} - b_i \\right) = 0\\) for all \\(i\\). In other words, either the \\(i\\)'th primal constraint is active (binding, tight) such that \\(\\mathbf{a}^T_i \\mathbf{x} = b_i\\), or the corresponding dual variable is zero, i.e., \\(\\lambda_i = 0\\).</p> <p>Dual Complementary Slakness: \\(x_j \\left( c_j - \\boldsymbol{\\lambda}^T \\mathbf{A}_j \\right) = 0\\) for all \\(j\\). In other words, either the \\(j\\)'th dual constraint is active (binding, tight) such that \\(\\boldsymbol{\\lambda}^T \\mathbf{A}_j = c_j\\), or the corresponding primal variable is zero, i.e., \\(x_j = 0\\).</p>"},{"location":"optimization/duality/#example-on-complementary-slackness","title":"Example on Complementary Slackness","text":"<p>Consider the following primal dual pair:</p> \\[ \\begin{align} \\min \\quad&amp; 13x_1 + 10x_2 + 6x_3 \\quad\\quad\\quad &amp;\\max \\quad&amp; 8 \\lambda_1 + 3 \\lambda_2 \\\\ \\text{s.t.} \\quad&amp; 5x_1 + x_2 + 3x_3 = 8 \\quad\\quad\\quad &amp;\\text{s.t.} \\quad&amp; 5\\lambda_1 + 3\\lambda_2 \\leq 13 \\\\ &amp;3x_1 + x_2 = 3 &amp;&amp;\\lambda_1 + \\lambda_2 \\leq 10\\\\ &amp;x_1, x_2, x_3 \\geq 0 &amp;&amp;3\\lambda_1 \\leq 6. \\end{align} \\] <p>Let the optimal solution to the dual problem be \\((\\lambda^*_1, \\lambda^*_2) = (2, 1)\\).</p> <ol> <li> <p>At the dual optimum:</p> \\[ \\begin{align} &amp;5\\lambda^*_1 + 3\\lambda^*_2 = 13 \\\\ &amp;\\lambda^*_1 + \\lambda^*_2 = 3 &lt; 10 \\\\ &amp;3\\lambda^*_1 = 6. \\end{align} \\] <p>Therefore, by the Dual Complementary Slackness, \\(x^*_2 \\left( \\lambda^*_1 + \\lambda^*_2 - 10 \\right) = 0\\), we know that \\(x^*_2 = 0\\).</p> </li> <li> <p>Primaly Complementary Slackness is automatically satisfied since the primal constraints are equalities. We have:</p> \\[ \\begin{align} &amp;5x^*_1 + 3x^*_3 = 8 \\\\ &amp;3x^*_1 = 3. \\end{align} \\] <p>The optimal primal solution is then \\((x^*_1, x^*_2, x^*_3) = (1, 0, 1)\\).</p> </li> </ol>"},{"location":"optimization/optimization_problem_formulation/","title":"Optimization Problem Formulation","text":""},{"location":"optimization/optimization_problem_formulation/#definition","title":"Definition","text":"<p>A mathematical optimization problem (in minimization), or just optimization problem is defined as:</p> \\[ \\begin{align} \\min \\quad &amp; f(\\mathbf{x}) \\\\ \\textrm{s.t.} \\quad &amp; g_i(\\mathbf{x}) \\leq b_i, \\quad i = 1, \\ldots, m \\\\ \\quad &amp; h_i(\\mathbf{x}) = c_i, \\quad i = 1, \\ldots, p \\end{align} \\] <p>Here the vector \\(\\mathbf{x} = (x_1, \\ldots, x_n)\\) is the optimization variable or the decision variable of the problem,  the function \\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R}\\) is the objective function, the  functions \\(g_i: \\mathbb{R}^n \\rightarrow \\mathbb{R}, \\ i = 1, \\ldots, m\\), are the (inequality) constraint functions, and the constants \\(b_1, \\ldots, b_m\\) are the limits, or bounds, for the constraints. \\(h_i: \\mathbb{R}^n \\rightarrow \\mathbb{R}, \\ i = 1, \\ldots, p\\) are the equality constraints, and  the constants \\(c_1, \\ldots, c_p\\) are the equality for the constraints. If there are no constraint functions, we call  the problem is unconstrained. </p> <p>A vector \\(\\mathbf{x}^*\\) is the optimal solution of the problem, if it has the smallest objective value among all vectors that  satisfy the constrains; for any \\(\\mathbf{z}\\) with \\(g_1(\\mathbf{z}) \\leq b_1, \\ldots, g_m(\\mathbf{z}) \\leq b_m\\) and  \\(h_1(\\mathbf{z}) = c_1, \\ldots, h_k(\\mathbf{z}) = c_p\\),  we have \\(f(\\mathbf{z}) \\geq f(\\mathbf{x}^*)\\).</p> <p>The constraints define a set of values that the optimization variable can take, e.g., \\(X = \\left\\{ \\mathbf{x} \\in \\mathbb{R}^{n - p} \\times \\mathbb{Z}^p : \\ g_i(\\mathbf{x}) \\leq b_i, \\ i = 1, \\ldots, m \\right\\}\\). A point \\(\\mathbf{x} \\in X\\) is called feasible if it satisfies all the constraints of the  optimization problem. Note that if \\(X = \\emptyset\\), then the optimization problem is infeasible.  The set of all feasible points is called the feasible set  or the constraint set. For example, the problem:</p> \\[ \\min \\left\\{ 3x + 2y \\ : \\ x + y \\leq 1, \\ x \\geq 2, \\ y \\geq 2 \\right\\}, \\] <p>is infeasible.</p> <p>An optimization problem is unbounded if there are feasible solutions with arbitrarily small objective values. Formally, optimization problem is unbounded if there exists a sequence of  feasible solutions \\(\\left\\{ \\mathbf{x}^i \\right\\}\\) such that \\(\\lim_{i \\rightarrow \\infty} f(\\mathbf{x}^i) = - \\infty\\). Note that an unbounded problem must be  feasible. If \\(X\\) is bounded set, then the optimization problem cannot be unbounded.</p>"},{"location":"optimization/optimization_problem_formulation/#minimization-vs-maximization","title":"Minimization vs. Maximization","text":"<p>Without loss of generality, it is sufficient to consider a minimization problem since:</p> \\[ \\begin{align} \\max \\quad &amp; f(\\mathbf{x}) \\\\ \\textrm{s.t.} \\quad &amp; g_i(\\mathbf{x}) \\leq b_i, \\\\ \\end{align} \\] <p>is equivalent to</p> \\[ \\begin{align} -\\min \\quad &amp; -f(\\mathbf{x}) \\\\ \\textrm{s.t.} \\quad &amp; g_i(\\mathbf{x}) \\leq b_i. \\\\ \\end{align} \\]"},{"location":"optimization/optimization_problem_formulation/#existence-of-an-optimal-solution","title":"Existence of an Optimal Solution","text":"<p>Thereom Weierstrass Theorem.</p> <p>Consider an optimization problem:</p> \\[ \\begin{align} \\min \\quad &amp; f(\\mathbf{x}) \\\\ \\textrm{s.t.} \\quad &amp; \\mathbf{x} \\in X. \\end{align} \\] <p>If \\(f\\) is continuous function and \\(X\\) is a nonempty, closed, and bounded set (equivalently,  nonempty and compact), then the optimization problem has an optimal solution, i.e., there exists \\(\\mathbf{x}^* \\in X\\) such that \\(f(\\mathbf{x}^*) \\leq f(\\mathbf{x})\\) for all \\(\\mathbf{x} \\in X\\).</p> <p>Remarks:</p> <ol> <li>This is a sufficient condition and not a necessary condition.</li> <li>\\(X\\) is not empty, thus the problem cannot be infeasible.</li> <li>\\(X\\) is bounded, thus the problem cannot be unbounded.W</li> <li>The continuity and closedness guarantees an optimal solution exists.</li> </ol>"},{"location":"optimization/optimization_problem_formulation/#global-and-local-optimal-solutions","title":"Global and Local Optimal Solutions","text":"<p>Consider again the problem:</p> \\[ \\begin{align} \\min \\quad &amp; f(\\mathbf{x}) \\\\ \\textrm{s.t.} \\quad &amp; \\mathbf{x} \\in X. \\end{align} \\] <p>A solution \\(\\mathbf{x}^*\\) is a global optimal solution if \\(\\mathbf{x}^* \\in X\\) and \\(f(\\mathbf{x}^*) \\leq f(\\mathbf{x})\\) for all \\(\\mathbf{x} \\in X\\).</p> <p>Given a solution \\(\\mathbf{x}^*\\) and a scalar \\(\\epsilon &gt; 0\\), an \\(\\epsilon\\)-neighborhood of \\(\\mathbf{x}^*\\) is defined as: </p> \\[ \\mathbb{B}_\\epsilon (\\mathbf{x}^*) =  \\left\\{ \\mathbf{x}: \\ ||\\mathbf{x} - \\mathbf{x}^* || \\leq \\epsilon \\right\\}. \\] <p>A solution \\(\\mathbf{x}^*\\) is a local optimal solution if  \\(\\mathbf{x}^* \\in X\\) and if there is an \\(\\epsilon &gt; 0\\) such that  \\(f(\\mathbf{x}^*) \\leq f(\\mathbf{x})\\) for all \\(\\mathbf{x} \\in X \\cap \\mathbb{B}_\\epsilon (\\mathbf{x}^*)\\).</p> <p>If the problem is a convex optimization problem, i.e., \\(f\\) is a convex function and \\(X\\) is a convex set, then any local optimal solution is also a global optimal solution.</p> <p>Remarks:</p> <ol> <li>Every global optimal solution is a local optimal solution, but not vice versa</li> <li>The objective function value at different local optimal solutions may be different</li> <li>The objective value at all global optimal solutions must be the same</li> <li>Typical optimization algorithms are designed to find local optimal solutions (at best)</li> <li>If the problem is convex, then we are sure that any local optimal solution we find is also a global optimal solution</li> </ol>"},{"location":"optimization/optimization_problem_formulation/#convex-optimization-problem","title":"Convex Optimization Problem","text":"<p>Given:</p> \\[ \\begin{align} \\min \\quad&amp; f(\\mathbf{x}) \\\\ \\text{s.t.} \\quad&amp; g_i(\\mathbf{x}) \\leq b_i \\quad i = 1, \\ldots, m \\\\ \\quad&amp; h_j(\\mathbf{x}) = d_j \\quad j = 1, \\ldots, l \\\\ \\quad&amp; \\mathbf{x} \\in \\mathbb{R}^n, \\end{align} \\] <p>a convex optimization problem is one in which the objective and constraint functions are convex, which means they satisfy the inequality:</p> \\[ f_i (\\alpha \\mathbf{x} + \\beta \\mathbf{y}) \\leq \\alpha f_i(\\mathbf{x}) + \\beta f_i(\\mathbf{y}), \\] <p>for all \\(\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^n\\) and all \\(\\alpha, \\beta \\in \\mathbf{R}\\) with \\(\\alpha + \\beta = 1\\), \\(\\alpha \\geq 0\\), \\(\\beta \\geq 0\\).</p> <p>In general, to check for convexity:</p> <ol> <li>Check that all variables are continuous</li> <li>Check that the objective function is convex</li> <li>Check each equality constraint to see if it is linear</li> <li>Write each constraint as an inequality contraint in \\(\\leq\\) form with a constant on the right-hand-side, and check         the convexity of the function on the left-hand-side </li> </ol> <p>If the problem passes all the checks, then it is a convex optimization problem. Otherwise, it may or may not be convex (the conditions are sufficient, not necessary).</p> <p>Proof. Define \\(X_{g_i} = \\left\\{ \\mathbf{x}: \\ g_i(\\mathbf{x}) \\leq b_i \\right\\}\\). If \\(g_i\\) is convex, \\(X_{g_i}\\) is a convex set since it is the level set of convex function \\(g_i\\). We can write an equality constraint \\(h_j (\\mathbf{x}) = d_j\\) as two inequalities \\(h_j(\\mathbf{x}) \\leq d_j\\) and \\(-h_j (\\mathbf{x}) \\leq -d_j\\). Define \\(X_{h_j} = \\left\\{\\mathbf{x} : \\ h_j(\\mathbf{x}) \\leq d_j \\right\\}\\) and \\(X_{-h_j} = \\left\\{\\mathbf{x} : \\ -h_j(\\mathbf{x}) \\leq -d_j \\right\\}\\). Since \\(h_j\\) is linear and convex, \\(-h_j\\) is convex. Thus both sets are convex. The constraint set of the problem can we written as:</p> \\[ X = X_{g_1} \\cap \\ldots X_{g_m} \\cap X_{h_1} \\cap \\ldots X_{h_l} \\cap X_{-h_1} \\cap \\ldots X_{-h_l}. \\] <p>Since intersection of convex sets is convex, \\(X\\) is a convex set. Since \\(f\\) is a convex function, the problem is a convex optimization problem.</p>"},{"location":"optimization/optimization_problem_formulation/#optimization-problem-classification","title":"Optimization Problem Classification","text":""},{"location":"optimization/optimization_problem_formulation/#linear-program","title":"Linear Program","text":"<p>Linear Program (LP) or linear optimization problem is where the functions are all linear and the variable domains are all continuous. LP is a convex optimization problem.</p>"},{"location":"optimization/optimization_problem_formulation/#nonlinear-program","title":"Nonlinear Program","text":"<p>Nonlinear Program (NLP) or nonlinear optimization problem is  where some of the functions are nonlinear and the variable domains are all continuous. NLPs can be an unconstrained optimizations where there are no constrains or simple bound constraints on the variables, or quadratic programming where objectives and constraints involve quadratic functions. NLPs can be convex optimziation problem.</p>"},{"location":"optimization/optimization_problem_formulation/#integer-program","title":"Integer Program","text":"<p>Integer Program (IP) or discrete optimization problem is  where the function is combination of linear and nonlinear with  discrete (some or all) variable domains. IPs can be:</p> <ol> <li> <p>Mixed Integer Linear Program (MILP)</p> <p>All linear functions and some variables are continuous and some are discrete</p> </li> <li> <p>Mixed Integer Nonlinear Program (MINLP)</p> <p>Some nonlinear functions and some variables are continuous and some are discrete.</p> </li> <li> <p>Mixed Integer Quadratic Program (MIQLP)</p> <p>Nonlinear functions are quadratic and some variables are continuous and some are discrete.</p> </li> </ol> <p>IPs are in general not convex optimization problem.</p>"},{"location":"optimization/perturbation_methods/","title":"Perturbation Methods","text":"<p>If we have a function, \\(f(\\mathbf{x})\\) of some vector variable, \\(\\mathbf{x}\\), then perturbing \\(\\mathbf{x}\\) slightly from its nominal value, \\(\\bar{\\mathbf{x}}\\), by an amount \\(\\delta \\mathbf{x}\\) will result a change in the function. Consider a standard Taylor series expansion of \\(f\\) around its nominal value:</p> \\[ f(\\mathbf{x}) \\approx \\left. f(\\mathbf{x}) \\right|_{\\mathbf{x} = \\bar{\\mathbf{x}}} + \\left. \\nabla^T f(\\mathbf{x}) \\right|_{\\mathbf{x} = \\bar{\\mathbf{x}}} \\left( \\mathbf{x} - \\bar{\\mathbf{x}} \\right) + \\frac{1}{2} \\left( \\mathbf{x} - \\bar{\\mathbf{x}} \\right)^T \\nabla^2 \\left. f(\\mathbf{x}) \\right|_{\\mathbf{x} = \\bar{\\mathbf{x}}} \\left(\\mathbf{x} - \\bar{\\mathbf{x}} \\right) + \\ldots. \\] <p>For convergence, we need \\(\\mathbf{x} - \\bar{\\mathbf{x}}\\) to be small in magnitude. Let \\(\\delta \\mathbf{x} = \\mathbf{x} - \\bar{\\mathbf{x}}\\) (or equivalently \\(\\mathbf{x} = \\bar{\\mathbf{x}} + \\delta \\mathbf{x}\\)). Substituting back and considering first-order approxmation yields to:</p> \\[ f(\\bar{\\mathbf{x}} + \\delta \\mathbf{x}) \\approx f(\\bar{\\mathbf{x}}) + \\left. \\frac{\\partial f(\\mathbf{x})}{\\partial \\mathbf{x}} \\right|_{\\mathbf{x} = \\bar{\\mathbf{x}}} \\delta \\mathbf{x}. \\] <p>https://stats.stackexchange.com/questions/5782/variance-of-a-function-of-one-random-variable</p>"},{"location":"optimization/integer_programming/discrete_optimization_models/","title":"Discrete Optimization Models","text":""},{"location":"optimization/integer_programming/discrete_optimization_models/#discrete-optimization-models","title":"Discrete Optimization Models","text":"<p>A discrete optimization or an integer programming model is an optimization problem where some of the optimization variables are required to take integer values:</p> \\[ \\begin{align} \\min \\quad&amp; f(\\mathbf{x}) \\\\  \\text{s.t.} \\quad&amp; g_i(\\mathbf{x}) \\leq b_i, \\ i = 1, \\ldots, m \\\\ &amp; \\mathbf{x} \\in \\mathbb{R}^{n - p} \\times \\mathbb{Z}^p. \\end{align} \\] <p>If the objective and constraints of a discrete optimization problem consists of linear functions then it is known as a linear discrete optimization problem or a mixed integer linear program:</p> \\[ \\begin{align} \\min \\quad&amp; \\mathbf{c}^T \\mathbf{x} \\\\  \\text{s.t.} \\quad&amp; \\mathbf{A} \\mathbf{x} \\geq \\mathbf{b} \\\\  &amp; \\mathbf{x} \\in \\mathbb{R}^{n - p} \\times \\mathbb{Z}^p. \\end{align} \\] <p>Discrete optimization involes optimization over a nonconvex set of feasible solutions.</p>"},{"location":"optimization/integer_programming/discrete_optimization_models/#binary-optimization-models","title":"Binary Optimization Models","text":"<p>If the discrete variables are required to be binary, then it is a binary optimization model:</p> \\[ \\begin{align} \\min \\quad&amp; f(\\mathbf{x}) \\\\ \\text{s.t.} \\quad&amp; g_i (\\mathbf{x}) \\leq b_i, \\ i = 1, \\ldots, m \\\\ &amp;\\mathbf{x} \\in \\mathbb{R}^{n - p} \\times \\left\\{ 0, 1 \\right\\}^p. \\end{align} \\]"},{"location":"optimization/integer_programming/discrete_optimization_models/#examples","title":"Examples","text":""},{"location":"optimization/integer_programming/discrete_optimization_models/#indivisible-decisions","title":"Indivisible Decisions","text":"<p>Given a set of supply ports and a set of demand ports with given supplies and demans, we are interested in formulating how many cargo ships to lease for each route (supply-demand pair) at minimum cost:</p> \\[ \\begin{align} \\min \\quad&amp; \\sum_{i \\in I} \\sum_{j \\in J} c_{ij} y_{ij} \\\\  \\text{s.t.} \\quad&amp; \\sum_{i \\in I} x_{ij} \\geq d_{j}, \\ \\forall j \\in J \\\\ &amp; \\sum_{j \\in J} x_{ij} \\leq s_i, \\ \\forall i \\in I \\\\  &amp; x_{ij} \\leq U y_{ij}, \\ \\forall i \\in I, j \\in J \\\\ &amp; x_{ij} \\geq 0, \\ y_{ij} \\in \\mathbb{Z}_{+}, \\ \\forall i \\in I, j \\in J. \\end{align} \\]"},{"location":"optimization/integer_programming/discrete_optimization_models/#yesno-decisions","title":"Yes/No Decisions","text":"<p>Given a set of projects with their returns, costs, and an overall budget, we would like to decide whether to invest in a project or not to maximize returns:</p> \\[ \\begin{align} \\max \\quad&amp; \\sum^{n}_{j = 1} r_j x_j \\\\  \\text{s.t.} \\quad&amp; \\sum^n_{j = 1} c_j x_j \\leq B \\\\  &amp; x_j \\in \\left\\{ 0, 1 \\right\\}, \\ \\forall j = 1, \\ldots, n. \\end{align} \\]"},{"location":"optimization/integer_programming/discrete_optimization_models/#logical-conditions","title":"Logical Conditions","text":"<p>A logical condition of investing in project 1 results in a must in investing in projects 2 and 3:</p> \\[ \\begin{align} \\max \\quad&amp; \\sum^n_{j = 1} r_j x_j \\\\ \\text{s.t.} \\quad&amp; \\sum^n_{j = 1} c_j x_j \\leq B \\\\ &amp;x_1 \\leq x_2 \\\\  &amp;x_1 \\leq x_3 \\\\  &amp;x_j \\in \\left\\{0, 1 \\right\\}, \\ j = 1, \\ldots, n. \\end{align} \\]"},{"location":"optimization/integer_programming/modelling_logical_relations/","title":"Modelling Logical Relations","text":""},{"location":"optimization/integer_programming/modelling_logical_relations/#modelling-with-binary-variables","title":"Modelling with Binary Variables","text":"<p>Consider the following investment example:</p> <ol> <li>We would like to invest in 5 assets, labelled \\(\\left\\{ 1, 2, 3, 4, 5 \\right\\}\\).</li> <li>We can invest only nonnegative amounts, and have a total budget of $1000 dollars. </li> </ol> <p>Let \\(x_j\\) to denote the amount invested in asset \\(j\\). Then we can formulate an optimization model:</p> \\[ 0 \\leq x_j, \\ \\forall j = 1, \\ldots, 5, \\ \\sum^5_{j = 1} x_j \\leq 1000. \\] <p>Let \\(y_j\\) be a binary variable which will take a value \\(1\\) if \\(x_j &gt; 0\\). Then we have:</p> \\[ 0 \\leq x_j \\leq 1000 y_j, \\ y_j \\in \\left\\{0, 1 \\right\\}, \\ \\forall j = 1, \\ldots, 5. \\]"},{"location":"optimization/integer_programming/modelling_logical_relations/#or-constraint","title":"OR Constraint","text":"<p>Consider a case where we have to invest at least $100 in asset 1 or asset 5. Logically, this constraint is:</p> \\[ (x_1 \\geq 100) \\lor (x_5 \\geq 100). \\] <p>Algebraically, we can write this as:</p> \\[ x_1 \\geq 100 y_1, \\ x_5 \\geq 100 y_2, \\ y_1 + y_2 \\geq 1. \\]"},{"location":"optimization/integer_programming/modelling_logical_relations/#xor-constraint","title":"XOR Constraint","text":"<p>Consider a case where we have to invest at least $100 in asset 1 or asset 5 but not both.  Logically, this constraint is:</p> \\[ (x_1 \\geq 100) \\oplus (x_5 \\geq 100). \\] <p>Algebraically, we can write this as:</p> \\[ x_1 \\geq 100 y_1, \\ x_5 \\geq 100 y_2, \\ y_1 + y_2 = 1. \\]"},{"location":"optimization/integer_programming/modelling_logical_relations/#implications","title":"Implications","text":"<p>Consider a case where if we invest $100 or more in asset 1, then we must invest $100 or more in asset 5.  Logically, this constraint is:</p> \\[ (x_1 \\geq 100) \\Rightarrow (x_5 \\geq 100). \\] <p>Let \\(z\\) be a binary variable that gets set to 1 if \\(x_1 \\geq 100\\). Algebraically, we can write this as:</p> \\[ z \\in \\left\\{ 0, 1\\right\\}, \\ z \\geq \\frac{(x_1 - (100 - \\epsilon))}{(900 + \\epsilon)}, \\ 100z \\leq x_5, \\] <p>where \\(\\epsilon\\) is a small positive number.</p>"},{"location":"optimization/integer_programming/modelling_logical_relations/#examples","title":"Examples","text":"<ol> <li> <p>If \\(x_1 &gt; 0\\), then \\(x_2 = 0\\) or \\(x_3 = 0\\). Constraint:</p> \\[ y_2 + y_3 \\leq 2 - y_1. \\] </li> <li> <p>If \\(x_1 &gt; 0\\) or \\(x_2 &gt; 0\\), then \\(x_5 = 0\\). Constraint:</p> \\[ y_5 \\leq 1 - y_1, y_5 \\leq 1 - y_2. \\] </li> </ol>"},{"location":"optimization/integer_programming/modelling_nonconvex_functions/","title":"Modelling Nonconvex Functions","text":""},{"location":"optimization/integer_programming/modelling_nonconvex_functions/#nonconvex-functions","title":"Nonconvex Functions","text":"<p>By definition, a function is nonconvex if it is not convex. Nonconvex functions can be modelled using mixed integer linear constraints. We are interested in the following class of problems with form:</p> \\[ \\begin{align} \\min \\quad&amp; \\sum^n_{j = 1} f_j (x_j) \\\\  \\text{s.t.} \\quad&amp; \\mathbf{A} \\mathbf{x} \\geq \\mathbf{b} \\\\ &amp; 0 \\leq x_j \\leq U_j, \\ j = 1, \\ldots, n, \\end{align} \\] <p>where:</p> <ol> <li>The \\(n\\) optimization variables are bounded.</li> <li>The objective function is separable, i.e., sum of univariate functions.</li> <li>Each of the separable functions is piecewise linear (PWL).</li> <li>The objective function is nonconvex, nonlinear and continuous.</li> </ol>"},{"location":"optimization/integer_programming/modelling_nonconvex_functions/#piecewise-linear-function","title":"Piecewise Linear Function","text":"<p>Refer to Wikipedia for more details.</p> <p>For simplicity, consider one univariate PWL nonconvex function \\(f(x)\\) with \\(K\\) pieces. Figure 1 shows a PWL function (on a bounded interval) of form:</p> \\[ f(x) = f(\\ell_k) + c_k (x - \\ell_k), \\ \\ell_k \\leq x \\leq \\ell_{k + 1}, k = 0, \\ldots, K - 1. \\] <p> </p> Figure 1: PWL function <p>For \\(k = 0, \\ldots, K - 1\\), we have:</p> <ol> <li>The function value at breakpoint, \\(f(\\ell_k)\\).</li> <li>The slope, \\(c_k\\).</li> <li>The breakpoint, \\(\\ell_{k}\\).</li> </ol>"},{"location":"optimization/integer_programming/modelling_nonconvex_functions/#modelling-approach-1","title":"Modelling Approach 1","text":"<p>We can introduce new variables \\(u_0, \\ldots, u_{K - 1}\\) and \\(y_0, \\ldots, y_{K - 1}\\) and constraints:</p> \\[ \\begin{align} x = &amp;\\sum^{K - 1}_{k = 0} u_k \\\\ &amp;\\ell_k y_k \\leq u_k \\leq \\ell_{k + 1} y_k, \\ k = 0, \\ldots, K - 1 \\\\ &amp;\\sum^{K - 1}_{k = 0} y_k = 1 \\\\ &amp;y_l \\in \\left\\{ 0, 1\\right\\}, \\ k = 0, \\ldots, K - 1, \\end{align} \\] <p>and \\(f(x)\\) can be replaced by \\(\\sum^{K - 1}_{k = 0} \\left[f(\\ell_k) + c_k (u_k - \\ell_k) \\right]y_k\\). However, this is not the correct approach because it is nonlinear. The correct approach to model function \\(f(x)\\) is:</p> \\[ \\sum^{K - 1}_{k = 0} f(\\ell_k) y_k + c_k \\left( u_k - \\ell_k \\right) + c_k \\ell_k \\left( 1 - y_k \\right), \\] <p>or after some simplifications:</p> \\[ f(x) = \\sum^{K - 1}_{k = 0} f(\\ell_k) y_k + c_k \\left( u_k - \\ell_k y_k \\right). \\] <p>This is correct formulation of the function \\(f\\) because on intervals that do not contain \\(x\\) indicator variable \\(y_k = 0\\) which will also force \\(u_k = 0\\) and hence the summation terms become:</p> \\[ f(\\ell_k) y_k + c_k (u_k - \\ell_k y_k) = f(\\ell_k) \\cdot 0 + c_k (0 - \\ell_k \\cdot 0) = 0. \\] <p>On the other hand, for interval \\(\\left[ \\ell_k, \\ell_{k + 1} \\right]\\) which contains \\(x\\), we will have \\(y_k = 1\\) and \\(x = u_k \\in \\left[ \\ell_k, \\ell_{k + 1} \\right]\\) hence the appropriate summation term will become:</p> \\[ \\begin{align} f(\\ell_k) y_k + c_k (u_k - \\ell_k y_k) &amp;=  f(\\ell_k) \\cdot 1 + c_k (u_k - \\ell_k \\cdot 1) \\\\ &amp;= f(\\ell_k) + c_k (u_k - \\ell_k) \\\\  &amp;= f(\\ell_k) + c_k (x - \\ell_k), \\end{align} \\] <p>which is the exact definition of \\(f(x)\\).</p>"},{"location":"optimization/integer_programming/modelling_nonconvex_functions/#modelling-approach-2","title":"Modelling Approach 2","text":"<p>We can introduce new variables \\(\\lambda_0, \\ldots, \\lambda_K\\) and \\(y_0, \\ldots, y_{K - 1}\\) and constraints:</p> \\[ \\begin{align} x &amp;= \\sum^K_{k = 0} \\lambda_k \\ell_k, \\ \\sum^{K}_{k = 0} \\lambda_k = 1, \\ \\sum^{K - 1}_{k = 0} y_k = 1 \\\\ &amp;y_k \\in \\left\\{0 ,1 \\right\\}, \\ k = 0, \\ldots, K - 1, \\ \\lambda_k \\geq 0, k = 0, \\ldots, K \\\\ &amp;\\lambda_0 \\leq y_0, \\ \\lambda_k \\leq y_{k - 1} + y_k, \\ k = 1, \\ldots, K - 1, \\ \\lambda_K \\leq y_{K - 1}, \\end{align} \\] <p>and \\(f(x)\\) can be replaced by \\(\\sum^K_{k = 0} f(\\ell_k) \\lambda_k\\).</p>"},{"location":"optimization/integer_programming/modelling_nonconvex_functions/#example","title":"Example","text":"<p>Consider a problem where we are interested in buying supplies from a set of different vendors (offering quantity discounts) to satisfy a total need. The problem can be formualted as:</p> \\[ \\begin{align} \\min \\quad&amp; \\sum^n_{j = 1} f_j (x_j) \\\\ \\text{s.t.} \\quad&amp; \\mathbf{A} \\mathbf{x} \\geq \\mathbf{b} \\\\ &amp; 0 \\leq x_j \\leq U_j, \\ j = 1, \\ldots, n, \\end{align} \\] <p>where \\(x_j\\) is the amount to be purchased from \\(j\\)'th vendor and each \\(f_j\\) is a PWL function:</p> \\[ \\begin{align} &amp; f_j (x_j) =  \\begin{cases}     p_j x_j, &amp; \\text{if }  0 \\leq x_j \\leq L_j \\\\     p_j L_j + q_j (x_j - L_j), &amp; \\text{if } L_j \\leq x_j \\leq U_j. \\end{cases} \\label{a} \\\\ \\end{align} \\]"},{"location":"optimization/integer_programming/modelling_nonconvex_functions/#modelling-approach-1_1","title":"Modelling Approach 1","text":"\\[ \\begin{align} \\min \\quad&amp; \\sum^n_{j = 1} \\left[ p_j u_j + p_j L_j y_j + q_j (v_j - L_j) \\right] \\\\ \\text{s.t.} \\quad&amp; \\mathbf{A} \\mathbf{x} \\geq \\mathbf{b} \\\\ &amp; 0 \\leq x_j \\leq U_j, \\ j = 1, \\ldots, n \\\\ &amp; x_j = u_j + v_j, \\ j = 1, \\ldots, n \\\\ &amp; 0 \\leq u_j \\leq L_j (1 - y_j), \\ j = 1, \\ldots, n \\\\ &amp; L_j y_j \\leq v_j \\leq U_j y_j, \\ j = 1, \\ldots, n \\\\ &amp; y_j \\in \\left\\{ 0, 1 \\right\\}, \\ j = 1, \\ldots, n. \\end{align} \\]"},{"location":"optimization/integer_programming/modelling_nonconvex_functions/#modelling-approach-2_1","title":"Modelling Approach 2","text":"\\[ \\begin{align} \\min \\quad&amp; \\sum^n_{j = 1} \\left[ (0) \\lambda_{j, 1} + (p_j L_j) \\lambda_{j, 2} + \\left(p_j + L_j + q_j (U_j - L_j) \\right) \\lambda_{j, 3} \\right] \\\\  \\text{s.t.} \\quad&amp; A x \\geq b, \\ 0 \\leq x_j \\leq U_j, \\ j = 1, \\ldots, n \\\\ &amp; x_j = (0) \\lambda_{j, 1} + (L_j) \\lambda_{j, 2} + (U_j) \\lambda_{j, 3}, \\ j = 1, \\ldots, n \\\\  &amp; \\lambda_{j, 1} + \\lambda_{j, 2} + \\lambda_{j, 3} = 1, \\ j = 1, \\ldots, n, \\ \\lambda \\geq 0 \\\\  &amp; y_{j, 1} + y_{j, 2} = 1, \\ j = 1, \\ldots, n, \\ y \\in \\left\\{0, 1 \\right\\} \\end{align} \\]"},{"location":"optimization/integer_programming/modelling_nonconvex_functions/#generalization","title":"Generalization","text":"<p>Assuming that we have \\(n\\) univariate PWL functions \\(f_j(x_j)\\), such that function \\(f_j(x_j)\\) has \\(K_j\\) pieces, then using the same approach we can model it as:</p> \\[ \\begin{align} &amp;f_j(x_j) = \\sum^{K_j - 1}_{k = 0} f_j \\left( \\ell^{(j)}_k \\right) y^{(j)}_k + c^{(j)}_{j} \\left( u^{(j)}_k - \\ell^{(j)}_{k} y^{(j)}_k \\right) \\\\  &amp;x_j = \\sum^{K_j - 1}_{k = 0} u^{(j)}_k \\\\  &amp; \\ell^{(j)}_k y^{(j)}_k \\leq u^{(j)}_k \\leq \\ell^{(j)}_{k + 1} y^{(j)}_{k}, \\ \\forall k = 0, \\ldots, K_{j - 1} \\\\ \\end{align} \\]"},{"location":"optimization/integer_programming/modelling_nonconvex_sets/","title":"Modelling Nonconvex Sets","text":""},{"location":"optimization/integer_programming/modelling_nonconvex_sets/#discrete-variables","title":"Discrete Variables","text":"<p>A discrete variable has a domain of the form:</p> \\[ x \\in \\left\\{a_1, a_2, \\ldots, a_K \\right\\}. \\] <p>If \\(a_1, a_2, \\ldots, a_K\\) are contiguous integers, we can model as:</p> \\[ a_1 \\leq x \\leq a_K, \\ x \\in \\mathbb{Z}. \\] <p>Otherwise:</p> \\[ x = \\sum^K_{k = 1} a_k y_k, \\ \\sum^K_{k = 1} y_k = 1, \\ y_k \\in \\left\\{ 0, 1\\right\\}, \\ \\forall k = 1, \\ldots, K. \\]"},{"location":"optimization/integer_programming/modelling_nonconvex_sets/#semicontinuous-variables","title":"Semicontinuous Variables","text":"<p>A Semicontinuous variable has a domain of the form:</p> \\[ x \\in \\left[ \\ell_1, u_1 \\right] \\cup \\left[ \\ell_2, u_2 \\right] \\cup \\ldots \\cup \\left[ \\ell_K, u_K \\right], \\] <p>where \\(\\ell_1 \\leq u_1 \\leq \\ell_2 \\leq u_2 \\leq \\ldots \\leq \\ell_k \\leq u_K\\). One modelling approach for this system is:</p> \\[ \\begin{align} &amp;x = \\sum^K_{k = 1} z_k, \\ \\ell_k y_k \\leq z_k \\leq u_k y_k \\ \\forall k = 1, \\ldots, K \\\\ &amp;\\sum^K_{k = 1} y_k = 1, \\ y_k \\in \\left\\{ 0, 1\\right\\}, \\forall k = 1, \\ldots, K. \\end{align} \\]"},{"location":"optimization/integer_programming/modelling_nonconvex_sets/#union-of-polytopes","title":"Union of Polytopes","text":"<p>Suppose we require that \\(\\mathbf{x}\\) satisfies one of the following \\(K\\) systems of inequalities: \\(\\mathbf{A}_k \\mathbf{x} \\leq \\mathbf{b}_k\\) for \\(k = 1, \\ldots, K\\). Suppose that each system defines a polytope, i.e., a bounded polyhedron. The system can be formulated as:</p> \\[ \\mathbf{A}_k \\mathbf{u}^k \\leq \\mathbf{b}_k y_k, \\ \\mathbf{x} = \\sum^K_{k = 1} \\mathbf{u}^k, \\ \\sum^K_{k = 1} y_k = 1, \\ y_k \\in \\left\\{ 0, 1 \\right\\}, \\forall k = 1, \\ldots, K. \\]"},{"location":"optimization/integer_programming/modelling_nonconvex_sets/#examples","title":"Examples","text":""},{"location":"optimization/integer_programming/modelling_nonconvex_sets/#example-1","title":"Example 1","text":"<p>Consider the union of the following two sets:</p> \\[ \\begin{align} \\left( \\begin{array}{c} x_1 + x_2 \\leq 2 \\\\ -x_1 \\leq 0, \\ -x_2 \\leq 0 \\end{array} \\right) \\cup \\left( \\begin{array}{c} -x_1 \\leq -1, \\ x_1 \\leq 3 \\\\  -x_2 \\leq 0, x_2 \\leq 2 \\end{array} \\right). \\end{align} \\] <p>This set is illustrated in Figure 1.</p> <p> </p> Figure 1 Example 1 <p>The problem is in 2D and we have two possibe sets. The first set describes the polytope on the left and the second set describes the polytope on the right. Define:</p> \\[ \\begin{align} &amp;x_1 = u^1_1 + u^2_1 \\\\  &amp;x_2 = u^1_2 + u^2_2, \\end{align} \\] <p>where \\(u^j\\) indicates whether \\(x\\) is in the \\(j\\)'th set. The constraints in the first set can be written as:</p> \\[ \\begin{align} &amp;u^1_1 + u^1_2 \\leq 2 y_1, \\ -u^1_1 \\leq 0, \\ -u^1_2 \\leq 0. \\\\ \\end{align} \\] <p>Similarly, the constraints in the second set can be written as:</p> \\[ \\begin{align} -u^2_1 \\leq -1 y_2, \\ -u^2_1 \\leq 3y_2, \\ -u^2_2 \\leq 0, \\ u^2_2 \\leq 2y_2, \\\\ \\end{align} \\] <p>with: </p> \\[ y_1 + y_2 = 1,  \\ y_1, y_2 \\in \\left\\{ 0, 1\\right\\}. \\]"},{"location":"optimization/integer_programming/modelling_nonconvex_sets/#bounds","title":"Bounds","text":"<p>Note that:</p> <ol> <li>We've been making use of the bounds on the variables to develop these formulations.</li> <li>In general, it is not possible to develop correct mixed integer linear formulations without bounds on variables.</li> <li>If there are no bounds, we will impose large artificial numbers (big-M) as variable bounds.</li> </ol>"},{"location":"optimization/integer_programming/modelling_nonconvex_sets/#example-2","title":"Example 2","text":"<p>Consider a nonconvex set:</p> \\[ X = \\left\\{ \\mathbf{x} \\in \\mathbb{R}^n \\ : \\ ||\\mathbf{x}||_0 \\leq k \\right\\}, \\] <p>where \\(k\\) is an integer between \\(0\\) and \\(n\\). Here, \\(||\\mathbf{x}||_0\\) is the number of nonzero components of \\(\\mathbf{x}\\). This set is not bounded. We will impose bounds, \\(-M \\leq x_j \\leq M\\) for all \\(j = 1, \\ldots, n\\) where \\(M\\) is an arbitrary large number. Then, a mixed integer linear formulation is:</p> \\[ -M y_j \\leq x_j \\leq M y_j, \\ \\sum^n_{j = 1} y_j \\leq k, \\ y_j \\in \\left\\{ 0, 1\\right\\}, \\ \\forall j = 1, \\ldots, n. \\]"},{"location":"optimization/linear_programming/algebraic_aspects/","title":"Algrebraic Aspects","text":""},{"location":"optimization/linear_programming/algebraic_aspects/#contraint-concepts","title":"Contraint Concepts","text":"<ol> <li> <p>Active Contraints</p> <p>A linear constraint that is satisfied as equality at a given point is said to be active or binding at that point. Otherwise, if an inequality constraint is satisfied as strict inequality at a point, it is called inactive.</p> </li> <li> <p>Linear Independent Constraints</p> <p>If the normal direction of two or more linear constraints are linearly independent, then these constraints are called linearly independent.</p> </li> <li> <p>Linearly Independent Active Constraints</p> <p>Active constraints that are linearly independent.</p> </li> </ol>"},{"location":"optimization/linear_programming/algebraic_aspects/#standard-form-on-linear-programming","title":"Standard Form on Linear Programming","text":"<p>A standard form linear program consists of equality constraints and nonnegative contraints on all optimization variables. It can be written as:</p> \\[ \\begin{align} \\min \\quad&amp; \\mathbf{c}^T \\mathbf{x} \\\\ \\text{s.t.} \\quad&amp; \\mathbf{A} \\mathbf{x} = \\mathbf{b}\\\\ \\quad&amp; \\mathbf{x} \\geq 0, \\end{align} \\] <p>where \\(\\mathbf{x} \\in \\mathbb{R}^n\\), \\(\\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\), and the \\(m\\) equality constraints are linearly independent.</p> <p>Every LP can be written equivalently in the standard form. For example:</p> <ol> <li> <p>Objective function conversion</p> <p>\\(\\max \\mathbf{c}^T \\mathbf{x} \\longrightarrow -\\min -\\mathbf{c}^T \\mathbf{x}\\)</p> </li> <li> <p>Inequality constraint conversion</p> <p>\\(\\mathbf{a}^T_i \\mathbf{x} \\geq b_i \\longrightarrow \\mathbf{a}^T_i \\mathbf{x} - s_i = b_i, \\ s_i \\geq 0\\)</p> <p>\\(\\mathbf{a}^T_i \\mathbf{x} \\leq b_i \\longrightarrow \\mathbf{a}^T_i \\mathbf{x} + s_i = b_i, \\ s_i \\geq 0\\)</p> </li> <li> <p>Negativity conversion</p> <p>\\(\\mathbf{x}_j \\leq 0 \\longrightarrow \\mathbf{x}'_j \\geq 0\\), by replacing \\(\\mathbf{x}_j\\) with \\(-\\mathbf{x}'_j\\)</p> </li> <li> <p>Free variable conversion</p> <p>\\(\\mathbf{x}_j\\) is a free variable \\(\\longrightarrow\\) replace \\(\\mathbf{x}_j = \\mathbf{x}^+_j - \\mathbf{x}^-_j, \\ \\mathbf{x}^+_j \\geq 0, \\mathbf{x}^-_j \\geq 0\\)</p> </li> </ol>"},{"location":"optimization/linear_programming/algebraic_aspects/#example","title":"Example","text":"<p>Consider the following LP as another example:</p> \\[ \\begin{align} \\max \\quad&amp; x_1 - x_2 \\\\ \\text{s.t.} \\quad&amp; x_1 + x_2 \\leq 2 \\\\ \\quad&amp; 2x_1 - x_2 \\geq 3 \\\\ \\quad&amp; x_1 \\leq 0, \\ x_2 \\ \\text{free}. \\end{align} \\] <p>First, we can convert the inequality constraints into equality constraints:</p> \\[ \\begin{align} -\\min \\quad&amp; -x_1 + x_2 \\\\ \\text{s.t.} \\quad&amp; x_1 + x_2 + s_1 = 2, \\ s_1 \\geq 0 \\\\ \\quad&amp; 2x_1 - x_2 - s_2 = 3, \\ s_2 \\geq 0 \\\\ \\quad&amp; x_1 \\leq 0, \\ x_2 \\ \\text{free}. \\end{align} \\] <p>Then we convert the free variable:</p> \\[ \\begin{align} -\\min \\quad&amp; x_1 + x_2 - x_3 \\\\ \\text{s.t.} \\quad&amp; -x_1 + x_2 - x_3 + s_1 = 2 \\\\ \\quad&amp; -2x_1 - x_2  + x_3 - s_2 = 3 \\\\ \\quad&amp; x_1, x_2, x_3, s_1, s_2 \\geq 0. \\end{align} \\]"},{"location":"optimization/linear_programming/algebraic_aspects/#basic-solution","title":"Basic Solution","text":"<p>The unique solution of \\(n\\) linearly independent active constraints in \\(\\mathbb{R}^n\\) is called basic solution. A basic solution that is feasible is called basic feasible solution. For example, consider the LP shown in Figure 1:</p> <ol> <li>\\(\\mathbf{x}^1, \\mathbf{x}^2, \\mathbf{x}^3, \\mathbf{x}^4\\) are basic feasible solutions.</li> <li>\\(\\mathbf{x}^5, \\mathbf{x}^6\\) are basic solutions but not feasible.</li> </ol> <p> </p> Figure 1 Basic solution of a polyhedron <p>Basic feasible solutions are extreme points of the polyhedron and vice versa. In order words, basic feasible solution is an algebraic description of an extreme point.</p> <p>For a standard form LP, we have \\(m\\) linearly independent active constraints. We need \\(n - m\\) additional linearly independent active constraints which can be obtained from the nonnegative constraints, \\(\\mathbf{x} \\geq 0\\). </p> <p>To find basic solutions in standard form LP:</p> <ol> <li> <p>Since \\(\\mathbf{A} \\mathbf{x} = \\mathbf{b}\\) has \\(m\\) linearly independent rows, there are also \\(m\\) linearly independent columns. Choose \\(m\\) such linearly independent columns and denote the corresponding matrix as basis matrix, \\(\\mathbf{B} \\in \\mathbb{R}^{m \\times m}\\). The corresponding \\(m \\mathbf{x}_j\\)'s are denoted as basic variables, \\(\\mathbf{x}_B\\).</p> </li> <li> <p>Partition \\(\\mathbf{A}\\) as \\(\\mathbf{A} = \\left[\\mathbf{B}, \\mathbf{N} \\right]\\), where \\(\\mathbf{N}\\) is \\(m \\times (n - m)\\). The corresponding \\((n - m) \\mathbf{x}_j\\)'s are denoted as \\(\\mathbf{x}_N\\), nonbasic variables.</p> </li> <li> <p>Choose \\(\\mathbf{x}_j = 0\\) for all \\(i\\) corresponds to the columns in \\(\\mathbf{N}\\), such that \\(\\mathbf{x}_N = 0\\). We can write the \\(n\\) active constraints as:</p> \\[ \\begin{align} \\left[ \\begin{array}{cc} \\mathbf{B} &amp; \\mathbf{N} \\\\  \\mathbf{0} &amp; \\mathbf{I} \\end{array} \\right] \\left[ \\begin{array}{c} \\mathbf{x}_B\\\\  \\mathbf{x}_N \\end{array} \\right] = \\left[ \\begin{array}{c} \\mathbf{b} \\\\ \\mathbf{0} \\end{array} \\right] \\end{align} \\] <p>Since \\(\\mathbf{B}\\) is an invertible matrix, and \\(\\mathbf{I}\\) is an identity matrix, the entire matrix is invertible. Therefore, \\(n\\) active constraints are linearly independent and has a unique solution, which is the basic solution. </p> </li> <li> <p>The solution can be computed as:</p> </li> </ol> \\[ \\begin{align} &amp;\\mathbf{x}_B = \\mathbf{B}^{-1} \\mathbf{b} \\\\ &amp;\\mathbf{x}_N = \\mathbf{0}. \\end{align} \\] <p>Not every LP has a basic feasible solution, i.e., not every polyhedron has an extreme point (e.g., a line or a halfspace). A polyhedron \\(P\\) has an extreme point if and only if it does not contain a line. A feasible standard form LP always has a basic feasible solution. </p> <p>If a LP has a finite optimal solution, then an optimal solution is a basic feasible solution. Note that this does not mean that all optimal solutions must be basic feasible solution. Hence, for LPs, we only need to look for basic feasible solutions and select the solution with the minimum objective cost.</p>"},{"location":"optimization/linear_programming/algebraic_aspects/#example_1","title":"Example","text":"<p>Consider a standard form LP:</p> \\[ \\begin{align} \\min \\quad&amp; x_1 + x_2 - x_3 \\\\ \\text{s.t.} \\quad&amp; -x_1 + x_2 - x_3 + x_4 = 2 \\\\ \\quad&amp; -2x_1 + x_2 + x_3 - x_5 = 3 \\\\ \\quad&amp; x_1, x_2, x_3, x_4, x_5 \\geq 0. \\end{align} \\] <p>The objective function can be written as \\(\\mathbf{c}^T \\mathbf{x}\\), where \\(\\mathbf{c} = \\left[1, 1, -1, 0, 0 \\right]^T\\), and the equality constraints can be written as \\(\\mathbf{A} \\mathbf{x} = \\mathbf{b}\\) with:</p> \\[ \\mathbf{A} =  \\left[ \\begin{array}{ccccc} -1 &amp; 1 &amp; -1 &amp; 1 &amp; 0 \\\\ -2 &amp; 1 &amp; 1 &amp; 0 &amp; -1 \\end{array} \\right], \\quad \\mathbf{b} =  \\left[ \\begin{array}{c} 2 \\\\ 3 \\end{array} \\right]. \\] <p>We can choose a basis matrix \\(\\mathbf{B}\\) as the first two columns of \\(\\mathbf{A}\\):</p> \\[ \\mathbf{B} = \\left[ \\mathbf{A}_1 \\ \\mathbf{A}_2 \\right] = \\left[ \\begin{array}{cc} -1 &amp; 1 \\\\ -2 &amp; 1 \\end{array} \\right], \\] <p>which corresponds to \\(\\mathbf{x}_B = \\left[ x_1, x_2 \\right]^T\\). \\(\\mathbf{N}\\) will be:</p> \\[ \\mathbf{N} = \\left[ \\begin{array}{ccc} -1 &amp; 1 &amp; 0 \\\\ 1 &amp; 0 &amp; -1 \\end{array} \\right], \\] <p>which corresponds to \\(\\mathbf{x}_N = \\left[ x_3, x_4, x_5 \\right]^T\\). The solution is then:</p> \\[ \\begin{align} \\mathbf{x}_B &amp;= \\mathbf{B}^{-1} \\mathbf{b} =  \\left[ \\begin{array}{c} -1 \\\\ 1 \\end{array} \\right] \\\\ \\mathbf{x}_N &amp;= \\left[ \\begin{array}{c} 0 \\\\ 0 \\\\ 0 \\end{array} \\right]. \\\\ \\end{align} \\] <p>The basic solution is \\(\\mathbf{x} = \\left[-1, 1, 0, 0, 0 \\right]^T\\) which is not feasible since \\(x_1 &lt; 0\\). Choosing the third and the fourth column yields to a basic feasible solution \\(\\mathbf{x} = \\left[ 0, 0, 3, 5, 0 \\right]\\).</p>"},{"location":"optimization/linear_programming/column_and_constraint_generation/","title":"Column and Constraint Generation","text":""},{"location":"optimization/linear_programming/column_and_constraint_generation/#column-generation","title":"Column Generation","text":"<p>Consider a master problem:</p> \\[ \\begin{align} (MP) \\quad \\min \\quad&amp; \\sum^N_{j = 1} c_j x_j \\\\ \\quad\\text{s.t.} \\quad&amp; \\sum^N_{j = 1} \\mathbf{A}_j x_j = \\mathbf{b} \\\\ &amp; x_j \\geq 0, \\quad \\forall i = 1, \\ldots, N. \\end{align} \\] <p>The column generation algorithm is useful when \\(N\\) is extremely large number.</p> <p>Algorithm: Column Generation</p> <p>\\(\\quad\\) 1. Pick a subset of columns \\(\\left\\{ \\mathbf{A}_j \\right\\}\\) and variables \\(x_j\\)'s for \\(j \\in I\\), where \\(I\\) is a subset of \\(\\left\\{1, 2, \\ldots, N \\right\\}\\).  \\(\\quad\\) 2. Solve the restricted master problem: \\(\\begin{align} (RMP) \\quad \\min \\quad&amp; \\sum_{j \\in I} c_j x_j \\\\ \\quad \\text{s.t.} \\quad&amp; \\sum_{j \\in I} \\mathbf{A}_j x_j = \\mathbf{b} \\\\ &amp;x_j \\geq 0, \\quad \\forall j \\in I. \\end{align}\\).  \\(\\quad\\quad\\) Denote the optimal solution of \\((RMP)\\) as \\(\\hat{\\mathbf{x}}_I\\).  \\(\\quad\\) 3. Pricing subproblem: Compute all the reduced  costs for \\(\\hat{\\mathbf{x}}\\) and decide if \\(\\hat{\\mathbf{x}}\\) is optimal for \\((MP)\\): \\(\\begin{align} w = \\min_{j = 1, \\ldots, N} \\left\\{ c_j - \\mathbf{c}^T_B \\mathbf{B}^{-1} \\mathbf{A}_k \\right\\}, \\end{align}\\) \\(\\quad\\quad\\) where \\(\\mathbf{B}\\) is the optimal basis obtained from solving the \\((RMP)\\). There are two possibilities for \\(w\\):  \\(\\quad\\quad\\) (a) If \\(w \\geq 0\\), then all the reduced costs are nonnegative, therefore \\(\\hat{\\mathbf{x}}\\) is optimal for \\((MP)\\). Terminate.  \\(\\quad\\quad\\) (b) If \\(w &lt; 0\\), pick the column \\(j\\) with the minimum reduced cost, and add \\(\\mathbf{A}_j\\) to the subset of columns, i.e., \\(I \\leftarrow I \\cup \\left\\{ j \\right\\}\\).  \\(\\quad\\quad\\quad\\) Repeat from Step (2).</p> <p>Remarks on Step 2:</p> <ol> <li> <p>Since (RMP) has all the constraints in the master problem \\((MP)\\), the optimal solution \\(\\hat{\\mathbf{x}}_I\\) of \\((RMP)\\) satisfies all the demand. Moreover, \\(\\hat{\\mathbf{x}}_I\\) only contains components \\(x_j\\) for \\(j \\in I\\). We can set all the other components \\(x_j = 0\\) for \\(j \\notin I\\). This provides us a feasible solution, \\(\\hat{\\mathbf{x}} = \\left( \\hat{\\mathbf{x}}_I, 0 \\right)\\) , to \\((MP)\\).</p> </li> <li> <p>\\(\\hat{\\mathbf{x}}\\) is a basic feasible solution of \\((MP)\\). Consider a case where simplex method was used to solve \\((RMP)\\). When the simplex method terminates on \\((RMP)\\), it finds an optimal solution \\(\\hat{\\mathbf{x}}_I\\) of \\((RMP)\\) and the associated basis matrix \\(\\hat{\\mathbf{B}}\\). This basis matrix has the same number of rows as the constraint matrix \\(\\mathbf{A}\\) and it is invertible, therefore, \\(\\hat{\\mathbf{B}}\\) is also a basis matrix for \\((MP)\\).  </p> </li> </ol>"},{"location":"optimization/linear_programming/dantzig_wolfe_decomposition/","title":"Dantzig-Wolfe Decomposition","text":""},{"location":"optimization/linear_programming/dantzig_wolfe_decomposition/#dantzig-wolfe-decomposition","title":"Dantzig-Wolfe Decomposition","text":""},{"location":"optimization/linear_programming/dantzig_wolfe_decomposition/#problem-formulation","title":"Problem Formulation","text":"<p>The Dantzig-Wolfe decomposition is designed to deal with large scale LPs with special structures. Consider the following LP:</p> \\[ \\begin{align} (LP) \\quad \\min \\quad&amp; \\mathbf{c}^T \\mathbf{x} \\\\ \\text{s.t.} \\quad&amp; \\mathbf{D} \\mathbf{x} = \\mathbf{b}_0 \\\\ \\quad&amp; \\mathbf{F} \\mathbf{x} = \\mathbf{b} \\\\ \\quad&amp; \\mathbf{x} \\geq 0, \\end{align} \\] <p>where \\(\\mathbf{D} \\in \\mathbb{R}^{m_1 \\times n}\\) and \\(\\mathbf{F} \\in \\mathbb{R}^{m_2 \\times n}\\).  In general, the first set of equality constraints are called the coupling constraints. The second set of equality constraints are independent. </p>"},{"location":"optimization/linear_programming/dantzig_wolfe_decomposition/#constraint-separation","title":"Constraint Separation","text":"<p>Suppose that the first set \\(\\mathbf{D} \\mathbf{x} = \\mathbf{b}_0\\) is harder to deal with. Define a polyhedron \\(P\\):</p> \\[ P = \\left\\{ \\mathbf{x} \\ | \\ \\mathbf{F} \\mathbf{x} = \\mathbf{b}, \\ \\mathbf{x} \\geq 0 \\right\\}. \\] <p>Then the original LP can be written as:</p> \\[ \\begin{align} (LP_2) \\quad \\min \\quad&amp; \\mathbf{c}^T \\mathbf{x} \\\\ \\text{s.t.} \\quad&amp; \\mathbf{D} \\mathbf{x} = \\mathbf{b}_0 \\\\ \\quad&amp; \\mathbf{x} \\in P, \\end{align} \\] <p>where we have singled out the hard constraint \\(\\mathbf{D} \\mathbf{x} = \\mathbf{b}_0\\). \\(P\\) is assumed to be a bounded polyhedron, i.e., polytope, and therefore must have a finite number of extreme points.</p>"},{"location":"optimization/linear_programming/dantzig_wolfe_decomposition/#extreme-points-representation","title":"Extreme Points Representation","text":"<p>Let \\(\\mathbf{x}^1, \\mathbf{x}^2, \\ldots, \\mathbf{x}^N\\) denote all the extreme points of \\(P\\), where \\(\\mathbf{x}^i \\in \\mathbb{R}^n\\) and \\(N\\) is arbitrarily large. Any point in a polytope (i.e., bounded polyhedron) can be represented as a convex combination of its extreme points:</p> \\[ \\begin{align} &amp;\\mathbf{x} = \\sum^N_{i = 1} \\lambda_i \\mathbf{x}^i \\\\ &amp;\\sum^N_{i = 1} \\lambda_i = 1 \\\\ &amp;\\lambda_i \\geq 0, \\ \\forall i = 1, \\ldots, N, \\end{align} \\] <p>where the extreme points \\(\\mathbf{x}^i\\)'s are fixed for the polyhedron \\(P\\). Then, we can write \\((LP_2)\\) as:</p> \\[ \\begin{align} (MP) \\quad \\min_{\\lambda_1, \\ldots, \\lambda_N} \\quad&amp;   \\sum^N_{i = 1} \\lambda_i \\left( \\mathbf{c}^T \\mathbf{x}^i \\right) \\\\ \\text{s.t.} \\quad&amp; \\sum^{N}_{i = 1} \\lambda_i \\left( \\mathbf{D} \\mathbf{x}^i \\right) = \\mathbf{b}_0 \\\\ &amp;\\sum^N_{i = 1} \\lambda_i = 1 \\\\ &amp;\\lambda_i \\geq 0, \\ \\forall i = 1, \\ldots, N. \\end{align} \\] <p>The master problem, \\((MP)\\), is equivalent to the original problem \\((LP)\\), namely, if \\(\\lambda_1, \\ldots, \\lambda_N\\) is optimal for \\((MP)\\).</p>"},{"location":"optimization/linear_programming/dantzig_wolfe_decomposition/#column-generation","title":"Column Generation","text":"<p>\\((MP)\\) has an arbitrarily large \\(N\\) extreme points, corresponding variables \\(\\lambda_1, \\lambda_2, \\ldots, \\lambda_N\\) with \\((m_1 + 1)\\) equality constraints. However, \\((MP)\\) doesn not have many constraints but have many variables, i.e., columns. We can rewrite \\((MP)\\) as:</p> \\[ \\begin{align} (MP) \\quad \\min_{\\lambda_1, \\ldots, \\lambda_N} \\quad&amp; \\left[ \\begin{array}{cccc} \\mathbf{c}^T \\mathbf{x}^1 &amp; \\mathbf{c}^T \\mathbf{x}^2 &amp; \\ldots &amp; \\mathbf{c}^T \\mathbf{x}^N \\end{array} \\right] \\left[ \\begin{array}{c} \\lambda_1 \\\\ \\lambda_2 \\\\ \\vdots \\\\ \\lambda_N \\end{array} \\right] \\\\ \\text{s.t.} \\quad&amp;  \\left[ \\begin{array}{cccc} \\mathbf{D} \\mathbf{x}^1 &amp; \\mathbf{D} \\mathbf{x}^2 &amp; \\ldots &amp; \\mathbf{D} \\mathbf{x}^N \\\\ 1 &amp; 1 &amp; \\ldots &amp; 1 \\end{array} \\right] \\left[ \\begin{array}{c} \\lambda_1 \\\\ \\lambda_2 \\\\ \\vdots \\\\ \\lambda_N \\end{array} \\right] =  \\left[ \\begin{array}{c} \\mathbf{b}_0 \\\\ 1 \\end{array} \\right] \\\\ &amp; \\lambda_i \\geq 0, \\ \\forall i = 1, \\ldots, N. \\end{align} \\] <p>We apply Column Generation algorithm to solve \\((MP)\\):</p> <ol> <li> <p>Choose a subset of \\(I\\) of columns and variables. The restricted master problem will be:</p> \\[ \\begin{align} (RMP) \\quad \\min_{\\lambda_i, \\ \\forall i \\in I} \\quad&amp; \\sum_{i \\in I} \\lambda_i \\left( \\mathbf{c}^T \\mathbf{x}^i \\right) \\\\ \\text{s.t.} \\quad&amp; \\sum_{i \\in I} \\lambda_i \\left( \\mathbf{D} \\mathbf{x}^i \\right) = \\mathbf{b}_0 \\quad \\leftarrow \\hat{\\mathbf{y}} \\\\ &amp; \\sum_{i \\in I} \\lambda_i = 1 \\quad \\leftarrow \\hat{r} \\\\ &amp;\\lambda_i \\geq 0, \\ \\forall i \\in I. \\end{align} \\] <p>Obtain an optimal solution \\(\\hat{\\boldsymbol{\\lambda}}\\) of \\((RMP)\\), and an optimal dual solution \\(\\hat{\\mathbf{y}}\\) and \\(\\hat{r}\\).</p> </li> <li> <p>Check the optimality of \\(\\hat{\\boldsymbol{\\lambda}}\\) using the dual information. Find the minimum reduced cost:</p> \\[ Z = \\min_{i = 1, \\ldots, N} \\left\\{ \\left( \\mathbf{c}^T \\mathbf{x}^i \\right) - \\hat{\\mathbf{y}}^T \\left( \\mathbf{D} \\mathbf{x}^i \\right) - \\hat{r} \\right\\}. \\] <p>If \\(Z \\geq 0\\), then \\(\\hat{\\boldsymbol{\\lambda}}\\) is optimal for \\((MP)\\) and terminate. Otherwise, add the column with the minimum reduced cost to \\((RMP)\\), and continue.</p> </li> </ol> <p>Enumerating all the extreme points in (2) is computationally expensive. Moreover, we do not know all the extreme points. We need to be able to generate them on the fly. The key idea of Dantzig-Wolfe is that enumerating through all the extreme points of \\(P\\) is equivalent to minimizing the reduced cost over the polytope \\(P\\) directly.</p> \\[ \\begin{align} Z &amp;= \\min_{i = 1, \\ldots, N} \\left\\{ \\left( \\mathbf{c}^T \\mathbf{x}^i \\right) - \\hat{\\mathbf{y}}^T  \\left( \\mathbf{D} \\mathbf{x}^i \\right) - \\hat{r} \\right\\} \\\\  &amp;= \\min_{\\mathbf{x}} \\left\\{ \\left( \\mathbf{c}^T \\mathbf{x} \\right) - \\hat{\\mathbf{y}}^T \\left( \\mathbf{D} \\mathbf{x} \\right) - \\hat{r} \\right\\} \\\\  &amp; \\quad\\quad \\text{s.t.} \\quad \\mathbf{x} \\in P \\\\ &amp;= \\min_{\\mathbf{x}} \\left\\{ \\left( \\mathbf{c}^T - \\hat{\\mathbf{y}}^T \\mathbf{D} \\right) \\mathbf{x} \\right\\} - \\hat{r} \\\\ &amp; \\quad\\quad \\text{s.t.} \\quad \\mathbf{F} \\mathbf{x} = \\mathbf{b}, \\ \\mathbf{x} \\geq 0. \\end{align} \\] <p>Note that the dual variable \\(\\hat{r}\\) is fixed, so it can be pulled outside of the minimization problem. The column generation algorithm can be rewritten as:</p> <ol> <li> <p>Choose a subset \\(I\\) of columns and variables. Solve the \\((RMP)\\):</p> \\[ \\begin{align} (RMP) \\quad \\min_{\\lambda_i, \\ \\forall i \\in I} \\quad&amp; \\sum_{i \\in I} \\lambda_i \\left( \\mathbf{c}^T \\mathbf{x}^i \\right) \\\\ \\text{s.t.} \\quad&amp; \\sum_{i \\in I} \\lambda_i \\left( \\mathbf{D} \\mathbf{x}^i \\right) = \\mathbf{b}_0 \\quad \\leftarrow \\hat{\\mathbf{y}} \\\\ &amp;\\sum_{i \\in I} \\lambda_i = 1 \\quad \\leftarrow \\hat{r} \\\\ &amp;\\lambda_i \\geq 0, \\forall i \\in I. \\end{align} \\] <p>Obtain the optimal solution \\(\\hat{\\boldsymbol{\\lambda}}\\) of \\((RMP)\\) and the optimal dual solution \\(\\hat{\\mathbf{y}}\\) and \\(\\hat{r}\\).</p> </li> <li> <p>To check the optimality of \\(\\hat{\\boldsymbol{\\lambda}}\\), we solve the following subproblem \\((SP)\\):</p> \\[ \\begin{align} (SP) \\quad w = \\min \\quad&amp; \\left( \\mathbf{c}^T - \\hat{\\mathbf{y}}^T \\mathbf{D} \\right) \\mathbf{x} \\\\ \\text{s.t.} \\quad&amp; \\mathbf{F} \\mathbf{x} = \\mathbf{b}, \\ \\mathbf{x} \\geq 0. \\end{align} \\] <p>If \\(w \\geq \\hat{r}\\), then \\(\\hat{\\boldsymbol{\\lambda}}\\) is optimal for \\((MP)\\). Terminate. Otherwise, the optimal BFS of the above problem is an extreme point of the polyhedron \\(P\\). Denote it as \\(\\mathbf{x}^i\\). Add the column \\(\\left[ \\begin{array}{c} \\mathbf{D} \\mathbf{x}^i \\\\ 1 \\end{array} \\right]\\) to the constraints matrix in \\((RPM)\\), and add \\(\\mathbf{c}^T \\mathbf{x}^i\\) to the cost coefficient.</p> </li> </ol> <p>Note that the dual variables \\(\\hat{\\mathbf{y}}\\) and \\(\\hat{r}\\) can be obtained from computing \\(\\mathbf{c}^T_B \\mathbf{B}^{-1}\\) as done in simplex method. In particular, \\(\\hat{\\mathbf{y}}\\) is the first \\(m_1\\) components of \\(\\mathbf{c}^T_B \\mathbf{B}^{-1}\\), and \\(\\hat{r}\\) is the last component of \\(\\mathbf{c}^T_B \\mathbf{B}^{-1}\\). Here, \\(\\mathbf{c}_B\\) is the vector of coefficients of \\(\\lambda_i\\)'s corresponding to the basic variables, and \\(\\mathbf{B}\\) is the basis matrix of \\(\\left[ \\begin{array}{cccc}\\mathbf{D} \\mathbf{x}^1 &amp; \\mathbf{D} \\mathbf{x}^2 &amp; \\ldots &amp; \\mathbf{D} \\mathbf{x}^N \\\\ 1 &amp; 1 &amp; \\ldots &amp; 1 \\end{array} \\right]\\).</p>"},{"location":"optimization/linear_programming/dantzig_wolfe_decomposition/#numerical-example","title":"Numerical Example","text":"<p>Consider the following LP:</p> \\[ \\begin{align} \\min \\quad&amp; -4x_1 -x_2 - 6x_3 \\\\ \\text{s.t.} \\quad&amp; 3x_1 + 2x_2 + 4x_3 = 17 \\\\ &amp; 1 \\leq x_1 \\leq 2 \\\\ &amp; 1 \\leq x_2 \\leq 2 \\\\ &amp; 1 \\leq x_3 \\leq 2. \\end{align} \\] <p>Divide the constraints into two groups: The first group consists of the constraint \\(\\mathbf{D} \\mathbf{x} = \\mathbf{b}_0\\) where \\(\\mathbf{D} = \\left[\\begin{array}{ccc} 3 &amp; 2 &amp; 4 \\end{array} \\right]\\) and \\(\\mathbf{b}_0 = 17\\). The second group is the constraint \\(\\mathbf{x} \\in P\\), where the polyhedron \\(P = \\left\\{ \\mathbf{x} \\in \\mathbb{R}^3 \\ : \\ 1 \\leq x_i \\leq 2, \\ \\forall i = 1, 2, 3 \\right\\}\\). \\(P\\) is a 3-D cube, which has eight extreme points \\(\\mathbf{x}^1, \\ldots, \\mathbf{x}^8\\); it is bounded and has no extreme rays.</p> <p>The master problem \\((MP)\\) in the \\(\\boldsymbol{\\lambda}\\) can be written as:</p> \\[ \\begin{align} (MP) \\quad \\min_{\\lambda_1, \\ldots, \\lambda_8} \\quad&amp; \\sum^8_{i = 1} \\lambda_i \\left( \\mathbf{c}^T \\mathbf{x}^i \\right) \\\\ \\text{s.t.} \\quad&amp; \\sum^8_{i = 1} \\lambda_i \\left( \\mathbf{D} \\mathbf{x}^i \\right) = 17 \\\\ &amp; \\sum^8_{i = 1} \\lambda_i = 1 \\\\ &amp; \\lambda_i \\geq 0, \\ \\forall i = 1, \\ldots, 8. \\end{align} \\] <p>Note that \\((MP)\\) has two equality constraints. Pick two columns, or equivalently choose two extreme points of \\(P\\), to start the column generation algorithm. Pick \\(\\mathbf{x}^1 = (2, 2, 2)\\) and \\(\\mathbf{x}^2 = (1, 1, 2)\\), and the corresponding convex weights \\(\\lambda_1, \\lambda_2\\). Note that the specific indices do not matter. We can always order the extreme points such that the first extreme point is \\((2, 2, 2)\\) and the second is \\((1, 1, 2)\\). We have:</p> \\[ \\begin{align} &amp;\\mathbf{c}^T \\mathbf{x}^1 =  \\left[ \\begin{array}{ccc} -4 &amp; -1 &amp; -6 \\end{array} \\right] \\left[ \\begin{array}{c} 2 \\\\ 2 \\\\ 2 \\end{array} \\right] = -22, \\ \\mathbf{c}^T \\mathbf{x}^2 =  \\left[ \\begin{array}{ccc} -4 &amp; -1 &amp; -6 \\end{array} \\right] \\left[ \\begin{array}{c} 1 \\\\ 1 \\\\ 2 \\end{array} \\right] = 17 \\\\ &amp;\\mathbf{D} \\mathbf{x}^1 =  \\left[  \\begin{array}{ccc} 3 &amp; 2 &amp; 4 \\end{array} \\right] \\left[ \\begin{array}{c} 2 \\\\ 2 \\\\ 2 \\end{array} \\right] = 18, \\ \\mathbf{D} \\mathbf{x}^2 =  \\left[  \\begin{array}{ccc} 3 &amp; 2 &amp; 4 \\end{array} \\right] \\left[ \\begin{array}{c} 1 \\\\ 1 \\\\ 2 \\end{array} \\right] = 13. \\end{align} \\] <p>The \\((RMP)\\) can be written explicitly as:</p> \\[ \\begin{align} (RMP) \\quad \\min_{\\lambda_1, \\lambda_2} \\quad&amp; -22 \\lambda_1 - 17 \\lambda_2 \\\\ \\text{s.t.} \\quad&amp; 18 \\lambda_1 + 13 \\lambda_2 = 17 \\\\ &amp; \\lambda_1 + \\lambda_2 = 1 \\\\ &amp; \\lambda_1, \\lambda_2 \\geq 0. \\end{align} \\] <p>The basis matrix and its inverse are:</p> \\[ \\begin{align} \\mathbf{B} =  \\left[ \\begin{array}{cc} 18 &amp; 13 \\\\ 1 &amp; 1 \\end{array} \\right], \\quad \\mathbf{B}^{-1} =  \\left[ \\begin{array}{cc} 0.2 &amp; -2.6 \\\\ -0.2 &amp; 3.6 \\end{array} \\right]. \\end{align} \\] <p>The optimal solution is:</p> \\[ \\begin{align} \\left[ \\begin{array}{c} \\hat{\\lambda}_1 \\\\ \\hat{\\lambda}_2 \\end{array} \\right] =  \\mathbf{B}^{-1} \\left[ \\begin{array}{c} 17 \\\\ 1 \\end{array} \\right] =  \\left[ \\begin{array}{c} 0.8 \\\\ 0.2 \\end{array} \\right]. \\end{align} \\] <p>Form the dual variable:</p> \\[ \\left[ \\begin{array}{cc} \\hat{\\mathbf{y}}^T &amp; \\hat{r} \\end{array} \\right] =  \\mathbf{c}^T_B \\mathbf{B}^{-1} =  \\left[ \\begin{array}{cc} -22 &amp; -17 \\end{array} \\right] \\mathbf{B}^{-1} =  \\left[ \\begin{array}{cc} -1 &amp; -4 \\end{array} \\right]. \\] <p>Note that the optimal dual variable \\(\\hat{\\mathbf{y}}\\) corresponds to the hard constraints, \\(18 \\lambda_1 + 13 \\lambda_2 = 17\\), and the optimal dual variable \\(\\hat{r}\\) corresponds to \\(\\lambda_1 + \\lambda_2 = 1\\).</p> <p>To compute the minimum reduced cost, we form the pricing problem:</p> \\[ \\begin{align} \\hat{Z} = \\min \\quad&amp; \\left( \\mathbf{c}^T - \\hat{\\mathbf{y}}^T \\mathbf{D} \\right) \\mathbf{x} - \\hat{r} \\\\ \\text{s.t.} \\quad&amp; \\mathbf{x} \\in P, \\end{align} \\] <p>which is:</p> \\[ \\begin{align} \\hat{Z} = &amp;\\min \\quad -x_1 + x_2 - 2x_3 + 4 \\\\ &amp;\\text{s.t.} \\quad 1 \\leq x_1 \\leq 2, \\ 1 \\leq x_2 \\leq 2, \\ 1 \\leq x_3 \\leq 2. \\end{align} \\] <p>The optimal solution is \\(\\mathbf{x}^3 = \\left[\\begin{array}{ccc}2 &amp; 1 &amp; 2\\end{array}\\right]\\), which is another extreme point of the cube \\(P\\). The optimal cost \\(\\hat{Z} = -1\\), therefore, the reduced cost of \\(\\lambda_3\\) is \\(-1\\). This variables enters the restricted problem. The associated column is \\(\\left[\\begin{array}{cc} \\mathbf{D} \\mathbf{x}^3 &amp; 1 \\end{array}\\right] = \\left[\\begin{array}{cc}16 &amp; 1 \\end{array} \\right]\\), and the associated cost coefficient is \\(\\mathbf{c}^T \\mathbf{x}^3 = -21\\).</p> <p>The new \\((RMP)\\) is:</p> \\[ \\begin{align} (RMP) \\quad \\min_{\\lambda_1, \\lambda_2, \\lambda_3} \\quad&amp; -22 \\lambda_1 - 17 \\lambda_2 - 21 \\lambda_3 \\\\ \\text{s.t.} \\quad&amp; 18 \\lambda_1 + 13 \\lambda_2 + 16 \\lambda_3 = 17 \\\\ &amp; \\lambda_1 + \\lambda_2 + \\lambda_3 = 1 \\\\ &amp; \\lambda_1, \\lambda_2, \\lambda_3 \\geq 0. \\end{align} \\] <p>The optimal solution is \\(\\hat{\\lambda}_1 = 0.5\\), \\(\\hat{\\lambda}_2 = 0\\), \\(\\hat{\\lambda}_3 = 0.5\\). The optimal basis matrix and its inverse are:</p> \\[ \\begin{align} \\mathbf{B} =  \\left[ \\begin{array}{cc} 18 &amp; 16 \\\\ 1 &amp; 1 \\end{array} \\right], \\  \\mathbf{B}^{-1} =  \\left[ \\begin{array}{cc} 0.5 &amp; -8 \\\\ -0.5 &amp; 9 \\end{array} \\right]. \\end{align} \\] <p>The dual variables and the cost coefficients are:</p> \\[ \\begin{align} &amp;\\left[\\begin{array}{cc}\\hat{\\mathbf{y}} &amp; \\hat{r} \\end{array}\\right] = \\mathbf{c}^T_B \\mathbf{B}^{-1} =  \\left[\\begin{array}{cc} -22 &amp; -21 \\end{array} \\right]\\mathbf{B}^{-1}=  \\left[\\begin{array}{cc} -0.5 &amp; -13 \\end{array} \\right] \\\\ &amp;\\mathbf{c}^T - \\hat{\\mathbf{y}}^T \\mathbf{D} =  \\left[\\begin{array}{ccc}-4 &amp; -1 &amp; -6 \\end{array} \\right] - (-0.5) \\left[\\begin{array}{ccc}3 &amp; 2 &amp; 4 \\end{array} \\right] =  \\left[\\begin{array}{ccc}-2.5 &amp; 0 &amp; -4 \\end{array} \\right]. \\end{align} \\] <p>The pricing porblem is:</p> \\[ \\begin{align} \\hat{Z} = \\min \\quad&amp; -2.5 x_1 - 4x_3 + 13 \\\\ \\text{s.t.} \\quad&amp; 1 \\leq x_1 \\leq 2, \\ 1 \\leq x_2 \\leq 2, \\ 1 \\leq x_3 \\leq 2. \\end{align} \\] <p>The optimal \\(\\hat{Z} = 0\\), implying the current solution is optimal for the master problem. Hence, the final optimal solution is:</p> \\[ \\mathbf{x}^* = 0.5 \\mathbf{x}^1 + 0.5 \\mathbf{x}^3 = 0.5 \\left[\\begin{array}{c} 2 \\\\ 2 \\\\ 2 \\end{array} \\right] +  0.5 \\left[\\begin{array}{c} 2 \\\\ 1 \\\\ 2 \\end{array} \\right] =  \\left[\\begin{array}{c} 2 \\\\ 1.5 \\\\ 2 \\end{array} \\right] \\]"},{"location":"optimization/linear_programming/linear_stochastic_program/","title":"Linear Stochastic Program","text":""},{"location":"optimization/linear_programming/linear_stochastic_program/#two-stage-stochastic-program-formulation","title":"Two-Stage Stochastic Program Formulation","text":"<p>A general two-stage stochastic program can be formulated as:</p> \\[ \\begin{align} \\min_{x, y(\\cdot)} \\quad&amp; cx + E_{w} \\left[ q(w)^T y(w) \\right] \\\\  \\text{s.t.} \\quad&amp; Ax \\leq b \\\\ \\quad&amp; T(w)x + Wy(w) \\leq h(w), \\quad \\forall w \\in W \\\\ \\quad&amp; y(w) \\geq 0, \\quad \\forall w \\in W. \\end{align} \\] <p>If we are dealing with discrete random variable, then:</p> \\[ \\begin{align} \\min_{x, y_i} \\quad&amp; cx + \\sum^{S}_{i} p_i q^T_i y_i \\\\ \\text{s.t.} \\quad&amp; Ax \\leq b \\\\ \\quad&amp; T_i x + W y_i \\leq h_i, \\quad \\forall i = 1, \\ldots, S \\\\ \\quad&amp; y_i \\geq 0, \\quad \\forall i = 1, \\ldots, S \\end{align} \\]"},{"location":"optimization/linear_programming/linear_stochastic_program/#example-stochastic-inventory-control","title":"Example - Stochastic Inventory Control","text":""},{"location":"optimization/linear_programming/linear_stochastic_program/#problem-definition","title":"Problem Definition","text":"<p>Consider a company that designs, produces, and sells winter items such as  ski jackets. The company must commit to a specific production quantity,  \\(x\\), before knowing the exact demand, \\(d\\), 3 months before the winter season starts. Demand \\(d\\) is estimated as a random variable. After seeing the demand, the company decides how many to sell and how many to sell at a discounted price \\(v\\). This is called Decision Making under Uncertainty, since decision \\(x\\) is made under uncertain demand \\(d\\).</p>"},{"location":"optimization/linear_programming/linear_stochastic_program/#problem-formulaton","title":"Problem Formulaton","text":"<p>The decision variables for the optimization problem are:</p> <ol> <li>Here-and-Now decision: Production quantity $x. The decision must be made before the uncertainty is realized. It cannot change after the uncertainty is realized.</li> <li>Wait-and-See decision: Sell quantity \\(y\\), discount (savage) quantity \\(z\\). The decision must be made after the uncertainty is realized.</li> </ol> <p>The objective function can be defined as minimizing the production cost and expected future cost which yields to a two-stage stochastic program:</p> <p>First Stage: Problem with \\(x\\) as first-stage decision:</p> \\[ \\begin{align} \\min_{x} \\quad&amp; cx + E_d \\left[ Q(x, d) \\right] \\\\ \\text{s.t.} \\quad&amp; 0 \\leq x \\leq \\bar{x} \\end{align} \\] <p>Second Stage: Problem with second-stage decision \\(y\\) and \\(v\\). Note that the second-stage decisions depend on \\(d\\), i.e., \\(y\\) and \\(z\\) are functions of \\(d\\):</p> \\[ \\begin{align} Q(x, d) = \\min_{y, z} \\quad&amp; -ry - sz \\\\  \\quad \\text{s.t.} \\quad&amp; y \\leq d \\\\ \\quad&amp; y + z \\leq x \\\\ \\quad&amp; y \\geq 0, z \\geq 0 \\end{align} \\]"},{"location":"optimization/linear_programming/linear_stochastic_program/#problem-reformulation","title":"Problem Reformulation","text":"<p>The two-stage program can be combined into a single stage program:</p> \\[ \\begin{align} \\min_{x} \\quad&amp; cx + E_d \\left[\\min_{y(d), z(d)} -ry(d) - sz(d) \\right] \\\\  \\text{s.t.} \\quad&amp; 0 \\leq x \\leq \\bar{x} \\\\  \\quad&amp; y(d) \\leq d, \\quad \\forall d \\in D \\\\ \\quad&amp; -x + y(d) + z(d) \\leq 0, \\quad \\forall d \\in D \\\\ \\quad&amp; y(d) \\geq 0, z(d) \\geq 0 \\quad \\forall d \\in D, \\end{align} \\] <p>or equivalently:</p> \\[ \\begin{align} \\min_{x, y(\\cdot), z(\\cdot)} \\quad&amp; cx + E_d \\left[ -ry(d) - sz(d) \\right] \\\\  \\text{s.t.} \\quad&amp; 0 \\leq x \\leq \\bar{x} \\\\  \\quad&amp; y(d) \\leq d, \\quad \\forall d \\in D \\\\ \\quad&amp; -x + y(d) + z(d) \\leq 0, \\quad \\forall d \\in D \\\\ \\quad&amp; y(d) \\geq 0, z(d) \\geq 0 \\quad \\forall d \\in D. \\end{align} \\] <p>Suppose the demand \\(d\\) is a discrete random variable with \\(S\\) scenarios,  \\(d_1, \\ldots, d_S\\) each \\(d_i\\) with a probability \\(p_i\\). Suppose each policy  \\(y(\\cdot)\\) has values \\(y_1, \\ldots, y_S\\) corresponding to \\(d_i\\)'s. Then  the problem can be converted to a deterministic Linear Program:</p> \\[ \\begin{align} \\min_{x, y_i, z_i} \\quad&amp; cx + \\sum^S_{i = 1} p_i \\left( -ry_i - sz_i \\right) \\\\  \\text{s.t.} \\quad&amp; 0 \\leq x \\leq \\bar{x} \\\\  \\quad&amp; y_i \\leq d_i, \\quad \\forall d \\in D \\\\ \\quad&amp; -x + y_i + z_i \\leq 0, \\quad \\forall d \\in D \\\\ \\quad&amp; y_i \\geq 0, z_i \\geq 0 \\quad \\forall d \\in D. \\end{align} \\]"},{"location":"optimization/linear_programming/modelling_using_linear_programs/","title":"Modelling Using Linear Programs","text":""},{"location":"optimization/linear_programming/modelling_using_linear_programs/#transportation-problem","title":"Transportation Problem","text":"<p>Suppose there are \\(m\\) suppliers and \\(n\\) customers. The \\(i\\)'th supplier can supply up to \\(s_i\\) units of supply, and the \\(j\\)'th customer has \\(d_j\\) units of demand. It costs \\(c_{ij}\\) to transport a unit of product from \\(i\\)'th supplier to the \\(j\\)'th customer. We want to find a transportation schedule to satisfy all demands with minimum transportation cost.</p> <p>Let \\(x_{ij}\\) denote the amount of product trasnported from \\(i\\)'th supplier to \\(j\\)'th customer for \\(i = 1, \\ldots, m\\) and \\(j = 1, \\ldots, n\\). The LP is then:</p> \\[ \\begin{align} \\min \\quad&amp; \\sum^m_{i = 1} \\sum^n_{j = 1} c_{ij} x_{ij} \\\\  \\text{s.t.} \\quad&amp; \\sum^m_{i = 1} x_{ij} \\geq d_j, \\quad j = 1, \\ldots, n \\\\ \\quad&amp; \\sum^{n}_{j = 1} x_{ij} \\leq s_i, \\quad i = 1, \\ldots, m \\\\ \\quad&amp; x_{ij} \\geq 0, \\quad i = 1, \\dots, m, \\quad j = 1, \\ldots, n. \\end{align} \\]"},{"location":"optimization/linear_programming/modelling_using_linear_programs/#maximum-flow-problem","title":"Maximum Flow Problem","text":"Figure 1: Maximum flow problem <p>Let \\(x_{ij}\\) for \\((i, j) \\in A\\), where \\(A\\) is the set of arcs. Figure 2 shows the I/O for a single node.</p> <p> </p> Figure 2: Maximum flow problem on a single node <p>Then we can formulate the problem as an LP:</p> \\[ \\begin{align} \\max \\quad&amp; b_s \\\\ \\text{s.t.} \\quad&amp; \\sum_{k \\in O(i)} x_{ik} - \\sum_{j \\in I(i)} x_{ji} = b_i, \\quad \\forall i \\\\ \\quad&amp; b_t = -b_s \\\\ \\quad&amp; b_i = 0, \\quad \\forall i \\neq s, t \\\\ \\quad&amp; 0 \\leq x_{ij} \\leq u_{ik}, \\quad \\forall(i, j) \\in A. \\end{align} \\] <p>Here, the first constraint is called the flow conservation constraint. The second constraint is called the </p>"},{"location":"optimization/linear_programming/modelling_using_linear_programs/#shortest-path-problem","title":"Shortest Path Problem","text":"<p>Figure 3 shows a directed network, where then number on each edge is the distance for traversing that edge. We want to go from starting point \\(s\\) to the target point \\(t\\).</p> <p> </p> Figure 3: Shortest path problem <p>The basic idea is to find a minimum cost way to ship 1 unit of flow from \\(s\\) to all other nodes as shown in Figure 4.</p> <p> </p> Figure 3: Shortest path problem reformulated <p>The shortest distance from \\(s\\) to \\(t\\) can be formulated as an LP:</p> \\[ \\begin{align} \\min \\quad&amp; \\sum_{(i, j) \\in A} c_{ij} x_{ij} \\\\  \\text{s.t.} \\quad&amp; \\sum_{k \\in O(i)} x_{ik} - \\sum_{j \\in I(i)} x_{ji} = -1, \\quad \\forall i \\neq s \\\\ \\quad&amp; \\sum_{k \\in O(s)} x_{sk} - \\sum_{j \\in I(s)} x_{js} = n - 1 \\\\ \\quad&amp; x_{ij} \\geq 0, \\quad \\forall (i, j) \\in A. \\end{align} \\]"},{"location":"optimization/linear_programming/nonlinear_program/","title":"Nonlinear Program","text":""},{"location":"optimization/linear_programming/nonlinear_program/#overview","title":"Overview","text":"<p>This section deals with solving nonlinear programs by converting team into linear programs. Given a nonlinear function \\(f(\\mathbf{x})\\), we are interested in solving:</p> \\[ \\begin{align} \\min \\quad&amp; f(\\mathbf{x}) \\\\  \\text{s.t.} \\quad&amp; \\mathbf{x} \\in X \\end{align} \\]"},{"location":"optimization/linear_programming/nonlinear_program/#convex-piecewise-linear-function","title":"Convex Piecewise Linear Function","text":"<p>Any convex piecewise linear function (PWL), \\(\\tilde{f}(\\mathbf{x})\\), can be written as a maximum of a finite number of linear functions:</p> \\[ \\tilde{f}(\\mathbf{x}) = \\max \\left\\{ \\mathbf{a}^T_1 \\mathbf{x} + b_1, \\ldots, \\mathbf{a}^T_m \\mathbf{x} + b_m \\right\\}. \\] <p>Similarly, any concave PWL can be writtes as a minimum of a finite number of linear functions.</p>"},{"location":"optimization/linear_programming/nonlinear_program/#convex-piecewise-linear-approximation","title":"Convex Piecewise Linear Approximation","text":"<p>Any convex function, \\(f(\\mathbf{x})\\), can be approximated by a convex PWL function, \\(\\tilde{f}(\\mathbf{x})\\) to an arbitrary accuracy as shown in the Figure 1.</p> <p> </p> Figure 1: PWL approximation of a nonlinear convex function <p>The optimization problem then becomes:</p> \\[ \\begin{align} \\min_{\\mathbf{x} \\in X} \\quad f(\\mathbf{x}) \\Rightarrow \\min_{\\mathbf{x} \\in X} \\quad \\max \\left\\{ \\mathbf{a}^T_1 \\mathbf{x}+ b_1, \\ldots, \\mathbf{a}^T_m \\mathbf{x} + b_m \\right\\}. \\end{align} \\]"},{"location":"optimization/linear_programming/nonlinear_program/#reformulation","title":"Reformulation","text":"<p>We can further reformulate the problem by introducing a new variable, \\(z\\), and putting the objective into a constraint:</p> \\[ \\begin{align} \\min_{\\mathbf{x}, z} \\quad&amp; z \\\\ \\text{s.t.} \\quad&amp; f(\\mathbf{x}) \\leq z \\\\ \\quad&amp; \\mathbf{x} \\in X, \\end{align} \\] <p>or equivalently:</p> \\[ \\begin{align} \\min_{\\mathbf{x} \\in X, z} \\quad&amp; z \\\\ \\text{s.t.} \\quad&amp; \\max \\left\\{\\mathbf{a}^T_1 \\mathbf{x} + b_1, \\ldots, \\mathbf{a}^T_m \\mathbf{x} + b_m \\right\\} \\leq z, \\end{align} \\] <p>which is a Linear Program:</p> \\[ \\begin{align} \\min_{\\mathbf{x} \\in X, z} \\quad&amp; z \\\\ \\text{s.t.} \\quad&amp; \\mathbf{a}^T_i \\mathbf{x} + b_i \\leq z, \\quad \\forall i = 1, \\ldots, m. \\end{align} \\]"},{"location":"optimization/linear_programming/nonlinear_program/#example-1-linear-classification-and-robust-regression","title":"Example 1: Linear Classification and Robust Regression","text":"<p>Consider a set of training data \\((\\mathbf{x}_i, y_i)\\) for \\(i = 1, \\ldots, N\\) where  \\(\\mathbf{x}_i \\in \\mathbb{R}^n\\) is a feature vector and \\(y_i\\) is a binary label. We are interested in building a linear classifier:</p> \\[ f(\\mathbf{x}) = b_0 + \\sum^N_{j = 1} \\mathbf{b}_j^T \\mathbf{x}_j, \\] <p>such that, for a given feature vector \\(\\mathbf{x}\\), if \\(f(\\mathbf{x}) \\geq 0.5\\), then  \\(\\mathbf{x}\\) is classified as \\(y = 1\\), otherwise \\(y = 0\\).</p> <p>The classifier should be optimal in minimizing total prediction error over the training data. The prediction error is a measure of distance between classifier's output and the true label. If we use \\(l_1\\)-metric, we will have the following robust regression model:</p> \\[ \\begin{align} \\min_{b_0, \\ldots, b_n} \\quad&amp; \\sum^N_{i = 1} \\left| b_0 + \\sum^n_j b_j x_{ij} - y_i \\right|. \\end{align} \\] <p>The equivalent LP reformulation of the problem is:</p> \\[ \\begin{align} \\min_{b_0, \\ldots, b_n} \\quad&amp; \\sum^N_{i = 1} z_i \\\\  \\textrm{s.t.} \\quad&amp; b_0 + \\sum^n_j b_j x_{ij} - y_i \\leq z_i, \\quad \\forall i = 1, \\ldots, N \\\\ \\quad&amp; b_0 + \\sum^n_j b_j x_{ij} - y_i \\geq -z_i, \\quad \\forall i = 1, \\ldots, N \\\\ \\end{align} \\]"},{"location":"optimization/linear_programming/nonlinear_program/#example-2-concrete-facility-location","title":"Example 2: Concrete Facility Location","text":"<p>A concrete facility is planning to produce concrete poles. It requires two new facilities in its factory, a new concrete casting area (a) to make concrete poles and storage area (b) for storing the finished product. The current layout of the factory is shiown in Figure 2.</p> <p> </p> Figure 2: Concrete factory map <p>The costs of moving parts per unit distance is shown below:</p> Material Handling Cost Pole Casting a Pole Storage b Pole Casting - - Pole Storage 4.00 - Concrete Batch 1.10 - Steel Mfch 0.70 0.65 Shipping - 0.40 <p>We are interesting in finding locations for \\(a: (x_1, y_1)\\) and \\(b: (x_2, y_2)\\) such that the total cost of transporting between facilities is minimized. The problem can be formulated as:</p> \\[ \\begin{align} \\min \\quad&amp; 4d(x_1, y_1, x_2, y_2) + 1.1d(x_1, y_1, 300, 1200) + 0.7d(x_1, y_1, 0, 600) \\\\ \\quad&amp; + 0.65d(x_2, y_2, 0, 600) + 0.4d(x_2, y_2, 600, 0) \\\\ \\textrm{s.t.} \\quad&amp; 0 \\leq x_i \\leq 900, \\quad \\forall i = 1, 2 \\\\ \\quad&amp; 0 \\leq y_i \\leq 900, \\quad \\forall i = 1, 2. \\end{align} \\] <p>Using Manhattan distance:</p> \\[ \\begin{align} \\min \\quad&amp; 4(|x_1 - x_2| + |y_1 - y_2|) + 1.1(|x_1 - 300| + |y_1 - 1200|) \\\\ \\quad&amp; + 0.7(|x_1| + |y_1 - 600|) + 0.65(|x_2| + |y_2 - 600|) \\\\ \\quad&amp; + 0.4(|x_2 - 600| + |y_2|) \\\\ \\textrm{s.t.} \\quad&amp; 0 \\leq x_i \\leq 900, \\quad \\forall i = 1, 2 \\\\ \\quad&amp; 0 \\leq y_i \\leq 900, \\quad \\forall i = 1, 2. \\end{align} \\] <p>Using auxiliary variables, the equivalent LP formulation of the problem is:</p> \\[ \\begin{align} \\min \\quad&amp; 4(z_1 + z_2) + 1.1(z_3 + z_4) + 0.7(z_5 + z_6)  \\\\ \\quad&amp; + 0.65(z_7 + z_8) + 0.4(z_9 + z_{10}) \\\\  \\textrm{s.t.} \\quad&amp; -z_1 \\leq x_1 - x_2 \\leq z_1 \\\\ \\quad&amp; -z_2 \\leq y_1 - y_2 \\leq z_2 \\\\ \\quad&amp; -z_3 \\leq x_1 - 300 \\leq z_z \\\\ \\quad&amp; \\quad \\ldots \\end{align} \\]"},{"location":"optimization/linear_programming/nonlinear_program/#example-3-radiation-therapy-planning-problem","title":"Example 3: Radiation Therapy Planning Problem","text":"<p>For a given tumor and given critical areas obtained from imaging, and a given set of possible beamlet origins and angles (we assume that the angles are fixed), we are interested in determining the weight of each beamlet such that:</p> <ol> <li>Dosage over the tumor area will be at least a target level \\(\\gamma_L\\)</li> <li>Dosage over the critical area (e.g., spine etc.) will be at most a target level \\(\\gamma_U\\)</li> </ol>"},{"location":"optimization/linear_programming/robust_optimization/","title":"Robust Optimization","text":""},{"location":"optimization/linear_programming/robust_optimization/#robust-constraint","title":"Robust Constraint","text":"<p>Given a linear constraint:</p> \\[ \\mathbf{a}^T \\mathbf{x} \\leq b, \\] <p>suppose the coefficient \\(\\mathbf{a}\\) is uncertain, but is in polytope \\(\\mathcal{U}\\):</p> \\[ \\mathcal{U} = \\left\\{ \\mathbf{a} \\in \\mathbb{R}^n \\ : \\ \\mathbf{B} \\mathbf{a} \\leq \\mathbf{d} \\right\\}. \\] <p>We are interested in finding \\(\\mathbf{x}\\) such that:</p> \\[ \\mathbf{a}^T \\mathbf{x} \\leq b, \\quad \\forall \\mathbf{a} \\in \\mathcal{U}. \\label{robust_constraint} \\] <p>Constraint \\((\\ref{robust_constraint})\\) is called a robust constraint. Notice that since \\(\\mathcal{U}\\) could contain infinite number of realizations of \\(\\mathbf{a}\\), the robust constraint contains the conjunction of an infinite number of linear constraints, each for specific value of \\(\\mathbf{a}\\) in \\(\\mathcal{U}\\). To deal with \\((\\ref{robust_constraint})\\), we need to reformulate it into a finite set of constraints.</p>"},{"location":"optimization/linear_programming/robust_optimization/#reformulation","title":"Reformulation","text":"<p>The general way to reformulate the robust constraint into a set of linear constraints is:</p> \\[ \\begin{align} &amp; \\mathbf{a}^T \\mathbf{x} \\leq b, \\quad \\forall \\mathbf{a} \\in \\mathcal{U} := \\left\\{ \\mathbf{a} \\in \\mathbb{R}^n \\ : \\ \\mathbf{B} \\mathbf{a} \\leq \\mathbf{d} \\right\\} \\\\ \\Rightarrow &amp;\\max_{\\mathbf{a}: \\ \\mathbf{B} \\mathbf{a} \\leq \\mathbf{d}} \\quad \\mathbf{a}^T \\mathbf{x} \\leq b \\label{1} \\\\ \\Rightarrow &amp;\\min_{\\boldsymbol{\\lambda}: \\ \\mathbf{B}^T \\boldsymbol{\\lambda} = \\mathbf{x}, \\ \\boldsymbol{\\lambda} \\geq 0} \\quad \\mathbf{d}^T \\boldsymbol{\\lambda} \\leq b \\label{2} \\\\ \\Rightarrow &amp; \\begin{cases}     \\mathbf{d}^T \\boldsymbol{\\lambda} \\leq b \\\\     \\mathbf{B}^T \\boldsymbol{\\lambda} = \\mathbf{x} \\\\     \\boldsymbol{\\lambda} \\geq 0. \\end{cases} \\label{f} \\\\ \\end{align} \\] <p>Equation \\((\\ref{1})\\) uses a simple observation that if a real number (i.e., \\(b\\)) is greater than or equal to a set of real numbers (i.e., \\(\\mathbf{a}^T \\mathbf{x}\\) for each \\(\\mathbf{a} \\in \\mathcal{U}\\)), then \\(b\\) should be greater than or equal to the supremum of this set of real numbers. Moreover, the supremum is achieved by some particular \\(\\mathbf{a} \\in \\mathcal{U}\\) since the function \\(\\mathbf{a}^T \\mathbf{x}\\) and \\(\\mathcal{U}\\) are linear, so the max operator and the supremum operator coincide. Equation \\((\\ref{2})\\) holds since the uncertainty set \\(\\mathcal{U}\\) is a nonempty polytope, so the maximum in equation \\((\\ref{1})\\) for any \\(\\mathbf{x}\\) is finite, therefore, LP strong duality holds between the primal maximization problem and the dual problem in equation \\((\\ref{2})\\). Finally, since the minimum in \\((\\ref{2})\\) exists for any \\(\\mathbf{x}\\) and is less than or equal to \\(b\\), then there must exist some \\(\\mathbf{\\lambda}\\) in the dual polyhedron such that the objective value of the dual problem is less than \\(b\\).</p> <p>This procedure of reformulating the robust linear constraint is a general procedure that can be applied to any polyhedral uncertainty set.</p>"},{"location":"optimization/linear_programming/simplex_method/","title":"Simplex Method","text":""},{"location":"optimization/linear_programming/simplex_method/#local-search","title":"Local Search","text":"<p>Local search is generalized version of gradient descent or Newton's method and can be described as follows:</p> <p>Algorithm: Local Search </p> <p>\\(\\quad\\)Start from feasible solution \\(\\mathbf{x}_t\\).  \\(\\quad\\)Find a direction \\(\\mathbf{d}\\) that points inside the feasible region and decreases the objective value.  \\(\\quad\\)Find a step length \\(\\theta\\) along \\(\\mathbf{d}\\) to move to next iterate: \\(\\mathbf{x}_{t + 1} \\leftarrow \\mathbf{x}_t + \\theta \\mathbf{d}\\).  \\(\\quad\\)If no good direction or step length can be found, terminate. Otherwise, \\(t \\leftarrow t + 1\\) and repeat.   </p> <p>The only class of optimization problems for which local search can guarantee to find a global minimum is the class of convex programs, i.e., minimization problems with a convex objective function and a convex feasible region, since for this class of problems, a local minimum is a global minimum. </p> <p>Theorem. A local minimum of a convex optimization problem is also a global minimum.</p> <p>Proof. Let \\(\\mathbf{x}^*\\) be a local minimum of \\(\\min_{\\mathbf{x} \\in X} f(\\mathbf{x})\\), where \\(f(\\mathbf{x})\\) is a convex function and \\(X\\) is a convex set. Then by definition, there exists a neighborhood of \\(\\mathbf{x}^*\\) in \\(X\\), denoted as \\(U_{\\epsilon} (\\mathbf{x}^*) = \\left\\{ \\mathbf{x}: \\ ||\\mathbf{x} - \\mathbf{x}^*|| \\leq \\epsilon \\right\\}\\) for some \\(\\epsilon &gt; 0\\), where \\(f(\\mathbf{x}^*) \\leq f(\\mathbf{x})\\) for all \\(\\mathbf{x} \\in U_{\\epsilon}(\\mathbf{x}^*)\\). Now suppose there is a different point \\(\\hat{\\mathbf{x}} \\in X\\) such that \\(f(\\hat{\\mathbf{x}}) &lt; f(\\mathbf{x}^*)\\). Since \\(X\\) is a convex set, for any \\(0 &lt; \\lambda &lt; 1\\), the point \\(\\mathbf{x} = \\lambda \\hat{\\mathbf{x}} + (1 - \\lambda) \\mathbf{x}^*\\) is in \\(X\\). We can choose \\(\\lambda\\) to be very close to zero such that \\(\\mathbf{x}\\) is also in the neighborhood \\(U_{\\epsilon}(\\mathbf{x}^*)\\). Since \\(f\\) is convex, we have \\(f(\\mathbf{x}) \\leq \\lambda f(\\hat{\\mathbf{x}}) + (1 - \\lambda) f(\\mathbf{x}^*) &lt; \\lambda f(\\mathbf{x}^*) + (1 - \\lambda) f(\\mathbf{x}^*) = f(\\mathbf{x}^*)\\), i.e., \\(\\mathbf{x}\\) is a point in \\(U_{\\epsilon} (\\mathbf{x}^*)\\) with a strict lower objective value than \\(\\mathbf{x}^*\\), which contradicts with \\(\\mathbf{x}^*\\) being a local minimum in \\(U_{\\epsilon} (\\mathbf{x}^*)\\).</p>"},{"location":"optimization/linear_programming/simplex_method/#simplex-method","title":"Simplex Method","text":""},{"location":"optimization/linear_programming/simplex_method/#overview","title":"Overview","text":"<p>Algorithm: Simplex Method </p> <p>\\(\\quad\\)Start from basic feasible solution (BFS) \\(\\mathbf{x}_t\\).  \\(\\quad\\)Find a direction \\(\\mathbf{d}\\) that points to an adjactent BFS and decreases the objective value.  \\(\\quad\\)Find a step length \\(\\theta\\) so that the next iterate, \\(\\mathbf{x}_{t + 1} \\leftarrow \\mathbf{x}_t + \\theta \\mathbf{d}\\), is a BFS.  \\(\\quad\\)If no such direction or step length can be found, terminate. Otherwise, \\(t \\leftarrow t + 1\\) and repeat.   </p> <p>An important point is that the simplex method goes from one BFS to another BFS. This is because if an LP has a BFS (which is true for any standard form LP) and if the optimal objective value is bounded, then a BFS is an optimal solution.</p>"},{"location":"optimization/linear_programming/simplex_method/#start-from-bfs","title":"Start from BFS","text":"<p>Recall that a basic feasible solution is a feasible solution where all equality constraints \\(\\mathbf{A}\\mathbf{x} = \\mathbf{b}\\) are satisfied and out of all the active constraints, \\(n\\) of them are linearly independent. A BFS \\(\\mathbf{x}\\) can be partioned into two parts: \\(\\mathbf{x} = \\left[ \\mathbf{x}_B, \\mathbf{x}_N \\right]\\), the basic variable part \\(\\mathbf{x}_B\\) and the nonbasic variable part \\(\\mathbf{x}_N\\). The nonbasic variable is always zero, i.e., \\(\\mathbf{x}_N = \\mathbf{0}\\). The basic variable \\(\\mathbf{x}_B = \\left[x_{B(1)}, \\ldots, x_{B(m)} \\right]\\) is associated with the basis matrix \\(\\mathbf{B} = \\left[ \\mathbf{A}_{B(1)}, \\ldots, \\mathbf{A}_{B(m)} \\right]\\). In particular we have:</p> \\[ \\mathbf{b} = \\mathbf{A} \\mathbf{x} = \\left[\\mathbf{B}, \\mathbf{N} \\right] \\left[ \\begin{array}{c} \\mathbf{x}_B \\\\ \\mathbf{x}_N \\\\ \\end{array} \\right]  = \\mathbf{B} \\mathbf{x}_B + \\mathbf{N} \\mathbf{x}_N = \\mathbf{B} \\mathbf{x}_B \\ \\Rightarrow \\ \\mathbf{x}_B = \\mathbf{B}^{-1} \\mathbf{b}. \\]"},{"location":"optimization/linear_programming/simplex_method/#find-a-feasible-direction","title":"Find a Feasible Direction","text":"<p>Starting from BFS \\(\\mathbf{x}\\), the algorithm moves to a new point \\(\\hat{\\mathbf{x}} = \\mathbf{x} + \\theta \\mathbf{d}\\). The new point needs to be a feasible point and and adjacent BFS. </p> <ol> <li> <p>For \\(\\hat{\\mathbf{x}}\\) to be feasible, we have constraint \\(\\mathbf{A} \\hat{\\mathbf{x}} = \\mathbf{b}\\) or equivalently, \\(\\mathbf{A} (\\mathbf{x} + \\theta \\mathbf{d}) = \\mathbf{b}\\). Since we already have \\(\\mathbf{A} \\mathbf{x} = \\mathbf{b}\\) and \\(\\theta &gt; 0\\), we get \\(\\mathbf{A} \\mathbf{d} = \\mathbf{0}\\) or equivalently:</p> \\[ \\mathbf{A} \\mathbf{d} = \\left[ \\mathbf{B}, \\mathbf{N} \\right]  \\left[ \\begin{array}{c} \\mathbf{d}_B \\\\ \\mathbf{d}_N \\end{array} \\right] =  \\mathbf{B} \\mathbf{d}_B + \\mathbf{N} \\mathbf{d}_N = \\mathbf{0}. \\] </li> <li> <p>Mathetmatically, an adjacent BFS is defined as:</p> <p>Definition (Adjacent BFS). Two BFSs \\(\\hat{\\mathbf{x}}\\) and \\(\\mathbf{x}\\) of a polyhedron \\(P\\) are called adjacent, if they share the same \\(n - 1\\) linearly independent active constraints.</p> <p>Geometrically, the solutions of \\(n - 1\\) linearly independent equations in \\(n\\) variables form a line. Hence, two adjacent BFS are connected by line segment on this line. This line segment is called an edge of the polyhedron. </p> <p>Proposition. In a standard form LP, two BFSs \\(\\mathbf{x}\\) and \\(\\hat{\\mathbf{x}}\\) are adjacent if they have the same \\(n - m - 1\\) nonbasic variables.</p> <p>Proof. First, each BFS has \\(n - m\\) nonbasic variables, which are all zero. Since \\(\\mathbf{x}\\) and \\(\\hat{\\mathbf{x}}\\) share \\(n - 1\\) active constraints and both have to satisfy all the \\(m\\) equality constraints \\(\\mathbf{A} \\mathbf{x} = \\mathbf{b}\\), then they can only differ in one nonbasic variable. In other words, they have the same \\(n - m - 1\\) nonbasic variables.</p> <p>For example, if the BFS \\(\\mathbf{x} \\in \\mathbb{R}^5\\) has two basic variables \\(x_1, x_2\\) and three nonbasic variables \\(x_3, x_4, x_5\\), then its adjacent BFS \\(\\hat{\\mathbf{x}}\\) should share two same nonbasic variables \\(x_3, x_4\\) or \\(x_3, x_5\\) or \\(x_4, x_5\\), plus one different nonbasic variable \\(x_1\\) or \\(x_2\\). In other words, going from \\(\\mathbf{x}\\) to \\(\\hat{\\mathbf{x}}\\), two nonbasic variables of \\(\\mathbf{x}\\) stay as nonbasic variables of \\(\\hat{\\mathbf{x}}\\) and only one of the nonbasic variables of \\(\\mathbf{x}\\) becomes a basic variable of \\(\\hat{\\mathbf{x}}\\).</p> </li> </ol> <p>(2) gives us a way to specify \\(\\mathbf{d}_N \\in \\mathbb{R}^{n - m}\\) because \\(n - m - 1\\) nonbasic variables of \\(\\mathbf{x}\\) need to remain nonbasic, i.e., at zero value, \\(\\mathbf{d}_N\\) must have \\(n - m - 1\\) components at zero value; and because one nonbasic variable of \\(\\mathbf{x}\\) needs to become basic, i.e., to increase from zero value to some positive value, then the corresponding component of \\(\\mathbf{d}_N\\) has to be positive number, and without loss of generality, we can fix this component at value 1 and use the step length \\(\\theta\\) to control its size.</p> <p>We can select a nonbasic variable \\(x_j\\) (initially \\(x_j = 0\\)), increase \\(x_j\\) to \\(\\theta \\geq 0\\), while keeping other nonbasic variables at zero. In other words, the simplex method makes \\(\\mathbf{d}_N = \\left[0, \\ldots, 0, 1, 0, \\ldots, 0 \\right]^T := \\mathbf{e}^T_j\\) for some \\(d_j = 1\\), where \\(\\mathbf{e}_j\\) is the \\(j\\)-th unit vector. It follows that:</p> \\[ \\mathbf{B} \\mathbf{d}_B + \\mathbf{N} \\mathbf{d}_N = \\mathbf{B} \\mathbf{d}_B + \\mathbf{A}_j = \\mathbf{0}, \\] <p>where \\(\\mathbf{A}_j\\) is the column in \\(\\mathbf{N}\\) associated with the 1 component in \\(\\mathbf{d}_N\\) of the column of the matrix \\(\\mathbf{A}\\). Since \\(\\mathbf{B}\\) is invertible, we have:</p> \\[ \\mathbf{d}_B = - \\mathbf{B}^{-1} \\mathbf{A}_j. \\] <p>Hence, we have \\(\\mathbf{d} = \\left[-\\mathbf{B}^{-1} \\mathbf{A}_j, \\mathbf{e}_j \\right]\\), which is the \\(j\\)-th basic direction.</p>"},{"location":"optimization/linear_programming/simplex_method/#measure-the-cost-change","title":"Measure the Cost Change","text":"<p>The change of cost by moving along the \\(j\\)-th basic direction can be calculated as:</p> \\[ \\mathbf{c}^T (\\mathbf{x} + \\theta \\mathbf{d}) - \\mathbf{c}^T \\mathbf{x} = \\theta \\mathbf{c}^T \\mathbf{d} = \\theta \\left( \\mathbf{c}^T_B \\mathbf{d}_B + \\mathbf{c}^T_N \\mathbf{d}_N \\right) = \\theta \\left(-\\mathbf{c}^T_B \\mathbf{B}^{-1} \\mathbf{A}_j + c_j \\right) := \\theta \\bar{c}_j. \\] <p>Definition. Let \\(\\mathbf{x}\\) be a basic solution, let \\(\\mathbf{B}\\) be an associated basis matrix, and let \\(\\mathbf{c}_B\\) be the vector of costs of the basic variables. For each \\(j\\), we define the reduced cost \\(\\bar{c}_j\\) of the variable \\(x_j\\) to be \\(\\bar{c}_j = c_j - \\mathbf{c}^T_B \\mathbf{B}^{-1} \\mathbf{A}_j\\).</p> <p>\\(\\bar{c}_j\\) is the unit change of cost when me move along the \\(j\\)-th basic direction. Clearly, we would select the \\(j\\)-th basic direction only if \\(\\bar{c}_j &lt; 0\\), i.e., the cost reduces by going to the specified direction. This is the criterion for selecting a feasible direction from \\(n - m\\) possible feasible directions.</p> <p>Theorem (Optimality Conditions). Consider a basic feasible solution \\(\\mathbf{x}\\) associated with a basis matrix \\(\\mathbf{B}\\), and let \\(\\bar{\\mathbf{x}}\\) be the corresponding vector of reduced costs.</p> <p>1. If \\(\\bar{\\mathbf{c}} \\geq 0\\), then \\(\\mathbf{x}\\) is optimal.</p> <p>2. If \\(\\mathbf{x}\\) is optimal and nondegenerate, then \\(\\bar{\\mathbf{c}} \\geq 0\\).</p>"},{"location":"optimization/linear_programming/simplex_method/#find-the-step-length","title":"Find the Step Length","text":"<p>Once a basis direction is selected, i.e., \\(\\bar{c}_j &lt; 0\\) for some \\(j \\in N\\), we want to go along this direction as far as possible to maximize the cost reduction. We want to move until some basic variable \\(x_{B(l)}\\) becomes zero at \\(\\mathbf{x} + \\theta^* \\mathbf{d}\\), where:</p> \\[ \\theta^* := \\max \\left\\{ \\theta \\geq 0 \\ | \\ \\mathbf{x} + \\theta \\mathbf{d} \\in P \\right\\}. \\]"},{"location":"optimization/linear_programming/simplex_method/#arrive-at-an-adjacent-bfs","title":"Arrive at an Adjacent BFS","text":"<p>After moving by \\(\\theta^* \\mathbf{d}\\), we have \\(x_{B(l)} = 0\\), i.e., \\(x_{B(l)}\\) becomes a nonbasic variable. At the same time, \\(x_j = \\theta &gt; 0\\) becomes a basic variable. We may say that \\(x_j\\) enters the basis and \\(x_{B(l)}\\) leaves the basis. If we look at the initial basis matrix \\(\\mathbf{B}\\) and the new basis matrix \\(\\bar{\\mathbf{B}}\\), they only differ in one column:</p> \\[ \\begin{align} \\mathbf{B} &amp;= \\left[ \\mathbf{A}_{B(1)}, \\ldots, \\mathbf{A}_{B(l) - 1}, \\mathbf{A}_{B(l)}, \\mathbf{A}_{B(l) + 1}, \\ldots, \\mathbf{A}_{B(m)} \\right] \\in \\mathbb{R}^{m \\times m} \\\\ \\bar{\\mathbf{B}} &amp;= \\left[ \\mathbf{A}_{B(1)}, \\ldots, \\mathbf{A}_{B(l) - 1}, \\mathbf{A}_{B,j}, \\mathbf{A}_{B(l) + 1}, \\ldots, \\mathbf{A}_{B(m)} \\right] \\in \\mathbb{R}^{m \\times m} \\\\ \\end{align} \\] <p>Theorem. </p> <p>1. \\(\\bar{\\mathbf{B}}\\) is a basis matrix, that is, columns \\(\\mathbf{A}_{B(i)}, i \\neq l\\) and \\(\\mathbf{A}_j\\) are linearly independent.</p> <p>2. The vector \\(\\mathbf{y} = \\mathbf{x} + \\theta^* \\mathbf{d}\\) is a BFS associated with the basis matrix \\(\\bar{\\mathbf{B}}\\).</p>"},{"location":"optimization/linear_programming/simplex_method/#summary","title":"Summary","text":"<p>Algorithm: Simplex Method</p> <p>\\(\\quad\\)Step 1</p> <p>\\(\\quad\\) We start the simplex method with a BFS \\(\\mathbf{x}\\) and the associated basis consisting of the basis matrix  \\(\\quad\\) \\(\\mathbf{B} = \\left[ \\mathbf{A}_{B(1)}, \\ldots, \\mathbf{A}_{B(m)} \\right]\\), where \\(\\mathbf{A}_{B(i)}\\)'s are the basic columns of \\(\\mathbf{A}\\).   </p> <p>\\(\\quad\\)Step 2</p> <p>\\(\\quad\\) Compute the reduced cost \\(\\bar{c}_j = c_j - \\mathbf{c}^T_B \\mathbf{B}^{-1} \\mathbf{A}_j\\) for each nonbasic variable \\(x_j\\). There are two possibilities:  </p> <p>\\(\\quad\\) 2.1 If all the reduced costs are nonnegative, the current BFS is optimal, and the algorithm terminates  \\(\\quad\\) 2.2 Otherwise, select some \\(j\\) with \\(\\bar{c}_j &lt; 0\\), so \\(x_j\\) enters the basis   </p> <p>\\(\\quad\\)Step 3</p> <p>\\(\\quad\\) Compute \\(\\mathbf{d}_B = -\\mathbf{B}^{-1} \\mathbf{A}_j\\). There are two possibilities:</p> <p>\\(\\quad\\) 3.1 If \\(\\mathbf{d}_B \\geq 0\\), we know the optimal cost is \\(- \\infty\\), and the algorithm terminates  \\(\\quad\\) 3.2 Otherwise, if some entry of \\(\\mathbf{d}_B\\) is negative, continue to next step   </p> <p>\\(\\quad\\)Step 4</p> <p>\\(\\quad\\) If some entry of \\(\\mathbf{d}_B\\) is negative, compute the stepsize \\(\\theta^*\\) by the min-ratio test: \\(\\quad\\) \\(\\theta^* = \\min_{\\left\\{ i = 1, \\ldots, m \\ | \\ d_{B(i)} &lt; 0 \\right\\}} \\frac{x_{B(i)}}{-d_{B(i)}}\\).  \\(\\quad\\) Suppose the index \\(B(l)\\) achieves the minimum: \\(x_{B(l)}\\) exits the basis.</p> <p>\\(\\quad\\)Step 5</p> <p>\\(\\quad\\) Form the new basis matrix \\(\\bar{\\mathbf{B}}\\) by replacing \\(\\mathbf{A}_{B(l)}\\) column with \\(\\mathbf{A_j}\\). The new BFS \\(\\mathbf{y}\\) has basic variable part  \\(\\quad\\) \\(y_{B(i)} = x_{B(i)} + \\theta^* d_{B(i)}\\) and \\(y_j = \\theta^*\\). Start a new iteration.</p>"},{"location":"optimization/linear_programming/simplex_method/#degenerate-problems","title":"Degenerate Problems","text":"<p>Definition. A BFS of a standard for LP is said to be nondegenerate, if every basic variable is positive, i.e., \\(x_{B, i} &gt; 0\\) for all \\(i = 1, \\ldots, m\\). A BFS pf a standard form LP is said to be degenerate, if some basic variable \\(x_{B, i}\\) is zero.</p> <p>The simplex method introduced before moves by a positive amount \\(\\theta^* &gt; 0\\) along a direction \\(\\mathbf{d}\\), and no BFS can be visited twice if every BFS is non-degenerate. Since any polyhedron can only have a finite number of BFS, the algorithm must terminate after a finite number of iterations.</p> <p>Theorem (Correctness of the Simplex Method). If every BFS of a standard form LP is nondegenerate, then the simplex method always terminates in a finite number of steps, either:</p> <p>1. Finds an optimal solution \\(\\mathbf{x}_B = \\mathbf{B}^{-1} \\mathbf{b}\\) and \\(\\mathbf{x}_N = \\mathbf{0}\\), with the associated optimal basis matrix \\(\\mathbf{B}\\)</p> <p>2. Finds a direction \\(\\mathbf{d} = \\left[ \\mathbf{d}_B, \\mathbf{d}_N \\right]\\), such that \\(\\mathbf{A} \\mathbf{d} = \\mathbf{0}\\), \\(\\mathbf{d}_B \\geq 0\\), \\(\\mathbf{d_N} = \\left[ 0, \\ldots, 0, 1, 0, \\ldots, 0 \\right]^T\\) with \\(j\\)-th element being \\(1\\), \\(\\mathbf{c}^T \\mathbf{d} &lt; 0\\), and the optimal cost is \\(- \\infty\\).</p> <p>If not careful, the simplex method may run into cycles and never terminates.</p>"},{"location":"optimization/linear_programming/simplex_method/#blands-rule","title":"Bland's Rule","text":"<ol> <li> <p>Among all the eligible choices of nonbasic variables to enter the basis, select the one with the smallest subscript.</p> </li> <li> <p>Among all the eligible choices of basic variables to exit the basis, select the one with the smallest subscript.</p> </li> </ol> <p>For example, in an iteration of the simplex method, we have basic variables \\(\\mathbf{x}_B = (x_5 = 0, x_6 = 0, x_7 = 1)\\) and the reduced costs of the nonbasic variables \\(x_1, x_2, x_3, x_4\\) are \\((-1/2, 20, -3/4, 6)\\), respectively. Then, both \\(x_1\\) and \\(x_3\\) are candidates to enter the basis. Per Bland's rule, choose \\(x_1\\) to enter, which has smaller subscript than \\(x_3\\). Suppose the feasible direction is \\(\\mathbf{d} = -\\mathbf{B}^{-1} \\mathbf{A}_1 = (-1/4, -1/2, 0)\\). The min-ratio test has \\(\\theta^*  = \\min \\left\\{0/(1/4), 0/(1/2) \\right\\} = 0\\), so both \\(x_5\\) and \\(x_6\\) can exit. Per Bland's rule, pick \\(x_5\\).</p>"},{"location":"optimization/linear_programming/simplex_method/#phase-i-phase-ii-simplex-method","title":"Phase I/ Phase II Simplex Method","text":"<p>Finding a BFS is extremely challenging. In two-phase method, the first phase, Phase I, finds an initial BFS for a standard form LP, or detects the LP is infeasible. In the second phase, Phase II, it uses the initial BFS to start the simplex method.</p> <ol> <li> <p>For any standard form LP, we can always make the right-hand side vector \\(\\mathbf{b}\\) a nonnegative vector, i.e., \\(\\mathbf{b} \\geq 0\\) by multiplying \\(-1\\) to both sides of the \\(i\\)'th equality constraint if \\(b_i &lt; 0\\). We want to solve the standard form LP:</p> \\[ \\begin{align} \\min \\quad&amp; \\mathbf{c}^T \\mathbf{x} \\\\ \\text{s.t.} \\quad&amp; \\mathbf{A} \\mathbf{x} = \\mathbf{b} \\\\ \\quad&amp; \\mathbf{x} \\geq 0, \\end{align} \\] <p>where \\(\\mathbf{b} \\geq 0\\).</p> </li> <li> <p>Construct an auxiliary problem, which we call the Phase I LP:</p> \\[ \\begin{align} z^* = \\min \\quad&amp; y_1 + y_2 + \\ldots + y_m \\\\ \\text{s.t.} \\quad&amp; \\mathbf{A} \\mathbf{x} + \\mathbf{I} \\mathbf{y} = \\mathbf{b} \\\\ \\quad&amp; \\mathbf{x} \\geq 0, \\mathbf{y} \\geq 0. \\end{align} \\] <p>Here we introduce auxiliary variable \\(\\mathbf{y} = (y_1, \\ldots, y_m)\\), similar to the case where we introduce slack variables (but here the purpose is not to transform a LP into standard form, but to find an initial BFS to detect infeasibility).</p> <p>For this problem, we can easily find an initial BFS, namely \\(\\mathbf{x} = \\mathbf{0}, \\mathbf{y} = \\mathbf{b}\\). Hence, we can solve the Phase I LP using the simplex method starting with the BFS \\(\\mathbf{x} = \\mathbf{0}, \\mathbf{y} = \\mathbf{b}\\). After Phase I problem is solved, the optimal cost \\(z^*\\) has two possibilities: \\(z^* = 0\\) or \\(z^* &gt; 0\\).</p> <ol> <li> <p>If \\(z^* = 0\\), then the optimal solution \\(y^*_1, \\ldots, y^*_m\\) must be all zero, because each of \\(y^*_i \\geq 0\\) and their sum is zero. In this case, the \\(x\\)-variable part \\(\\mathbf{x}^* = (x^*_1, \\ldots, x^*_n)\\) is a feasible solution to the original problem, i.e., \\(\\mathbf{A} \\mathbf{x}^* = \\mathbf{b}\\) and \\(\\mathbf{x}^* \\geq 0\\). Furthermore, either \\(\\mathbf{x}^*\\) already contains all the basic variables, or after some simple operations, we can obtain a BFS to the original problem.</p> </li> <li> <p>If \\(z^* &gt; 0\\), then some \\(y^*_i &gt; 0\\). This shows the original problem is infeasible by the following theorem.</p> </li> </ol> <p>Theorem. The original LP is feasible if and only if \\(z^* = 0\\).</p> <p>Proof. If the original LP is feasible, there exists some \\(\\mathbf{x}^*\\) such that \\(\\mathbf{A} \\mathbf{x}^*\\) and \\(\\mathbf{x}^* \\geq 0\\). Then, \\(\\mathbf{x} = \\mathbf{x}^*, \\mathbf{y} = \\mathbf{0}\\) is also feasible for the Phase I problem. The cost associated with this solution is 0. However, since we know \\(z^* \\geq 0\\), this feasible solution is actually optimal, that is, we have \\(z^* = 0\\). For the other direction, if \\(z^* = 0\\), let the optimal solution of the Phase I problem be \\(\\mathbf{x}^*, \\mathbf{y}^*\\). Then \\(y^*_1, \\ldots, y^*_m = 0\\), therefore, \\(\\mathbf{A} \\mathbf{x}^* + \\mathbf{I} \\mathbf{y}^* = \\mathbf{b}\\) which implies \\(\\mathbf{A} \\mathbf{x}^* = \\mathbf{b}\\). We laso have \\(\\mathbf{x}^* \\geq 0\\), so the original problem is feasible.</p> </li> </ol> <p>In summary:</p> <p>Algorithm: Two Phase Simple Method</p> <p>\\(\\quad\\)Phase I</p> <p>\\(\\quad\\) Solve the Phase I LP. Denote the optimal cost as \\(z^*\\). We have to possibilities:</p> <p>\\(\\quad\\) 1. If \\(z^* &gt; 0\\), the original LP is infeasible. The algorithm terminates.  \\(\\quad\\) 2. If \\(z^* = 0\\), a feasible solution to the original LP is found, from which we can obtain a BFS for the original LP.    </p> <p>\\(\\quad\\)Phase II</p> <p>\\(\\quad\\) Solve the original LP by the simplex method, starting wit hthe BFS found in Phase I.</p>"},{"location":"optimization/linear_programming/simplex_method/#examples","title":"Examples","text":""},{"location":"optimization/linear_programming/simplex_method/#simplex-method-in-detail","title":"Simplex Method in Detail","text":"<p>Consider the following LP:</p> \\[ \\begin{align} \\max \\quad&amp; 2x_1 + 3x_2 \\\\ \\text{s.t.} \\quad&amp; -x_1 + x_2 \\leq 10 \\\\ \\quad&amp; 3x_1 + 2x_2 \\leq 60 \\\\ \\quad&amp; 2x_1 + 3x_2 \\leq 60 \\\\ \\quad&amp; x_1, x_2 \\geq 0. \\end{align} \\] <ol> <li> <p>The feasible region of this LP in \\(\\mathbb{R}^2\\) is shown in Figure 1.</p> <p> Figure 1 A simplex example </p> <p>The blue dots are BFSs. The green dots are basic solutions but not feasible. In total, there are 10 basic solutions.</p> </li> <li> <p>Transform the problem into a standard form LP (the simplex method works on standard form LP):</p> \\[ \\begin{align} \\min \\quad&amp; -2x_1 - 3x_2 \\\\ \\text{s.t.} \\quad&amp; -x_1 + x_2 + x_3 = 10 \\\\ \\quad&amp; 3x_1 + 2x_2 + x_4 = 60 \\\\ \\quad&amp; 2x_1 + 3x_2 + x_5 = 60 \\\\ \\quad&amp; x_1, x_2, x_3, x_4, x_5 \\geq 0. \\end{align} \\] <p>or in matrix form:</p> \\[ \\begin{align} \\min \\quad&amp; \\mathbf{c}^T \\mathbf{x} \\\\  \\text{s.t.} \\quad&amp; \\mathbf{A} \\mathbf{x} = \\mathbf{b} \\\\ \\quad&amp; \\mathbf{x} \\geq 0, \\end{align} \\] <p>where</p> \\[ \\mathbf{c} =  \\left[ \\begin{array}{c} -2 \\\\ -3 \\\\ 0 \\\\ 0 \\\\ 0 \\end{array} \\right], \\ \\mathbf{A} =  \\left[ \\begin{array}{ccccc} -1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 \\\\ 3 &amp; 2 &amp; 0 &amp; 1 &amp; 0 \\\\ 2 &amp; 3 &amp; 0 &amp; 0 &amp; 1 \\end{array} \\right], \\ \\mathbf{b} =  \\left[ \\begin{array}{c} 10 \\\\ 60 \\\\ 60 \\end{array} \\right] \\] </li> <li> <p>Start the simplex method:</p> <p>Iteration 1:</p> <ol> <li> <p>Choose a starting BFS: Select the basis \\(\\mathbf{B} = \\left[ \\mathbf{A}_3, \\mathbf{A}_4, \\mathbf{A}_5 \\right]\\). The corresponding basic solution is:</p> \\[ \\mathbf{x}_B =  \\left[ \\begin{array}{c} x_3 \\\\ x_4 \\\\ x_5  \\end{array} \\right] = \\mathbf{B}^{-1} \\mathbf{b} =  \\left[ \\begin{array}{c} 10 \\\\ 60 \\\\ 60 \\end{array} \\right], \\ \\mathbf{x}_N =  \\left[ \\begin{array}{c} x_1 \\\\ x_2 \\end{array} \\right] =  \\left[ \\begin{array}{c} 0 \\\\ 0 \\end{array} \\right], \\] <p>and the cost coefficients associated with the basic and nonbasic variables are:</p> \\[ \\mathbf{c}_B =  \\left[ \\begin{array}{c} c_3 \\\\ c_4 \\\\ c_5  \\end{array} \\right] =  \\left[ \\begin{array}{c} 0 \\\\ 0 \\\\ 0  \\end{array} \\right], \\ \\mathbf{c}_N =  \\left[ \\begin{array}{c} c_1 \\\\ c_2 \\end{array} \\right] =  \\left[ \\begin{array}{c} -2 \\\\ -3 \\end{array} \\right]. \\] <p>Since \\(\\mathbf{x}_B \\geq 0\\), the current basic solution is a BFS. Hence, we are ready to start the simplex method.</p> </li> <li> <p>Compute the reduced costs for nonbasic variables:</p> \\[ \\begin{align} \\bar{c}_1 = c_1 - \\mathbf{c}^T_B \\mathbf{B}^{-1} \\mathbf{A}_1 = -2 \\\\ \\bar{c}_2 = c_2 - \\mathbf{c}^T_B \\mathbf{B}^{-1} \\mathbf{A}_2 = -3 \\\\ \\end{align} \\] <p>Both \\(\\bar{c}_1\\) and \\(\\bar{c}_2\\) are negative. Therefore, the current BFS is not optimal, and both \\(x_1\\) and \\(x_2\\) are candidates to enter the basis, i.e., to increase to a positive value. Let us take \\(x_2\\) to enter the basis, and keep \\(x_1\\) at zero.</p> </li> <li> <p>Compute feasible direction \\(\\mathbf{d}\\):</p> <p>Since we decided to increase \\(x_2\\) and keep \\(x_1\\) at zero, the nonbasic variable part of the feasible direction \\(\\mathbf{d}_N\\) is \\(\\mathbf{d}_N = \\left[0, 1 \\right]^T\\), and the basic variable part of the feasible direction \\(\\mathbf{d}_B\\) is:</p> \\[ \\mathbf{d}_B = -\\mathbf{B}^{-1} \\mathbf{A}_2 = \\left[ \\begin{array}{c} -1 \\\\ -2 \\\\ -3 \\end{array} \\right] \\] <p>Since all components of \\(\\mathbf{d}_B\\) are negative, we do not have an unbounded optimal solution, and we need to decide how far to go along this direction while still remaining in the feasible region.</p> </li> <li> <p>Min-ratio test: By going along the previously calculated direction, we are going from the initial BFS \\(\\mathbf{x}\\) to a new point \\(\\mathbf{x} + \\theta \\mathbf{d}\\):</p> \\[ \\begin{align} \\mathbf{x} + \\theta \\mathbf{d} =  \\left[ \\begin{array}{c} \\mathbf{x}_B + \\theta \\mathbf{d}_B \\\\ \\mathbf{x}_N + \\theta \\mathbf{d}_N \\end{array} \\right] =  \\left[ \\begin{array}{c} x_{B, 1} + \\theta d_{B, 1} \\\\  x_{B, 2} + \\theta d_{B, 2} \\\\ x_{B, 3} + \\theta d_{B, 3} \\\\ x_1 + \\theta \\cdot 0 \\\\ x_2 + \\theta \\cdot 1 \\end{array} \\right] =  \\left[ \\begin{array}{c} x_3 + \\theta d_3 \\\\ x_4 + \\theta d_4 \\\\ x_5 + \\theta d_5 \\\\ x_1 \\\\ x_2 + \\theta \\end{array} \\right] =  \\left[ \\begin{array}{c} 10 - \\theta \\\\ 60 - 2\\theta \\\\ 60 - 3\\theta \\\\ 0 \\\\ \\theta \\end{array} \\right] \\end{align} \\] <p>To decide the largest \\(\\theta\\) such that \\(\\mathbf{x} + \\theta \\mathbf{d} \\geq 0\\), we need to do the min-ratio test:</p> \\[ \\theta^* = \\min_{\\left\\{ i = 1, \\ldots, m \\ | \\ d_{B, i} &lt; 0 \\right\\}} \\frac{x_{B, i}}{-d_{B, i}} = \\min \\left\\{\\frac{10}{1}, \\frac{60}{2}, \\frac{60}{3} \\right\\} = 10. \\] <p>Hence, \\(x_{B, 1} = x_3\\) exits the basis.</p> </li> <li> <p>The new basis: The new basis \\(\\bar{\\mathbf{B}} = \\left[ \\mathbf{A_2}, \\mathbf{A_4}, \\mathbf{A_5} \\right]\\), which differs from the original basis only in one column: \\(\\mathbf{A_3}\\) is replaced by \\(\\mathbf{A}_2\\), i.e., \\(x_3\\) exits the basis and \\(x_2\\) enters the basis. The new basic and nonbasic variables are:</p> \\[ \\mathbf{x}_{\\bar{B}} = \\left[ \\begin{array}{c} x_2 \\\\ x_4 \\\\ x_5  \\end{array} \\right] =  \\left[ \\begin{array}{c} 10 \\\\ 40 \\\\ 30  \\end{array} \\right], \\  \\mathbf{x}_{\\bar{N}} =  \\left[ \\begin{array}{c} x_1 \\\\ x_3 \\end{array} \\right] =  \\left[ \\begin{array}{c} 0 \\\\ 0 \\end{array} \\right]. \\] <p>Continue two the next iteration.</p> </li> </ol> <p>Iteration 2:</p> <ol> <li> <p>The new basis and its inverse are:</p> \\[ \\mathbf{B} = \\left[\\mathbf{A}_2, \\mathbf{A}_4, \\mathbf{A}_5 \\right] =  \\left[ \\begin{array}{ccc} 1 &amp; 0 &amp; 0 \\\\ 2 &amp; 1 &amp; 0 \\\\ 3 &amp; 0 &amp; 1 \\end{array} \\right], \\  \\mathbf{B}^{-1} =  \\left[ \\begin{array}{ccc} 1 &amp; 0 &amp; 0 \\\\ -2 &amp; 1 &amp; 0 \\\\ -3 &amp; 0 &amp; 1 \\end{array} \\right]. \\] <p>The cost coefficients associated with the basic and nonbasic variables are:</p> \\[ \\mathbf{c}_B =  \\left[ \\begin{array}{c} c_2 \\\\ c_4 \\\\ c_5  \\end{array} \\right] =  \\left[ \\begin{array}{c} -3 \\\\ 0 \\\\ 0  \\end{array} \\right], \\ \\mathbf{c}_N =  \\left[ \\begin{array}{c} c_1 \\\\ c_3 \\end{array} \\right] =  \\left[ \\begin{array}{c} -2 \\\\ 0 \\end{array} \\right]. \\] </li> <li> <p>Compute the reduced costs for nonbasic variables:</p> \\[ \\begin{align} \\bar{c}_1 = c_1 - \\mathbf{c}^T_B \\mathbf{B}^{-1} \\mathbf{A}_1 =  -2 -  \\left[  \\begin{array}{ccc} -3 &amp; 0 &amp; 0 \\end{array} \\right]  \\left[ \\begin{array}{ccc} 1 &amp; 0 &amp; 0 \\\\ -2 &amp; 1 &amp; 0 \\\\ -3 &amp; 0 &amp; 1 \\end{array} \\right] \\left[ \\begin{array}{ccc} -1 \\\\ 3 \\\\ 2 \\end{array} \\right] = -5 \\\\ \\bar{c}_2 = c_2 - \\mathbf{c}^T_B \\mathbf{B}^{-1} \\mathbf{A}_2 = 0 -  \\left[  \\begin{array}{ccc} -3 &amp; 0 &amp; 0 \\end{array} \\right]  \\left[ \\begin{array}{ccc} 1 &amp; 0 &amp; 0 \\\\ -2 &amp; 1 &amp; 0 \\\\ -3 &amp; 0 &amp; 1 \\end{array} \\right] \\left[ \\begin{array}{ccc} 1 \\\\ 0 \\\\ 0 \\end{array} \\right] = 3. \\\\ \\end{align} \\] <p>\\(\\bar{c}_1 &lt; 0\\), so the current BFS is not optimal, and \\(x_1\\) enters the basis.</p> </li> <li> <p>Compute feasible direction \\(\\mathbf{d}\\):</p> \\[ \\mathbf{d}_N =  \\left[ \\begin{array}{c} d_1 \\\\ d_3 \\end{array} \\right] =  \\left[ \\begin{array}{c} 1 \\\\ 0 \\end{array} \\right], \\ \\mathbf{d}_B = \\left[ \\begin{array}{c} d_2 \\\\ d_4 \\\\ d_5 \\end{array} \\right] = -\\mathbf{B}^{-1} \\mathbf{A}_1 = \\left[ \\begin{array}{ccc} 1 &amp; 0 &amp; 0 \\\\ -2 &amp; 1 &amp; 0 \\\\ -3 &amp; 0 &amp; 1 \\end{array} \\right] \\left[ \\begin{array}{c} -1 \\\\ 3 \\\\ 2 \\end{array} \\right] =  \\left[ \\begin{array}{c} 1 \\\\ -5 \\\\ -5 \\end{array} \\right]. \\] <p>Since some components of \\(\\mathbf{d}_B\\) are negative, we do not have an unbounded optimal solution.</p> </li> <li> <p>Min-ratio test: By going along the previously calculated direction, we are going from the initial BFS \\(\\mathbf{x}\\) to a new point \\(\\mathbf{x} + \\theta \\mathbf{d}\\):</p> \\[ \\mathbf{x}_B + \\theta \\mathbf{d}_B =  \\left[ \\begin{array}{c} 10 \\\\ 40 \\\\ 30 \\end{array} \\right] +  \\theta  \\left[ \\begin{array}{c} 1 \\\\ -5 \\\\ -5 \\end{array} \\right]. \\] <p>To decide the largest \\(\\theta\\) such that \\(\\mathbf{x} + \\theta \\mathbf{d} \\geq 0\\), we need to do the min-ratio test:</p> \\[ \\theta^* = \\min_{\\left\\{ i = 1, \\ldots, m \\ | \\ d_{B, i} &lt; 0 \\right\\}} \\frac{x_{B, i}}{-d_{B, i}} = \\min \\left\\{\\frac{40}{-(-5)}, \\frac{60}{2}, \\frac{30}{-(-5)} \\right\\} = 6. \\] <p>Hence, \\(x_{B, 3} = x_5\\) becomes zero and exits the basis.</p> </li> <li> <p>The new basis: The new basis matrix is \\(\\bar{\\mathbf{B}} = \\left[ \\mathbf{A_2}, \\mathbf{A_4}, \\mathbf{A_1} \\right]\\). The new nonbasis matrix is \\(\\bar{\\mathbf{B}} = \\left[ \\mathbf{A}_5, \\mathbf{A}_3 \\right]\\). The new BFS is:</p> \\[ \\mathbf{x}_{\\bar{B}} = \\left[ \\begin{array}{c} x_2 \\\\ x_4 \\\\ x_1  \\end{array} \\right] =  \\left[ \\begin{array}{c} 16 \\\\ 10 \\\\ 6  \\end{array} \\right], \\  \\mathbf{x}_{\\bar{N}} =  \\left[ \\begin{array}{c} x_5 \\\\ x_3 \\end{array} \\right] =  \\left[ \\begin{array}{c} 0 \\\\ 0 \\end{array} \\right]. \\] <p>To decide if this BFS is optimal, we need to start another iteration.</p> </li> </ol> <p>Iteration 3:</p> <ol> <li> <p>The new basis and its inverse are:</p> \\[ \\mathbf{B} = \\left[\\mathbf{A}_2, \\mathbf{A}_4, \\mathbf{A}_1 \\right] =  \\left[ \\begin{array}{ccc} 1 &amp; 0 &amp; -1 \\\\ 2 &amp; 1 &amp; 3 \\\\ 3 &amp; 0 &amp; 2 \\end{array} \\right], \\  \\mathbf{B}^{-1} =  \\left[ \\begin{array}{ccc} 0.4 &amp; 0 &amp; 0.2 \\\\ 1 &amp; 1 &amp; -1 \\\\ -0.6 &amp; 0 &amp; 0.2 \\end{array} \\right]. \\] <p>The cost coefficients associated with the basic and nonbasic variables are:</p> \\[ \\mathbf{c}_B =  \\left[ \\begin{array}{c} c_2 \\\\ c_4 \\\\ c_1  \\end{array} \\right] =  \\left[ \\begin{array}{c} -3 \\\\ 0 \\\\ -2  \\end{array} \\right], \\ \\mathbf{c}_N =  \\left[ \\begin{array}{c} c_5 \\\\ c_3 \\end{array} \\right] =  \\left[ \\begin{array}{c} 0 \\\\ 0 \\end{array} \\right]. \\] </li> <li> <p>Compute the reduced costs for nonbasic variables:</p> \\[ \\begin{align} \\bar{c}_5 &amp;= c_5 - \\mathbf{c}^T_B \\mathbf{B}^{-1} \\mathbf{A}_5 =  -0 -  \\left[  \\begin{array}{ccc} -3 &amp; 0 &amp; -2 \\end{array} \\right]  \\left[ \\begin{array}{ccc} 0.4 &amp; 0 &amp; 0.2 \\\\ 1 &amp; 1 &amp; -1 \\\\ -0.6 &amp; 0 &amp; 0.2 \\end{array} \\right] \\left[ \\begin{array}{ccc} 0 \\\\ 0 \\\\ 1 \\end{array} \\right] = 1 \\\\ \\bar{c}_3 &amp;= c_3 - \\mathbf{c}^T_B \\mathbf{B}^{-1} \\mathbf{A}_3 = 0 -  \\left[  \\begin{array}{ccc} -3 &amp; 0 &amp; -2 \\end{array} \\right]  \\left[ \\begin{array}{ccc} 0.4 &amp; 0 &amp; 0.2 \\\\ 1 &amp; 1 &amp; -1 \\\\ -0.6 &amp; 0 &amp; 0.2 \\end{array} \\right] \\left[ \\begin{array}{ccc} 1 \\\\ 0 \\\\ 0 \\end{array} \\right] = 0. \\\\ \\end{align} \\] <p>Since all the reduced costs are nonnegative, the current BFS is optimal. The final optimal solution is:</p> \\[ \\mathbf{x} =  \\left[ \\begin{array} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\\\ x_5  \\end{array} \\right] =  \\left[ \\begin{array} 6 \\\\ 16 \\\\ 0 \\\\ 10 \\\\ 0  \\end{array} \\right]. \\] </li> </ol> </li> </ol> <p>We started at the initial BFS \\((x_1, x_2, x_3, x_4, x_5) = (0, 0, 10, 60, 60)\\), which corresponds to the origin \\((x_1, x_2) = (0, 0)\\) in Figure 2. After the first iteration, we moved to a new BFS \\((x_1, x_2, x_3, x_4, x_5) = (0, 10, 0, 40, 30)\\), which is the extreme point \\((x_1, x_2) = (0, 10)\\) on the \\(x_2\\) axis. We decided that this is not an optimal solution, and continued with iteration. This time, we reached the BFS \\((x_1, x_2, x_3, x_4, x_5) = (6, 16, 0, 10, 30)\\), which corresponds to \\((x_1, x_2) = (6, 16)\\) on the graph, which is the optimal solution. </p> <p> </p> Figure 1 A simplex trajectory"},{"location":"optimization/linear_programming/simplex_method/#two-phase-simplex-method","title":"Two-Phase Simplex Method","text":"<p>Consider LP problem:</p> \\[ \\begin{align} \\min \\quad&amp; x_1 + 3x_2 + 2x_3 \\\\ \\text{s.t.} \\quad&amp; x_1 + 2x_2 + x_3 \\\\ \\quad&amp; -x_1 + 2x_2 - 6x_4 = 2 \\\\ \\quad&amp; x_1, x_2, x_3, x_4 \\geq 0. \\end{align} \\] <p>The Phase I problem is formulated as:</p> \\[ \\begin{align} \\min \\quad&amp; y_1 + y_2 \\\\ \\text{s.t.} \\quad&amp; x_1 + 2x_2 + x_3 + y_1 = 3\\\\ \\quad&amp; -x_1 + 2x_2 - 6x_4 + y_2 = 2 \\\\ \\quad&amp; x_1, x_2, x_3, x_4, y_1, y_2 \\geq 0. \\end{align} \\] <p>We can choose \\((y_1, y_2)\\) to be the basic variables, which gives the BFS \\((x_1 = 0, x_2 = 0, x_3 = 0, x_4 = 0, y_1 = 3, y_2 = 2)\\). Then, we can start the simplex method to solve the Phase I problem. The optimal solution to the Phase I problem is \\(\\mathbf{x}^* = (0, 3/2, 0, 1/6)\\) and \\(\\mathbf{y}^* = (0, 0)\\). The \\(\\mathbf{x}\\) variable part is a BFS for the original LP, with basic variables \\((x_2 = 3/2, x_4 = 1/6)\\), and nonbasic variables \\((x_1 = 0, x_3 =0)\\).</p>"},{"location":"optimization/nonlinear_programming/least_squares/","title":"Least Squares","text":""},{"location":"optimization/nonlinear_programming/least_squares/#polynomial-fitting","title":"Polynomial Fitting","text":"<p>Suppose we have \\(m\\) pairs of data points \\((a_1, \\ b_1), \\ldots, (a_m, \\ b_m)\\) and we'd like to fit a cubic polynomial:</p> \\[ p(a) = b = x_0 + x_1 a + x_2 a^2 + x_3 a^3. \\] <p>Let \\(\\mathbf{x} = \\left[\\begin{array}{ccc} x_0 &amp; \\ldots &amp; x_3 \\end{array} \\right]\\) be the coefficients of \\(p(a)\\). The residual can be written as:</p> \\[ \\begin{align} r(\\mathbf{x}) &amp;=  \\left[ \\begin{array}{c} p(a_1) - b_1 \\\\ \\vdots \\\\ p(a_m) - b_m \\end{array} \\right] =  \\left[ \\begin{array}{c} p(a_1) \\\\ \\vdots \\\\ p(a_m) \\end{array} \\right] -  \\left[ \\begin{array}{c} b_1 \\\\ \\vdots \\\\ b_m \\end{array} \\right] =  \\left[ \\begin{array}{c} x_0 + x_1 a_1 + x_2 a^2_1 + x_3 a^3_1 \\\\ \\vdots \\\\ x_0 + x_1 a_m + x_2 a^2_m + x_3 a^3_m \\end{array} \\right] -  \\left[ \\begin{array}{c} b_1 \\\\ \\vdots \\\\ b_m \\end{array} \\right] \\\\  &amp;=  \\left[ \\begin{array}{cccc} 1 &amp; a_1 &amp; a^2_1 &amp; a^3_1 \\\\ \\vdots &amp; \\ddots &amp; \\ddots &amp; \\vdots \\\\ 1 &amp; a_m &amp; a^2_m &amp; a^3_m \\end{array} \\right] \\left[ \\begin{array}{c} x_0 \\\\ x_1 \\\\ x_2 \\\\ x_3 \\end{array} \\right] -  \\left[ \\begin{array}{c} b_1 \\\\ \\vdots \\\\ b_m \\end{array} \\right] \\\\ &amp;= \\mathbf{A} \\mathbf{x} - \\mathbf{b}. \\end{align} \\] <p>The matrix \\(\\mathbf{A}\\) is called the Vandermonde matrix.</p>"},{"location":"optimization/unconstrained_optimization/gauss_newton_method/","title":"Gauss-Netwon Method","text":""},{"location":"optimization/unconstrained_optimization/gauss_newton_method/#general-descent-methods","title":"General Descent Methods","text":"<p>The basic paradigm of descent methods is as follows:</p> <p>Algorithm: Descent Methods </p> <p>\\(\\quad\\) Choose an initial solution \\(\\mathbf{x}^0\\).  \\(\\quad\\) Choose a descent direction \\(\\mathbf{d}^0\\).  \\(\\quad\\) Choose a step size \\(\\alpha_0\\).  \\(\\quad\\) Update the solution \\(\\mathbf{x}^1 = \\mathbf{x}^0 + \\alpha_0 \\mathbf{d}^0\\).  \\(\\quad\\) If a stopping criteria is met, stop; else re-iterate with current solution.   </p>"},{"location":"optimization/unconstrained_optimization/gauss_newton_method/#gauss-newton-method","title":"Gauss-Newton Method","text":"<p>Let \\(\\mathbf{x}^k\\) be the current iterate and consider a second-order Taylor series of \\(f(\\mathbf{x})\\) at \\(\\mathbf{x}^k\\), \\(g(\\mathbf{x})\\):</p> \\[ g(\\mathbf{x}) = f(\\mathbf{x}^k) + \\nabla f(\\mathbf{x}^k)^T (\\mathbf{x} - \\mathbf{x}^k) + \\frac{1}{2}(\\mathbf{x} - \\mathbf{x}^k) \\nabla^2  f(\\mathbf{x}^k) (\\mathbf{x} - \\mathbf{x}^k). \\] <p>In Newton's method, we choose the next iterate as the solution that minimizes the approximate function \\(g(\\mathbf{x})\\). Setting \\(\\nabla g(\\mathbf{x}) = \\mathbf{0}\\) yields to a linear system:</p> \\[ \\nabla f(\\mathbf{x}^k) + \\nabla^2 f(\\mathbf{x}^k) (\\mathbf{x} - \\mathbf{x}^k) = 0. \\] <p>If the Hessian is non-singular, a solution to the above system is well-defined. The update for next iteration is then:</p> \\[ \\mathbf{x}^{k + 1} = \\mathbf{x}^k - \\left[ \\nabla^2 f(\\mathbf{x}^k) \\right]^{-1} \\nabla f(\\mathbf{x}^k). \\] <p>In this case, the improving direction is:</p> \\[ \\mathbf{d}^k = -\\left[ \\nabla^2 f(\\mathbf{x}^k) \\right]^{-1} \\nabla f(\\mathbf{x}^k) \\] <p>and a step size of \\(\\alpha = 1\\).</p>"},{"location":"optimization/unconstrained_optimization/gauss_newton_method/#newtons-method-single-iteration-example","title":"Newton's Method Single Iteration Example","text":"<p>Let \\(\\mathbf{x} = \\left[x_1, x_2 \\right]^T\\). We are interested in the optimization problem:</p> \\[ \\min f(\\mathbf{x}) = (x_1 + 1)^4 + x_1 x_2  + (x_2 + 1)^4.  \\] <p>To solve it with the Newton's method:</p> <ol> <li>Choose initial conditions \\(\\mathbf{x}^0 = \\left[0, 1 \\right]^T\\). The initial cost is \\(f(\\mathbf{x}^0) = 17.0\\)</li> <li> <p>The gradient is:</p> \\[ \\nabla f(\\mathbf{x}) = \\left[ \\begin{array}{c} 4(x_1 + 1)^3 + x_2 \\\\ x_1 + 4(x_2 + 1)^3 \\end{array} \\right]. \\] <p>The Hessian is:</p> \\[ \\nabla^2 f(\\mathbf{x}) =  \\left[ \\begin{array}{cc} 12(x_1 + 1)^2 &amp; 1 \\\\ 1 &amp; 12(x_2 + 1) \\end{array} \\right]. \\] <p>Evaluating the gradient at \\(\\mathbf{x}^0\\), we get \\(\\nabla f(\\mathbf{x}^0) = \\left[5, 32 \\right]^T\\).</p> <p>Evaluating the Hessian at \\(\\mathbf{x}^0\\), we get \\(\\nabla^2 f(\\mathbf{x}^0) = \\left[\\begin{array}{cc}12 &amp; 1 \\\\ 1 &amp; 48 \\end{array} \\right]\\)</p> </li> <li> <p>The next iterate is then \\(\\mathbf{x}^1 = \\left[ -0.3617, 0.3409 \\right]^T\\) and \\(f(\\mathbf{x}^1) = 3.2755\\).</p> </li> </ol>"},{"location":"optimization/unconstrained_optimization/gauss_newton_method/#newtons-method-characteristics","title":"Newton's Method Characteristics","text":"<ol> <li> <p>If we start close to a local minimum and the Hessian is positive definite, then Newton's method has a quadratic convergence. </p> </li> <li> <p>In general, Newton's method does not guarantee to converge. The direction may not be improving at all. For example, if we start     from \\(\\mathbf{x}^0 = \\left[ -1, 1 \\right]^T\\) with \\(f(\\mathbf{x}^0) = 15\\), the next iterate is \\(\\mathbf{x}^1 = \\left[ -2, 18 \\right]\\) with \\(f(\\mathbf{x}^1) = 130286\\).</p> </li> <li> <p>If the Hessian is singular (or ill-conditioned), Newton's method will halt.</p> </li> <li> <p>Computing gradient and Hessian (and its inverse) is computationally expensive.</p> </li> </ol>"},{"location":"optimization/unconstrained_optimization/golden_section/","title":"Golden Section","text":"<p>Golden section method is a derivative-free method designed for univariate functions. </p> <p>Algorithm: Golden Section</p> <p>Start with an initial inverval \\(\\left[ x_l, x_u \\right]\\) containing the minima and successively narrow this interval.</p> <p>\\(\\quad\\) 0. Set \\(x_1 = x_u - \\alpha(x_u - x_l)\\) and \\(x_2 = x_l + \\alpha(x_u - x_l)\\). Compute \\(f(x)\\) at \\(x_l, x_1, x_2, x_u\\).  \\(\\quad\\) 1. If \\((x_u - x_l) \\leq \\epsilon\\), stop and return \\(x^* = 0.5 (x_l + x_u)\\) as the minima.  \\(\\quad\\) 2. If \\(f(x_1) &lt; f(x_2)\\), set \\(x_u \\leftarrow x_2\\), \\(x_2 \\leftarrow x_1\\), and \\(x_1 \\leftarrow x_u - \\alpha (x_u - x_l)\\). Evaluate \\(f(x_1)\\).  \\(\\quad\\quad\\)Else, set \\(x_l \\leftarrow x_1\\), \\(x_1 \\leftarrow x_2\\), and \\(x_2 \\leftarrow x_l + \\alpha(x_u - x_l)\\). Evaluate \\(f(x_2)\\). Go to step 1.   </p> <p>Use \\(\\alpha = 0.618\\), the Golden Ratio.</p>"},{"location":"optimization/unconstrained_optimization/gradient_descent/","title":"Gradient Desent","text":""},{"location":"optimization/unconstrained_optimization/gradient_descent/#general-descent-methods","title":"General Descent Methods","text":"<p>The basic paradigm of descent methods is as follows:</p> <p>Algorithm: Descent Methods </p> <p>\\(\\quad\\) Choose an initial solution \\(\\mathbf{x}^0\\).  \\(\\quad\\) Choose a descent direction \\(\\mathbf{d}^0\\).  \\(\\quad\\) Choose a step size \\(\\alpha_0\\).  \\(\\quad\\) Update the solution \\(\\mathbf{x}^1 = \\mathbf{x}^0 + \\alpha_0 \\mathbf{d}^0\\).  \\(\\quad\\) If a stopping criteria is met, stop; else re-iterate with current solution.   </p>"},{"location":"optimization/unconstrained_optimization/gradient_descent/#gradient-descent","title":"Gradient Descent","text":"<p>The gradient descent method moves from one iteration to the next by moving along the negative of the gradient direction in order to mnimize the  objective function. Let \\(\\mathbf{x}^k\\) be the current iterate, and we want to choose a \"downhill direction\", \\(\\mathbf{d}^k\\), and a step size, \\(\\alpha\\), such that:</p> \\[ f(\\mathbf{x}^k + \\alpha \\mathbf{d}^k) &lt; f(\\mathbf{x}^k). \\] <p>By first-order Taylor series:</p> \\[ f(\\mathbf{x}^k + \\alpha \\mathbf{d}^k) \\approx f(\\mathbf{x}^k) + \\alpha \\nabla f(\\mathbf{x}^k)^T \\mathbf{d}^k. \\] <p>Hence, we want \\(\\alpha \\nabla f(\\mathbf{x}^k)^T \\mathbf{d}^k &lt; 0\\). The steepest descent direction is the opposite direction of the gradient vector:</p> \\[ \\mathbf{d}^k = -\\nabla f(\\mathbf{x}^k). \\] <p>For choosing the step size (or learning rate), we can do:</p> <ol> <li>Line search - Define \\(g(\\alpha) := f(\\mathbf{x}^k + \\alpha \\mathbf{d}^k)\\). Choose \\(\\alpha\\) to minimze \\(g\\).</li> <li>Fixed step size - Fix \\(\\alpha\\) a priori (may not converge if \\(\\alpha\\) is too large) </li> </ol> <p>The next iteration can be computed as:</p> \\[ \\mathbf{x}^{k + 1} = \\mathbf{x}^k - \\alpha \\nabla f(\\mathbf{x}^k). \\] <p>The stop criterian is \\(|| \\nabla f(\\mathbf{x}^k)|| \\leq \\epsilon\\).</p>"},{"location":"optimization/unconstrained_optimization/gradient_descent/#gradient-descent-single-iteration-example","title":"Gradient Descent Single Iteration Example","text":"<p>Let \\(\\mathbf{x} = \\left[x_1, x_2 \\right]^T\\). We are interested in the optimization problem:</p> \\[ \\min f(\\mathbf{\\mathbf{x}}) = (x_1 + 1)^4 + x_1 x_2  + (x_2 + 1)^4. xw \\] <p>To solve it with a gradient descent method:</p> <ol> <li>Choose initial conditions \\(\\mathbf{x}^0 = \\left[0, 1 \\right]^T\\). The initial cost is \\(f(\\mathbf{x}^0) = 17.0\\).</li> <li> <p>The gradient is:</p> \\[ \\nabla f(\\mathbf{x}) = \\left[ \\begin{array}{c} 4(x_1 + 1)^3 + x_2 \\\\ x_1 + 4(x_2 + 1)^3 \\end{array} \\right]. \\] <p>Evaluating the gradient at \\(\\mathbf{x}^0\\), we get \\(\\nabla f(\\mathbf{x^0}) = \\left[5, 32 \\right]^T\\)</p> </li> <li> <p>The next iterate can be computed as:</p> \\[ \\begin{align} \\mathbf{x}^1 &amp;= \\mathbf{x}^0 - \\alpha \\nabla f(\\mathbf{x}^0) \\\\ &amp;=  \\left[ \\begin{array}{c} -5 \\alpha \\\\ 1 - 32\\alpha \\end{array} \\right] \\end{align} \\] <p>Using the line search method, we get:</p> \\[ \\begin{align} g(\\alpha) = f(\\mathbf{x}^1) = &amp;(-5\\alpha + 1)^4 - 5 \\alpha (1 - 32 \\alpha) \\\\ + (1 - 32 \\alpha + 1)^4. \\end{align} \\] <p>Minimizing \\(g(\\alpha)\\) results in \\(\\alpha = 0.0527\\). </p> </li> <li> <p>Substituting back, we get \\(\\mathbf{x}^1 = \\left[-0.2635, -0.6864 \\right]^T\\) and \\(f(\\mathbf{x}^1) = 0.4848\\).</p> </li> </ol>"},{"location":"optimization/unconstrained_optimization/gradient_descent/#gradient-descent-characteristics","title":"Gradient Descent Characteristics","text":"<ol> <li> <p>At any point \\(\\mathbf{x}^k\\) with \\(\\nabla f(\\mathbf{x}^k) \\neq 0\\), the gradient descent produces the most rapid convergence (locally).</p> </li> <li> <p>Initial progress is good, but near a stationary point, the convergence behavior degrades.</p> </li> <li> <p>\"Zig-zags\", i.e., each successive direction (of move) is perpendicular to the previous direction. Let \\(\\mathbf{d}^k\\) be the descent direction and      \\(\\alpha_k\\) be the optimum step length at step \\(k\\), i.e.,      \\(0 = \\frac{dg(\\alpha)}{d \\alpha}|_{\\alpha = \\alpha_k} = \\nabla f(\\mathbf{x}^k + \\alpha_k \\mathbf{d}^k)^T \\mathbf{d}^k = \\nabla f(\\mathbf{x}^{k + 1})^T \\mathbf{d}^k\\). </p> <p>Since \\(\\mathbf{d}^{k + 1} = - \\nabla f(\\mathbf{x}^{k + 1})\\), we have that \\(\\left( \\mathbf{d}^{k + 1} \\right)^T \\mathbf{d}^k = 0\\), i.e., two successive directions are perpendicular.</p> </li> </ol>"},{"location":"optimization/unconstrained_optimization/levernberg_marquatdt_method/","title":"Levernberg-Marquatdt Method","text":""},{"location":"optimization/unconstrained_optimization/levernberg_marquatdt_method/#definition","title":"Definition","text":"<p>The approximate second-order Taylor series used in the Gauss-Newton method can only have a good approximation effect near the expansion point. Naturally, it makes sense to have a range added to \\(\\Delta \\mathbf{x}\\), called the trust-region. This range defines under what circumstances the second-order approximation is valid. This type of method is called the trust-region method.</p> <p>To determine the trust-region, we can compute the difference between our approximate model and the real object function such that if the difference is small, the approximation is good and we may expand the trust-region; conversely, if the difference is large, the range of approximation will be reduced. Define an indicator \\(\\rho\\) to describe the degree of approximation:</p> \\[ \\rho = \\frac{f(\\mathbf{x} + \\Delta \\mathbf{x}) - f(\\mathbf{x})}{\\mathbf{J}^T(\\mathbf{x}) \\Delta \\mathbf{x}}. \\] <p>The numerator of \\(\\rho\\) is the decreasing value of the real object function, and the denominator is the decreasing value of the approximate model. If \\(\\rho\\) is close to 1, the approximation is valid. A small \\(\\rho\\) indicates that the actual reduced value is far less than the approximate reduced value. The approximation is poor and the trust-region should be reduced in this case. Conversely, if \\(\\rho\\) is relatively large, the actual decline is greater than expected, and the approximate range can be enlargened. This is an improved version of the Gauss-Newton method.</p> <p>Improved Gauss-Newton Method</p> <ol> <li>Set an initial value \\(\\mathbf{x}_0\\) and initial trust-region radius \\(\\mu\\).</li> <li>For \\(k\\)-th iteration, solve a linear problem based on Gauss-Newton method with a trust-region constraint:</li> </ol> \\[ \\begin{align} \\min_{\\Delta \\mathbf{x}_k} \\frac{1}{2} &amp;||f(\\mathbf{x}_k) + \\mathbf{J}^T(\\mathbf{x}_k) \\Delta \\mathbf{x}_k||^2 \\\\ \\quad&amp; \\text{s.t.} ||\\mathbf{D} \\Delta \\mathbf{x}_k||^2 \\leq \\mu, \\end{align} \\] <p>where \\(\\mu\\) is the radius and \\(\\mathbf{D}\\) is a coefficient matrix. 3. Compute \\(\\rho\\). 4. If \\(\\rho &gt; \\frac{3}{4}\\), set \\(\\mu = 2 \\mu\\). Otherwise, if \\(\\rho &lt; \\frac{1}{4}\\), set \\(\\mu = 0.5 \\mu\\). 5. If \\(\\rho\\) is larger than a given threshold, set \\(\\mathbf{x}_{k + 1} = \\mathbf{x}_k + \\Delta \\mathbf{x}_k\\). 6. Repeat from step 2 if not converged, else end.</p>"},{"location":"optimization/unconstrained_optimization/nelder_mead_method/","title":"Nelder-Mead Method","text":"<p>Nelder-Mead method fit is a derivative-free method designed for multivariate functions. Consider an optimization problem:</p> \\[ \\min \\quad \\left\\{f(\\mathbf{x}) \\ | \\ \\mathbf{x} \\in \\mathbb{R}^n \\right\\}. \\] <p>Each iteration maintains an ordered set of \\(n + 1\\) solution points, i.e., at iteration \\(k\\), the solution points are labeled \\(\\mathbf{x}^k_1, \\ldots, \\mathbf{x}^k_{n + 1}\\) such that:</p> \\[ f(\\mathbf{x}^k_1) \\leq f(\\mathbf{x}^k_2) \\leq \\ldots \\leq f(\\mathbf{x}^k_{n + 1}). \\] <p>Each iteration requires function evaluations and sorting. Nelder-Mead method doesn't have a formal convergence theory but works well in practice.</p> <p>Algorithm: Nelder-Mead Method </p> <p>\\(\\quad\\) 0. Choose \\(n + 1\\) distinct solution points \\(\\mathbf{x}^k_1, \\ldots, \\mathbf{x}^k_{n + 1}\\). Set the iteration counter \\(k = 0\\).  \\(\\quad\\) 1. Order the solution points. Compute the best \\(n\\)-centroid \\(\\bar{\\mathbf{x}}^k = (1 / n) \\sum^n_{i = 1} \\mathbf{x}^k_i\\).  \\(\\quad\\) 2. If \\(\\sum^n_{i = 1} |f(\\mathbf{x}^k_i) - f(\\bar{\\mathbf{x}}^k)| &lt; \\epsilon\\), terminate and report the better of \\(\\mathbf{x}^k_1\\) and \\(\\bar{\\mathbf{x}}^k\\).  \\(\\quad\\) 3. Try to find a better solution point \\(\\mathbf{x}^k_b\\) along the direction \\((\\bar{\\mathbf{x}}^k - \\mathbf{x}^k_{n + 1})\\) using various rules. If we find one, replace  \\(\\quad\\quad\\) \\(\\mathbf{x}^k_{n + 1}\\) by \\(\\mathbf{x}^k_b\\), update \\(k \\leftarrow k + 1\\) and go to Step 1.  \\(\\quad\\) 4. Shrink the current solution set towards the best solution \\(\\mathbf{x}^k_1\\) by \\(\\mathbf{x}^{k + 1}_i \\leftarrow 0.5 (\\mathbf{x}^k_1 + \\mathbf{x}^k_i)\\) \\(\\quad\\quad\\) for all \\(i = 1, \\ldots, n + 1\\). Update \\(k\\) and go to Step 1.   </p> <p>Refer to Nelder-Mead method.</p>"},{"location":"optimization/unconstrained_optimization/newton_method/","title":"Newton's Method","text":""},{"location":"optimization/unconstrained_optimization/newton_method/#general-descent-methods","title":"General Descent Methods","text":"<p>The basic paradigm of descent methods is as follows:</p> <p>Algorithm: Descent Methods </p> <p>\\(\\quad\\) Choose an initial solution \\(\\mathbf{x}^0\\).  \\(\\quad\\) Choose a descent direction \\(\\mathbf{d}^0\\).  \\(\\quad\\) Choose a step size \\(\\alpha_0\\).  \\(\\quad\\) Update the solution \\(\\mathbf{x}^1 = \\mathbf{x}^0 + \\alpha_0 \\mathbf{d}^0\\).  \\(\\quad\\) If a stopping criteria is met, stop; else re-iterate with current solution.   </p>"},{"location":"optimization/unconstrained_optimization/newton_method/#newtons-method","title":"Newton's Method","text":"<p>Let \\(\\mathbf{x}^k\\) be the current iterate and consider a second-order Taylor series of \\(f(\\mathbf{x})\\) at \\(\\mathbf{x}^k\\), \\(g(\\mathbf{x})\\):</p> \\[ g(\\mathbf{x}) = f(\\mathbf{x}^k) + \\nabla f(\\mathbf{x}^k)^T (\\mathbf{x} - \\mathbf{x}^k) + \\frac{1}{2}(\\mathbf{x} - \\mathbf{x}^k) \\nabla^2  f(\\mathbf{x}^k) (\\mathbf{x} - \\mathbf{x}^k). \\] <p>In Newton's method, we choose the next iterate as the solution that minimizes the approximate function \\(g(\\mathbf{x})\\). Setting \\(\\nabla g(\\mathbf{x}) = \\mathbf{0}\\) yields to a linear system:</p> \\[ \\nabla f(\\mathbf{x}^k) + \\nabla^2 f(\\mathbf{x}^k) (\\mathbf{x} - \\mathbf{x}^k) = 0. \\] <p>If the Hessian is non-singular, a solution to the above system is well-defined. The update for next iteration is then:</p> \\[ \\mathbf{x}^{k + 1} = \\mathbf{x}^k - \\left[ \\nabla^2 f(\\mathbf{x}^k) \\right]^{-1} \\nabla f(\\mathbf{x}^k). \\] <p>In this case, the improving direction is:</p> \\[ \\mathbf{d}^k = -\\left[ \\nabla^2 f(\\mathbf{x}^k) \\right]^{-1} \\nabla f(\\mathbf{x}^k) \\] <p>and a step size of \\(\\alpha = 1\\).</p>"},{"location":"optimization/unconstrained_optimization/newton_method/#newtons-method-single-iteration-example","title":"Newton's Method Single Iteration Example","text":"<p>Let \\(\\mathbf{x} = \\left[x_1, x_2 \\right]^T\\). We are interested in the optimization problem:</p> \\[ \\min f(\\mathbf{x}) = (x_1 + 1)^4 + x_1 x_2  + (x_2 + 1)^4.  \\] <p>To solve it with the Newton's method:</p> <ol> <li>Choose initial conditions \\(\\mathbf{x}^0 = \\left[0, 1 \\right]^T\\). The initial cost is \\(f(\\mathbf{x}^0) = 17.0\\)</li> <li> <p>The gradient is:</p> \\[ \\nabla f(\\mathbf{x}) = \\left[ \\begin{array}{c} 4(x_1 + 1)^3 + x_2 \\\\ x_1 + 4(x_2 + 1)^3 \\end{array} \\right]. \\] <p>The Hessian is:</p> \\[ \\nabla^2 f(\\mathbf{x}) =  \\left[ \\begin{array}{cc} 12(x_1 + 1)^2 &amp; 1 \\\\ 1 &amp; 12(x_2 + 1) \\end{array} \\right]. \\] <p>Evaluating the gradient at \\(\\mathbf{x}^0\\), we get \\(\\nabla f(\\mathbf{x}^0) = \\left[5, 32 \\right]^T\\).</p> <p>Evaluating the Hessian at \\(\\mathbf{x}^0\\), we get \\(\\nabla^2 f(\\mathbf{x}^0) = \\left[\\begin{array}{cc}12 &amp; 1 \\\\ 1 &amp; 48 \\end{array} \\right]\\)</p> </li> <li> <p>The next iterate is then \\(\\mathbf{x}^1 = \\left[ -0.3617, 0.3409 \\right]^T\\) and \\(f(\\mathbf{x}^1) = 3.2755\\).</p> </li> </ol>"},{"location":"optimization/unconstrained_optimization/newton_method/#newtons-method-characteristics","title":"Newton's Method Characteristics","text":"<ol> <li> <p>If we start close to a local minimum and the Hessian is positive definite, then Newton's method has a quadratic convergence. </p> </li> <li> <p>In general, Newton's method does not guarantee to converge. The direction may not be improving at all. For example, if we start     from \\(\\mathbf{x}^0 = \\left[ -1, 1 \\right]^T\\) with \\(f(\\mathbf{x}^0) = 15\\), the next iterate is \\(\\mathbf{x}^1 = \\left[ -2, 18 \\right]\\) with \\(f(\\mathbf{x}^1) = 130286\\).</p> </li> <li> <p>If the Hessian is singular (or ill-conditioned), Newton's method will halt.</p> </li> <li> <p>Computing gradient and Hessian (and its inverse) is computationally expensive.</p> </li> </ol>"},{"location":"optimization/unconstrained_optimization/optimality_conditions/","title":"Optimality Conditions","text":""},{"location":"optimization/unconstrained_optimization/optimality_conditions/#problem-statement","title":"Problem Statement","text":"<p>We are interested in solving unconstrained optimization problem:</p> \\[ \\min \\quad f(\\mathbf{x}) \\ \\text{s.t.} \\ \\mathbf{x} \\in \\mathbb{R}^n, \\] <p>where \\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R}\\) is continuous and twice continuously differentiable. </p>"},{"location":"optimization/unconstrained_optimization/optimality_conditions/#optimality-conditions","title":"Optimality Conditions","text":"<p>Two optimality conditions that are necessary but not sufficient are as follows:</p>"},{"location":"optimization/unconstrained_optimization/optimality_conditions/#first-order","title":"First-Order","text":"<p>What are the conditions under which \\(\\mathbf{x}^*\\) is a local optima? From Taylor series:</p> \\[ f(\\mathbf{x}^* + \\Delta \\mathbf{x}) = f(\\mathbf{x}^*) + \\frac{\\nabla f(\\mathbf{x}^*)^T \\Delta \\mathbf{x}}{1!} + \\frac{\\Delta \\mathbf{x}^T \\nabla^2 f(\\mathbf{x}^*) \\Delta \\mathbf{x}}{2!} + \\ldots \\] <p>If \\(\\mathbf{x}^*\\) is a local minima, then we know that \\(f(\\mathbf{x}^* + \\Delta \\mathbf{x}) \\geq f(\\mathbf{x}^*)\\) for a sufficiently small \\(\\Delta \\mathbf{x}\\), i.e.:</p> \\[ \\frac{\\nabla f(\\mathbf{x}^*)^T \\Delta \\mathbf{x}}{1!} \\geq 0, \\] <p>since the lower order term dominates. However, \\(\\Delta \\mathbf{x}\\) can be either positive or negative. Hence, we must have:</p> \\[ \\nabla f(\\mathbf{x}^*) = 0. \\] <p>This also holds for local maxima, i.e., if \\(\\mathbf{x}^*\\) is a local maxima or minima, then we must have \\(\\nabla f(\\mathbf{x}^*) = 0\\). A point where the gradient  vanishes is called a stationary point.</p>"},{"location":"optimization/unconstrained_optimization/optimality_conditions/#second-order","title":"Second-Order","text":"<p>Per first-order condition, if \\(\\mathbf{x}^*\\) is a local minima, then we have a vanishing gradient, i.e., \\(\\nabla f(\\mathbf{x}^*) = 0\\). For \\(f(\\mathbf{x}^* + \\Delta \\mathbf{x}) \\geq f(\\mathbf{x}^*)\\) to hold for all  \\(\\Delta \\mathbf{x} = 0\\), we must have:</p> \\[ \\Delta \\mathbf{x}^T \\nabla^2 f(\\mathbf{x}^*) \\Delta \\mathbf{x} \\geq 0, \\quad \\forall \\Delta \\mathbf{x}, \\] <p>i.e., the Hessian must be positive semidefinite.</p>"},{"location":"optimization/unconstrained_optimization/quadratic_fit/","title":"Quadratic Fit","text":"<p>Quadratic fit is a derivative-free method designed for univariate functions.</p> <p>Algorithm: Quadratic Fit </p> <p>\\(\\quad\\) 0. Start with an initial inverval \\(\\left[ x_l, x_u \\right]\\) and a point \\(x_m\\) in the interval. Let \\(\\epsilon\\) be a termination tolerance.  \\(\\quad\\) 1. If \\((x_u - x_l) \\leq \\epsilon\\), stop and return \\(x_m\\) as the minima.  \\(\\quad\\) 2. Compute \\(x_q\\).  \\(\\quad\\quad\\) If \\(x_q \\approx x_m\\), go to Step 3.  \\(\\quad\\quad\\) If \\(x_q &lt; x_m\\), go to Step 4.  \\(\\quad\\quad\\) If \\(x_q &gt; x_m\\), go to Step 5.  \\(\\quad\\) 3. If \\((x_m - x_l) &gt; (x_u - x_m)\\), then \\(x_q \\leftarrow x_m - 0.5 \\epsilon\\) and go to Step 4; else \\(x_q \\leftarrow x_m + 0.5 \\epsilon\\) and go to Step 5.  \\(\\quad\\) 4. If \\(f(x_m) &lt; f(x_q)\\), then \\(x_l \\leftarrow x_q\\); otherwise \\(x_u \\leftarrow x_m\\) and \\(x_m \\leftarrow x_q\\). Go to Step 1.  \\(\\quad\\) 5. If \\(f(x_m) &lt; f(x_q)\\), then \\(x_u \\leftarrow x_q\\); otherwise \\(x_l \\leftarrow x_m\\) and \\(x_m \\leftarrow x_q\\). Go to Step 1.</p> <p>\\(x_q\\) is computed as:</p> \\[ x_q = \\frac{1}{2} \\frac{f_l \\left[x^2_m - x^2_u \\right] + f_m \\left[x^2_u - x^2_l \\right] + f_u \\left[x^2_l - x^2_m \\right]}{f_l \\left[x_m - x_u \\right] + f_m \\left[ x_u - x_l \\right] + f_u \\left[x_l - x_m \\right]}, \\] <p>where \\(f_i = f(x_i)\\), \\(i \\in \\left\\{ l, m, u \\right\\}\\).</p>"},{"location":"optimization/unconstrained_optimization/quasi_newton_method/","title":"Quasi-Newton Method","text":""},{"location":"optimization/unconstrained_optimization/quasi_newton_method/#broyden-fletcher-goldfarb-shanno","title":"Broyden-Fletcher-Goldfarb-Shanno","text":"<p>Quasi-Newton is a blend of gradient descent and Newton's method. It avoids computation of the Hessian and its inverse. The update rule is:</p> \\[ \\mathbf{x}^{k + 1} = \\mathbf{x}^k - \\alpha_k \\mathbf{H}_k \\nabla f(\\mathbf{x}^k), \\] <p>where \\(\\alpha_k\\) is determined by line-search and \\(\\mathbf{H}_k\\) is an approximation to the Hessian inverse, \\(\\left[ \\nabla^2 f(\\mathbf{x}^k) \\right]^{-1}\\). \\(\\mathbf{H}_k\\) must be symmetric and positive definite. Since \\(\\mathbf{H]^{-1}_{k + 1}\\)  approximates the Hessian, we have :</p> \\[ \\mathbf{H}_{k + 1} \\left( \\nabla f(\\mathbf{x}^{k + 1}) - \\nabla f (\\mathbf{x}^k) \\right) = \\mathbf{x}^{k + 1} - \\mathbf{x}^k. \\] <p>Along with the iterate, the matrix \\(\\mathbf{H}_k\\) is updated in each iteration. A widely used method is the Broyden-Fletcher-Goldfarb-Shanno (BFGS):</p> \\[ \\mathbf{H}_{k + 1} =  \\mathbf{H}_{k} - \\frac{\\mathbf{d}_k \\mathbf{g}^T_k \\mathbf{H}_k + \\mathbf{H}_k \\mathbf{g}_k \\mathbf{d}^T_k}{\\mathbf{d}^T_k \\mathbf{g}_k} +  \\left( 1 + \\frac{\\mathbf{g}^T_k \\mathbf{H}_k \\mathbf{g}_k}{\\mathbf{d}^T_k \\mathbf{g}_k} \\right) \\frac{\\mathbf{d}_k \\mathbf{d}^T_k}{ \\mathbf{d}^T_k \\mathbf{g_k}}, \\] <p>where \\(\\mathbf{g}_k = \\nabla f(\\mathbf{x}^{k + 1}) - \\nabla f(\\mathbf{x}^k)\\) and \\(\\mathbf{d}_k = \\mathbf{x}^{k + 1} - \\mathbf{x}^k\\). Most nonlinear programming solvers uses variants of quasi-Newton methods with BFGS updates.</p>"},{"location":"papers/software/","title":"Software","text":""},{"location":"papers/software/#high-performance-computing","title":"High Performance Computing","text":"<ol> <li>Aggarwal A., Vitter J.S., \"The Input/Output Complexity of Sorting and Related Problems\", 1988.</li> </ol>"},{"location":"prerequisites/functions/","title":"Functions","text":""},{"location":"prerequisites/functions/#definition","title":"Definition","text":"<p>A function \\(f: D \\rightarrow R\\) means it takes an argument element of its domain \\(D\\) and returns an element of its range \\(R\\); in particular we can have a domain of \\(f\\) as a proper subset of the set \\(D\\). Thus, the notation \\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m\\) means that \\(f\\) maps (some)  \\(n\\)-vectors into \\(m\\)-vectors; it does not mean that \\(f(\\mathbf{x})\\) is defined for every \\(\\mathbf{x} \\in \\mathbb{R}^n\\). For example,  \\(f(\\mathbf{x}) = \\sum^n_{j = 1} |x_j|\\), with \\(D = \\mathbb{R}^n\\) and \\(R = \\mathbb{R}_{+}\\).</p>"},{"location":"prerequisites/functions/#continuity","title":"Continuity","text":"<p>A function \\(f: D \\rightarrow R\\) is continuous at a point \\(\\mathbf{x}_0 \\in D\\), if for any sequence \\(\\left\\{ \\mathbf{x}_i \\right\\}\\) such that \\(\\lim_{i \\rightarrow \\infty} \\mathbf{x}_i = \\mathbf{x}_0\\), it holds \\(\\lim_{i \\rightarrow \\infty} f(\\mathbf{x}_i) = f(\\mathbf{x}_0)\\). A function is continuous if it is continuous at every point in its domain.</p> <p>Continuity can also be defined in terms of an epsilon and delta. A function \\(f: D \\rightarrow R\\) is continuous at \\(\\mathbf{x} \\in D\\) if for all \\(\\epsilon &gt; 0\\) there exists a \\(\\delta\\) such that:</p> \\[ \\mathbf{y} \\in D, \\quad ||\\mathbf{y} - \\mathbf{x}||_2 \\leq \\delta \\Rightarrow ||f(\\mathbf{y}) - f(\\mathbf{x})||_2 \\leq \\epsilon. \\] <p>Roughly, a function is continuous if it does not have any \"jumps\".</p>"},{"location":"prerequisites/functions/#differentiability","title":"Differentiability","text":"<p>A univariate function \\(f: \\mathbb{R} \\rightarrow \\mathbb{R}\\) is  differentiable at a point \\(x_0\\) if the derivative:</p> \\[ f'(x_0) = \\lim_{h \\rightarrow 0} \\frac{f(x_0 + h) - f(x_0)}{h} \\] <p>exists. A multivariate function \\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R}\\) is differentiable at a point \\(\\mathbf{x}_0\\) if all partial derivatives:</p> \\[ \\left. \\frac{\\partial f(\\mathbf{x})}{\\partial x_j} \\right|_{\\mathbf{x} = \\mathbf{x}_0} = \\lim_{h \\rightarrow 0} \\frac{f(\\mathbf{x}_0 + h \\mathbf{e}_j) - f(\\mathbf{x}_0)}{h}, \\quad j = 1, \\dots, n \\] <p>exists and are continuous. A function \\(f\\) is differentiable if it is differentiable at every point in its domain.</p>"},{"location":"prerequisites/functions/#convex-concave-and-non-convex-functions","title":"Convex, Concave, and Non-Convex Functions","text":"<p>A function \\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R}\\) is convex if:</p> \\[ f(\\theta \\mathbf{x} + (1 - \\theta)\\mathbf{y}) \\leq \\theta f(\\mathbf{x}) + (1 - \\theta)f(\\mathbf{y}) \\quad \\forall \\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^n \\ \\text{and} \\ \\theta \\in \\left[0, 1 \\right]. \\] <p>Geometrically, this inequality means that the line segment between  \\(\\mathbf{x}, f(\\mathbf{x})\\) and \\(\\mathbf{y}, f(\\mathbf{y})\\), which is the chord from \\(\\mathbf{x}\\) to \\(\\mathbf{y}\\), lies above the graph of \\(f\\).</p> <p>A function \\(f\\) is concave if \\(-f\\) is convex, i.e., the inequality is reversed. A linear function is both convex and concave. A function is non-convex if it is not convex. Non-convex functions can be modelled using mixed integer linear constraints.</p>"},{"location":"prerequisites/functions/#examples","title":"Examples","text":""},{"location":"prerequisites/functions/#example-convex-functions","title":"Example Convex Functions","text":"<ol> <li>Affine: \\(ax + b\\), \\(x \\in \\mathbb{R}\\), \\(\\forall a, b \\in R\\).</li> <li>Affine: \\(\\mathbf{a}^T \\mathbf{x} + \\mathbf{b}\\), \\(\\mathbf{x} \\in \\mathbb{R}^n\\)</li> <li>Exponential: \\(e^{ax}\\), \\(\\forall a \\in \\mathbb{R}\\).</li> <li>Powers: \\(x^\\alpha\\), \\(x \\in \\mathbb{R}_{++}\\), for \\(\\alpha \\geq 1\\) or \\(\\alpha \\leq 0\\)</li> <li>Powers of absolute value: \\(|x|^p\\), \\(x \\in \\mathbb{R}\\), for \\(p \\geq 1\\)</li> <li>Negative entropy: \\(x\\log x\\), \\(x \\in \\mathbb{R}_{++}\\)</li> <li>Norms: \\(||\\mathbf{x}||_p = \\left( \\sum^n_{i = 1} |\\mathbf{x}_i|^p \\right)^{1/p}\\), \\(\\mathbf{x} \\in \\mathbb{R}^n\\), for \\(p \\geq 1\\); \\(||\\mathbf{x}||_\\infty = \\max_k |\\mathbf{x}_k|\\)</li> </ol>"},{"location":"prerequisites/functions/#examples-of-concave-functions","title":"Examples of Concave Functions","text":"<ol> <li>Affine: \\(ax + b\\), \\(x \\in \\mathbb{R}\\), \\(\\forall a, b \\in R\\).</li> <li>Powers: \\(x^\\alpha\\), \\(x \\in \\mathbb{R}_{++}\\), for \\(0 \\leq \\alpha \\leq 1\\)</li> <li>Logarithm: \\(\\log x\\), \\(x \\in \\mathbb{R}_{++}\\)</li> </ol>"},{"location":"prerequisites/functions/#restriction-of-a-convex-function-to-a-line","title":"Restriction of a Convex Function to a Line","text":"<p>A function \\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R}\\) is convex if and only if the function \\(g: \\mathbb{R} \\rightarrow \\mathbb{R}\\):</p> \\[ g(t) = f(\\mathbf{x} + t \\mathbf{v}), \\quad \\textbf{dom}g = \\left\\{ t \\ | \\ \\mathbf{x} + t \\mathbf{v} \\in \\textbf{dom}f \\right\\} \\] <p>is convex for any \\(\\mathbf{x} \\in \\textbf{dom}f\\), \\(\\mathbf{v} \\in \\mathbb{R}^n\\).</p>"},{"location":"prerequisites/functions/#conditions-for-convexity","title":"Conditions for Convexity","text":""},{"location":"prerequisites/functions/#first-order-condition","title":"First-Order Condition","text":"<p>A differentiable function \\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R}\\) is convex if and only if:</p> \\[ f(\\mathbf{y}) \\geq f(\\mathbf{x}) + \\nabla f(\\mathbf{x})^T (\\mathbf{y} - \\mathbf{x}) \\quad \\forall \\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^n, \\] <p>that is, the first-order Taylor approximation is a global under-estimator.</p>"},{"location":"prerequisites/functions/#second-order-condition","title":"Second-Order Condition","text":"<p>A twice differentiable univariate function \\(\\mathbb{R} \\rightarrow \\mathbb{R}\\) is  convex if \\(f''(x) \\geq 0\\) for \\(\\forall x \\in \\mathbb{R}\\), i.e., the slopes (or gradients) of \\(f\\) are non-decreasing.</p> <p>Twice differentiable function \\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R}\\) is convex if and only if its Hessian matrix \\(\\nabla^2 f(\\mathbf{x})\\) is  positive semidefinite for \\(\\forall \\mathbf{x} \\in \\mathbb{R}^n\\). </p> <p>A \\(n \\times n\\) matrix \\(A\\) is positive semidefinite if \\(\\mathbf{x}^T A \\mathbf{x} \\geq 0\\) for \\(\\forall \\mathbf{x} \\in \\mathbb{R}^n\\). Equivalently, \\(A\\) is positive semidefinite if all its eigenvalues are nonnegative.</p>"},{"location":"prerequisites/functions/#example","title":"Example","text":"<p>Consider a quadratic function:</p> \\[ f(\\mathbf{x}) = \\frac{1}{2} \\mathbf{x}^T \\mathbf{P} \\mathbf{x} + \\mathbf{q}^T \\mathbf{x} + r, \\] <p>where \\(\\mathbf{P} \\in \\mathbb{S}^N_{+}\\). The first and second-order derivatives will be:</p> \\[ \\begin{align} \\nabla f(\\mathbf{x}) &amp;= \\mathbf{x}^T \\mathbf{P} + \\mathbf{q}^T \\\\ \\nabla^2 f(\\mathbf{x}) &amp;= \\mathbf{P}^T = \\mathbf{P} \\geq 0. \\end{align} \\] <p>Hence, convex. Note that these conditions are sufficient and not necessary.</p>"},{"location":"prerequisites/functions/#establishing-convexity-and-operations-preserving-convexity","title":"Establishing Convexity and Operations Preserving Convexity","text":"<p>A practical methods for establishing convexity of function is as follows:</p> <ol> <li>Verify convexity definition (often simplified by restricting to a line)</li> <li>For a twice differentiable functions, show \\(\\nabla^2 f(\\mathbf{x}) \\geq 0\\)</li> <li> <p>Show that \\(f\\) is obtained from simple convex functions by operations that preserve convexity:</p> <ol> <li>Nonnegative weighted sum of convex functions is convex, i.e., if \\(f_i\\) is convex and \\(\\alpha_x \\geq 0\\) for \\(\\forall i = 1, \\dots, m\\),          then \\(g(\\mathbf{x}) = \\sum^m_{i = 1} \\alpha_i f_i(\\mathbf{x})\\) is convex.</li> <li>Composition with affine function</li> <li>Maximum of convex functions is convex, i.e., if \\(f_i\\) is convex for \\(\\forall i = 1, \\dots, m\\), then \\(g(\\mathbf{x}) = \\text{max}_i \\left\\{ f_i(\\mathbf{x}) \\right\\}\\)         is convex.</li> <li>Composition: Let \\(f: \\mathbb{R}^m \\rightarrow \\mathbb{R}\\) be a convex function, and \\(g_i: \\mathbb{R}^n \\rightarrow \\mathbb{R}\\) be         convex for \\(\\forall i = 1, \\dots, m\\). Then the composition function          \\(h(\\mathbf{x}) = f(g_1(\\mathbf{x}), g_2(\\mathbf{x}), \\dots, g_m(\\mathbf{x}))\\) is convex if either \\(f\\) is nondecreasing or          if each \\(g_i\\) is a linear function.</li> <li>Minimization</li> <li>Perspective</li> </ol> </li> </ol> <p>For example, consider the function \\(f(\\mathbf{x}) = \\exp \\left( \\sum^m_{i = 1} |a^T_i \\mathbf{x} - b_i| \\right)\\).</p> <ol> <li>Let \\(g_i(\\mathbf{x}) = |a^T_i \\mathbf{x} - b_i|\\). It is obtained by the composition of the convex function \\(|\\cdot|\\) and the linear function \\(a^T_i \\mathbf{x} - b_i\\).          Hence, \\(g_i\\) is convex.</li> <li>The function \\(h(\\mathbf{x}) = \\sum^m_{i = 1} g_i (\\mathbf{x})\\) is a sum of convex functions. Hence, \\(h\\) is convex. </li> <li>\\(f\\) is obtained by taking composition of the function \\(m(a) = \\exp(a)\\) with \\(h\\), i.e., \\(f(\\mathbf{x}) = m(h(\\mathbf{x}))\\). Since \\(m\\) is nondecreasing          and h is convex, \\(f\\) is convex.</li> </ol>"},{"location":"prerequisites/functions/#convex-set-and-convex-functions-relationship","title":"Convex Set and Convex Functions Relationship","text":""},{"location":"prerequisites/functions/#epigraph","title":"Epigraph","text":"<p>The epigraph of a function \\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R}\\) is a set defined as:</p> \\[ \\text{epi} f = \\left\\{ (y, \\mathbf{x}) \\in \\mathbb{R}^{n + 1} : y \\geq f(\\mathbf{x}) \\right\\}. \\] <p>\"Epi\" means \"above\", so epigraph means \"above the graph\". </p> <p>The link between convex sets and convex functions is via the epigraph: A function is convex if and only if its epigraph is convex set.</p>"},{"location":"prerequisites/functions/#sublevel-sets","title":"Sublevel Sets","text":"<p>Given scalar \\(\\alpha\\), the \\(\\alpha\\)-level set of a function \\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R}\\) is a set defined as:</p> \\[ X_\\alpha = \\left\\{ \\mathbf{x} \\in \\mathbb{R}^n : f(\\mathbf{x}) \\leq \\alpha \\right\\}. \\] <p>The epigraph and the \\(\\alpha\\)-level set (\\(\\forall \\alpha \\in R\\)) of a convex function are convex sets.</p>"},{"location":"prerequisites/gradient_jacobian_hessian/","title":"Gradient, Jacobian, Hessian","text":""},{"location":"prerequisites/gradient_jacobian_hessian/#gradient","title":"Gradient","text":"<p>The gradient operator with respect to the \\(n\\)-vector \\(\\mathbf{x}\\) is defined as:</p> \\[ \\nabla_{\\mathbf{x}} = \\left[ \\begin{array}{ccc} \\frac{\\partial}{\\partial x_1} &amp; \\cdots &amp; \\frac{\\partial}{\\partial x_n} \\end{array} \\right]^T. \\] <p>The gradient of an \\(m\\)-dimensional vector-valued function \\(\\mathbf{f}(\\mathbf{x})\\) is:</p> \\[ \\nabla_{\\mathbf{x}} \\mathbf{f}(\\mathbf{x})^T = \\left[ \\begin{array}{c} \\frac{\\partial}{\\partial x_1} \\\\ \\vdots \\\\ \\frac{\\partial}{\\partial x_n} \\end{array} \\right] \\left[ \\begin{array}{ccc} f_1(\\mathbf{x}) &amp; \\cdots &amp; f_m(\\mathbf{x}) \\end{array} \\right] = \\left[ \\begin{array}{ccc} \\frac{\\partial f_1}{\\partial x_1} &amp; \\cdots &amp; \\frac{\\partial f_m}{\\partial x_1} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\frac{\\partial f_1}{\\partial x_n} &amp; \\cdots &amp; \\frac{\\partial f_m}{\\partial x_n} \\end{array} \\right]. \\]"},{"location":"prerequisites/gradient_jacobian_hessian/#jacobian","title":"Jacobian","text":"<p>The transpose of the above is the \\(m \\times n\\) Jacobian matrix:</p> \\[ \\begin{align} \\mathbf{J}_{\\mathbf{x}} \\triangleq \\mathbf{f}_{\\mathbf{x}}(\\mathbf{x}) \\triangleq \\frac{\\partial \\mathbf{f}}{\\partial \\mathbf{x}} = \\left[ \\nabla_{\\mathbf{x}} \\mathbf{f}(\\mathbf{x})^T\\right]^T = \\left[ \\begin{array}{ccc} \\frac{\\partial f_1}{\\partial x_1} &amp; \\cdots &amp; \\frac{\\partial f_1}{\\partial x_n} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\frac{\\partial f_m}{\\partial x_1} &amp; \\cdots &amp; \\frac{\\partial f_m}{\\partial x_n} \\end{array} \\right]. \\end{align} \\]"},{"location":"prerequisites/gradient_jacobian_hessian/#hessian","title":"Hessian","text":"<p>The Hessian of a (twice) differentiable scalar function \\(\\phi\\) with respect to the \\(n\\)-vector \\(\\mathbf{x}\\) is a \\(n \\times n\\) symmetric matrix:</p> \\[ \\begin{align} \\mathbf{H}(\\phi) \\triangleq \\phi_{\\mathbf{x}\\mathbf{x}}(\\mathbf{x}) \\triangleq \\frac{\\partial^2 \\phi(\\mathbf{x})}{\\partial \\mathbf{x}^2} = \\nabla_{\\mathbf{x}} \\nabla_{\\mathbf{x}}^T \\phi(\\mathbf{x}) = \\left[ \\begin{array}{ccc} \\frac{\\partial^2 \\phi}{\\partial x_1 \\partial x_1} &amp; \\cdots &amp; \\frac{\\partial^2 \\phi}{\\partial x_1 \\partial x_n} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\frac{\\partial^2 \\phi}{\\partial x_n \\partial x_1} &amp; \\cdots &amp; \\frac{\\partial^2 \\phi}{\\partial x_n \\partial x_n} \\end{array} \\right] \\end{align} \\] <p>For \\(m\\)-dimensional vector-valued function \\(\\mathbf{f}(\\mathbf{x})\\), the Hessian is a third-order tensor which is an array of \\(m\\) Hessian matrices, one for each component of \\(\\mathbf{f}\\):</p> \\[ \\mathbf{H}(\\mathbf{f}) \\triangleq \\left[ \\begin{array}{ccc} \\mathbf{H}(f_1) &amp; \\cdots &amp; \\mathbf{H}(f_m) \\end{array} \\right]. \\] <p>This tensor degenerates to the usual Hessian matrix when \\(m = 1\\).</p>"},{"location":"prerequisites/gradient_jacobian_hessian/#useful-identities","title":"Useful Identities","text":""},{"location":"prerequisites/gram_schmidt_process/","title":"Gram-Schmidt Process","text":""},{"location":"prerequisites/gram_schmidt_process/#overview","title":"Overview","text":"<p>Gram-Schmidt process provides a conversion from a naive basis set to an orthornormal basis set:</p> \\[ \\begin{align*} \\underbrace{\\left\\{ \\mathbf{v}^{(k)} \\right\\}}_{\\text{original set}} \\longrightarrow \\underbrace{\\left\\{ \\mathbf{u}^{(k)} \\right\\}}_{\\text{orthonormal set}}, \\end{align*} \\] <p>for \\(k \\leq n\\), where \\(n\\) is the dimension of the Euclidean space.</p>"},{"location":"prerequisites/gram_schmidt_process/#orthogonal-projection","title":"Orthogonal Projection","text":"<p>The vector projection of a vector \\(\\mathbf{v}\\) on a nonzero vector \\(\\mathbf{u}\\) is:</p> \\[ \\begin{align*} \\boldsymbol{\\Pi}_{\\mathbf{u}}(\\mathbf{v}) = \\text{proj}_{\\mathbf{u}}(\\mathbf{v}) = \\frac{\\langle \\mathbf{u}, \\mathbf{v} \\rangle}{||\\mathbf{u}||^2} \\mathbf{u}. \\end{align*} \\] <p>Given a vector \\(\\mathbf{x} \\in V\\) and a subspace \\(S \\subset V\\) with orthonormal basis set \\(\\left\\{ \\mathbf{s}^{(k)} \\right\\}_{k = 0, 1, \\ldots K - 1}\\), the orthogonal projection of \\(\\mathbf{x}\\) in \\(S\\) is:</p> \\[ \\begin{align*} \\hat{\\mathbf{x}} = \\sum^{K - 1}_{k = 0} \\langle \\mathbf{s}^{(k)}, \\mathbf{x}  \\rangle \\mathbf{s}^{(k)}. \\end{align*} \\]"},{"location":"prerequisites/gram_schmidt_process/#algorithm","title":"Algorithm","text":"<p>Gram-Schmidt Process</p> <p>At each step \\(k\\):</p> <ol> <li> <p>From the \\(k\\)'th vector in the original set, remove all components that are colinear as all the other vectors we have produced so far in the orthonormal set:</p> \\[ \\begin{align*} \\mathbf{p}^{(k)} = \\mathbf{v}^{(k)} - \\sum^{k - 1}_{n = 0} \\langle \\mathbf{u}^{(n)}, \\mathbf{v}^{(k)} \\rangle \\mathbf{u}^{(n)} \\end{align*} \\] </li> <li> <p>Normalize to generate a new member of the orthonormal set:</p> \\[ \\begin{align*} \\mathbf{u}^{(k)} = \\mathbf{p}^{(k)} / || \\mathbf{p}^{k} || \\end{align*} \\] </li> </ol>"},{"location":"prerequisites/matrix_calculus/","title":"Matrix Calculus","text":""},{"location":"prerequisites/matrix_calculus/#definition","title":"Definition","text":"<p>There are two layouts for computing partial derivatives. Consider a vector function \\(\\mathbf{y}\\) and a vector \\(\\mathbf{x}\\). The two commonly used layouts are:</p> <ol> <li>Numerator layout which lays out according to \\(\\mathbf{y}\\) and \\(\\mathbf{x}^T\\).  </li> <li>Denominator layout which lays out according to \\(\\mathbf{y}^T\\) and \\(\\mathbf{x}\\).</li> </ol> <p>In general, to transform from one layout to another, we can just take the transpose of the result.</p>"},{"location":"prerequisites/matrix_calculus/#layouts","title":"Layouts","text":"Type Numerator Layout Denominator Layout Vector-by-Scalar  Consider a scalar \\(x\\) and a column vector \\(\\mathbf{y} = \\left[\\begin{array}{cccc}y_1 &amp; y_2 &amp; \\ldots &amp; y_m\\end{array}\\right]^T\\) The derivative will be \\(m \\times 1\\) column vector:  \\(\\frac{\\partial \\mathbf{y}}{\\partial x} = \\left[\\begin{array}{c}\\frac{\\partial y_1}{\\partial x} \\\\ \\frac{\\partial y_2}{\\partial x} \\\\ \\vdots \\\\ \\frac{\\partial y_m}{\\partial x}\\end{array}\\right]\\) The derivative will be \\(1 \\times m\\) row vector:  \\(\\frac{\\partial \\mathbf{y}}{\\partial x} = \\left[\\begin{array}{cccc}\\frac{\\partial y_1}{\\partial x} &amp;\\frac{\\partial y_2}{\\partial x} &amp; \\ldots &amp;\\frac{\\partial y_m}{\\partial x}\\end{array}\\right]\\) Scalar-by-Vector  Consider a scalar \\(y\\) and a column vector \\(\\mathbf{x} = \\left[\\begin{array}{cccc}x_1 &amp; x_2 &amp; \\ldots &amp; x_n\\end{array}\\right]^T\\) The derivative will be \\(1 \\times n\\) vector:  \\(\\frac{\\partial y}{\\partial \\mathbf{x}} = \\left[\\begin{array}{cccc}\\frac{\\partial y}{\\partial x_1} &amp; \\frac{\\partial y}{\\partial x_2} &amp; \\ldots &amp; \\frac{\\partial y}{\\partial x_n}\\end{array}\\right]\\) The derivative will be \\(n \\times 1\\) vector:  \\(\\frac{\\partial y}{\\partial \\mathbf{x}} = \\left[\\begin{array}{cccc}\\frac{\\partial y}{\\partial x_1} \\\\ \\frac{\\partial y}{\\partial x_2} \\\\ \\vdots \\\\ \\frac{\\partial y}{\\partial x_n}\\end{array}\\right]\\) Vector-by-Vector  Consider column vectors \\(\\mathbf{y} = \\left[\\begin{array}{cccc}y_1 &amp; y_2 &amp; \\ldots &amp; y_m\\end{array}\\right]^T\\) and \\(\\mathbf{x} = \\left[\\begin{array}{cccc}x_1 &amp; x_2 &amp; \\ldots &amp; x_n\\end{array}\\right]^T\\) The derivative will be \\(m \\times n\\) matrix:  \\(\\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}} = \\left[\\begin{array}{cccc}\\frac{\\partial y_1}{\\partial x_1} &amp; \\frac{\\partial y_1}{\\partial x_2} &amp; \\ldots &amp; \\frac{\\partial y_1}{\\partial x_n} \\\\\\frac{\\partial y_2}{\\partial x_1} &amp; \\frac{\\partial y_2}{\\partial x_2} &amp; \\ldots &amp; \\frac{\\partial y_2}{\\partial x_n} \\\\\\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\\\frac{\\partial y_m}{\\partial x_1} &amp; \\frac{\\partial y_m}{\\partial x_2} &amp; \\ldots &amp; \\frac{\\partial y_m}{\\partial x_n}\\end{array}\\right]\\) The derivative will be \\(n \\times m\\) matrix:  \\(\\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}} = \\left[\\begin{array}{cccc}\\frac{\\partial y_1}{\\partial x_1} &amp; \\frac{\\partial y_2}{\\partial x_1} &amp; \\ldots &amp; \\frac{\\partial y_m}{\\partial x_1} \\\\\\frac{\\partial y_1}{\\partial x_2} &amp; \\frac{\\partial y_2}{\\partial x_2} &amp; \\ldots &amp; \\frac{\\partial y_m}{\\partial x_2} \\\\\\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\\\frac{\\partial y_1}{\\partial x_n} &amp; \\frac{\\partial y_2}{\\partial x_n} &amp; \\ldots &amp; \\frac{\\partial y_m}{\\partial x_n}\\end{array}\\right]\\) Scalar-by-Matrix  Consider a scalar function \\(y\\) and a \\(p \\times q\\) matrix \\(\\mathbf{X}\\) The derivative will be \\(q \\times p\\) matrix:  \\(\\frac{\\partial y}{\\partial \\mathbf{X}} = \\left[\\begin{array}{cccc}\\frac{\\partial y}{\\partial x_{11}} &amp; \\frac{\\partial y}{\\partial x_{21}} &amp; \\ldots &amp; \\frac{\\partial y}{\\partial x_{p1}} \\\\ \\frac{\\partial y}{\\partial x_{12}} &amp; \\frac{\\partial y}{\\partial x_{22}} &amp; \\ldots &amp; \\frac{\\partial y}{\\partial x_{p2}} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\\\frac{\\partial y}{\\partial x_{1q}} &amp; \\frac{\\partial y}{\\partial x_{2q}} &amp; \\ldots &amp; \\frac{\\partial y}{\\partial x_{pq}}\\end{array}\\right]\\) The derivative will be \\(p \\times q\\) matrix:  \\(\\frac{\\partial y}{\\partial \\mathbf{X}} = \\left[\\begin{array}{cccc}\\frac{\\partial y}{\\partial x_{11}} &amp; \\frac{\\partial y}{\\partial x_{12}} &amp; \\ldots &amp; \\frac{\\partial y}{\\partial x_{1q}} \\\\ \\frac{\\partial y}{\\partial x_{21}} &amp; \\frac{\\partial y}{\\partial x_{22}} &amp; \\ldots &amp; \\frac{\\partial y}{\\partial x_{2q}} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\\\frac{\\partial y}{\\partial x_{p1}} &amp; \\frac{\\partial y}{\\partial x_{p2}} &amp; \\ldots &amp; \\frac{\\partial y}{\\partial x_{pq}}\\end{array}\\right]\\) Matrix-by-Scalar  Consider a \\(m \\times n\\) matrix function \\(\\mathbf{Y}\\) and a scalar \\(x\\) The derivative will be \\(m \\times n\\) matrix:  \\(\\frac{\\partial \\mathbf{Y}}{\\partial x} = \\left[\\begin{array}{cccc}\\frac{\\partial y_{11}}{\\partial x} &amp; \\frac{\\partial y_{12}}{\\partial x} &amp; \\ldots &amp; \\frac{\\partial y_{1n}}{\\partial x} \\\\ \\frac{\\partial y_{21}}{\\partial x} &amp; \\frac{\\partial y_{22}}{\\partial x} &amp; \\ldots &amp; \\frac{\\partial y_{2n}}{\\partial x} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\\\frac{\\partial y_{m1}}{\\partial x} &amp; \\frac{\\partial y_{m2}}{\\partial x} &amp; \\ldots &amp; \\frac{\\partial y_{mn}}{\\partial x} \\\\ \\end{array}\\right]\\) The derivative will be \\(n \\times m\\) matrix:  \\(\\frac{\\partial \\mathbf{Y}}{\\partial x} = \\left[\\begin{array}{cccc}\\frac{\\partial y_{11}}{\\partial x} &amp; \\frac{\\partial y_{21}}{\\partial x} &amp; \\ldots &amp; \\frac{\\partial y_{m1}}{\\partial x} \\\\ \\frac{\\partial y_{12}}{\\partial x} &amp; \\frac{\\partial y_{22}}{\\partial x} &amp; \\ldots &amp; \\frac{\\partial y_{m2}}{\\partial x} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\\\frac{\\partial y_{1n}}{\\partial x} &amp; \\frac{\\partial y_{2n}}{\\partial x} &amp; \\ldots &amp; \\frac{\\partial y_{mn}}{\\partial x} \\\\ \\end{array}\\right]\\)"},{"location":"prerequisites/matrix_calculus/#useful-identities","title":"Useful Identities","text":"Type Identity Notes Vector-by-Vector (numerator) \\(\\begin{alignat*}{2}&amp;\\frac{\\partial (\\mathbf{A} \\mathbf{x})}{\\mathbf{x}} = \\mathbf{A}, \\\\&amp;\\mathbf{x}^T \\mathbf{y} = x_1 y_1 + \\ldots + x_n y_n, \\\\&amp;\\frac{\\partial (\\mathbf{y}^T \\mathbf{x} )}{\\partial \\mathbf{x}} = \\frac{\\partial (\\mathbf{x}^T \\mathbf{y})}{\\partial \\mathbf{x}} &amp;&amp;=\\left[\\begin{array}{ccc}\\partial (\\mathbf{x}^T \\mathbf{y}) / \\partial x_1 &amp; \\ldots &amp; \\partial (\\mathbf{x}^T \\mathbf{y}) / \\partial x_n\\end{array}\\right] \\\\&amp; &amp;&amp;=\\left[\\begin{array}{ccc}y_1 &amp; \\ldots &amp; y_n\\end{array}\\right] \\\\ &amp; &amp;&amp;= \\mathbf{y}^T.\\end{alignat*}\\) The denominator layout will yield in \\(\\mathbf{A}^T\\) and \\(\\mathbf{y}\\) Scalar-by-Vector \\(\\begin{align*}\\frac{\\partial (\\mathbf{x}^T \\mathbf{A} \\mathbf{x})}{\\mathbf{x}} &amp;=\\left[\\begin{array}{ccc}\\partial (\\mathbf{x}^T \\mathbf{A} \\mathbf{x}) / \\partial x_1 &amp;\\ldots &amp;\\partial (\\mathbf{x}^T \\mathbf{A} \\mathbf{x}) / \\partial x_n\\end{array}\\right] \\\\&amp;= \\left[\\begin{array}{ccc}\\sum_j x_j A_{1j} + \\sum_i x_i A_{i1} &amp; \\ldots &amp;\\sum_j x_j A_{nj} + \\sum_i x_i A_{in}\\end{array}\\right] \\\\&amp;= \\left[\\begin{array}{ccc}\\sum_j x_j A_{1j} &amp; \\ldots &amp; \\sum_j x_j A_{nj}\\end{array}\\right] + \\left[\\begin{array}{ccc}\\sum_i x_i A_{i1} &amp; \\ldots &amp; \\sum_i x_i A_{in}\\end{array}\\right] \\\\&amp;= \\mathbf{x}^T \\mathbf{A}^T + \\mathbf{x}^T \\mathbf{A}.\\end{align*}\\) If \\(\\mathbf{A}\\) is a symmetric matrix, then \\(\\mathbf{A} = \\mathbf{A}^T\\), which yields to:  \\(\\frac{\\partial (\\mathbf{x}^T \\mathbf{A} \\mathbf{x})}{\\mathbf{x}} = 2 \\mathbf{x}^T \\mathbf{A}.\\)  Again this is in numerator layout. In denominator layout it will be \\(2 \\mathbf{A}^T \\mathbf{x}\\)."},{"location":"prerequisites/matrix_exponential/","title":"Matrix exponential","text":""},{"location":"prerequisites/matrix_exponential/#matrix-exponential-and-logarithm","title":"Matrix Exponential and Logarithm","text":""},{"location":"prerequisites/matrix_exponential/#logarithm","title":"Logarithm","text":"<p>The inverse conversion is the logarithm map:</p> \\[ \\ln \\left( \\mathbf{A} \\right) = \\sum^{\\infty}_{n = 1} \\frac{(-1)^{n - 1}}{n} (\\mathbf{A} - \\mathbf{I})^n. \\]"},{"location":"prerequisites/matrix_properties/","title":"Matrix Properties","text":""},{"location":"prerequisites/matrix_properties/#quadratic-forms","title":"Quadratic Forms","text":"<p>The (scalar) function of the real vector \\(\\mathbf{x} \\in \\mathbb{R}^n\\):</p> \\[ \\begin{align} q =  \\mathbf{x}^T \\mathbf{A} \\mathbf{x} &amp;=  \\left[ \\begin{array}{ccc} x_1 &amp; \\ldots &amp; x_n \\end{array} \\right] \\left[ \\begin{array}{ccc} A_{11} &amp; \\ldots &amp; A_{1n} \\\\  \\vdots &amp; \\ddots &amp; \\vdots \\\\ A_{n1} &amp; \\ldots &amp; A_{nn} \\end{array} \\right] \\left[ \\begin{array}{c} x_1 \\\\ \\vdots \\\\ x_n \\end{array} \\right] \\\\ &amp;=  \\left[ \\begin{array}{ccc} \\sum_i x_i A_{i1} &amp; \\ldots &amp; \\sum_i x_i A_{in} \\end{array} \\right] \\left[ \\begin{array}{c} x_1 \\\\ \\vdots \\\\ x_n \\end{array} \\right] \\\\ &amp;= \\sum_{i, j} x_i x_j A_{ij}, \\end{align} \\] <p>is called a quadratic form. \\(\\mathbf{A}\\) is positive semidefinite iff \\(\\mathbf{x}^T \\mathbf{A} \\mathbf{x} \\geq 0\\), \\(\\forall\\mathbf{x} \\neq \\mathbf{0}\\) and positive definite iff \\(\\mathbf{x}^T \\mathbf{A} \\mathbf{x} &gt; 0\\), \\(\\forall\\mathbf{x} \\neq \\mathbf{0}\\). A matrix is positive (semi)definite if and only if all its eigenvalues are positive (nonnegative).</p>"},{"location":"prerequisites/matrix_properties/#inequality-of-two-matrices","title":"Inequality of Two Matrices","text":"<p>The matrix \\(\\mathbf{A}\\) is smaller (not larger) than the matrix \\(\\mathbf{B}\\) if and only if \\(\\mathbf{B} - \\mathbf{A}\\) is positive (semi) definite.</p>"},{"location":"prerequisites/matrix_properties/#condition-number","title":"Condition Number","text":"<p>The condition number of a positive definite symmetric matrix is defined as:</p> \\[ \\kappa(\\mathbf{A}) \\triangleq \\log_{10} \\frac{\\lambda_{\\text{max}}}{\\lambda_{\\text{min}}}. \\] <p>Large condition numbers indicate near-singularty (e.g., \\(\\kappa &gt; 6\\) for a 32-bit computer indicates an ill-conditioned matrix).</p>"},{"location":"prerequisites/norms/","title":"Norms","text":""},{"location":"prerequisites/norms/#definitions","title":"Definitions","text":"Type Definition Vector Norms A vector norm on \\(\\mathbb{R}^n\\) is a function \\(f: \\ \\mathbb{R}^n \\rightarrow \\mathbb{R}\\) that satisfies the following three properties: <ol><li>\\(f\\) is nonnegative: \\(f(\\mathbf{x}) \\geq 0\\), \\(\\forall \\mathbf{x} \\in \\mathbb{R}^n\\)</li><li>\\(f\\) satisfies the triangle inequality: \\(f(\\mathbf{x} + \\mathbf{y}) \\leq f(\\mathbf{x}) + f(\\mathbf{y})\\), for all \\(\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^n\\)</li><li>\\(f\\) is homogeneuous: \\(f( t \\mathbf{x}) = \\|t\\| f(\\mathbf{x})\\), for all \\(\\mathbf{x} \\in \\mathbb{R}^n\\) and \\(t \\in \\mathbb{R}\\)</li><li>\\(f\\) is definite: \\(f(\\mathbf{x}) = 0\\) if and only if \\(\\mathbf{x} = \\mathbf{0}\\)</li></ol> Matrix Norms A function \\(f: \\ \\mathbb{R}^{m \\times n} \\rightarrow \\mathbb{R}\\) is a matrix norm if the following holds: <ol><li>\\(f\\) is nonnegative: \\(f(\\mathbf{A}) \\geq 0\\), \\(\\forall \\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\)</li><li>\\(f\\) satisfies the triangle inequality: \\(f(\\mathbf{A} + \\mathbf{B}) \\leq f(\\mathbf{A}) + f(\\mathbf{B})\\), for all \\(\\mathbf{A}, \\mathbf{B} \\in \\mathbb{R}^{m \\times n}\\)</li><li>\\(f\\) is homogeneuous: \\(f( t \\mathbf{A}) = \\|t\\| f(\\mathbf{A})\\), for all \\(\\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\) and \\(t \\in \\mathbb{R}\\)</li><li>\\(f\\) is definite: \\(f(\\mathbf{A}) = 0\\) if and only if \\(\\mathbf{A} = \\mathbf{0}\\)</li>"},{"location":"prerequisites/norms/#common-norms","title":"Common Norms","text":"Norm Vector Matrix 1-norm \\(\\| \\mathbf{x} \\|_1 = \\| x_1 \\| + \\cdots + \\| x_n \\|\\) 2-norm (\\(l_2\\)) \\(\\| \\mathbf{x} \\|_2 = \\left( \\| x_1 \\|^2 + \\cdots + \\| x_n \\|^2 \\right)^{1/2} = \\left(\\mathbf{x}^T \\mathbf{x} \\right)^{1/2}\\) If \\(\\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\), then there exists a unit 2-norm n-vector \\(\\mathbf{z}\\) such that:  \\(\\mathbf{A}^T \\mathbf{A} \\mathbf{z} = \\mu^2 \\mathbf{z}\\),  where \\(\\mu = \\|\\mathbf{A}\\|_2\\). This implies that \\(\\|\\mathbf{A}\\|^2_2\\) is a zero of \\(p(\\lambda) = \\text{det} \\left( \\mathbf{A}^T \\mathbf{A} - \\lambda \\mathbf{I} \\right)\\). In particular:  \\(\\|\\mathbf{A}\\|_2 = \\sqrt{\\lambda_{max} \\left( \\mathbf{A}^T \\mathbf{A} \\right)}\\). \\(p\\)-norm \\(\\| \\mathbf{x} \\|_p = \\left( \\| x_1 \\|^p + \\cdots + \\| x_n \\|^p \\right)^{1/p}, \\quad p \\geq 1\\) \\(\\|\\mathbf{A}\\|_p = \\sup_{x \\neq 0} \\frac{\\|\\mathbf{A} \\mathbf{x}\\|_p}{\\|\\mathbf{x}\\|_p}\\) Infinity norm \\(\\| \\mathbf{x} \\|_{\\infty} = \\max_{1 \\leq i \\leq n} \\| x_i \\|\\) Frobenius norm \\(\\|\\mathbf{A}\\|_F = \\sqrt{\\sum^m_{i = 1} \\sum^n_{j = 1} \\|A_{ij}\\|^2}\\)"},{"location":"prerequisites/norms/#properties","title":"Properties","text":"Property Vector Matrix Cauchy-Schwarz Inequality \\(\\| \\mathbf{x}^T \\mathbf{y} \\| \\leq \\| \\mathbf{x}\\|_2 \\| \\mathbf{y} \\|_2\\) Norm Preservation 2-norm is preserved under orthogonal transformation. Let \\(\\mathbf{Q} \\in \\mathbb{R}^{n \\times n}\\) be orthogonal matrix and \\(\\mathbf{x} \\in \\mathbb{R}^n\\). Then:  \\(\\| \\mathbf{Q} \\mathbf{x} \\|^2_2 = \\left( \\mathbf{Q} \\mathbf{x}\\right)^T \\left( \\mathbf{Q} \\mathbf{x}\\right) = \\mathbf{x}^T \\mathbf{x} = \\| \\mathbf{x} \\|^2_2\\) Absolute and Relative Errors Let \\(\\hat{\\mathbf{x}}\\) be an approximation of \\(\\mathbf{x} \\in \\mathbb{R}^n\\). For a given vector norm \\(\\| \\cdot \\|\\), the absolute error in \\(\\hat{\\mathbf{x}}\\) is defined as:  \\(\\boldsymbol{\\epsilon}_{abs} = \\|\\hat{\\mathbf{x}} - \\mathbf{x} \\|\\).  If \\(\\mathbf{x} \\neq \\mathbf{0}\\), then the relative error in \\(\\hat{\\mathbf{x}}\\) is defined as:  \\(\\boldsymbol{\\epsilon}_{rel} = \\frac{\\| \\hat{\\mathbf{x}} - \\mathbf{x} \\|}{\\| \\mathbf{x}\\|}\\). Sequence Convergence A sequence \\(\\left\\{ \\mathbf{x}^{(k)} \\right\\}\\) of \\(n\\)-vectors converges to \\(\\mathbf{x}\\) if:  \\(\\lim_{k \\rightarrow \\infty} \\|\\mathbf{x}^{(k)} - \\mathbf{x} \\| = 0.\\)"},{"location":"prerequisites/references/","title":"References","text":"<p>Contents are from:</p> <ol> <li>Golub, G., Matrix Computations</li> <li>Bar-Shalom et al., Estimation with Applications to Tracking and Navigation, 2001</li> <li>Boyd S., Convex Optimization, 2014</li> <li>Vidakovic, B., Engineering Biostatistics</li> </ol>"},{"location":"prerequisites/conditioning_and_stability/term/","title":"Term","text":"Term Description Conditioning Perturbation behavior of a mathematical problem Well-conditioned All small perturbations of \\(\\mathbf{x}\\) lead to only small changes in \\(f(\\mathbf{x})\\) Ill-conditioned \\(Small perturbation of \\(\\mathbf{x}\\) leads to a large change in \\(f(\\mathbf{x})\\)\\) Stability Perturbation behavior of an algorithm used to solve that problem on a computer"},{"location":"prerequisites/dsp_notes/complex_exponential/","title":"Complex Exponential","text":""},{"location":"prerequisites/dsp_notes/complex_exponential/#discrete-time-oscillatory-heartbeat","title":"Discrete-Time Oscillatory Heartbeat","text":"<p>The complex exponential describes in compact form an oscillatory behavior with a given frequency and an initial phase. A disrete-time oscillatory heartbeat with amplitude \\(A\\), frequency \\(w\\), and an initial phase \\(\\phi\\) can be described as:</p> \\[ x(n) = A \\exp \\left\\{ j(wn + \\phi) \\right\\} = A \\left[\\cos\\left(wn + \\phi \\right) + j \\sin(wn + \\phi) \\right] \\]"},{"location":"prerequisites/dsp_notes/complex_exponential/#complex-exponential-generating-machine","title":"Complex Exponential Generating Machine","text":"<p>Rotation can be achieved by multiplication by a complex exponential to a point on a complex plane. This gives a basis to a complex exponential generating machine:</p> \\[ \\begin{align} x(n) &amp;= \\exp\\left\\{j (wn  + \\phi) \\right\\} \\\\ x(n + 1) &amp;= \\exp\\left\\{ j(w (n + 1) + \\phi) \\right\\} = \\exp \\left\\{j w \\right\\} x(n). \\end{align} \\] <p>In discrete time, not every sinusoid is periodic. The complex exponential \\(\\exp \\left\\{ jwn \\right\\}\\) is periodic in \\(n\\) iff \\(w = \\frac{M}{N} 2 \\pi\\), \\(M, N \\in \\mathbb{N}\\), i.e., the frequency is a rational multiple of \\(2\\pi\\):</p> \\[ \\begin{align} x(n) &amp;= x(n + N) \\\\ \\exp\\left\\{j (wn + \\phi) \\right\\} &amp;= \\exp\\left\\{ j(w (n + N) + \\phi) \\right\\} \\\\ \\exp\\left\\{ jwn \\right\\} \\exp\\left\\{j \\phi \\right\\} &amp;= \\exp\\left\\{jwn \\right\\} \\exp\\left\\{jwN \\right\\} \\exp\\left\\{j \\phi \\right\\} \\\\ \\exp\\left\\{jwN \\right\\} &amp;= 1 \\\\ wN &amp;= 2 M \\phi, \\ M \\in \\mathbb{Z} \\\\ w &amp;= \\frac{M}{N} 2 \\pi. \\end{align} \\]"},{"location":"prerequisites/dsp_notes/complex_exponential/#aliasing","title":"Aliasing","text":"<p>The natural property of a complex exponential is that it has \\(2\\pi\\) periodicity. In discrete time, it puts a limit on how fast we can go around the unit circle with the discrete time signal.</p>"},{"location":"prerequisites/dsp_notes/decibels/","title":"Decibals","text":""},{"location":"prerequisites/dsp_notes/decibels/#definition","title":"Definition","text":"<p>The use of decibels is an expedient mathematical method for comparing the amplitude, or power, or difference between two signals. Decibel values are often used to describe the performance of both analog and digital filters. </p>"},{"location":"prerequisites/dsp_notes/decibels/#power-quantities","title":"Power Quantities","text":"<p>When referring to measurements of power quantities, a ratio can be expressed as a level in decibels by evaluating ten times the base-10 logarithm of the ratio of the measured quantity to reference value Thus, the ratio of \\(P\\) (measured power), to \\(P_0\\) (reference power) is represented by \\(L_p\\):</p> \\[ L_P = 10 \\log_{10} \\left( \\frac{P}{P_0} \\right) \\ \\text{dB}. \\] <p>\\(P\\) and \\(P_0\\) must measure the same type of quantity, and have the same units before calculating the ratio. If \\(P = P_0\\), then \\(L_p = 0\\). If \\(P\\) is greater than \\(P_0\\), then \\(L_p\\) is positive; else negative.</p> <p>A difference of 10dB means a difference factor of 10. Similarly, a difference of 20dB means a difference factor of 100.</p>"},{"location":"prerequisites/dsp_notes/decibels/#amplitude-quantities","title":"Amplitude Quantities","text":"<p>For amplitudes:</p> \\[ 20 \\log_{10} \\left( \\frac{A_1}{A_2} \\right) \\ \\text{dB}. \\] <p>When \\(A_1\\) is less than \\(A_2\\), the dB value is a negative number.</p> Amplitude Ratio (\\(A_1 / A_2\\)) Relative dB \\(1/1000\\) \\(-60\\) \\(1/100\\) \\(-40\\) \\(1/10\\) \\(-20\\) \\(1/4\\) \\(-12\\) \\(1/2\\) \\(-6\\) \\(1\\) \\(0\\) \\(2\\) \\(6\\) \\(4\\) \\(12\\) \\(10\\) \\(20\\) \\(100\\) \\(40\\) \\(1000\\) \\(60\\)"},{"location":"prerequisites/dsp_notes/dft/","title":"Discrete Fourier Transform","text":""},{"location":"prerequisites/dsp_notes/dft/#leakage","title":"Leakage","text":"<p>The DFT's frequency spacing (resolution) is \\(f_s / N\\) and the analytical frequencies always have an integral number of cycles over our total sample interval. In practice, the input signal's frequencies will not be integral number of cycles of the DFT's fundamental frequency. Consider DFT of a length-\\(M\\) step (\\(1\\) for \\(n = 0\\) to \\(M - 1\\), and zero otherwise) in \\(\\mathbb{C}^N\\):</p> \\[ x(n) = \\sum^{M - 1}_{h = 0}\\delta(n - h), \\quad n = 0, 1, \\ldots, N - 1. \\] <p>Computing the DFT:</p> \\[ \\begin{align*} X(m) &amp;= \\sum^{N - 1}_{n = 0} x(n) \\exp \\left\\{ -j 2 \\pi n m / N \\right\\} = \\sum^{M - 1}_{n = 0} \\exp \\left\\{- j 2 \\pi n m / N \\right\\} \\\\ &amp;= \\frac{1 - \\exp \\left\\{ -j 2 \\pi m M / N\\right\\}}{1 - \\exp \\left\\{ -j 2 \\pi m / N \\right\\}} \\\\ &amp;= \\frac{\\exp \\left\\{- j \\pi m M / N \\right\\} \\left[\\exp \\left\\{ j \\pi m M / N \\right\\} - \\exp \\left\\{ - j \\pi m M / N \\right\\} \\right]}{\\exp\\left\\{-j \\pi m / N \\right\\} \\left[ \\exp\\left\\{j \\pi m / N \\right\\} - \\exp\\left\\{-j \\pi m / N \\right\\} \\right]} \\\\ &amp;= \\frac{\\sin\\left(\\pi m M / N \\right)}{\\sin \\left(\\pi m / N \\right)} \\exp \\left\\{-j \\pi (M - 1)m / N \\right\\} \\end{align*} \\] <p>Note that:</p> <ol> <li>\\(X(0) = M\\), from the definition of the sum</li> <li>\\(X(m) = 0\\) if \\(M m / N\\) is an integer (\\(0 \\leq m \\leq N\\))</li> <li>\\(\\angle X(m)\\) linear in \\(m\\) (except at sign changes for the part)</li> </ol>"},{"location":"prerequisites/dsp_notes/dft/#time-frequency-properties","title":"Time-Frequency Properties","text":"Property/Operation Time Function Fourier Transform Linearity \\(k_1 x(n) + k_2 y(n)\\) \\(k_1 X(m) + k_2 Y(m)\\) Shift Theorem \\(x(n - k)\\) \\(X(m) \\exp\\left\\{ -j2 \\pi km / N \\right\\}\\), where the input is shifted to the left by \\(k\\) samples"},{"location":"prerequisites/dsp_notes/dft/#dft-leakage","title":"DFT Leakage","text":"<p>To reduce sidelobes and DFT leakage, a windowing function, \\(w(n)\\), needs to be applied:</p> \\[ X_w (m) = \\sum^{N - 1}_{n = 0} w(n) x(n) \\exp \\left\\{ -j 2 \\pi n m / N \\right\\}. \\] <p>The benchmark windowing function is a rectangular window, i.e., \\(w(n) = 1\\), for \\(n = 0, 1, \\ldots, N - 1\\). The continuous Fourier transform of the rectangular window function is \\(X(m) = \\frac{A_0 N}{2} \\frac{\\sin \\left( \\pi (k - m) \\right)}{\\pi(k - m)}\\), where \\(A_0\\) is the peak amplitude and \\(k\\) is the input cycles which is not required to be an integer.</p> Window Function Name Function Rectangular Window \\(w(n) = 1\\), for \\(n = 0, 1, 2, \\ldots, N - 1\\) Hanning Window \\(w(n) = 0.5 - 0.5 \\cos \\left( 2 \\pi n / N \\right)\\), for \\(n = 0, 1, 2, \\ldots, N - 1\\) Hamming Window \\(w(n) = 0.54 - 0.46 \\cos \\left( 2 \\pi n / N \\right)\\), for \\(n = 0, 1, 2, \\ldots, N - 1\\) <p>Window selection is a trade-off between main lobe widening, first sidelobe levels, and how fast the sidelobes decrease with increased frequency.</p>"},{"location":"prerequisites/dsp_notes/digital_filters/","title":"Digital Filters","text":""},{"location":"prerequisites/dsp_notes/digital_filters/#types","title":"Types","text":"<p>Filter types according to impulse response:</p>"},{"location":"prerequisites/dsp_notes/digital_filters/#finite-impulse-response-fir","title":"Finite Impulse Response (FIR)","text":"<ol> <li>Impulse response has finite support. </li> <li>Only a finite number of samples are involved in the computation of each output sample. Typical example of FIR filter is a moving average filter.</li> <li>FIR filters are always stable.</li> </ol>"},{"location":"prerequisites/dsp_notes/digital_filters/#infinite-impulse-response-iir","title":"Infinite Impulse REsponse (IIR)","text":"<ol> <li>Impulse response has infinite support. </li> <li>A potentially infinite number of samples are involved in the computation of each output sample. </li> <li>Surprisingly, in many cases the computation can still be performed in a finite amount of steps. For example, Leaky Integrator.</li> <li>Stability needs to be explicitly checked for IIR filters.</li> </ol>"},{"location":"prerequisites/dsp_notes/digital_filters/#causal-vs-noncausal","title":"Causal vs Noncausal","text":"<p>Causal:</p> <ol> <li>Impulse response is zero for \\(n &lt; 0\\).</li> <li>Only past samples (with respect to the present) are involved in the computation of each output sample.</li> <li>Causal filters can work online since they only need the past</li> </ol> <p>E.g., causal is moving average filter.</p> <p>Noncausal:</p> <ol> <li>Impulse response is nonzero for some (or all) \\(n &lt; 0\\)</li> <li>Can still be implemented in a offline fashion (when all input data is available on storage, e.g. in Image Processing)</li> </ol>"},{"location":"prerequisites/dsp_notes/discrete_fourier_transform/","title":"Discrete Fourier Transform","text":""},{"location":"prerequisites/dsp_notes/discrete_fourier_transform/#overview","title":"Overview","text":"<p>Discrete Fourier Transform (DFT) extracts the frequency contents (frequencies and their phase relationships) of any discrete sequence regardless of what the sequence represents. Consider a continuous sinusoidal signal \\(x(t)\\). Sampling at \\(f_s\\) over \\(N\\) samples yields to a discrete signal \\(x(n) \\in \\mathbb{C}^N\\), where \\(n = 0, 1, \\ldots, N - 1\\) is the sampling index. DFT determines the spectral content of the input \\(x(n)\\) at \\(N\\) equally spaced \\(k = 0, 1, \\ldots, N - 1\\) frequency points.</p> <p>The fundamental frequency is \\(w = \\frac{2 \\pi }{ N}\\) or equivalently \\(f = \\frac{f_s}{ N}\\). All other analysis frequencies will be multiples of the fundamental frequency, i.e., \\(f_k = \\frac{k f_s}{N}\\).</p>"},{"location":"prerequisites/dsp_notes/discrete_fourier_transform/#fourier-basis","title":"Fourier Basis","text":"<p>The \\(k\\)'th frequency basis is defined as \\(w_k (n) \\triangleq w^{(k)}_n = \\exp \\left\\{ j \\frac{2 \\pi}{N} n k \\right\\}\\) for \\(k, n = 0, 1, \\ldots, N - 1\\). Note that this is a complex exponential series at frequencies \\(w = \\frac{2\\pi}{N}k\\) with \\(k = 0, 1, \\ldots, N - 1\\). As \\(k\\) increases, the fundamental frequency increases. The highest it can reach is at \\(w = \\pi\\) at \\(N / 2\\).</p> <p>The set of \\(N\\) signals in \\(\\mathbb{C}^N\\), \\(\\left\\{\\boldsymbol{\\omega}^{(k)} \\right\\}_{k = 0, 1, \\ldots, N - 1}\\) is an orthogonal basis in \\(\\mathbb{C}^N\\) since:</p> \\[ \\begin{align*} \\langle \\boldsymbol{\\omega}^{(k)}, \\boldsymbol{\\omega}^{(h)} \\rangle &amp;= \\sum^{N - 1}_{n = 0} \\left( e^{j \\frac{2 \\pi}{N} nk} \\right)^{*} e^{j \\frac{2 \\pi}{N} nh} \\\\ &amp;= \\sum^{N - 1}_{n = 0} e^{j \\frac{2 \\pi}{N} (h - k)n} \\\\ &amp;= \\begin{cases} N \\quad &amp;\\text{iff} \\ h = k \\\\ \\frac{1 - e^{j 2 \\pi (h - k)}}{1 - e^{j \\frac{2 \\pi}{N}(h - k)}} = 0 \\quad &amp;\\text{otherwise} \\end{cases} \\end{align*} \\] <p>Note that the vectors are not orthonormal and requires a normalization factor of \\(\\frac{1}{\\sqrt{N}}\\). The normalization factor should be explicit in DFT formulas.</p>"},{"location":"prerequisites/dsp_notes/discrete_fourier_transform/#discrete-fourier-transform-algorithm","title":"Discrete Fourier Transform Algorithm","text":"<p>A signal \\(\\mathbf{x}\\) can be expressed in Fourier basis as \\(X_k = \\langle \\boldsymbol{\\omega}^{(k)}, \\mathbf{x} \\rangle\\) which is the analysis formula, and the inverse process can be done as \\(\\mathbf{x} = \\frac{1}{N} \\sum^{N - 1}_{k = 0} X_k \\boldsymbol{w}^{(k)}\\) which is the synthesis formula.</p> <p>Let \\(W = \\exp\\left\\{ -j \\frac{2 \\pi}{N} \\right\\}\\). The change of basis matrix \\(\\mathbf{W}\\) with \\(\\mathbf{W}(n, m) = W^{nm}_{N}\\) is:</p> \\[ \\begin{align} \\mathbf{W} =  \\left[ \\begin{array}{cccccc} 1 &amp; 1 &amp; 1 &amp; 1 &amp; \\ldots &amp; 1 \\\\ 1 &amp; W^1 &amp; W^2 &amp; W^3 &amp; \\ldots &amp; W^{N - 1} \\\\ 1 &amp; W^2 &amp; W^4 &amp; W^6 &amp; \\ldots &amp; W^{2(N - 1)} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 1 &amp; W^{N - 1} &amp; W^{2 (N - 1)} &amp; W^{3(N - 1)} &amp; \\ldots &amp; W^{(N - 1)^2} \\\\ \\end{array} \\right]. \\end{align} \\] <p>Then we can write the analysis formula as \\(\\mathbf{X} = \\mathbf{W} \\mathbf{x}\\) and the synthesis formula as: \\(\\mathbf{x} = \\frac{1}{N} \\mathbf{W}^H \\mathbf{X}\\).</p> <p>Explicitly writing the analysis and synthesis formula yields to the following table:</p> Formula Continuous FT \\(N\\)-Point Discrete FT Analysis \\(X(f) = \\int^{\\infty}_{-\\infty} x(t) \\exp \\left\\{ -j 2 \\pi f t \\right\\} dt\\) \\(\\begin{align*} X(k) &amp;= \\sum^{N - 1}_{n = 0} x(n) \\exp\\left\\{ -j \\frac{2 \\pi}{N} nk \\right\\}, \\ k = 0, 1, \\ldots, N - 1\\end{align*}\\) Synthesis \\(x(t) = \\frac{1}{2 \\pi} \\int X(f) \\exp \\left\\{j 2 \\pi f t \\right\\}df\\) \\(\\begin{align*}x(n) &amp;= \\frac{1}{N} \\sum^{N - 1}_{m = 0} X(k) \\exp\\left\\{ j \\frac{2 \\pi}{N} nk \\right\\}, \\ n = 0, 1, \\ldots, N - 1 \\end{align*}\\) <p>The exact frequencies of the different sinusoids depend on both the sampling rate \\(f_s\\) at which the original signal was sampled, and the number of samples \\(N\\). For example, if we are sampling a continuous signal at a rate of \\(500\\)Hz and perform a 16-point DFT on the sampled data, the fundamental frequency of the sinusoids is \\(31.25\\)Hz.</p>"},{"location":"prerequisites/dsp_notes/discrete_fourier_transform/#properties","title":"Properties","text":"Property Definition Conjugate Symmetry When the input sequence \\(x(n)\\) is real, the complex DFT outputs for \\(k = 1\\) to \\(k = \\lfloor N / 2 \\rfloor\\) are redundant with frequency output values for \\(k &gt; \\lceil N / 2 \\rceil\\). The \\(k\\)'th and \\((N - k)\\)'th outputs are related by:  \\(\\begin{align*} &amp;X(k) = \\|X(k)\\| \\angle X(k) = \\|X(N - k)\\| \\angle - X(N - k), \\ \\text{for} \\ 1 \\leq k \\leq \\lfloor N / 2 \\rfloor \\\\ &amp;X(k) = X^* (N - k). \\end{align*}\\).  Hence, for \\(N\\)-point DFT on a real input sequence, only the first \\(N / 2 + 1\\) terms are independent. Magnitude Given DFT transformation on an input signal with frequency \\(f &lt; f_s / 2\\) peak amplitude \\(A_0\\) with an integral number of cycles over \\(N\\) input samples, the output amplitude for that particular sinewave (\\(M_r\\)) is: \\(\\begin{align*} &amp;M_r = A_0 N / 2 \\\\  &amp;\\|X(k)\\| = \\sqrt{\\text{Re}\\left\\{ X(k) \\right\\}^2 + \\text{Im}\\left\\{ X(k) \\right\\}^2} \\end{align*}\\) Phase \\(\\angle X(k) = \\tan^{-1} \\frac{\\text{Im}\\left\\{ X(k) \\right\\}}{\\text{Re}\\left\\{ X(k) \\right\\}}\\)"},{"location":"prerequisites/dsp_notes/discrete_fourier_transform/#dft-of-length-m-step","title":"DFT of Length-M Step","text":"<p>Consider a length-\\(M\\) step (non-zero only in \\(0\\) to \\(M - 1\\)) in \\(\\mathbb{C}^N\\):</p> \\[ x(n) = \\sum^{M - 1}_{h = 0} \\delta (n - h), \\ n = 0, 1, \\ldots, N - 1. \\] <p>Computing the DFT:</p> \\[ \\begin{align} X(k) &amp;= \\sum^{N - 1}_{n = 0} x(n) \\exp\\left\\{- j \\frac{2 \\pi}{N} nk \\right\\} = \\sum^{M - 1}_{n = 0} \\exp\\left\\{-j \\frac{2\\pi}{N} nk \\right\\} \\\\ &amp;= \\frac{1 - \\exp\\left\\{ -j \\frac{2\\pi}{N} kM \\right\\}}{1 - \\exp\\left\\{-j \\frac{2\\pi}{N} k \\right\\}} \\\\ &amp; = \\frac{\\exp\\left\\{- j \\frac{\\pi}{N} kM \\right\\} \\left[\\exp\\left\\{j \\frac{\\pi}{N} k M \\right\\} - \\exp\\left\\{-j \\frac{\\pi}{N} k M \\right\\} \\right]}{\\exp\\left\\{ -j \\frac{\\pi}{N} k \\right\\} \\left[ \\exp\\left\\{ j \\frac{\\pi}{N}k \\right\\} - \\exp\\left\\{ -j \\frac{\\pi}{N} k \\right\\} \\right]} \\\\ &amp;= \\frac{\\sin\\left( \\frac{\\pi}{N} M k \\right)}{\\sin\\left( \\frac{\\pi}{N} k \\right)} \\underbrace{\\exp \\left\\{ -j \\frac{\\pi}{N} \\left(M - 1 \\right) k \\right\\}}_{\\text{phase term}} \\end{align} \\]"},{"location":"prerequisites/dsp_notes/discrete_fourier_transform/#short-time-fourier-transform-algorithm","title":"Short-Time Fourier Transform Algorithm","text":"<p>Time representation obfuscates frequency and frequency representation obfuscates time. For a time-varying frequencies, it's better to plot spectrogram.</p> <p>The idea behind STFT is to take small signal pieces of length \\(L\\) and look at the DFT of each piece:</p> \\[ X(m; k) = \\sum^{L - 1}_{n = 0} x(m + n) \\exp\\left\\{- j \\frac{2 \\pi}{L} n k \\right\\}, \\] <p>where \\(m\\) is the starting point for the localized DFT and \\(k\\) is the DFT index for that chunk. Given sampling rate \\(f_s\\), the highest positive frequency available will be \\(f_s / 2\\). The frequency resolution will be \\(f_s / L\\) and the width of the time slices will be \\(L t_s = L / f_s\\).</p>"},{"location":"prerequisites/dsp_notes/discrete_fourier_transform/#interpreting-dft-spectrum","title":"Interpreting DFT Spectrum","text":"<p>For real signals, magnitutde plots need only \\(\\lfloor N / 2 \\rfloor + 1\\) frequencies. The vertical axis is the mantitude \\(|X(k)|\\) and the horizontal axis is the analysis frequencies.</p> <ol> <li>Frequency cofficients, \\(k\\) are from \\(0\\) to \\(N - 1\\).</li> <li>The first \\(N / 2\\) coefficients correspond to frequencies less than \\(\\pi\\) (counterclockwise rotation).</li> <li>The second \\(N / 2\\) coefficients correspond to frequencies greater than \\(\\pi\\) (clockwise rotation).</li> <li>Low frequency bands are close to \\(0\\) and \\(N - 1\\) (slow rotation around the unit circle either counterclockwise or clockwise).</li> <li>High frequency band is centered around \\(N / 2\\).</li> <li>Sudden transitions in a time sequence represents high-frequency components (as well as increase in frequency components).</li> <li>Square magnitude of \\(k\\)-th DFT coefficient is proportional to signal's energy at frequency \\(w = \\frac{2 \\pi}{N} k\\).</li> </ol>"},{"location":"prerequisites/dsp_notes/discrete_time_fourier_transform/","title":"Discrete-Time Fourier Transform","text":""},{"location":"prerequisites/dsp_notes/discrete_time_fourier_transform/#overview","title":"Overview","text":"<p>Discrete-Time Fourier Transform is an extension of DFT for infinite length non-periodic signals. Intuitively, as \\(N \\rightarrow \\infty\\), the analysis frequencies \\((2 \\pi / N) k\\) becomes denser in \\(\\left[0, 2\\pi\\right]\\), i.e., \\(w \\in \\mathbb{R}\\). Hence, DTFT is continuous in the frequency domain whereas DFT is discrete in the frequency domain. Formally, DTFT is a change of basis in the space \\(\\mathbb{C}^{\\infty}\\), where the uncountable set of functions \\(e^{jwn}\\), \\(w \\in \\mathbb{R}\\) forms an orthogonal basis.</p> <p>While DTFT is defined to process an infinitely long signal, DFT is defined to process a periodic signal (the periodic part being of finite length). For DFT, the number of frequency bins in your spectrum is always equal to the number or samples processed, so this also gives a difference in spectrums they produce. Whilst DFT is suitable for signal processing, the fact that the input signal is supposed to be an excerpt of a periodic signal however is disregarded most of the time. Hence, the spectrum from DFT is not the actual spectrum of your signal. It is the spectrum of a theoretical signal that you would get if you periodically repeated the input vector (reference).</p>"},{"location":"prerequisites/dsp_notes/discrete_time_fourier_transform/#discrete-time-fourier-transform-algorithm","title":"Discrete-Time Fourier Transform Algorithm","text":"<p>Let the input signal be square summable (finite-energy), i.e., \\(x(n) \\in \\ell_2(\\mathbb{Z})\\). Define the function of \\(w \\in \\mathbb{R}\\):</p> \\[ \\begin{align} F(w) = \\sum^{\\infty}_{n = -\\infty} x(n) \\exp \\left\\{-jwn \\right\\}. \\end{align} \\] <p>The inverse transform is (when \\(F(w)\\) exists):</p> \\[ \\begin{align} x(n) = \\frac{1}{2\\pi} \\int^{\\pi}_{-\\pi} F(w) \\exp \\left\\{j w n \\right\\} dw, \\quad n \\in \\mathbb{Z}. \\end{align} \\] <p>The DTFT, as an operator, maps an infinite-length sequence \\(x(n)\\) to a function of real variable \\(w\\); by definition, the resulting function is \\(2 \\pi\\)-periodic in \\(w\\), and therefere the notation \\(X(e^{jw})\\) is used to highlight this property:</p> \\[ X(e^{jw}) = \\sum^{\\infty}_{n = -\\infty} x(n) \\exp\\left\\{ -jwn \\right\\}. \\]"},{"location":"prerequisites/dsp_notes/discrete_time_fourier_transform/#properties","title":"Properties","text":"Property Definition Linearity \\(\\text{DTFT}\\left\\{\\alpha x(n) + \\beta y(n) \\right\\} = \\alpha X(e^{jw}) + \\beta Y(e^{jw})\\) Time Shift \\(\\text{DTFT}\\left\\{ x(n - M) \\right\\} = e^{-jwM} X(e^{jw})\\) Modulation \\(\\text{DTFT}\\left\\{ e^{jw_0 n} x(n) \\right\\} = X(e^{j(w - w_0)})\\) Time Reversal \\(\\text{DTFT}\\left\\{ x(-n) \\right\\} = X(e^{-jw})\\) Conjugation \\(\\text{DTFT}\\left\\{ x^* (n) \\right\\} = X^* (e^{-jw})\\)"},{"location":"prerequisites/dsp_notes/discrete_time_fourier_transform/#interpreting-dtft-spectrum","title":"Interpreting DTFT Spectrum","text":"<ol> <li>By convention, \\(X(e^{jw})\\) is represented over \\(\\left[-\\pi, \\pi \\right]\\).</li> <li>Positive frequencies between \\(0\\) and \\(\\pi\\) are associated to counterclockwise rotations of the underlying complex exponentials; conversely, frequencies between \\(-\\pi\\) and \\(0\\) are associated to clockwise rotations.</li> <li>Low frequencies (slow) will be centered around \\(0\\) and the high frequencies (fast) will be closer to \\(\\pm\\pi\\).</li> <li>The period is \\(2\\pi\\).</li> </ol>"},{"location":"prerequisites/dsp_notes/fir_filters/","title":"Finite Impulse Response Filters","text":""},{"location":"prerequisites/dsp_notes/fir_filters/#overview","title":"Overview","text":"<p>Given a finite duration of nonzero input values, an FIR filter will always have a finite duration of nonzero output values. No previous filter output value is used to determine a current output value; only input values are used to calculate output values.</p>"},{"location":"prerequisites/dsp_notes/fir_filters/#designing-fir-filters","title":"Designing FIR Filters","text":"<p>Define \\(H(m)\\) over the frequency span \\(-f_s / 2\\) to \\(f_s / 2\\).</p> Algebraic Coefficient Determination <ol><li>Develop an expression for the discrete frequency response \\(H(m)\\)</li><li>Apply that expression to the inverse DFT equation to get the time domain \\(h(k)\\), where \\(k\\) is the time-domain index</li><li>Evaluate that \\(h(k)\\) expression as a function of time index \\(k\\)</li></ol> Inverse DFT \\(\\begin{align*}h(k) &amp;= \\frac{1}{N} \\sum^{N / 2}_{m = -(N / 2) + 1} H(m) \\exp \\left\\{j 2 \\pi m k / N \\right\\} \\\\ &amp;= \\frac{1}{N} \\frac{\\sin\\left( \\pi k K / N \\right)}{\\sin \\left(\\pi k / N \\right)}\\end{align*}\\)"},{"location":"prerequisites/dsp_notes/harmonics/","title":"Harmonics","text":""},{"location":"prerequisites/dsp_notes/harmonics/#definition","title":"Definition","text":"<p>The spectrum of a periodically varying voltages, except single-frequency sine and cosine wave voltages, contains a fundamental frequency component plus harmonic frequency components (higher frequency sinusoids.) A time signal having very abrupt ampltitude changes, like a square wave, contains higher-frequency spectral content than a single-frequency sinusoidal signal that has more gradual ampltitude changes.</p>"},{"location":"prerequisites/dsp_notes/harmonics/#example","title":"Example","text":"<p>Consider a high-amplitude 2Hz sine wave along with lower-amplitude 6Hz and 10Hz sine waves as shown in Figure 1 (a). The summation of the three waves yields to the square wave as shown in (b). The more of its odd harmonics we add to a 2Hz sine wave, the closer the summation waveform will look like a 2Hz square wave. Hence, we say that a square wave compromises a fundamental 2Hz sine wave plus that sine wave's odd harmonics.</p> <p>The spectrum of the square wave is shown in (c).</p> <p> </p> Figure 1 Harmonics of 2Hz sine wave"},{"location":"prerequisites/dsp_notes/iir/","title":"Infinite Impuse Response Filters","text":""},{"location":"prerequisites/dsp_notes/iir/#overview","title":"Overview","text":"<p>Class of digital filters that are not guaranteed to be stable and always have nonlinear phase response. IIR filters have a much steeper transition region roll-off (superior performance) than digital FIR filters.</p> <p>Where FIR filter output samples depend only on past input samples, each IIR filter output sample depends on previous input samples and previous filter output samples.</p>"},{"location":"prerequisites/dsp_notes/modulation/","title":"Modulation","text":""},{"location":"prerequisites/dsp_notes/modulation/#definition","title":"Definition","text":"<p>Modulation is a method to shift the spectral content of a signal in frequency. Sinusoidal modulation:</p> \\[ \\begin{align} \\text{DTFT}\\left\\{ x(n) \\cos \\left( w_c n \\right) \\right\\} &amp;= \\text{DTFT} \\left\\{\\frac{1}{2} e^{jw_c n} x(n) + \\frac{1}{2} e^{-jw_c n} x(n) \\right\\} \\\\ &amp;= \\frac{1}{2} \\left[ X(e^{j(w - w_c)}) + X(e^{j(w + w_c)}) \\right]. \\end{align} \\] <p>Usually \\(x(n)\\) is baseband and \\(w_c\\) is called the carrier frequency.</p>"},{"location":"prerequisites/dsp_notes/modulation/#demodulation","title":"Demodulation","text":"<p>Just multiply the received signal by the carrier again</p> \\[ \\begin{align} y(n) = x(n) \\cos(w_c n) \\quad Y(e^{jw}) = \\frac{1}{2} \\left[ X(e^{j(w - w_c)}) + X(e^{j(w + w_c)}) \\right]. \\end{align} \\] <p>Then:</p> \\[ \\begin{align} \\text{DTFT} \\left\\{ y(n) * 2 \\cos(w_c n) \\right\\} &amp;= Y(e^{j(w - w_c) + Y(e^{j(w + w_c)})}) \\\\ &amp;= \\frac{1}{2}\\left[X(e^{j(w - 2w_c)}) + X(e^{j(w)}) + X(e^{j(w)}) + X(e^{j(w + 2w_c)}) \\right] \\\\ &amp;= X(e^{j(w)}) + \\frac{1}{2} \\left[ X(e^{j(w - w_c)}) + X(e^{j(w + w_c)}) \\right]. \\end{align} \\]"},{"location":"prerequisites/dsp_notes/references/","title":"References","text":"<ol> <li>Lyons, Richard, Understanding Digital Signal Processing, 3rd Edition, 2010. </li> <li>https://pysdr.org/</li> </ol>"},{"location":"prerequisites/dsp_notes/sampling_theorem/","title":"Sampling Theorem","text":""},{"location":"prerequisites/dsp_notes/sampling_theorem/#proper-sampling","title":"Proper Sampling","text":"<p>To describe a full revolution around a unit circle for the fastest sinusoid with a positive frequency (\\(w = \\pi\\)), it requires two samples. If the system clock is \\(t_s\\) (\\(f_s = 1 / t_s\\)), to sample the real-world fastest sinusoid, the overall period required is \\(2 t_s\\) or \\(f_s / 2\\) frequency. Hence, the highest frequency spectral content that can be captured is \\(f_s / 2\\) which corresponds to the analysis frequency \\(k = N / 2\\) where \\(N\\) is the number of samples. This gives the basis for the Nyquist sampling theorem.</p> <p>The Nyquist sampling criterion indicates that a continuous signal can be properly sampled, only if it does not contain frequency components above one-half of the sampling rate (the Nyquist frequency, the folding frequency, or the cutoff frequency). In order words, given a band-limited signal with band \\(\\pm B\\), \\(f_s\\) must be greater than \\(2B\\) to separate spectral replications at the folding frequencies of \\(\\pm f_s / 2\\).</p> <p>In most systems, the frequency band between about 0.4 and 0.5 of the sampling frequency is an ususable wasteland of filter roll-off and aliased signals. This is a direct result of the limitations of analog filters.</p>"},{"location":"prerequisites/dsp_notes/sampling_theorem/#sample-rate-conversion","title":"Sample Rate Conversion","text":"<p>Changing the sample rate of a digital signal can be done via decimation (reduction in sample rate) and interpolation (increase in sample rate). A common interpolation scheme is via zero-insertion followed by a lowpass filter.</p>"},{"location":"prerequisites/dsp_notes/sampling_theorem/#aliasing-and-spectral-replica","title":"Aliasing and Spectral Replica","text":"<p>Aliasing gets introduced when we do improper sampling. Consider a continuous sinusoidal signal \\(x(t) = \\sin \\left( 2 \\pi f t \\right)\\). Sampling at \\(f_s = 1 / t_s\\) yields to a discrete samples:</p> \\[ \\begin{align} x(n) &amp;= \\sin(2 \\pi f n t_s) \\\\ &amp;= \\sin(2 \\pi f n t_s + 2 \\pi m) \\\\ &amp;= \\sin \\left( 2\\pi \\left(f + \\frac{m}{nt_s} \\right) nt_s \\right). \\end{align} \\] <p>Let \\(m\\) be an integer multiple of \\(n\\), i.e., \\(m = kn\\). Then we have:</p> \\[ x(n) = \\sin\\left( 2 \\pi \\left( f + k f_s \\right) n t_s \\right). \\] <p>This equation means that when the sampling rate is \\(f_s\\), we cannot distinguish between the sampled values of a sinewave of frequency \\(f\\), and a sinewave of \\(f + k f_s\\) for \\(k \\in \\mathbb{Z}\\). The spectrum of any discrete series of sampled values contains periodic replications of the original continuous spectrum. The period between these replicated spectra in the frequency domain will always be \\(f_s\\). Every sampling operation inherently results in spectral replications.</p>"},{"location":"prerequisites/dsp_notes/sampling_theorem/#bandpass-sampling","title":"Bandpass Sampling","text":"<p>Bandpass sampling (IF sampling or undersampling) is a technique where we can sample a bandpass-filtered signal at a sample rate below its Nyquist frequency without introducing aliasing. In bandpass sampling, we are more concerned with the signal's bandwidth than its highest frequency component. </p> <p>Consider a continuous bandpass signal with bandiwth \\(B\\) and carrier frequency \\(f_c\\) (center frequency). Given an arbitrary number of replications, \\(m\\), to avoid aliasing, we can choose \\(f_s\\) as:</p> \\[ \\frac{2f_c - B}{m} \\geq f_s \\geq \\frac{2f_c + B}{m + 1}, \\quad f_s \\geq 2B. \\] <p>The upper limit is because if we increase the sampling rate \\(f_s\\), the original spectra do not shift, but all the replications will shift, causing them to overlap and introduce aliasing.</p>"},{"location":"prerequisites/dsp_notes/sampling_theorem/#function-approximation","title":"Function Approximation","text":"<p>Under appropriate \"slowness\" conditions for a continuous signal \\(x(t)\\), we have:</p> \\[ x(t) = \\sum^{\\infty}_{n = -\\infty} x(n t_s) \\text{sinc} \\left( \\frac{t - nt_s}{t_s} \\right), \\] <p>where \\(t_s\\) is the sampling interval.</p>"},{"location":"prerequisites/dsp_notes/termanologies/","title":"Termanologies","text":"Term Definition Lowpass signal (baseband) Signals that have their frequency components centered around the zero frequency Highpass signal Signals that have their frequency components centered around high frequency Bandpass signal Inbetween lowpass and highpass signals Bandiwdth Frequency range over which a signal contains significant spectral energy IIR Infinite impulse response FIR Finite impulse response Signal-to-noise ratio \\(\\text{SNR} = \\frac{\\mu}{\\sigma}\\). Better data means a higher value for the SNR and a lower value for the CV. For example, signal with a CV of 2% has an SNR of 50. Coefficient of variation (CV) \\(\\text{CV} = \\frac{\\mu}{\\sigma} \\times 100\\) Stationary signal A signal whose statistical properties such as mean, variance, and autocorrelation, do no change over time Passband Frequency range of signals that will pass through the filter Stopband Frequency range of signals that will be blocked from passing through the filter"},{"location":"prerequisites/dsp_notes/wavelets/","title":"Wavelets","text":""},{"location":"prerequisites/dsp_notes/wavelets/#overview","title":"Overview","text":"<p>Refer to Conceptual Wavelets</p>"},{"location":"prerequisites/matrix_factorization/cholesky_decomposition/","title":"Cholesky Decomposition","text":""},{"location":"prerequisites/matrix_factorization/cholesky_decomposition/#definition","title":"Definition","text":"<p>A symmetric, positive definite matrix \\(\\mathbf{A}\\) can be decomposed into a product of a unique lower triangular matrix \\(\\mathbf{L}\\) and its transpose:</p> \\[ \\begin{align} &amp;\\mathbf{A} = \\mathbf{L} \\mathbf{L}^T, \\end{align} \\] <p>or equivalently:</p> \\[ \\begin{align} &amp;\\left[ \\begin{array}{ccc} A_{11} &amp; A_{12} &amp; A_{13} \\\\ A_{21} &amp; A_{22} &amp; A_{23} \\\\ A_{31} &amp; A_{32} &amp; A_{33} \\end{array} \\right] = \\left[ \\begin{array}{ccc} L_{11} &amp; 0 &amp; 0 \\\\ L_{21} &amp; L_{22} &amp; 0 \\\\ L_{31} &amp; L_{32} &amp; L_{33} \\end{array} \\right] \\left[ \\begin{array}{ccc} L_{11} &amp; L_{21} &amp; L_{31} \\\\ 0 &amp; L_{22} &amp; L_{32} \\\\ 0 &amp; 0 &amp; L_{33} \\end{array} \\right] \\\\ &amp;= \\left[ \\begin{array}{ccc} L^2_{11} &amp; L_{21} L_{11} &amp; L_{31} L_{11} \\\\ L_{21} L_{11} &amp; L^2_{21} + L^2_{22} &amp; L_{31} L_{21} + L_{32} L_{22} \\\\ L_{31} L_{11} &amp; L_{31} L_{21} + L_{32} L_{22} &amp; L^2_{31} + L^2_{32} + L^2_{33} \\end{array} \\right]. \\end{align} \\] <p>Hence, \\(\\mathbf{L}\\) can be obtained as:</p> \\[ \\mathbf{L} = \\left[ \\begin{array}{ccc} \\sqrt{A_{11}} &amp; 0 &amp; 0 \\\\ A_{21} / L_{11} &amp; \\sqrt{A_{22} - L^2_{21}} &amp; 0 \\\\ A_{31} / L_{11} &amp; (A_{32} - L_{31} L_{21}) / L_{22} &amp; \\sqrt{A_{33} - L^2_{31} - L^2_{32}} \\end{array} \\right], \\] <p>or equivalently:</p> \\[ \\begin{align} L_{jj} &amp;= (\\pm) \\sqrt{A_{jj} - \\sum^{j - 1}_{k = 1} L^2_{jk}}, \\\\ L_{ij} &amp;= \\frac{1}{L_{jj}} \\left(A_{ij} - \\sum^{j - 1}_{k = 1} L_{ik} L_{jk} \\right) \\quad \\text{for} \\ i &gt; j. \\end{align} \\]"},{"location":"prerequisites/matrix_factorization/cholesky_decomposition/#ldl-decomposition","title":"LDL Decomposition","text":"<p>A closely related variant of the classical Cholesky decomposition is the LDL decomposition:</p> \\[ \\mathbf{A} = \\mathbf{L} \\mathbf{D} \\mathbf{L}^{T}, \\] <p>where \\(\\mathbf{L}\\) is unit lower triangular (with zeros above the diagonal and units on the diagonal) and \\(\\mathbf{D}\\) is diagonal. Since \\(\\mathbf{L}^T = \\mathbf{U}\\) is a unit upper triangular matrix, it is also called the LDU factorization. The main advantage is that the LDL decomposition can be computed and used with essentially the same algorithms, but avoids extracting square roots. For this reason, it is also called the square-root-free Cholesky decomposition.</p>"},{"location":"prerequisites/matrix_factorization/cholesky_decomposition/#applications","title":"Applications","text":""},{"location":"prerequisites/matrix_factorization/cholesky_decomposition/#pseudo-inverse","title":"Pseudo-Inverse","text":"<p>For a full-rank \\(\\mathbf{A}\\) matrices (observable systems), we have:</p> \\[ \\begin{align} \\mathbf{A} \\mathbf{x} &amp;= \\mathbf{y} \\\\ \\mathbf{A}^T \\mathbf{A} \\mathbf{x} &amp;= \\mathbf{A}^T \\mathbf{y} \\\\ \\mathbf{x} &amp;= \\left( \\mathbf{A}^T \\mathbf{A} \\right)^{-1} \\mathbf{A}^T \\mathbf{y} \\\\ \\mathbf{A}^{\\dagger} &amp;= \\left( \\mathbf{A}^T \\mathbf{A} \\right)^{-1} \\mathbf{A}^T. \\end{align} \\] <p>Assume that back-substitution is quicker to compute than the full inverse. We know that \\(\\mathbf{A}^T \\mathbf{A}\\) is symmetric and positive definite.</p>"},{"location":"prerequisites/matrix_factorization/qr_decomposition/","title":"QR Decomposition","text":""},{"location":"prerequisites/matrix_factorization/qr_decomposition/#definition","title":"Definition","text":"<p>Theorem (QR Decomposition)</p> <p>A matrix \\(\\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\), with \\(m \\geq n\\) can be factorized to an unitary matrix \\(\\mathbf{Q} \\in \\mathbb{R}^{m \\times m}\\) and an upper triangular matrix \\(\\mathbf{R} \\in \\mathbb{R}^{m \\times n}\\) as:</p> \\[ \\mathbf{A} = \\mathbf{Q} \\mathbf{R}. \\] <p>The idea of QR decomposition is the construction of a sequence of orthonormal vectors \\(\\langle \\mathbf{q}_1, \\ldots, \\mathbf{q}_n\\rangle\\) that are the columns of matrix \\(\\mathbf{Q}\\) which spans the column spaces of matrix \\(\\mathbf{A}\\) which are \\(\\langle \\mathbf{a}_1, \\ldots, \\mathbf{a}_n \\rangle\\). Every \\(\\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\) \\(\\left(m \\geq n \\right)\\) has QR factorization. </p> <p>Since the bottom rows of the \\(\\mathbf{R}\\) consist entirely of zeroes, it is often useful to partition \\(\\mathbf{R}\\) and \\(\\mathbf{Q}\\) as:</p> \\[ \\mathbf{A} =  \\mathbf{Q} \\left[ \\begin{array}{c} \\mathbf{R}_1 \\\\ \\mathbf{0} \\end{array} \\right] =  \\left[ \\begin{array}{cc} \\mathbf{Q}_1 &amp; \\mathbf{Q}_2 \\end{array} \\right]  \\left[ \\begin{array}{c} \\mathbf{R}_1 \\\\ \\mathbf{0} \\end{array} \\right] =  \\mathbf{Q}_1 \\mathbf{R}_1, \\] <p>where \\(\\mathbf{R}_1\\) is an \\(n \\times n\\) upper triangular matrix, \\(\\mathbf{0}\\) is an \\((m - n) \\times n\\) zero matrix, \\(\\mathbf{Q}_1\\) is \\(m \\times n\\), \\(\\mathbf{Q}_2\\) is \\(m \\times (m - n)\\), and \\(\\mathbf{Q}_1\\) and \\(\\mathbf{Q}\\)_2 both have orthogonal columns.</p>"},{"location":"prerequisites/matrix_factorization/qr_decomposition/#applications","title":"Applications","text":""},{"location":"prerequisites/matrix_factorization/qr_decomposition/#pseudo-inverse","title":"Pseudo-Inverse","text":"<p>Compared to the direct matrix inverse, inverse solutions using QR decomposition are more numerically stable as evidenced by their reduced condition numbers.</p> <p>Given:</p> \\[ \\mathbf{A} = \\mathbf{Q} \\mathbf{R}, \\] <p>we have:</p> \\[ \\mathbf{A} \\mathbf{x} = \\mathbf{z} \\Rightarrow \\mathbf{R} \\mathbf{x} = \\mathbf{Q}^T \\mathbf{z}. \\]"},{"location":"prerequisites/matrix_factorization/singular_value_decomposition/","title":"Singular Value Decomposition","text":""},{"location":"prerequisites/matrix_factorization/singular_value_decomposition/#definition","title":"Definition","text":"<p>Theorem (Singular Value Decomposition)</p> <p>Given a matrix \\(\\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\), there exist orthogonal square matrices:</p> \\[ \\begin{align} \\mathbf{U} &amp;=  \\left[  \\begin{array}{ccccc} \\mathbf{u}_1 &amp; | &amp; \\cdots &amp; | &amp; \\mathbf{u}_m \\end{array} \\right] \\in \\mathbb{R}^{m \\times m}, \\\\  \\mathbf{V} &amp;=  \\left[  \\begin{array}{ccccc} \\mathbf{v}_1 &amp; | &amp; \\cdots &amp; | &amp; \\mathbf{v}_n \\end{array} \\right] \\in \\mathbb{R}^{n \\times n}, \\end{align} \\] <p>such that:</p> \\[ \\mathbf{U}^T \\mathbf{A} \\mathbf{V} = \\boldsymbol{\\Sigma} = \\text{diag} \\left(\\sigma_1, \\ldots, \\sigma_p \\right) \\in \\mathbb{R}^{m \\times n}, \\quad p = \\min \\left\\{m, n \\right\\}, \\] <p>where \\(\\sigma_1 \\geq \\sigma_2 \\geq \\ldots \\geq \\sigma_p \\geq 0\\). Equivalently:</p> \\[ \\mathbf{A} = \\mathbf{U} \\boldsymbol{\\Sigma} \\mathbf{V}^T. \\] <p>The number of non-zero singular values is equal to the rank of \\(\\mathbf{A}\\). The columns of \\(\\mathbf{U}\\) and the columns of \\(\\mathbf{V}\\) are called left-singular vectors and right-singular vectors of \\(\\mathbf{A}\\), respectively. They form two sets of orthonormal bases \\(\\mathbf{u}_1, \\ldots, \\mathbf{u}_m\\) and \\(\\mathbf{v}_1, \\ldots, \\mathbf{v}_n\\). </p> <p>For a square matrix \\(\\mathbf{A}\\), if they are sorted so that the singular values of \\(\\sigma_i\\) with value zero are all in the highest-numbered columns, the SVD can be written as:</p> \\[ \\mathbf{A} = \\sum^{r}_{i = 1} \\sigma_i \\mathbf{u}_i \\mathbf{v}^T_i, \\] <p>where \\(r\\) is the rank of \\(\\mathbf{A}\\).</p> <p>Separate visualizations of the SVD are required depending upon whether \\(\\mathbf{A}\\) has more rows or columns. 3-by-2 and 2-by-3 examples are:</p> \\[ \\begin{align} &amp;\\left[ \\begin{array}{ccc} u_{11} &amp; u_{12} &amp; u_{13} \\\\ u_{21} &amp; u_{22} &amp; u_{23} \\\\ u_{31} &amp; u_{32} &amp; u_{33} \\\\ \\end{array} \\right]^T \\left[ \\begin{array}{cc} a_{11} &amp; a_{12} \\\\ a_{21} &amp; a_{22} \\\\ a_{31} &amp; a_{32} \\\\ \\end{array} \\right] \\left[ \\begin{array}{cc} v_{11} &amp; v_{12} \\\\ v_{21} &amp; v_{22} \\\\ \\end{array} \\right] =  \\left[ \\begin{array}{cc} \\sigma_{1} &amp; 0 \\\\ 0 &amp; \\sigma_{2} \\\\ 0 &amp; 0 \\\\ \\end{array} \\right], \\\\  &amp;\\left[ \\begin{array}{cc} u_{11} &amp; u_{12} \\\\ u_{21} &amp; u_{22} \\\\ \\end{array} \\right]^T \\left[ \\begin{array}{ccc} a_{11} &amp; a_{12} &amp; a_{13} \\\\ a_{21} &amp; a_{22} &amp; a_{23} \\\\ \\end{array} \\right] \\left[ \\begin{array}{ccc} v_{11} &amp; v_{12} &amp; v_{13} \\\\ v_{21} &amp; v_{22} &amp; v_{23} \\\\ v_{31} &amp; v_{32} &amp; v_{33} \\\\ \\end{array} \\right] =  \\left[ \\begin{array}{ccc} \\sigma_{1} &amp; 0 &amp; 0 \\\\ 0 &amp; \\sigma_{2} &amp; 0 \\\\ \\end{array} \\right]. \\end{align} \\]"},{"location":"prerequisites/matrix_factorization/singular_value_decomposition/#properties","title":"Properties","text":"<p>Property 1</p> <p>If \\(\\mathbf{U}^T \\mathbf{A} \\mathbf{V} = \\boldsymbol{\\Sigma}\\) is the SVD of \\(\\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\) and \\(m \\geq n\\), then for \\(i = 1 \\ldots, n\\):</p> \\[ \\mathbf{A} \\mathbf{v}_i = \\sigma_i \\mathbf{u}_i \\ \\text{and} \\ \\mathbf{A}^T \\mathbf{u}_i = \\sigma_i \\mathbf{v}_i. \\] <p>The geometry behind this result is that the singular values of the matrix \\(\\mathbf{A}\\) are the lengths of the semiaxes of the hyperellipsoid \\(E\\) defined by \\(E = \\left\\{ \\mathbf{A} \\mathbf{x}: \\ ||\\mathbf{x}||_2 = 1 \\right\\}\\). The semiaxes directions are defined by the \\(\\mathbf{u}_i\\) and their lengths are the singular values. From the property:</p> \\[ \\begin{align} &amp; \\mathbf{A}^T \\mathbf{A} \\mathbf{v}_i = \\sigma^2_i \\mathbf{v}_i, \\\\  &amp;\\mathbf{A} \\mathbf{A}^T \\mathbf{u}_i = \\sigma^2_i \\mathbf{u}_i, \\end{align} \\] <p>for \\(i = 1, \\ldots, n\\). This shows that there is an intimate connection between the SVD of \\(\\mathbf{A}\\) and the eigensystems of the symmetric matrices \\(\\mathbf{A}^T \\mathbf{A}\\) and \\(\\mathbf{A} \\mathbf{A}^T\\).</p> <p>If \\(\\mathbf{M}\\) is a symmetric matrix with eigenvalues \\(\\lambda_1, \\ldots, \\lambda_n\\) and orthonormal eigenvectors \\(\\mathbf{u}_1, \\ldots, \\mathbf{u}_n\\), i.e., \\(\\mathbf{M} = \\mathbf{U} \\boldsymbol{\\Lambda} \\mathbf{U}^T\\), where \\(\\mathbf{U} = \\left[ \\begin{array}{ccc} \\mathbf{u}_1, \\ldots, \\mathbf{u}_n \\end{array}\\right]\\), then \\(\\mathbf{M = \\mathbf{U} \\boldsymbol{\\Sigma} \\mathbf{V}^T}\\), where \\(\\sigma_i = |\\lambda_i|\\) and \\(\\mathbf{v}_i = \\text{sign}(\\lambda_i) \\mathbf{u}_i\\).</p> <p>Eigenvalues of \\(\\mathbf{A}^T \\mathbf{A}\\) are \\(\\sigma^2_1, \\ldots, \\sigma^2_n\\) and the eigenvectors are \\(\\mathbf{v}_1, \\ldots, \\mathbf{v}_n\\):</p> \\[ \\mathbf{A}^T \\mathbf{A} = \\mathbf{V} \\boldsymbol{\\Sigma} \\mathbf{U}^T \\mathbf{U} \\boldsymbol{\\Sigma} \\mathbf{V}^T = \\mathbf{V} \\boldsymbol{\\Sigma}^2 \\mathbf{V}^T. \\] <p>Property 2</p> <p>If \\(\\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\), then:</p> \\[ ||\\mathbf{A}||_2 = \\sigma_1, \\quad ||\\mathbf{A}||_F = \\sqrt{\\sigma^2_1 + \\cdots + \\sigma^2_p}, \\] <p>where \\(p = \\min \\left\\{ m, n \\right\\}\\).</p> <p>If \\(\\mathbf{A}\\) is perturbed by a matrix \\(\\mathbf{E}\\), then no singular value can move by more than \\(||\\mathbf{E}||_2\\). The following property identifies two useful instances of this result.</p> <p>Property 3</p> <p>If \\(\\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\) and \\(\\mathbf{E} \\in \\mathbb{R}^{m \\times n}\\), then:</p> \\[ \\begin{align} \\sigma_{\\max} \\left( \\mathbf{A} + \\mathbf{E} \\right) &amp;\\leq \\sigma_\\max \\left( \\mathbf{A} \\right) + ||\\mathbf{E}||_2, \\\\ \\sigma_{\\min} \\left( \\mathbf{A} + \\mathbf{E} \\right) &amp;\\geq \\sigma_\\min \\left( \\mathbf{A} \\right) - ||\\mathbf{E}||_2. \\end{align} \\]"},{"location":"prerequisites/matrix_factorization/singular_value_decomposition/#applications","title":"Applications","text":""},{"location":"prerequisites/matrix_factorization/singular_value_decomposition/#pseudo-inverse","title":"Pseudo-Inverse","text":"<p>Given:</p> \\[ \\mathbf{A} = \\mathbf{U} \\boldsymbol{\\Sigma} \\mathbf{V}^T, \\] <p>the pseudo-inverse of \\(\\mathbf{A}\\), denoted as \\(\\mathbf{A}^\\dagger\\) can be computed as:</p> \\[ \\mathbf{A}^\\dagger = \\mathbf{V} \\boldsymbol{\\Sigma}^{\\ddagger} \\mathbf{U}^T, \\] <p>where \\(\\ddagger\\) implies inverting every non-zero diagonal element. See Least Squares for more information.</p>"},{"location":"prerequisites/matrix_factorization/singular_value_decomposition/#nearest-orthogonal-matrix","title":"Nearest Orthogonal Matrix","text":"<p>Given a real square matrix \\(\\mathbf{A}\\), the orthogonal matrix \\(\\mathbf{O}\\) closest to \\(\\mathbf{A}\\) is \\(\\mathbf{U} \\mathbf{V}^T\\). The closeness of fit is measured by the Frobenius norm of \\(\\mathbf{O} - \\mathbf{A}\\). The orthogonal matrix would have the decomposition \\(\\mathbf{O} = \\mathbf{U} \\mathbf{I} \\mathbf{V}^T\\), so that if \\(\\mathbf{A} = \\mathbf{U} \\boldsymbol{\\Sigma} \\mathbf{V}^T\\), then the product \\(\\mathbf{A} = \\mathbf{U} \\mathbf{V}^T\\) amounts to replacing the singular values with ones.</p>"},{"location":"prerequisites/matrix_factorization/singular_value_decomposition/#kabsch-algorithm","title":"Kabsch Algorithm","text":"<p>See Kabsch Algorithm.</p>"},{"location":"prerequisites/matrix_factorization/singular_value_decomposition/#low-rank-matrix-approximation","title":"Low-Rank Matrix Approximation","text":"<p>Given a full rank matrix \\(\\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\), we can use SVD to find a \"simpler\" matrix \\(\\tilde{\\mathbf{A}}\\) that \"approximates\" \\(\\mathbf{A}\\) well. </p> <ol> <li> <p>To define the criterion for a \"simple\" matrix, we can use the rank of the matrix:</p> \\[ \\text{rank}(\\tilde{\\mathbf{A}}) = r \\ll \\text{rank}(\\mathbf{A}). \\] </li> <li> <p>To define the criterion for \"approximation\", we can use \\(\\mathcal{l}_2\\) norm and \\(\\epsilon\\):</p> \\[ ||\\tilde{\\mathbf{A}} - \\mathbf{A}||_2 &lt; \\epsilon. \\] </li> </ol> <p>\\(\\tilde{\\mathbf{A}}\\) is called low rank matrix. Then the low-rank matrix approximation can turn into an optimization problem:</p> \\[ \\begin{align} \\min_{\\tilde{\\mathbf{A}}} \\quad&amp; ||\\tilde{\\mathbf{A}} - \\mathbf{A}||_2 \\\\ \\text{s.t.} \\quad&amp; \\text{rank}(\\tilde{\\mathbf{A}}) = r \\\\ &amp;\\tilde{\\mathbf{A}} \\in \\mathbb{R}^{m \\times n}, \\end{align} \\] <p>which is a least squares problem with a constraint.</p> <p>Theorem. Let \\(\\mathbf{A} = \\sum^n_{i = 1} \\sigma_i \\mathbf{u}_i \\mathbf{v}^T_i = \\mathbf{U} \\boldsymbol{\\Sigma} \\mathbf{V}^T\\) be the SVD of the \\(m \\times n\\) matrix \\(\\mathbf{A}\\) with \\(m \\geq n\\), where \\(\\mathbf{U} = \\left[ \\begin{array}{ccc} \\mathbf{u}_1, \\ldots, \\mathbf{u}_m \\end{array} \\right]\\), \\(\\mathbf{V} = \\left[ \\begin{array}{ccc} \\mathbf{v}_1, \\ldots, \\mathbf{v}_n \\end{array} \\right]\\), and \\(\\boldsymbol{\\Sigma} = \\text{diag}(\\sigma_1, \\ldots, \\sigma_n)\\) with \\(\\sigma_1 \\geq \\ldots \\geq \\sigma_n\\). Then the rank \\(r\\) matrix \\(\\tilde{\\mathbf{A}}\\) closest to \\(\\mathbf{A}\\) in \\(\\mathcal{l}_2\\) norm is given by \\(\\tilde{\\mathbf{A}} = \\sum^{r}_{i = 1} \\sigma_i \\mathbf{u}_i \\mathbf{v}^T_i = \\mathbf{U} \\boldsymbol{\\Sigma}_r \\mathbf{v}^T\\), where \\(\\boldsymbol{\\Sigma}_r = \\text{diag}(\\sigma_1, \\ldots, \\sigma_r, \\mathbf{0})\\). Furthemore, \\(||\\tilde{\\mathbf{A}} - \\mathbf{A}||_2 = \\sigma_{r + 1}\\).</p> <p>An example of low-rank matrix approximation is image compression. See Compression via Low-Rank Matrix Approximation.</p>"},{"location":"prerequisites/sets/convex_sets/","title":"Convex Sets","text":""},{"location":"prerequisites/sets/convex_sets/#line-and-line-segments","title":"Line and Line Segments","text":"<p>Let \\(\\mathbf{x}_1 \\neq \\mathbf{x}_2\\) be two points in \\(\\mathbb{R}^n\\). Points of the form:</p> \\[ \\mathbf{y} = \\theta \\mathbf{x}_1 + (1 - \\theta)\\mathbf{x}_2, \\] <p>where \\(\\theta \\in \\mathbb{R}\\), form the line passing through  points \\(\\mathbf{x}_1\\) and \\(\\mathbf{x}_2\\). If  \\(\\theta = 0\\), it corresponds to \\(\\mathbf{y} = \\mathbf{x}_2\\), and  if \\(\\theta = 1\\), it corresponds to \\(\\mathbf{y} = \\mathbf{x}_1\\). If  \\(0 &lt; \\theta &lt; 1\\), then it corresponds to the line segment between \\(\\mathbf{x}_1\\) and  \\(\\mathbf{x}_2\\).</p>"},{"location":"prerequisites/sets/convex_sets/#affine-sets","title":"Affine Sets","text":"<p>A set \\(C \\subseteq \\mathbb{R}^n\\) is affine if the  line through any two distinct points in \\(C\\) lies in \\(C\\), i.e.,  if for any \\(\\mathbf{x}_1, \\mathbf{x}_2 \\in C\\) and \\(\\theta \\in \\mathbb{R}\\), we have \\(\\theta \\mathbf{x}_1 + (1 - \\theta) \\mathbf{x}_2 \\in C\\).  In other words, \\(C\\) contains the linear combination of any two points in  \\(C\\), provided the coefficients in the linear combination sum to one. In general, a point of the form \\(\\theta_1 \\mathbf{x}_1 + \\ldots + \\theta_k \\mathbf{x}_k\\),  where \\(\\theta_1 + \\ldots + \\theta_k = 1\\) is an affine combination of points \\(\\mathbf{x}_1, \\ldots, \\mathbf{x}_k\\).</p>"},{"location":"prerequisites/sets/convex_sets/#convex-sets","title":"Convex Sets","text":"<p>A set \\(C \\in \\mathbb{R}^n\\) is convex if the line segment between any two points in \\(C\\) lies in \\(C\\), i.e., if \\(\\forall \\mathbf{x}_1, \\mathbf{x}_2 \\in C\\) and  \\(\\theta \\in \\left[0, 1 \\right]\\), we have:</p> \\[ \\theta \\mathbf{x}_1 + (1 - \\theta) \\mathbf{x}_2 \\in C. \\] <p>Informally, this means that a  line segment connecting two points in the set lies entirely in the set. Another interepretation is that a set is convex if every point in the set can be seen by every other point, along an unobstructed straigth path between them, where unobstructed means lying in the set. </p> <p>Every affine set is convex, since it contains the entire line between any two distinct points in it, and  therefore also the line segment between the points.</p>"},{"location":"prerequisites/sets/convex_sets/#convex-combination","title":"Convex Combination","text":"<p>A point of the form \\(\\theta_1 \\mathbf{x}_1 + \\ldots + \\theta_k \\mathbf{x}_k\\) where \\(\\theta_1 + \\ldots + \\theta_k = 1\\) and \\(\\theta_i \\geq 0, i = 1, \\ldots, k\\) is called  a convex combination of the points \\(\\mathbf{x}_1, \\ldots, \\mathbf{x}_k\\). As with affine sets, it can be shown that a set is convex if and only if it contains every convex combination of its points. A convex combination of points can be thought of as a mixture or weighted average of the points, with \\(\\theta_i\\) the fraction of \\(\\mathbf{x}_i\\) in the mixture.</p>"},{"location":"prerequisites/sets/convex_sets/#convex-hull","title":"Convex Hull","text":"<p>The convex hull of a set \\(C\\) is the set of all convex combinations of points in \\(C\\):</p> \\[ \\text{conv}\\left\\{C\\right\\} = \\left\\{ \\theta_1 \\mathbf{x}_1 + \\ldots + \\theta_k \\mathbf{x}_k \\ | \\ \\mathbf{x}_i \\in C, \\theta_i \\geq 0, i = 1, \\ldots, k, \\theta_1 + \\ldots + \\theta_k = 1 \\right\\}. \\]"},{"location":"prerequisites/sets/convex_sets/#establishing-convexity-and-operations-preserving-convexity","title":"Establishing Convexity and Operations Preserving Convexity","text":"<p>A practical methods for establishing convexity of a set \\(C\\) is as follows:</p> <ol> <li> <p>Apply the definition:</p> \\[ \\mathbf{x}_1, \\mathbf{x}_2 \\in C, \\ 0 \\leq \\theta \\leq 1 \\ \\Rightarrow \\ \\theta \\mathbf{x}_1 + (1 - \\theta) \\mathbf{x}_2 \\in C. \\] </li> <li> <p>Show that \\(C\\) is obtained from simple convex sets (hyperplanes, halfspaces, norm balls etc.) by operations that preserve convexity:</p> <ol> <li>Intersection: If \\(X_1, \\ldots, X_m\\) are convex sets, then \\(\\cap^m_{i = 1} X_i\\) is a convex set.</li> <li> <p>Affine functions: If \\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m\\) is affine (i.e., if it is a sum of a linear functions and a constant, \\(f(\\mathbf{x}) = \\mathbf{A}\\mathbf{x} + \\mathbf{b}\\) where \\(\\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\) and \\(\\mathbf{b} \\in \\mathbb{R}^m\\)) and if \\(S \\subseteq \\mathbb{R}^n\\) is convex, then the image of \\(S\\) under \\(f\\):</p> \\[ f(S) = \\left\\{ f(\\mathbf{x}) \\ | \\ \\mathbf{x} \\in S \\right\\}, \\] <p>is convex. Similarly, the inverse image is also convex. Examples include scaling, translation, and sum. Sum of two sets \\(X, Y \\subseteq \\mathbb{R}^n\\) is defined as \\(X + Y = \\left\\{ \\mathbf{x} + \\mathbf{y} : \\mathbf{x} \\in X, \\mathbf{y} \\in Y \\right\\}\\). Given two sets \\(X \\subseteq \\mathbb{R}^{n_1}\\) and \\(Y \\subseteq \\mathbb{R}^{n_2}\\), their (Cartesian) product \\(X \\times Y\\) is a set in \\(\\mathbb{R}^{n_1 + n_2}\\) and is defined as:</p> \\[ X \\times Y = \\left\\{ [\\mathbf{x}^T, \\mathbf{y}^T]^T : \\mathbf{x} \\in X, \\mathbf{y} \\in Y \\right\\}. \\] </li> <li> <p>Perspective function: \\(P: \\mathbb{R}^{n + 1} \\rightarrow \\mathbb{R}^n\\):</p> \\[ P(\\mathbf{x}, t) = \\mathbf{x} / t, \\quad \\mathbf{x} \\in \\mathbb{R}^n, \\ t \\in \\mathbb{R}_{++}. \\] </li> <li> <p>Linear-fractional functions: \\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m\\):</p> \\[ f(\\mathbf{x}) = \\frac{\\mathbf{A}\\mathbf{x} + \\mathbf{b}}{\\mathbf{c}^T \\mathbf{x} + d}, \\quad \\textbf{dom}f = \\left\\{ \\mathbf{x} \\ | \\ \\mathbf{c}^T \\mathbf{x} + d &gt; 0 \\right\\} \\] </li> <li> <p>Union of two convex sets is not convex in general.</p> </li> </ol> </li> </ol>"},{"location":"prerequisites/sets/convex_sets/#convex-set-and-convex-functions-relationship","title":"Convex Set and Convex Functions Relationship","text":""},{"location":"prerequisites/sets/convex_sets/#epigraph","title":"Epigraph","text":"<p>The epigraph of a function \\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R}\\) is a set defined as:</p> \\[ \\text{epi} f = \\left\\{ (y, \\mathbf{x}) \\in \\mathbb{R}^{n + 1} : y \\geq f(\\mathbf{x}) \\right\\}. \\] <p>\"Epi\" means \"above\", so epigraph means \"above the graph\". </p> <p>The link between convex sets and convex functions is via the epigraph: A function is convex if and only if its epigraph is convex set.</p>"},{"location":"prerequisites/sets/convex_sets/#sublevel-sets","title":"Sublevel Sets","text":"<p>Given scalar \\(\\alpha\\), the \\(\\alpha\\)-level set of a function \\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R}\\) is a set defined as:</p> \\[ X_\\alpha = \\left\\{ \\mathbf{x} \\in \\mathbb{R}^n : f(\\mathbf{x}) \\leq \\alpha \\right\\}. \\] <p>The epigraph and the \\(\\alpha\\)-level set (\\(\\forall \\alpha \\in R\\)) of a convex function are convex sets.</p>"},{"location":"prerequisites/sets/geometry/","title":"Geometry","text":""},{"location":"prerequisites/sets/geometry/#rays","title":"Rays","text":"<p>A ray consists of a starting point \\(\\mathbf{a}\\) and all the points in a direction \\(\\mathbf{d}\\). Rays can be described via an algebraic form:</p> \\[ \\left\\lbrace \\mathbf{x} \\in \\mathbb{R}^n \\ | \\ \\mathbf{x} = \\mathbf{a} + \\theta \\mathbf{d}, \\quad \\forall \\theta \\geq 0 \\right\\rbrace. \\]"},{"location":"prerequisites/sets/geometry/#lines","title":"Lines","text":"<p>A line consists of two rays starting at a point pointing two opposite directions:</p> \\[ \\left\\lbrace \\mathbf{x} \\in \\mathbb{R}^n \\ | \\ \\mathbf{x} = \\mathbf{a} + \\theta \\mathbf{d}, \\quad \\forall \\theta \\in \\mathbb{R} \\right\\rbrace. \\]"},{"location":"prerequisites/sets/geometry/#hyperplanes-and-halfspaces","title":"Hyperplanes and Halfspaces","text":"<p>A hyperplane is a set of the form:</p> \\[ \\left\\lbrace \\mathbf{x} \\ | \\ \\mathbf{a}^T \\mathbf{x} = b \\right\\rbrace, \\] <p>where \\(\\mathbf{a} \\in \\mathbb{R}^n\\), \\(\\mathbf{a} \\neq \\mathbf{0}\\), and \\(b \\in \\mathbb{R}\\). Analytically, it is the solution set of a nontrivial linear equation among the components of  \\(\\mathbf{x}\\). Geometrically, it can be interpreted as the set of points with a constant inner product to a given vector \\(\\mathbf{a}\\), or as a hyperplane with normal vector  \\(\\mathbf{a}\\); the constant \\(b\\) determines the offset of the hyperplane from the origin.</p> <p>A hyperplane divides \\(\\mathbb{R}^n\\) into two halfspaces. A (closed) halfspace is a set of the form:</p> \\[ \\left\\lbrace \\mathbf{x} \\ | \\ \\mathbf{a}^T \\mathbf{x} \\leq b \\right\\rbrace, \\] <p>where \\(\\mathbf{a} \\neq 0\\), i.e., the solution set of one (nontrivial) linear inequality. Halfspaces are convex, but not affine.</p>"},{"location":"prerequisites/sets/geometry/#cones","title":"Cones","text":"<p>A set \\(C\\) is called a cone, or nonnegative homogeneous, if for every \\(\\mathbf{x} \\in C\\) and \\(\\theta \\geq 0\\), we have \\(\\theta \\mathbf{x} \\in C\\). A set \\(C\\) is called convex cone if it is convex and a cone, i.e., for any \\(\\mathbf{x}_1, \\mathbf{x}_2 \\in C\\) and \\(\\theta_1, \\theta_2 \\geq\\), we have:</p> \\[ \\theta_1 \\mathbf{x}_1 + \\theta_2 \\mathbf{x}_2 \\in C. \\] <p>A ray \\(\\mathbf{d}\\) is a conic combination of two rays \\(\\mathbf{e}_1, \\mathbf{e}_2\\) if \\(\\mathbf{d}\\) is a nonnegative weighted sum of \\(\\mathbf{e}_1, \\mathbf{e}_2\\):</p> \\[ \\mathbf{d} = c_1 \\mathbf{e}_1 + c_2 \\mathbf{e}_2, \\quad \\forall c_1, c_2 \\geq 0. \\] <p>The set of all conic combinations of rays \\(\\mathbf{r}_1, \\ldots, \\mathbf{r}_m\\) is called the conic hull of \\(\\mathbf{r}_1, \\ldots, \\mathbf{r}_m\\):</p> \\[ \\text{conic} \\left\\lbrace \\mathbf{r}_1, \\ldots \\mathbf{r}_m \\right\\rbrace = \\left\\lbrace \\mathbf{x} \\ | \\ \\mathbf{x} = \\theta_1 \\mathbf{r}_1 + \\ldots \\theta_n \\mathbf{r}_n, \\ \\theta_i \\geq 0, \\ \\forall i = 1, \\ldots, n \\right\\rbrace. \\] <p>Such set is called a cone.</p> <p>An order \\(\\geq_{K}\\) is defined by an underlying convex cone \\(K\\) as:</p> \\[ \\mathbf{a} \\geq_{K} \\mathbf{b} \\ \\text{iff} \\ \\mathbf{a} - \\mathbf{b} \\in K. \\]"},{"location":"prerequisites/sets/geometry/#polyhedron","title":"Polyhedron","text":""},{"location":"prerequisites/sets/geometry/#polyhedron-via-halfspaces","title":"Polyhedron via Halfspaces","text":"<p>A polyhedra is the intersection of a finite number of halfspaces:</p> \\[ \\begin{align} P &amp;= \\left\\lbrace \\mathbf{x} \\in \\mathbb{R}^n \\ | \\ \\mathbf{a}^T_1 \\mathbf{x} \\leq b_1, \\ldots, \\mathbf{a}^T_m \\mathbf{x} \\leq b_m \\right\\rbrace \\\\ &amp;= \\left\\lbrace \\mathbf{x} \\in \\mathbb{R}^n \\ | \\ \\mathbf{A} \\mathbf{x} \\leq \\mathbf{b} \\right\\rbrace, \\end{align} \\] <p>where:</p> \\[ \\mathbf{A} =  \\left[ \\begin{array}{c} \\mathbf{a}^T_1 \\\\ \\vdots \\\\ \\mathbf{a}^T_m \\end{array} \\right] \\quad \\mathbf{b} =  \\left[ \\begin{array}{c} b_1 \\\\ \\vdots \\\\ b_m \\end{array} \\right]. \\] <p>Another way to define polyhedra is as the solution set of a finite number of linear equalities and inequalities:</p> \\[ P = \\left\\lbrace \\mathbf{x} \\ | \\ \\mathbf{A} \\mathbf{x} &lt; b, \\ \\mathbf{C} \\mathbf{x} = d \\right\\rbrace, \\] <p>where \\(\\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\) and \\(\\mathbf{C} \\in \\mathbb{R}^{p \\times n}\\).</p> <p>A polyhedron is thus the intersection of a finite number of halfspaces and hyper-planes. Affine sets (e.g., subspaces, hyperplanes, lines), rays, line segments, and  halfspaces are all polyhedra.</p>"},{"location":"prerequisites/sets/geometry/#bounded-polyhedron-via-corner-points","title":"Bounded Polyhedron via Corner Points","text":"<p>A point in \\(\\mathbf{x}\\) in a polyhedron \\(P\\) is an extreme point iff \\(\\mathbf{x}\\) is not a convex combination of other two different points in \\(P\\), i.e.,  there do not exist \\(\\mathbf{y}, \\mathbf{z} \\in P\\), such that \\(\\mathbf{y} \\neq \\mathbf{x}, \\mathbf{z} \\neq \\mathbf{x}\\) and \\(\\mathbf{x} = \\theta \\mathbf{y} + (1 - \\theta) \\mathbf{z}\\) for some \\(\\theta \\in \\left[0, 1 \\right]\\).  Extreme points are corner points. Figure 1 shows the extreme points and a non-extreme point of a tetrahedron.</p> <p> </p> Figure 1 Tetrahedron <p>A non-empty and bounded polyhedron is the convex hull of its extreme points. A bounded polyhedron is a polyhedron that does not extend to infinity in any direction. A bounded polyhedron is also called polytope.</p> <p>A ray \\(\\mathbf{e}\\) in a cone \\(C\\) is called an extreme ray if \\(\\mathbf{e}\\) is not a conic combination of other two different rays in the cone \\(C\\). Note that:</p> <ol> <li>If a polyhedron is bounded, there is no extreme ray.</li> <li>If a polyhedron is bounded, there must be an extreme point.</li> <li>If a polyhedron is unbounded and it does not contain a line, it must have an extreme ray.</li> <li>If a polyhedron is unbounded, it may not have an extreme point.</li> </ol>"},{"location":"prerequisites/sets/geometry/#weyl-caratheodery-theorem","title":"Weyl-Caratheodery Theorem","text":"<p>Any non-empty polyhedron \\(P\\) with at least one extreme point can be formed by its extreme points \\(\\mathbf{x}^1, \\ldots, \\mathbf{x}^m\\) and its extreme rays \\(\\mathbf{e}^1, \\ldots, \\mathbf{e}^k\\) as follows:</p> \\[ P = \\text{conv}\\left\\lbrace \\mathbf{x}^1, \\ldots, \\mathbf{x}^m \\right\\rbrace + \\text{conic}\\left\\lbrace \\mathbf{e}^1, \\ldots, \\mathbf{e}^k \\right\\rbrace. \\] <p>In order words, any point \\(\\mathbf{x}\\) in a polyedron \\(P\\) that has at least one extreme point can be written as a sum of two vectors:</p> \\[ \\mathbf{x} = \\mathbf{x}' + \\mathbf{d}, \\] <p>where \\(\\mathbf{x}'\\) is in the convex hull of its extreme points and \\(d\\) is in the conic hull of its extreme rays. Note that if \\(P\\) does not have an extreme ray, then \\(\\mathbf{d} = \\mathbf{0}\\).</p>"},{"location":"prerequisites/sets/geometry/#generic-polyhedron-example","title":"Generic Polyhedron Example","text":"<p>Consider an unbounded polyhedron as shown in Figure 2. The polyhedron set is given as:</p> \\[ P = \\left\\lbrace (x_1, x_2): \\ x_1 + x_2 \\geq 1, \\ x_1 - x_2 \\leq 2, \\ x_1, x_2 \\geq 0 \\right\\rbrace. \\] <p>The extreme points of the polyhedron are:</p> \\[ \\mathbf{x}^1 =  \\left[ \\begin{array}{c} 0 \\\\  1 \\end{array} \\right], \\mathbf{x}^2 =  \\left[ \\begin{array}{c} 1 \\\\ 0 \\end{array} \\right], \\mathbf{x}^3 =  \\left[ \\begin{array}{c} 2 \\\\  0 \\end{array} \\right], \\] <p>and the convex hull \\(Q\\) is formed by all possible convex combinations of these three extreme points. The extreme rays are:</p> \\[ \\mathbf{e}^1 =  \\left[ \\begin{array}{c} 0 \\\\  1 \\end{array} \\right], \\mathbf{e}^2 =  \\left[ \\begin{array}{c} 1 \\\\  1 \\end{array} \\right], \\] <p>and the conic hull \\(C\\) is formed by all possible conic combinations of these two rays.</p> <p>Then, any point \\(\\mathbf{x} \\in P\\) can be written as:</p> \\[ \\mathbf{x} = \\mathbf{x}' + \\mathbf{d}, \\] <p>where \\(\\mathbf{x}' \\in \\text{conv}\\left\\lbrace \\mathbf{x}^1, \\mathbf{x}^2, \\mathbf{x}^3 \\right\\rbrace\\) and \\(\\mathbf{d} \\in \\text{conic} \\left\\lbrace \\mathbf{e}^1, \\mathbf{e}^2 \\right\\rbrace\\).</p> <p> </p> Figure 2 Polyhedron example"},{"location":"prerequisites/sets/geometry/#positive-semidefinite-cone","title":"Positive Semidefinite Cone","text":"<p>Let \\(\\mathbb{S}^n\\) be the set of symmetric \\(n \\times n\\) matrices:</p> \\[ \\mathbb{S}^n = \\left\\lbrace X \\in \\mathbb{R}^{n \\times n} \\ | \\ X = X^T \\right\\rbrace, \\] <p>which is a vector space with dimension \\(n(n + 1)/2\\). Let \\(\\mathbb{S}^n_+\\) be the set of symmetric positive semidefinite matrices:</p> \\[ \\mathbb{S}^n_+ = \\left\\lbrace X \\in \\mathbb{S}^n \\ | \\ X \\geq 0 \\right\\rbrace, \\] <p>and \\(\\mathbb{S}^n_{++}\\) be the set of symmetric positive definite matrices:</p> \\[ \\mathbb{S}^n_{++} = \\left\\lbrace X \\in \\mathbb{S}^n \\ | \\ X &gt; 0 \\right\\rbrace. \\] <p>The set \\(\\mathbb{S}^n_+\\) is a convex cone if \\(\\theta_1, \\theta_2 \\geq 0\\) and \\(\\mathbf{A}, \\mathbf{B} \\in \\mathbb{S}^n_+\\), then \\(\\theta_1 \\mathbf{A} + \\theta_2 \\mathbf{B} \\in \\mathbb{S}^n_+\\). This is directly from the definition of positive semidefiniteness. For any \\(\\mathbf{x} \\in \\mathbb{R}^n\\), \\(\\mathbf{A}, \\mathbf{B} \\geq 0\\), and \\(\\theta_1, \\theta_2 \\geq 0\\):</p> \\[ \\mathbf{x}^T \\left( \\theta_1 \\mathbf{A} + \\theta_2 \\mathbf{B} \\right) \\mathbf{x} = \\theta_1 \\mathbf{x}^T \\mathbf{A} \\mathbf{x} + \\theta_2 \\mathbf{x}^T \\mathbf{B} \\mathbf{x} \\geq 0. \\]"},{"location":"prerequisites/sets/geometry/#euclidean-balls-and-ellipsoids","title":"Euclidean Balls and Ellipsoids","text":"<p>A (Euclidean) ball in \\(\\mathbb{R}^n\\) is defined as:</p> \\[ B(\\mathbf{x}_c, r) = \\left\\lbrace \\mathbf{x} \\ | \\ ||\\mathbf{x} - \\mathbf{x_c}||_2 \\leq r  \\right\\rbrace = \\left\\lbrace \\mathbf{x}_c + r \\mathbf{u} \\ | \\ ||\\mathbf{u}||_2 \\leq 1 \\right\\rbrace, \\] <p>where \\(r &gt; 0\\) is the scalar radius and \\(\\mathbf{x}_c\\) is the center of the ball. Euclidean ball is a convex set: if \\(||\\mathbf{x}_1 - \\mathbf{x}_c||_2 \\leq r\\), \\(||\\mathbf{x}_2 - \\mathbf{x}_c||_2 \\leq r\\), and \\(0 \\leq \\theta \\leq 0\\), then:</p> \\[ \\begin{align} ||\\theta \\mathbf{x_1} + (1 - \\theta) \\mathbf{x_2} - \\mathbf{x_c}||_2  &amp;= ||\\theta(\\mathbf{x}_1 - \\mathbf{x}_c) + (1 - \\theta)(\\mathbf{x}_2 - \\mathbf{x}_c)||_2 \\\\ &amp;\\leq \\theta || \\mathbf{x}_1 - \\mathbf{x}_c ||_2 + (1 - \\theta) || \\mathbf{x}_2 - \\mathbf{x}_c ||_2 \\\\ &amp;\\leq r. \\end{align} \\] <p>An ellipsoid is defined as:</p> \\[ E = \\left\\lbrace \\mathbf{x} \\ | \\ (\\mathbf{x} - \\mathbf{x}_c)^T \\mathbf{P}^{-1} (\\mathbf{x} - \\mathbf{x}_c) \\leq 1 \\right\\rbrace, \\] <p>where \\(\\mathbf{P} = \\mathbf{P}^T &gt; 0\\), i.e., \\(\\mathbf{P}\\) is a symmetric and positive definite. Ellipsoids are convex sets.</p>"},{"location":"prerequisites/sets/open_and_closed_sets/","title":"Open and Closed Sets","text":""},{"location":"prerequisites/sets/open_and_closed_sets/#open-sets","title":"Open Sets","text":"<p>An element \\(\\mathbf{x} \\in C \\subseteq \\mathbb{R}^n\\) is called an interior point of \\(C\\) if there exists and \\(\\epsilon &gt; 0\\) for which:</p> \\[ \\left\\{ \\mathbf{y} \\ | \\ ||\\mathbf{y} - \\mathbf{x}||_2 \\leq \\epsilon \\right\\}, \\] <p>i.e., there exists a ball centered at \\(\\mathbf{x}\\) that lies entirely in \\(C\\). The set of all points interior to \\(C\\) is called the interior of \\(C\\). </p> <p>A set \\(C\\) is open if the interior of \\(C\\) is equal to \\(C\\), i.e., every point in \\(C\\) is an interior point.</p>"},{"location":"prerequisites/sets/open_and_closed_sets/#closed-sets","title":"Closed Sets","text":"<p>A set \\(C \\subseteq \\mathbb{R}^n\\) is closed if its complement \\(\\mathbb{R}^n \\setminus C = \\left\\{ \\mathbf{x} \\in \\mathbb{R}^n \\ | \\ \\mathbf{x} \\notin C \\right\\}\\) is open, i.e., a set is closed if it includes its boundary points.  Formally, a set \\(X\\) is closed if for any convergent sequence  in \\(X\\), its limit point also belongs to \\(X\\), i.e.,  if \\(\\left\\{ \\mathbf{x}^i \\right\\} \\in X\\) and  \\(\\lim_{i \\rightarrow \\infty} \\mathbf{x}^i = \\mathbf{x}^0\\) then \\(\\mathbf{x}^0 \\in X\\). For example, \\(X = \\mathbb{R}^2\\) is a closed set. In contrast, \\(X = \\left\\{x: 0 &lt; x \\leq 1 \\right\\}\\) is not a closed set. Note that intersection  of closed sets is closed.</p>"},{"location":"prerequisites/sets/open_and_closed_sets/#bounded-sets","title":"Bounded Sets","text":"<p>A set is bounded if it can be enclosed in a large enough (hyper)-sphere or a box. Formally, the set \\(X\\) is bounded if \\(\\exists M \\geq 0\\) such that \\(||\\mathbf{x}|| \\leq M \\) for all \\( \\mathbf{x} \\in X\\).</p>"},{"location":"prerequisites/sets/open_and_closed_sets/#compact-sets","title":"Compact Sets","text":"<p>A set that is both bounded and closed is called a compact set.</p>"},{"location":"prerequisites/sets/open_and_closed_sets/#examples","title":"Examples","text":"<ol> <li> <p>\\(x = \\mathbb{R}^2\\) is closed but not bounded.</p> </li> <li> <p>\\(X = \\left\\{ (x, y): \\ x^2 + y^2 &lt; 1 \\right\\}\\) is bounded but not closed.</p> </li> <li> <p>\\(X = \\left\\{ (x, y): \\ x^2 + y^2 \\geq 1 \\right\\}\\) is closed but not bounded.</p> </li> <li> <p>\\(X = \\left\\{ (x, y): \\ x^2 + y^2 \\leq 1 \\right\\}\\) is compact.</p> </li> </ol>"},{"location":"prerequisites/software_implementation/storage/","title":"Storage","text":""},{"location":"prerequisites/software_implementation/storage/#row-and-column-major-order","title":"Row- and Column-major Order","text":"<p>Given matrix, \\(\\mathbf{A} \\in \\mathbb{R}^{3 \\times 3}\\), row-major and column-major ordering will be:</p> \\[ \\mathbf{A}_{\\text{row}} =  \\left[ \\begin{array}{ccc} A_{11} &amp; A_{12} &amp; A_{13} \\\\ A_{21} &amp; A_{22} &amp; A_{23} \\\\ A_{31} &amp; A_{32} &amp; A_{33} \\\\ \\end{array} \\right], \\quad \\mathbf{A}_{\\text{col}} =  \\left[ \\begin{array}{ccc} A_{11} &amp; A_{21} &amp; A_{31} \\\\ A_{12} &amp; A_{22} &amp; A_{32} \\\\ A_{13} &amp; A_{23} &amp; A_{33} \\\\ \\end{array} \\right]. \\] <p>Data layout is critical for performance when traversing an array because modern CPUs process sequential data more efficiently than nonsequential data. This is primarly due to CPU caching which exploits spatial locality of reference. In addition, contiguous access makes it possible to use SIMD instructions that operate on vectors of data.</p>"},{"location":"prerequisites/software_implementation/storage/#data-accessing","title":"Data Accessing","text":"<p>In C and C++, multidimensional arrays are stored in row-major order. Given:</p> \\[ \\mathbf{A} = \\left[ \\begin{array}{ccc} A_{11} &amp; A_{12} &amp; A_{13} \\\\ A_{21} &amp; A_{22} &amp; A_{23} \\end{array} \\right], \\] <p>data will be stored in the memory address as:</p> Address Row-Major Order Column-Major Order <code>0</code> <code>A11</code> <code>A11</code> <code>1</code> <code>A12</code> <code>A21</code> <code>2</code> <code>A13</code> <code>A12</code> <code>3</code> <code>A21</code> <code>A22</code> <code>4</code> <code>A22</code> <code>A13</code> <code>5</code> <code>A23</code> <code>A23</code> <p>Data Accessing</p> <p>To access elements of row-major layout: <pre><code>Eigen::MatrixXd A = Eigen::MatrixXd::Random(3, 3);\n\nsize_t N = A.rows();\nsize_T M = A.cols();\n\nfor (size_t i = 0; i &lt; N; ++i)\n{\n    for (size_t j = 0; j &lt; M; ++j&gt;)\n    {\n        std::cout &lt;&lt; A[i * M + j] std::endl;\n    }\n}\n</code></pre></p>"},{"location":"probability_theory/chi_square_distribution/","title":"Chi-Square Distribution","text":""},{"location":"probability_theory/chi_square_distribution/#definition","title":"Definition","text":"<p>Chi-square distribution is often used to check state estimators for \"consistency\" \\(-\\) whether their actual errors are consistent with the variances calculated by the estimator. A scalar random variable \\(q\\) is chi-square distributed with \\(n\\) degrees of freedom and is written as:</p> \\[ q \\sim \\chi^2_n. \\] <p>\\(q\\) is sum of squares of random variables \\(z_i \\sim \\mathcal{N}(0, 1)\\) for \\(i = 1, \\ldots n\\):</p> \\[ q = \\mathbf{z}^T \\mathbf{z}. \\] <p>Consider \\(\\mathbf{x} \\in \\mathbb{R}^n\\) with \\(\\mathbf{x} \\sim \\mathcal{N}(\\bar{\\mathbf{x}}, \\mathbf{P})\\). The whitened version of \\(\\mathbf{x}\\) is \\(\\mathbf{z} \\triangleq \\mathbf{P}^{-\\frac{1}{2}}(\\mathbf{x} - \\bar{\\mathbf{x}})\\), where \\(\\mathbf{P}^{-\\frac{1}{2}}\\) is a symmetric matrix satisfying \\(\\mathbf{P}^{-\\frac{1}{2}} \\mathbf{P} \\mathbf{P}^{-\\frac{1}{2}} = \\mathbf{I}\\). Since \\(\\mathbf{x} - \\bar{\\mathbf{x}}\\) is Gaussian with zero mean and covariance \\(\\mathbf{P}\\), applying the linear transformation \\(\\mathbf{P}^{-\\frac{1}{2}}\\) yields to:</p> \\[ \\mathbf{z} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I}), \\quad z_i \\sim \\mathcal{N}(0, 1), \\ \\text{for} \\ i = 1, \\ldots, n. \\] <p>Then the quadratic form can be described as:</p> \\[ \\begin{align} q &amp;= (\\mathbf{x} - \\bar{\\mathbf{x}})^{T} \\mathbf{P}^{-1} (\\mathbf{x} - \\bar{\\mathbf{x}}) \\\\ &amp;= \\left(\\mathbf{P}^{-\\frac{1}{2}} (\\mathbf{x} - \\bar{\\mathbf{x}}) \\right)^T \\left( \\mathbf{P}^{-\\frac{1}{2}}(\\mathbf{x} - \\bar{\\mathbf{x}}) \\right) \\\\ &amp;= \\mathbf{z}^T \\mathbf{z}. \\end{align} \\]"},{"location":"probability_theory/chi_square_distribution/#properties","title":"Properties","text":"Chi-Square Distribution Mean \\(\\begin{align*} \\mathbb{E}\\left[q \\right] = \\mathbb{E}\\left[  \\sum^{n}_{i = 1} z^2_i \\right] = n \\end{align*}\\) Variance \\(\\begin{align*} \\mathcal{V}\\text{ar}(q) &amp;= \\mathbb{E}\\left[\\sum^{n}_{i = 1} (z^2_i - 1) \\right]^2 = \\sum^{n}_{i = 1} \\mathbb{E}\\left[(z^2_i - 1)^2 \\right] =  2n  \\end{align*}\\) pdf \\(\\begin{align*}p(q) = \\frac{1}{2^{\\frac{n}{2}} \\Gamma\\left( \\frac{n}{2} \\right)} q^{\\frac{n - 2}{2}} e^{-\\frac{q}{2}}, \\quad q \\geq 0 \\end{align*}\\),  where \\(\\Gamma\\) is the gamma function with the following properties:  \\(\\begin{align*} \\Gamma\\left( \\frac{1}{2} \\right) = \\sqrt{\\pi}, \\ \\ \\Gamma(1) = 1, \\ \\ \\Gamma(m + 1) = m \\Gamma(m) \\end{align*}\\) Addition Rule Given the independent random variables \\(q_1 \\sim \\chi^2_{n_1}\\) and \\(q_2 \\sim \\chi^2_{n_2}\\), their sum \\(q_3 = q_1 + q_2\\) is chi-square distributed with \\(n_3 = n_1 + n_2\\) degrees of freedom"},{"location":"probability_theory/distributions/","title":"Distributions","text":""},{"location":"probability_theory/distributions/#uniform-distribution","title":"Uniform Distribution","text":"<p>The theoretical model for random sampling is the uniform distribution.</p> Continuous Discrete pdf/pmf \\(p(x) = \\mathcal{U}(x; a, b) \\triangleq \\begin{cases} \\begin{alignat*}{2} &amp;\\frac{1}{b - a}, \\quad &amp;&amp;a \\leq x \\leq b, \\\\ &amp;0, \\quad &amp;&amp;\\text{else}. \\end{alignat*} \\end{cases}\\) CDF \\(P_x(\\xi) = \\begin{cases} \\begin{alignat*}{2} &amp;0, \\quad &amp;&amp; \\xi &lt; a, \\\\ &amp;\\frac{\\xi - a}{b - a}, \\quad &amp;&amp;a \\leq \\xi \\leq b, \\\\ &amp;1, \\quad &amp;&amp;\\xi &gt; b. \\end{alignat*} \\end{cases}\\) \\(\\begin{align*} P_x(a, b) = \\frac{\\lfloor x \\rfloor - a + 1}{b - a + 1}  \\end{align*}\\) Expectation \\(\\begin{align*} \\mathbb{E} \\left[ x \\right] = \\frac{b + a}{2}\\end{align*}\\) \\(\\begin{align*} \\mathbb{E} \\left[ x \\right] = \\frac{b + a}{2}\\end{align*}\\) Variance \\(\\begin{align*}\\mathbb{V}\\text{ar}(x) = \\frac{(b - a)^2}{12}\\end{align*}\\) \\(\\begin{align*}\\mathbb{V}\\text{ar}(x) = \\frac{n^2 - 1}{12}, \\end{align*}\\)  where \\(n = b - a + 1\\)"},{"location":"probability_theory/distributions/#gaussian-distribution","title":"Gaussian Distribution","text":"Continuous pdf \\(\\begin{align*} p(x) = \\mathcal{N}(x; \\mu; \\sigma^2) \\triangleq \\frac{1}{\\sqrt{2\\pi} \\sigma} \\exp \\left\\{ -\\frac{(x - \\mu)^2}{2 \\sigma^2} \\right\\} \\end{align*}\\) CDF \\(\\begin{align*} P_x(\\xi) &amp;= \\int^{\\xi}_{-\\infty} \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp\\left\\{ -\\frac{(x - \\mu)^2}{2\\sigma^2} \\right\\}dx \\\\ &amp;= \\int^{(\\xi - \\mu) / \\sigma}_{-\\infty} \\frac{1}{\\sqrt{2 \\pi}} \\exp \\left\\{-\\eta^2 / 2 \\right\\} d \\eta \\\\ &amp;=\\int^{(\\xi - \\mu) / \\sigma}_{-\\infty} \\mathcal{N}(\\eta; 0, 1)d \\eta \\triangleq \\mathcal{G}\\left(\\frac{\\xi - \\mu}{\\sigma} \\right), \\end{align*}\\)  where \\(\\mathcal{G}\\) is the cumulative standard Gaussian distribtuion. Standardization \\(\\begin{align*} x \\sim \\mathcal{N}(\\mu, \\sigma^2) \\longrightarrow z = \\frac{x - \\mu}{\\sigma} \\sim \\mathcal{N}(0, 1) \\end{align*}\\) Sigma Rules Sigma rules (also known as empirical rule) state that for any normal distribution, the probability that an observation will fall in the interval \\(\\mu \\pm k\\sigma\\) for \\(k = 1, 2, 3\\) is \\(68.27\\%\\), \\(95.45\\%\\), and \\(99.73\\%\\), respectively. More precisely:  \\(\\begin{align*} &amp;\\mathbb{P}\\left\\{\\mu - \\sigma &lt; x &lt; \\mu + \\sigma\\right\\} = \\mathbb{P}\\left\\{-1 &lt; z &lt; 1\\right\\} = P_z(1) - P_z(-1) = 0.6827 \\\\ &amp;\\mathbb{P}\\left\\{\\mu - 2\\sigma &lt; x &lt; \\mu + 2\\sigma\\right\\} = \\mathbb{P}\\left\\{-2 &lt; z &lt; 2\\right\\} = P_z(2) - P_z(-2) = 0.9545 \\\\ &amp;\\mathbb{P}\\left\\{\\mu - 3\\sigma &lt; x &lt; \\mu + 3\\sigma\\right\\} = \\mathbb{P}\\left\\{-3 &lt; z &lt; 3\\right\\} = P_z(3) - P_z(-3) = 0.9973 \\\\ \\end{align*}\\)"},{"location":"probability_theory/distributions/#poisson-distribution","title":"Poisson Distribution","text":"<p>Poisson distribution is a discrete probability distribution that expresses the probability of a given number of events occuring in a fixed interval of time, or space if these events occur with a known constant rate, \\(\\lambda\\) and independently of the time since the last event.</p> Discrete pmf \\(\\begin{align*} p(x) = \\mathbb{P}(x = n) = \\frac{\\lambda^n}{n!} e^{-\\lambda}, \\quad n = 0, 1, \\ldots \\end{align*}\\) Moment-Generating Function \\(\\begin{align*} m_x(t) &amp;= \\mathbb{E}\\left[ e^{t x} \\right] = \\sum^{n}_{i = 1} \\mu_i e^{t \\xi_i} \\\\ &amp;= \\sum^{n}_{i = 1} \\frac{\\lambda^i}{i!} e^{-\\lambda} e^{ti} \\\\ &amp;= e^{-\\lambda} \\sum^{n}_{i = 1} \\frac{(\\lambda e^{t})^i}{i!} \\\\ &amp;= e^{-\\lambda} e^{\\lambda e^t} = e^{\\lambda(e^t - 1)} \\end{align*}\\) Expectation \\(\\begin{align*}\\mathbb{E}\\left[ x \\right] = \\frac{d m_x(t)}{dt} \\rvert_{t = 0} = e^{\\lambda(e^t - 1)} \\lambda e^{t} \\rvert_{t = 0} = \\lambda \\end{align*}\\) Variance \\(\\lambda\\) <p>Figure 1 shows the pmf and CDF example Poisson distributions.</p> <p> </p> Figure 1 Poisson distribution PMF and CDF"},{"location":"probability_theory/distributions/#exponential-distribution","title":"Exponential Distribution","text":"<p>The exponential distribution has an important connection to the Poisson distribution. It is the probability distribution of the time between events in a Poisson point process, i.e., a process in which events occur continuously and independently at a constant average rage.</p> Continuous pdf \\(p(x, \\lambda) = \\begin{cases}\\begin{alignat*}{2}&amp;\\lambda e^{-\\lambda x} \\quad &amp;&amp;x \\geq 0, \\\\&amp;0 \\quad &amp;&amp;\\text{else}\\end{alignat*}\\end{cases}\\) CDF \\(P_x(\\xi) = \\begin{cases}\\begin{alignat*}{2}&amp;1 - e^{-\\lambda \\xi} \\quad &amp;&amp;\\xi \\geq 0, \\\\&amp;0 &amp;&amp; \\text{else}\\end{alignat*}\\end{cases}\\) Moment-Generating Function \\(\\begin{align*}m_x(t) = \\lambda / (\\lambda - t),\\end{align*}\\)  for \\(t &lt; \\lambda\\) Expectation \\(1 / \\lambda\\) Variance \\(1 / \\lambda^2\\) <p>Figure 2 shows the pdf and CDF for example exponential distributions.</p> <p> </p> Figure 2 Exponential distribution PDF and CDF"},{"location":"probability_theory/distributions/#gamma-and-inverse-gamma-distributions","title":"Gamma and Inverse Gamma Distributions","text":"<p>The gamma distribution is an extension of the exponential distribution. The gamma function is defined as \\(\\Gamma(x) = \\int^{\\infty}_0 t^{x - 1} e^{-t} dt\\) for \\(x &gt; 0\\). If \\(n\\) is a positive integer, \\(\\Gamma(n) = (n - 1)!\\).</p> Continuous Gamma pdf \\(p(x) = \\mathcal{Ga}(r, \\lambda) = \\begin{cases}\\begin{alignat}{2}&amp; \\frac{\\lambda^r}{\\Gamma(r)} x^{r - 1} e^{-\\lambda x} \\quad &amp;&amp;x \\geq 0, \\\\&amp; 0 \\quad &amp;&amp;\\text{else}\\end{alignat}\\end{cases}\\),  where \\(r &gt; 0\\) is called the shape and \\(\\lambda &gt;0\\) is the rate Gamma Moment-Generating Function \\(\\begin{align*} m_x(t) = \\left(\\frac{\\lambda}{\\lambda - t}\\right)^r\\end{align*}\\),  where \\(r = 1\\) is the exponential distribution Gamma Expectation \\(r / \\lambda\\) Gamma Variance \\(r / \\lambda^2\\) Inverse Gamma pdf \\(p(x) = \\mathcal{IG}(r, \\lambda) = \\begin{cases}\\begin{alignat}{2}&amp; \\frac{\\lambda^r}{\\Gamma(r) x^{r + 1}} e^{-\\lambda / x} \\quad &amp;&amp; x \\geq 0, \\\\&amp;0 \\quad &amp;&amp; \\text{else}\\end{alignat}\\end{cases}\\) <p>Figure 3 shows the pdf for example gamma distributions.</p> <p> </p> Figure 3 Gamma function and gamma distributions"},{"location":"probability_theory/distributions/#other-important-distributions","title":"Other Important Distributions","text":"<ol> <li>Geometric distribution</li> <li>Multinomial distribution</li> <li>Logistic distribution</li> <li>Beta distribution</li> <li>Weibull distribution</li> </ol>"},{"location":"probability_theory/observations_as_time_series/","title":"Observations as Time Series","text":""},{"location":"probability_theory/observations_as_time_series/#autocorrelation","title":"Autocorrelation","text":"<p>Autocorrelation measures the level of correlation of the time series with a time-shifted version of itself. For example, autocorrelation at lag 2 would be a correlation between \\(X_1, X_2, X_3, \\ldots, X_{n - 3}, X_{n - 2}\\) and \\(X_3, X_4, \\ldots, X_{n - 1}, X_n\\). When the shift lag is 0, then the autocorrelation is just a correlation.</p> <p>Let \\(X_1, X_2, \\ldots, X_n\\) be a sample where the order of observations is important. The indices \\(1, 2, \\ldots, n\\) may correspond to measurements taken at time points \\(t, t + \\Delta t, t + 2 \\delta t, \\ldots, t + (n - 1) \\Delta t\\), for some start time \\(t\\) and time increment \\(\\Delta t\\). The autocovariance at lag \\(0 \\leq k \\leq n - 1\\) is defined as:</p> \\[ \\hat{\\gamma}(k) = \\frac{1}{n} \\sum^{n - k}_{i = 1}  \\left(X_{i + k} - \\bar{X} \\right) \\left( X_i - \\bar{X} \\right). \\] <p>Note that the sum is normalized by a factor \\(\\frac{1}{n}\\). The autocorrelation is defined as normalized autocovariance:</p> \\[ \\hat{\\rho}(k) = \\frac{\\hat{\\gamma}(k)}{\\hat{\\gamma}(0)}. \\]"},{"location":"probability_theory/sample_variability_measures/","title":"Sample Variability Measures","text":""},{"location":"probability_theory/sample_variability_measures/#sample-variance-and-sample-standard-deviation","title":"Sample Variance and Sample Standard Deviation","text":"<p>Sample variance is defined as:</p> \\[ \\begin{align} s^2 &amp;= \\frac{1}{n - 1} \\sum^n_{i = 1} \\left(X_i - \\bar{X} \\right)^2 \\\\  &amp;= \\frac{1}{n - 1} \\left(\\sum^n_{i = 1}\\left(X^2_i \\right) - n \\left(\\bar{X} \\right)^2 \\right). \\end{align} \\] <p>Note that we use \\(\\frac{1}{n - 1}\\) instead of \\(\\frac{1}{n}\\) because it is an unbiased estimator.</p> <p>The sample standard deviation is defined as:</p> \\[ s = \\sqrt{\\frac{1}{n - 1} \\sum^n_{i = 1} \\left(X_i - \\bar{X} \\right)^2}. \\] <p>When a new observation is obtained, one can update the sample variance without having to recalculate it. If \\(\\bar{x}_n\\) and \\(s^2_n\\) are the sample mean and variance based on \\(x_1, x_2, \\ldots, x_n\\) and a new observation \\(x_{n + 1}\\) is obtained, then:</p> \\[ s^2_{n + 1} = \\frac{(n - 1)s^2_n + (x_{n + 1} - \\bar{x}_n)(x_{n + 1} - \\bar{x}_{n + 1})}{n}, \\] <p>where \\(\\bar{x}_{n + 1} = (n \\bar{x}_n + x_{n + 1}) / (n + 1)\\).</p>"},{"location":"probability_theory/sample_variability_measures/#sample-quantilespercentiles","title":"Sample Quantiles/Percentiles","text":"<p>Sample quantiles (in units between 0 and 1) or sample percentiles (in units between 0 and 100) are important summaries that reveal both the location and the spread of a sample. For example, we may be interested in a point \\(x_p\\) that partitions the ordered sample into two parts, one with \\(p \\cdot 100\\%\\) of observations smaller than \\(x_p\\) and another with \\((1 - p) 100\\%\\) observations greater than \\(x_p\\). The median of the sample is the 50th percentile. </p> <p>Quartiles divide an ordered sample into four parts; the 25th percentile is known as the first quartile, \\(Q_1\\), and the 75th percentile is known as the third quartiles, \\(Q_3\\).</p>"},{"location":"probability_theory/sample_variability_measures/#sample-range-and-iqr","title":"Sample Range and IQR","text":"<p>The range \\(R\\) is the maximum minus the minimum of the sample, i.e., \\(R = X_{(n)} - X_{(1)}\\).</p> <p>The interquartile range (IQR) is \\(Q_3 - Q_1\\).</p>"},{"location":"probability_theory/sample_variability_measures/#z-scores","title":"z-Scores","text":"<p>For a sample \\(x_1, x_2, \\ldots, x_n\\) the \\(z\\)-score is the standardized sample \\(z_1, z_2, \\ldots, z_n\\), where \\(z_i = \\left( x_i - \\bar{x} \\right) / s\\). In the standardized sample, the mean is 0 and the sample variance (and standard deviation) is 1. The basic reason why standardization may be needed is to assess extreme values, or compare samples taken at different scales.</p>"},{"location":"probability_theory/sample_variability_measures/#moments-of-higher-order","title":"Moments of Higher Order","text":"<p>If the observations are interpreted as unit masses at positions \\(X_1, \\ldots, X_n\\), then the sample mean is the first moment in the mechanical sense - it represents the balance point for the system of all points. The \\(k\\)'th moment is defined as:</p> \\[ m_k = \\frac{1}{n} \\left(X^k_1 + \\ldots + X^k_n \\right) = \\frac{1}{n} \\sum^n_{i = 1} X^k_i. \\] <p>The moments \\(m_k\\) are sometimes called raw sample moments. The power \\(k\\) mean is \\(\\left( m_k \\right)^{1 / k}\\), that is:</p> \\[ \\left( \\frac{1}{n} \\sum^n_{i = 1} X^k_i \\right)^{1 / k}. \\] <p>The central moments of order \\(k\\) is defined as:</p> \\[ \\mu_k = \\frac{1}{n} \\sum^n_{i = 1} \\left( X_i - m_1 \\right)^k. \\] <p>Notice that the sample mean is the first moment and \\(\\mu_1 = 0\\), \\(\\mu_2\\) is the sample variance.</p>"},{"location":"probability_theory/sample_variability_measures/#skewness-and-kurtosis","title":"Skewness and Kurtosis","text":"<p>Skewness is defined as:</p> \\[ \\gamma_n = \\mu_3 / \\mu_2^{3 / 2}, \\] <p>and measures the degree of asymmetry in a sample distribution. Positively skewed distributions have longer right tails, and their sample mean is larger than the median. Negatively skewed sample distributions have longer left tails, and their mean is smaller than the median.</p> <p>Kurtosis is defined as:</p> \\[ \\kappa_n = \\mu_4 / \\mu^2_2, \\] <p>and represents the measure of \"peakedness\" or flatness of a sample distribution.</p>"},{"location":"probability_theory/sample_variability_measures/#coefficient-of-variation","title":"Coefficient of Variation","text":"<p>The coefficient of variation, CV, is the ratio:</p> \\[ \\text{CV} = \\frac{s}{\\bar{X}}. \\] <p>The CV expresses the variability of a sample in the units of its mean. In other words, a CV equal to 2 would mean that the standard deviation is equal to 2\\(\\bar{X}\\). </p> <p>The reciprocal of CV, \\(\\bar{X} / s\\), is called the signal-to-noise ratio.</p>"},{"location":"probability_theory/sample_variability_measures/#diversity-indices-for-categorical-data","title":"Diversity Indices for Categorical Data","text":"<p>If the data are categorical and numerical characteristics such as moments and percentiles cannot be defined but the frequencies \\(f_i\\) of classes/categories are given, one can define Shannon's diversity index:</p> \\[ H = \\frac{n \\log n - \\sum^k_{i = 1} f_i \\log f_i}{n}, \\] <p>where \\(n\\) is the total sample size and \\(k\\) is the number of categories.</p>"},{"location":"probability_theory/sample_variability_measures/#sturges-rule","title":"Sturges' Rule","text":"<p>There are several ruleso n how to automaticall determine the number of histogram plot bins or, equivalently, bin sizes, non of them superior to the others on all possible data sets. THe number of bins \\(k\\) can be computed via Sturges' rule:</p> \\[ k = 1 + \\log_2 n, \\] <p>where \\(n\\) is the size of the samples. Sturges' rule was intended for bell shaped distributions of data and may oversmooth data that are skewed, multimodal, or have some other features.</p>"},{"location":"probability_theory/terminologies/","title":"Terminologies","text":"Term Definition Population A population is a statistical universe. It is defined as a collection of existing attributes of some natural phenomenon or a collection of potential attributes when a process is involved.  Populations can be either finite or infinite. A subset of population selected by some relevant criteria is called a subpopulation. Sample A sample is an observed part of a population. Selection of a sample is a rich methodology in itself, but, unless otherwise specified, it is assumed that the sample is selected at a random. The randomness ensures that the sample is representitive of its population. Statistics The term statistics has a plural form but is used in the singular when it relates to methodology. A sample summary is called a statistic. For example, a sample mean is a statistic, and sample mean and sample range are statistics. The ultimate summary for quantifying a population attribute is a statistical model. Composite Sample When a sample is large and many observations are repetitive, data are often recorded as group with their unique values and their frequencies. This is called a composite sample. Experiment A phenomenon, action, or procedure where the outcomes are uncertain. Sample Space Set of all possible outcomes in an experiment. Event A collection of outcomes; a subset of the sample space."},{"location":"probability_theory/random_variables/multivariate_random_variables/","title":"Multiple Random Variables","text":""},{"location":"probability_theory/random_variables/multivariate_random_variables/#definition","title":"Definition","text":"<p>When two or more random variables constitute the coordinates of a random vector, their joint distribution is often of interest. For a random vector \\((x, y)\\), the joint distribution function is defined via the probability of the event \\(\\left\\{ x \\leq \\xi, y \\leq \\eta \\right\\}\\).</p>"},{"location":"probability_theory/random_variables/multivariate_random_variables/#cumulative-distribution-function","title":"Cumulative Distribution Function","text":"Continuous Random Variable Discrete Random Variable Joint Cumulative Distribution \\(\\begin{align*} P_{x, y}(\\xi, \\eta) &amp;= \\mathbb{P}\\left\\{x \\leq \\xi, y \\leq \\eta \\right\\} \\\\ &amp;= \\int^{\\xi}_{x = -\\infty} \\int^{\\eta}_{y = -\\infty} p_{x, y}(x, y) dx dy \\end{align*}\\) Properties \\(\\begin{align*}     P_{x, y} &amp;\\in \\left[0, 1 \\right] \\\\ P_{x, y}(\\xi, -\\infty) = P_{x, y}(-\\infty, \\eta) &amp;= 0 \\\\ P_{x, y}(\\infty, \\infty) &amp;= 1 \\\\ P_{x, y}(a, c) &amp;\\leq P_{x, y}(b, d) \\quad \\text{if} \\ a \\leq b \\ \\text{and} \\ c \\leq d\\\\ \\mathbb{P}(a &lt; x \\leq b, c &lt; y \\leq d) &amp;= P_{x, y}(b, d) + P_{x, y}(a, c) - P_{x, y}(a, d) - P_{x, y}(b, c) \\\\ P_{x, y}(\\xi, \\infty) = P_{x}(\\xi) \\\\ P_{x, y}(\\infty, \\eta) = P_y(\\eta) \\end{align*}\\)"},{"location":"probability_theory/random_variables/multivariate_random_variables/#probability-distribution-function","title":"Probability Distribution Function","text":"Continuous Random Variables Discrete Random Variables Joint Probability Distribution \\(\\begin{align*} p_{x, y}(\\xi, \\eta) \\triangleq \\lim_{d\\xi \\rightarrow 0, d\\eta \\rightarrow 0} \\frac{\\mathbb{P} \\left\\{ \\left\\{ \\xi - d\\xi &lt; x \\leq \\xi \\right\\} \\cap \\left\\{ \\eta - d \\eta &lt; y &lt; \\eta \\right\\} \\right\\} }{d \\xi d \\eta} \\end{align*}\\) \\(\\begin{align*} p_{x, y}(\\xi, \\eta) = \\mathbb{P}\\left\\{ x = \\xi, y = \\eta \\right\\} \\end{align*}\\) Marginal Densities \\(\\begin{align*} &amp;p_x(\\xi) = \\int^{\\infty}_{-\\infty} p_{x, y}(\\xi, \\eta) d\\eta \\rightarrow p(x) = \\int^{\\infty}_{-\\infty} p(x, y) dy \\\\ &amp;p_y(\\eta) = \\int^{\\infty}_{-\\infty} p_{x, y}(\\xi, \\eta) d\\xi \\rightarrow p(y) = \\int^{\\infty}_{-\\infty} p(x, y) dx \\end{align*}\\) \\(\\begin{align*}&amp;p(x) = \\sum_y p_{x, y}(x, y) \\\\ &amp;p(y) = \\sum_x p_{x, y}(x, y)\\end{align*}\\) Covariance \\(\\begin{align*} \\mathbb{C}\\text{ov}(x, y) &amp;\\triangleq \\mathbb{E}\\left[(x - \\bar{x})(y - \\bar{y}) \\right] \\\\ &amp;= \\int^{\\infty}_{-\\infty} \\int^{\\infty}_{-\\infty} (x - \\bar{x})(y - \\bar{y}) p(x, y) dx dy \\\\ &amp;\\triangleq \\sigma^2_{xy}  \\end{align*}\\) Correlation \\(\\begin{align*} \\rho_{xy} \\triangleq \\frac{\\sigma^2_{xy}}{\\sigma_x \\sigma_y} \\end{align*}\\) Independence \\(\\begin{align*} p(x, y) = p(x) p(y) \\end{align*}\\) Conditional pdf \\(\\begin{align*} p(x \\rvert y) = \\frac{p(x, y)}{p(y)} \\end{align*}\\) Bayes' Formula \\(\\begin{align*} p(x \\rvert y) = \\frac{p(y \\rvert x) p(x)}{ p(y)} = \\frac{p(y \\rvert x) p(x)}{\\int p(y \\rvert x) p(x) dx}\\end{align*}\\)"},{"location":"probability_theory/random_variables/multivariate_random_variables/#conditional-expectations","title":"Conditional Expectations","text":"Continuous Random Variables Conditional Expectations \\(\\begin{align*} \\mathbb{E}\\left[ x \\rvert y\\right] = \\int^{\\infty}_{-\\infty} x p(x \\rvert y) dx \\end{align*}\\) Conditional Expectation of a Function \\(\\begin{align*} \\mathbb{E}\\left[ g(x, y) \\rvert y\\right] = \\int^{\\infty}_{-\\infty} g(x,y) p(x \\rvert y) dx \\end{align*}\\)"},{"location":"probability_theory/random_variables/multivariate_random_variables/#mixture-probability-density-functions","title":"Mixture Probability Density Functions","text":"<p>A mixture pdf is a weighted sum of pdfs with the weights summing up to unity. A Gaussian mixture is a pdf consisting of a weighted sum of Gaussian densities:</p> \\[ p(x) = \\sum^{n}_{j = 1} p_j \\mathcal{N}(x; \\bar{x}_j, P_j), \\quad \\sum^{n}_{j = 1} p_j = 1. \\]"},{"location":"probability_theory/random_variables/random_variables/","title":"Random Variables","text":""},{"location":"probability_theory/random_variables/random_variables/#definition","title":"Definition","text":"<p>A scalar random variable is a real-valued function whose numerical value is determined by the outcome of a random experiment. Thus, a random variable is a mapping from the sample space of an experiment, \\(S\\), to a set of real numbers. The value taken by a random variable is called its realization</p>"},{"location":"probability_theory/random_variables/random_variables/#cumulative-distribution-functions","title":"Cumulative Distribution Functions","text":"<p>The cumulative distribution of a random variable \\(x\\) is the probability of all realizations smaller than or equal to \\(\\xi\\).</p> Continuous Random Variable Discrete Random Variable Random Variable Type Scalar continuous-valued random variable \\(x\\) Scalar discrete random variable \\(x\\) which can take values in the set \\(\\left\\{ \\xi_i, i = 1, \\ldots, k \\right\\}\\) with point masses \\(\\mu_i\\) Cumulative Distribution \\(\\begin{align*}P_x(\\xi) = \\mathbb{P}\\left\\{x \\leq \\xi \\right\\} = \\int^{\\xi}_{-\\infty}p_x(t)dt \\end{align*}\\) \\(\\begin{align*} P_x(\\xi) = \\mathbb{P}\\left\\{x \\leq \\xi \\right\\} =  \\sum^{n}_{i = 1} \\mu_i 1(\\xi - \\xi_i), \\end{align*}\\)  where \\(1(\\cdot)\\) is the unit step function Properties \\(\\begin{align*} P_x(\\xi) &amp;\\in \\left[0, 1 \\right] \\\\ P_x(-\\infty) &amp;= 0 \\\\ P_x(\\infty) &amp;= 1 \\\\ P_x(a) &amp;\\leq P_x(b) \\quad \\text{if} \\ a \\leq b \\\\ \\mathbb{P}(a &lt; x \\leq b) &amp;= P_x(b) - P_x(a)\\end{align*}\\)"},{"location":"probability_theory/random_variables/random_variables/#probability-distribution-functions","title":"Probability Distribution Functions","text":"<p>The probability distribution of a random variable \\(x\\) is a table, rule, assignment, or a formula that assigns probabilities to realizations of \\(x\\), or sets of realizations. A pdf has to have the normalization property that its total probability mass is unity \\(-\\) otherwise it is not a proper density.</p> Continuous Random Variable Discrete Random Variable Mixed Random Variable Random Variable Type Scalar continuous-valued random variable \\(x\\) Scalar discrete random variable \\(x\\) which can take values in the set \\(\\left\\{ \\xi_i, i = 1, \\ldots, k \\right\\}\\) with point masses \\(\\mu_i\\) Mixed random variable \\(x\\) Probability Distribution The probability density function (pdf), \\(p_x(\\xi)\\), of \\(x\\) at \\(x = \\xi\\) is:  \\(\\begin{align*} p_x(\\xi) = \\lim_{d\\xi \\rightarrow 0} \\frac{\\mathbb{P}\\left\\{\\xi - d\\xi &lt; x &lt; \\xi \\right\\}}{d\\xi} \\geq 0 \\end{align*}\\).  The more common notation \\(p_x(\\xi) = p(x)\\) where the argument defines the function is used The probability mass function (pmf), \\(\\mu_{x}(\\xi_i)\\), where \\(\\xi_i, i = 1, \\ldots, k\\) are set of values is:  \\(\\begin{align*} \\mu_x(\\xi_i) = \\mathbb{P}\\left\\{x = \\xi_i \\right\\} = \\mu_i, \\quad i = 1, \\ldots, k\\end{align*}\\)  where \\(\\mu_i\\) are the point masses. Using Dirac (impulse) delta function, we can write:  \\(\\begin{align*} p(x) = \\sum^{k}_{i = 1} \\mu_i \\delta(x - \\xi_i) \\end{align*}\\) The pdf of \\(x\\) which can take values in a continuous set \\(X\\) as well as over a discrete set of points \\(\\left\\{ \\xi_i, \\ i = 1, \\ldots, k \\right\\}\\) is:  \\(\\begin{align*} p(x) = p_c(x) + \\sum^{k}_{i = 1} \\mu \\delta(x - \\xi_i), \\end{align*}\\)  where \\(p_c(x)\\) is the continuous part of the pdf and the \\(\\mu_i\\) are the point masses Proper Density Property \\(\\begin{align*}\\int^{\\infty}_{-\\infty} p(x)dx = 1\\end{align*}\\) \\(\\begin{align*}&amp;\\sum^{k}_{i = 1} \\mu_i = 1\\end{align*}\\) \\(\\begin{align*} \\int^{\\infty}_{-\\infty} p(x) dx = \\int_{x \\in X} p_c(x) dx + \\sum^{k}_{i = 1} \\mu_i = 1 \\end{align*}\\) Probability Computation \\(\\begin{align*}&amp;\\mathbb{P}\\left\\{a &lt; x \\leq b \\right\\} = \\int^{b}_{a} p(x) dx\\end{align*}\\) Relationship to CDF \\(\\begin{align*} p(x) = \\frac{dP_x(\\xi)}{d\\xi} \\end{align*}\\)"},{"location":"probability_theory/random_variables/random_variables/#expectations-variances-and-moments","title":"Expectations, Variances, and Moments","text":"<p>The moment-generating function for a random variable \\(x\\) is defined as \\(m_x(t) = \\mathbb{E}\\left[e^{tx} \\right]\\). When the moment-generating function exists, it uniquely determines the distribution. The name moment-generating is motivated by the fact that the \\(n\\)'th derivative of \\(m_x(t)\\) (denoted as \\(m^{(n)}_x(t)\\)) evaluated at \\(t = 0\\) results in the n'th moment of \\(x\\). For random variables \\(x\\) and \\(y\\), the moment-generating functions satisfy \\(m_{x + y}(t) = m_x(t) m_y(t)\\) and \\(m_{cx}(t) = m_x(ct)\\).</p> Continuous Random Variable Discrete Random Variable Random Variable Type Scalar continuous-valued random variable \\(x\\) Scalar discrete random variable \\(x\\) which can take values in the set \\(\\left\\{ \\xi_i, i = 1, \\ldots, k \\right\\}\\) with point masses \\(\\mu_i\\) Moment-Generating Function \\(\\begin{align*} m_x(t) = \\mathbb{E}\\left[e^{tx} \\right] = \\int^{\\infty}_{-\\infty} e^{tx}p(x) dx \\end{align*}\\) \\(\\begin{align*} m_x(t) = \\mathbb{E}\\left[e^{tx} \\right] = \\sum^{k}_{i = 1} \\mu_i e^{t \\xi_i} \\end{align*}\\) n'th Moment \\(\\begin{align*} m^{(n)}_x(t = 0) = \\int^{\\infty}_{-\\infty} x^n p(x) dx \\end{align*}\\) \\(\\begin{align*} m^{(n)}_x(t = 0) = \\sum^{k}_{i = 1} \\mu_i \\xi^{n}_i \\end{align*}\\) Expectation (first moment) \\(\\begin{align*} \\mathbb{E}\\left[ x \\right] = \\int^{\\infty}_{-\\infty} x p(x) dx \\triangleq \\bar{x} \\end{align*}\\) \\(\\begin{align*} \\mathbb{E}\\left[ x \\right] = \\sum^{k}_{i = 1} \\xi_i \\mu_i \\end{align*}\\) Variance (second central moment) \\(\\begin{align*}\\mathbb{V}\\text{ar}(x) &amp;\\triangleq \\mathbb{E}\\left[(x - \\bar{x})^2 \\right] \\\\ &amp;= \\int^{\\infty}_{-\\infty} (x - \\bar{x})^2 p(x) dx \\\\ &amp;= \\mathbb{E}\\left[ x^2 \\right] - (\\bar{x})^2 \\triangleq \\sigma^2_x  \\end{align*}\\) \\(\\begin{align*} \\mathbb{V}\\text{ar}(x) = \\sum^{k}_{i = 1}\\left( \\xi_i - \\mathbb{E}\\left[ x \\right] \\right)^2 \\mu_i \\end{align*}\\) Mean Square (second moment) \\(\\begin{align*} \\mathbb{E}\\left[x^2 \\right] = \\left( \\mathbb{E}\\left[ x \\right]\\right)^2 + \\mathbb{V}\\text{ar}(x) = \\bar{x}^2 + \\sigma^2_x \\end{align*}\\) Expectation of Function The expected value of a function \\(g(x)\\) of the random variable \\(x\\) is:  \\(\\begin{align*} \\mathbb{E}\\left[ g(x) \\right] = \\int^{\\infty}_{-\\infty} g(x) p(x) dx \\end{align*}\\) The expected value of a function \\(g(x)\\) of the random variable \\(x\\) is:  \\(\\begin{align*} \\mathbb{E}\\left[ g(x) \\right] = \\sum^k_{i = 1} g(\\xi_i) \\mu_i \\end{align*}\\) Expectation Properties For any set of random variables (both discrete and continuous) \\(x_1, \\ldots, x_n\\) and a constant \\(c \\in \\mathbb{R}\\):  \\(\\begin{align*} &amp;\\mathbb{E}\\left[x_1 + \\ldots x_n \\right] = \\mathbb{E}\\left[x_1\\right] + \\ldots \\mathbb{E}\\left[x_n\\right] \\\\ &amp;\\mathbb{E}\\left[ c x \\right] = c \\mathbb{E}\\left[ x \\right]  \\end{align*}\\) Independence Properties For any independent set of random variables (both discrete and continues) \\(x_1, \\ldots, x_n\\) and a constant \\(c \\in \\mathbb{R}\\):  \\(\\begin{align*} &amp;\\mathbb{E}\\left[ x_1 \\cdot \\ldots \\cdot x_n \\right] = \\mathbb{E}\\left[ x_1 \\right] \\cdot \\ldots \\mathbb{E}\\left[ x_n \\right] \\\\ &amp;\\mathbb{V}\\text{ar}(x_1 + \\ldots x_n) = \\mathbb{V}\\text{ar}(x_1) + \\ldots + \\mathbb{V}\\text{ar}(x_n) \\\\ &amp;\\mathbb{V}\\text{ar}(cx) = c^2 \\mathbb{V}\\text{ar}(x) \\end{align*}\\)"},{"location":"probability_theory/random_variables/random_variables/#shannon-entropy","title":"Shannon Entropy","text":"<p>There are important properties of discrete distributions in which the realizations \\(x_1, x_2, \\ldots, x_n\\) are irrelevant and the focus is on the probabilities only, such as the measure of entropy. For a discrete random variable where the probabilities are \\(\\mathbf{p} = (p_1, p_2, \\ldots, p_n)\\), the Shannon entropy is defined as:</p> \\[ \\mathbb{H}(\\mathbf{p}) = -\\sum_i p_i \\log(p_i). \\] <p>Entropy</p> <p>Entropy is a measure of the uncertainty of a random variable and for finite discrete distributions achieves its maximum when the probabilities of realizations are equal, i.e., \\(\\mathbf{p} = (1/n, 1/n, \\ldots, 1/n)\\).</p>"},{"location":"probability_theory/random_variables/transformations_of_random_variables/","title":"Transformations of Random Variables","text":""},{"location":"probability_theory/random_variables/transformations_of_random_variables/#transformations-of-discrete-and-continuous-rvs","title":"Transformations of Discrete and Continuous RVs","text":"<p>When a random variable with known density is transformed, the result is a random variable as well.</p> <p>For a discrete random variable \\(X\\), the PMF of a function \\(Y = g(X)\\) is simply the table:</p> \\(g(X)\\) \\(g(x_1), \\ g(x_2), \\ \\ldots, \\ g(x_n), \\ \\ldots\\) Prob \\(p_1, \\ p_2, \\ \\ldots, \\ p_n, \\ \\ldots\\) <p>in which only realizations of \\(X\\) are transformed while the probabilities are kept unchanged.</p> <p>Transformation of acontinuous random variable is more complex. Let \\(X\\) and \\(Y\\) be two random variables, related to one another by a monotonic function \\(g\\) and its inverse \\(h\\), i.e., \\(h = g^{-1}\\):</p> \\[ \\begin{align} Y &amp;= g(X) \\\\ X &amp;= g^{-1}(Y) = h(Y). \\end{align} \\] <p>Suppose that \\(X\\) has a PDF \\(f_X(x)\\). Then the density of random variable \\(Y = g(X)\\) can be computed as:</p> \\[ \\begin{alignat}{2} \\mathbb{P}(X \\in \\left[x, x + dx \\right]) &amp;= \\mathbb{P}(Y \\in \\left[y, y + dy \\right]), \\quad (dx &gt; 0) \\\\ \\int^{x + dx}_{x} f_X(z) dz &amp;= \\begin{cases} \\int^{y + dy}_y f_Y(z) dz \\quad &amp;&amp; \\text{if} \\ dy &gt; 0 \\\\ -\\int^{y + dy}_y f_Y(z) dz \\quad &amp;&amp; \\text{if} \\ dy &lt; 0 \\\\ \\end{cases} \\\\ f_X(x) dx &amp;= f_Y(y) |dy| \\\\ f_Y(y) &amp;= \\left|\\frac{dx}{dx} \\right| f_X(h(y)) \\\\ &amp;= f_X(h(y)) |h'(y)|, \\end{alignat} \\] <p>where we have assumed that \\(dx\\) and \\(dy\\) are small.</p> <p>If \\(g\\) is not one-to-one, but has \\(k\\) one-to-one inverse branches, \\(h_1, h_2, \\ldots, h_k\\), then:</p> \\[ f_Y(y) = \\sum^k_{i = 1} f(h_i(y)) |h'_i(y)|. \\] <p>An example of a function which is not one-to-one is \\(g(x) = x^2\\), for which inverse branches are \\(h_1(y) = \\sqrt{y}\\) and \\(h_2(y) = -\\sqrt{y}\\).</p>"},{"location":"probability_theory/random_variables/transformations_of_random_variables/#examples","title":"Examples","text":""},{"location":"probability_theory/random_variables/transformations_of_random_variables/#linear-mapping","title":"Linear Mapping","text":"<p>Suppose \\(X \\sim \\mathcal{N}(\\bar{X}, \\sigma^2_X)\\) and \\(Y = g(X) = aX + b\\), where \\(a, b \\in \\mathbb{R}\\) and \\(a \\neq 0\\). </p> <p>The inverse mapping function and its Jacobian are:</p> \\[ \\begin{align} x &amp;= h(y) = (y - b) / a \\\\ h'(y) &amp;= 1 / a \\\\ \\end{align} \\] <p>Then the PDF of \\(Y\\), \\(f_Y(y)\\) can be computed as:</p> \\[ \\begin{align} f_Y(y) &amp;= f_X(h(y)) |h'(y)| = \\frac{1}{\\sqrt{2 \\pi} \\sigma_X} \\exp \\left\\{ \\frac{-\\left[(y - b)/a - \\bar{X} \\right]^2}{2 \\sigma^2_X} \\right\\} \\left| \\frac{1}{a} \\right|. \\end{align} \\] <p>In summary, the RV \\(Y\\) will be Gaussian with a mean and variance:</p> \\[ \\begin{align} \\bar{Y} &amp;= a \\bar{X} + b \\\\ \\sigma^2_Y &amp;= a^2 \\sigma^2_X. \\end{align} \\]"},{"location":"probability_theory/random_variables/transformations_of_random_variables/#quadratic-mapping","title":"Quadratic Mapping","text":"<p>Suppose \\(X \\sim \\mathcal{N}(0, \\sigma^2_X)\\) and \\(Y = g(X) = X^3\\). The inverse mapping function and its Jacobian are:</p> \\[ \\begin{align} y &amp;= h(y) = y^{1 / 3} \\\\ h'(y) &amp;= \\frac{y^{-2/3}}{3} \\\\ \\end{align} \\] <p>Then the PDF of \\(Y\\), \\(f_Y(y)\\) can be computed as:</p> \\[ \\begin{align} f_Y(y) &amp;= f_X(h(y)) |h'(y)| = \\frac{y^{-2/3}}{3} \\frac{1}{\\sqrt{2\\pi} \\sigma_X} \\exp \\left\\{-y^{2/3} / (2 \\sigma^2_X) \\right\\}. \\end{align} \\] <p>In summary, \\(g\\) converts a Gaussian RVt oa non-Gaussian RV.</p>"},{"location":"probability_theory/random_variables/transformations_of_random_variables/#square-root-mapping","title":"Square Root Mapping","text":"<p>Suppose \\(X \\sim \\text{Exp}(\\lambda)\\) and \\(Y = \\sqrt{X}\\). The inverse mapping function and its Jacobian are:</p> \\[ \\begin{align} x &amp;= h(y) = y^2 \\\\ h'(y) &amp;= 2y. \\end{align} \\] <p>Then the PDF of \\(Y\\), \\(f_Y(y)\\) can be computed as:</p> \\[ \\begin{align} f_Y(y) &amp;= f_X(h(y)) |h'(y)| \\\\ = \\lambda e^{-\\lambda y^2} \\cdot 2y, \\quad y \\geq 0, \\ \\lambda &gt; 0, \\end{align} \\] <p>which is known as the Rayleigh distribution.</p> <p>An alternative approach is to consider the CDF:</p> \\[ F_Y(y) = \\mathbb{P}(Y \\leq y) = \\mathbb{P}(\\sqrt{X} \\leq y) = \\mathbb{P}(X \\leq y^2) = 1 - e^{-\\lambda y^2}. \\] <p>Then the PDF is:</p> \\[ f_Y(y) = F'_Y(y) = 2\\lambda y e^{-\\lambda y^2}, \\quad y \\geq 0, \\ \\lambda &gt; 0. \\]"},{"location":"probability_theory/random_variables/transformations_of_random_variables/#mean-and-variance","title":"Mean and Variance","text":"<p>The distribution of a transformation can be often quite messy and lacks closed form. Sometimes only the mean and variance may be needed.</p> <p>If \\(X\\) is a random variable with \\(\\mathbb{E}X = \\mu\\) and \\(\\mathbb{V}\\text{ar} X = \\sigma^2\\), then for a function \\(Y = g(X)\\), the following approximation holds:</p> \\[ \\begin{align} \\mathbb{E} Y &amp;\\approx g(\\mu) + \\frac{1}{2}g''(\\mu) \\sigma^2 \\\\ \\mathbb{V}\\text{ar} Y &amp;\\approx (g'(\\mu))^2 \\sigma^2. \\end{align} \\] <p>If \\(n\\) independent random variables are transformed as \\(Y = g(X_1, X_2, \\ldots, X_n)\\), then:</p> \\[ \\begin{align} \\mathbb{E} Y &amp;\\approx g(\\mu_1, \\ldots, \\mu_n) + \\frac{1}{2} \\sum^n_{i = 1} \\frac{\\partial^2 g}{\\partial x^2} (\\mu_1, \\ldots, \\mu_n) \\sigma^2_i \\\\ \\mathbb{V}\\text{ar} Y &amp;\\approx \\sum^n_{i = 1} \\left( \\frac{\\partial g}{\\partial x_i}(\\mu_1, \\ldots, \\mu_n) \\right)^2 \\sigma^2_i, \\end{align} \\] <p>where \\(\\mathbb{E} X_i = \\mu_i\\) and \\(\\mathbb{V}\\text{ar}X_i = \\sigma^2_i\\).</p> <p>Note that if \\(X_1, \\ldots, X_n\\) are correlated, then additional covariance term must be added for the variance computation:</p> \\[ 2 \\sum_{1 \\leq i &lt; j \\leq n} \\frac{\\partial^2 g}{\\partial x_i \\partial x_j}(\\mu_1, \\ldots, \\mu_n) C_{X_i, X_j}. \\]"},{"location":"sensors/gnss/constellations/","title":"GNSS Constellations and Frequencies","text":""},{"location":"sensors/gnss/constellations/#constellations","title":"Constellations","text":"GPS Center Frequencies (UHF) L1 (1575.42MHz), L2 (1227.60MHz), L5 (1176.45MHz) Number of Satellites Baseline 24 satellites in 6 equally-spaced orbital planes for full coverage (in practice, 31 satellites) Orbit MEO. 4 satellites per orbital plane, 26,560 km from the center of the Earth (about 20,200 km above the surface) Satellite Types <ol><li>7 Block IIR (Replenishment)</li><li>7 Block IIRM (Modernized)</li><li>12 Block IIF (Follow on)</li><li>4 Block III</li>"},{"location":"sensors/gnss/constellations/#frequencies","title":"Frequencies","text":""},{"location":"sensors/gnss/constellations/#gps-frequencies","title":"GPS Frequencies","text":"Carrier Band L1 L2 L3 L4 L5 Center Frequency 1575.42MHz 1227.60MHz 1381.05MHz 1379.91MHz 1176.45MHz Carrier Wavelength (\\(c / f_0\\)) 19cm 24cm 25cm Quadrature I/Q I/Q I/Q I/Q I/Q Legacy Usage C/A, P(Y) P(Y) Modern Usage C/A, P(Y), M, L1C<sub>D</sub>, L1C<sub>P</sub> P(Y), M, L2C I5-code, Q5-code"},{"location":"sensors/gnss/gps_signals/","title":"GNSS Signal Model","text":""},{"location":"sensors/gnss/gps_signals/#signal-model-and-modulation","title":"Signal Model and Modulation","text":""},{"location":"sensors/gnss/gps_signals/#modulation","title":"Modulation","text":"<p>GPS receivers send serial data out of a transmit pin (TX) at a specific bit rate. The most common is\u00a09600bps for 1Hz receivers\u00a0but 57600bps is becoming more common. The code (C/A) is combined with the binary navigation data using modulo-2 addition as shown in Figure 1. The composite binary signal is then modulated with the carrier via BPSK. </p> <p> </p> Figure 1 Modulation (Mahalati, R.N.)"},{"location":"sensors/gnss/gps_signals/#signal-model","title":"Signal Model","text":"<p>Nominal signal on L1 can be modeled as:</p> \\[ \\begin{align} s(t) = \\underbrace{\\sqrt{2 P_I} x_I (t) D_I (t) \\cos \\left(2 \\pi f_c t + \\phi \\right)}_{\\text{In-phase}} + \\underbrace{\\sqrt{2 P_Q} x_Q (t) D_Q (t) \\cos \\left(2 \\pi f_c t + \\phi \\right)}_{\\text{Quadrature}} \\\\ \\end{align}, \\] <p>where,</p> Properties Definition \\(P_I\\) In-phase signal power (W) \\(P_Q\\) Quadrature signal power (W) \\(x_I(t)\\) In-phase ranging code. Modulation with the C/A-code, \\(x_I(t)\\) using BPSK modulation: \\(x(t) = \\begin{cases} \\exp \\left( j0 \\right) &amp;= +1, \\quad \\text{if code bit = 0} \\\\ \\exp\\left(j \\pi \\right) &amp;= -1, \\quad \\text{if code bit = 1}  \\end{cases}\\) \\(x_Q(t)\\) Quadrature ranging code (Modulation by the P(Y) code, i.e., military usage) \\(D_I(t)\\) In-phase navigation signal \\(D_Q(t)\\) Quadrature navigation signal \\(f_c\\) Carrier Frequency (Hz) \\(\\phi\\) Carrier phase offset (rad) <p>The in-phase component (generated by the clock) is modulated by the C/A code, and the quadrature component (phase shift by \\(90^o\\)) is modulated by the P(Y)-code. The phase shift makes the two carriers orthogonal in a sense, allowing the receiver to separate their modulating signals. The modulation of a carrier by a binary code spreats the signal energy, initially concentrated at a single frequency, over a wide frequency band; over 2MHz for the C/A-code and about 20MHz for the P(Y)-code, centered at the carrier frequency.</p>"},{"location":"sensors/gnss/gps_signals/#modulation_1","title":"Modulation","text":""},{"location":"sensors/gnss/gps_signals/#gps-signals","title":"GPS Signals","text":""},{"location":"sensors/gnss/gps_signals/#gps-navigation-data","title":"GPS Navigation Data","text":"LNAV L2 CNAV L5 CNAV CNAV-2 MNAV Definition Legacy navigation L2 civilian navigation L5 civilian navigation Civilian navigation Military navigation Data <ol><li>GPS date, time and the satellite status</li><li>Ephemeris. Received in 18-36 seconds and is valid up to 4 hours</li><li>Almanac (up to 32 satellites). Received in 12.5 minutes and is valid for up to 2 weeks</li> <ol><li>GPS date, time and the satellite status</li><li>Ephemeris. Received in 18-36 seconds and is valid up to 4 hours</li><li>Almanac (up to 64 satellites). Received in 12.5 minutes and is valid for up to 2 weeks</li> <ol><li>GPS date, time and the satellite status</li><li>Ephemeris. Received in 18-36 seconds and is valid up to 4 hours</li><li>Almanac (up to 64 satellites). Received in 12.5 minutes and is valid for up to 2 weeks</li> Unknown Properties Modulated onto C/A and P(Y) codes at 50b/s (very slow) with a bit duration of 20ms. It takes 12.5 minutes for the entire message to be received. The essential satellite ephemeris and clock parameters are repeated each thirty seconds <ol><li>Forward error correction (FEC) via convolution codes with rate 1/2</li><li>Modulated onto L2C code at 50bps. Navigation data at 25b/s (50% FEC overhead)</li><li> Improved data structure (packet based instead of frame based)</li><li>Better interoperability with other constellations and has excess bandiwdth to include more data in future</li></ol> <ol><li>Forward error correction (FEC) via convolution codes with rate 1/2</li><li>Modulated onto L5 code at 50b/s. Navigation data at 25b/s (50% FEC overhead)</li><li> Improved data structure (packet based instead of frame based)</li><li>Better interoperability with other constellations and has excess bandiwdth to include more data in future</li></ol> Modulated onto L1C code at 100b/s, navigation data at 50b/s (50% FEC overhead), and has similar data structure and FEC to L2 CNAV and L5 CNAV Packet based and uses FEC"},{"location":"sensors/gnss/gps_signals/#gps-ranging-signals","title":"GPS Ranging Signals","text":"C/A P(Y) L2C L5 L1C M Definition Coarse / Acquisition code Precision code Second civilian signal Third civilian signal Fourth civilian signal Military code Type Legacy Legacy Modernized Modernized Modernized Modernized Frequency Band L1 L1 and L2 L2 L5 L1 L1 and L2 Usage Civilian Military Civilian Civilian Civilian Military Properties <ol><li>Unique sequence of 1023 bits (chips) and is repeated each millisecond</li><li>Short code at 1.023Mb/s</li><li>Chip width or wavelength is about 300m</li></ol> <ol><li>Long code at 10.23Mb/s and the chip width is about 30m</li><li>Main P-code repeats every 37 weeks (2.289214E14 chips)</li><li>Each satellite transmits a different segment of the main code (6.187104E12 chips, repeats every 1 week)</li><li>P-code is XORed with a secret cryptographic W-code to give P(Y)</li><li>P(Y) is robust to interference and spoofing</li></ol> <ol><li>Contains two distinct codes multiplexed at 1.023Mb/s: CM, CL</li><li>CM (civil-moderate code): Medium code at 511.5kb/s, repeats every 20ms (10230 chips), and has a new navigation signal (L2 CNAV) modulated onto it</li><li>CL (civil-long-code): Long code at 511.5kb/s, repeats every 1.5 seconds (767250 chips), no navigation data modulation (dataless sequence), and improved SNR</li><li>2.7dB higher SNR than C/A at 2.3dB less power</li><li>As of 2021, broadcasting from 23 GPS satellites</li></ol> <ol><li>Contains two codes transmitted in quadrature (I/Q) at 10.23Mb/s</li><li>I5-code (in-phase code): Medium code at 10.23Mb/s, repeats every 1 ms (10230 chips), has a new navigation signal (L5 CNAV), has a synchronization sequence modulated onto it (10 bit Neuman-Hofman code)</li><li>Q5-code (quadrature code): Medium code at 10.23Mb/s, repeats every 1 millisecond (10230 chips), no navigation data modulation (dataless sequence), has a synchronization sequence modulated onto it (20-bit Neuman-Hofman code)</li><li>3dB higher power and 10x higher bandwidth than other civil signals</li><li>As of 2022, broadcasting from 17 GPS satellites</li></ol> <ol><li>Contains two codes transmitted in quadrature (I/Q) at 1.023Mb/s</li><li>L1C<sub>D</sub> (in-phase data signal): Repeats every 10 milliseconds (10230 chips), Binary Offset Carrier (BOC) modulation (not BPSK), has a new navigation signal (CNAV-2) modulated onto it</li><li>L1C<sub>P</sub> (quadrature pilot signal): Repeats every 10ms (10230 chips), Multiplexed Binary Offset Carrier (MBOC) modulation (not BPSK), additional overlay code (L1C<sub>O</sub>) modulated onto it for better acquisition</li><li>1.5dB higher power and improved tracking compared to C/A</li><li>As of 2021, broadcasting from 4 GPS satellites</li></ol> <ol><li>Improves the security, performance and robustness of legacy P(Y)</li><li>5.115Mb/s bitrate, BOC modulation</li><li>Has new navigation signal (MNAV) modulated onto it</li><li>Block III and later satellites will broadcast the M code from a dedicated directional high gain antenna in addition to the full-earth antenna. Providing 20dB signal gain in selective regions</li>"},{"location":"sensors/gnss/references/","title":"References","text":"<ol> <li>Misra, P., Global Positioning System, 2nd Edition</li> <li>Mahalati, R.N., EE259: Principles of Sensing for Autonomy, 2023</li> </ol>"},{"location":"software/termanologies/","title":"Termanologies","text":""},{"location":"software/termanologies/#kernel","title":"Kernel","text":"<p>Operating system is the one program that runs at all times on the coputer - usually called the kernel.</p>"},{"location":"software/termanologies/#system-calls","title":"System Calls","text":"<p>System calls provide an interface to the services made available by an OS.</p>"},{"location":"software/termanologies/#device-controller-and-device-driver","title":"Device Controller and Device Driver","text":"<p>Device Controller is responsible for moving the data between peripheral devices that it controls and its local buffer storage. Typically, operating systems have a device driver for each device controller. This device driver understands the device controller and provides the rest of the operating system with a uniform interface to the device.</p>"},{"location":"software/termanologies/#system-processes-or-daemons","title":"System Processes or Daemons","text":"<p>Once a kernel is loaded and is executing, it can start providing services to the system and its users. Some services are provided outside of the kernel, by system programs that are loaded into memory at boot time to become system processes, or system daemons that run the entire time the kernel is running. On Linux, the first system program is \"systemd\", and it starts many other daemons.</p>"},{"location":"software/termanologies/#word","title":"Word","text":"<p>A word is made up of one or more bytes. For example, a computer that has 64-bit registers and 64-bit memory addressing typically has 64-bit (8-byte) words. A computer executes many operations in its native word size rather than a byte at a time.</p>"},{"location":"software/termanologies/#dram","title":"DRAM","text":"<p>CPU can load instructions only from memory, so any programs must first be loaded into memory to run. General-purpose comptuers run most of their programs from rewritable memory, called main memory (RAM). Main memory commonly is implemented in a semiconductor technology called dynamic random-access memory (DRAM). RAM is volatile, i.e., loses its content when power is turned off.</p>"},{"location":"software/termanologies/#rom-and-eeprom","title":"ROM and EEPROM","text":"<p>For a computer to start running - for instance, when it is powered up or rebooted - it needs to have an initial program to run. This initial program, or bootstrap program, tends to be simple. Typicall, it is stored within the computer hardware in read-only memory (ROM) or electrically erasable programmable read-only memory (EEPROM), known by the general term firmware. Since ROM cannot be changed, only static programs, such as programs in game cartridges are stored there. EEPFROM can be changed but cannot be changed frequently and so contains mostly static programs. For example, smartphones have EEPROM to store their factory-installed programs, serial numbers, and hwardware information about the device.</p>"},{"location":"software/termanologies/#dma","title":"DMA","text":"<p>After setting up buffers, pointers, and counters for the I/O device, the device controller transfers an entire block of data directly to or from the device and the main memory, with no intervention by the CPU. Only one interrupt is generated per block, to tell the device driver that the operation has completed, rather than the one interrupt per byte generated for low-speed devices. This is a usage of direct memory access (DMA).</p>"},{"location":"software/termanologies/#computing-systems","title":"Computing Systems","text":"<p>CPU is the hardware that executes instructions. Processor is a physical chip that contains one or more CPUs. Core is the basic computation unit of the CPU. The core is the component that typo executes instructions and registers for storing data locally. The one main CPU with its core is capable of executing a general-purpose instruction set, including instructions from processes. Multicore* includes multiple computing cores on the same CPU. </p>"},{"location":"software/termanologies/#numa","title":"NUMA","text":"<p>Adding additional CPUs to a multiprocessor system will increase computing power; however, the concept does not scale very well, and once we add too many CPUs, contention for the system bus becomes a bottleneck and performance begins to degrade. An alternative approach is instead to provide each CPU (or group of CPUs) with its own local meory that is accessed via a small, fast local bus. The CPUs are connected by a shared system interconnect, so that all CPUs share one physical address space. This is known as non-uniform memory access (NUMA).</p>"},{"location":"software/termanologies/#process","title":"Process","text":"<p>Multiprogramming increases CPU utilization, as well as keeping users satisfied, by organizing programs so that the CPU always has one to execute. In a multiprogrammed system, a program in execution is called a process.</p>"},{"location":"software/termanologies/#program-counter","title":"Program Counter","text":"<p>A single-threaded process has one program counter specifying the next instruction to execute. The execution of such a process must be sequential. The CPU executes one instruction of the process after another, until the process completes. Further, at any time, one instruction at most is executed on behalf of the process. Thus, although, two processes may be associated with the same program, they are nevertheless considered two separate execution sequences. A multithreaded process has multiple program counters, each pointing to the next instruction to execute for a given thread.</p>"},{"location":"software/termanologies/#bootloader","title":"Bootloader","text":"<p>A small piece of computer porgram that is responsible for booting a computer. </p> <p>p71</p>"},{"location":"software/concurrency/primer/","title":"Primer","text":"<ol> <li>Introduction to Parallel Computing Tutorial</li> <li></li> </ol>"},{"location":"software/concurrency/open_mp/basic_usage/","title":"Simple Example","text":""},{"location":"software/concurrency/open_mp/basic_usage/#adding-openmp","title":"Adding OpenMP","text":"BaseAdding OpenMPRestricting Team Size <pre><code>// Base Example\n\nint main()\n{\n\n\n\n\n    {\n        printf(\"hello, world!\\n\"); // Execute in parallel\n    } // Implicity join\n    return 0;\n}\n</code></pre> <pre><code>#include &lt;omp.h&gt;\n\nint main()\n{\n    omp_set_num_threads(16); // OPTIONAL - Can also use \n                            // OMP_NUM_THREADS environment variable\n\n    #pragma omp parallel\n    {\n        printf(\"hello, world!\\n\"); // Execute in parallel\n    } // Implicity join\n    return 0;\n}\n</code></pre> <pre><code>#include &lt;omp.h&gt;\n\nint main()\n{\n    omp_set_num_threads(16); // OPTIONAL - Can also use \n                            // OMP_NUM_THREADS environment variable\n\n    #pragma omp parallel num_threads(8) // Restrict team size locally\n    {\n        printf(\"hello, world!\\n\"); // Execute in parallel\n    } // Implicity join\n    return 0;\n}\n</code></pre>"},{"location":"software/concurrency/open_mp/basic_usage/#compiling","title":"Compiling","text":"<pre><code>gcc -fopenmp ...\nicc -openmp ...\n</code></pre>"},{"location":"software/concurrency/open_mp/open_mp/","title":"Parallel Loops","text":"BaseOpenMPOpenMP v2OpenMP v3 <pre><code>for (i = 0; i &lt; n; ++i)\n{\n    a[i] += foo (i);\n}\n</code></pre> <pre><code>#pragma omp parallel // Activates the team of threads\n{\n    #pragma omp for shared (a, n) private (i) // Declares work sharing loop\n    for (i = 0; i &lt; n; ++i)\n    {\n        a[i] += foo (i);\n    } // Implicit join\n} // Implicit join\n</code></pre> <pre><code>#pragma omp parallel\n{\n    foo(a, n);\n} // Implicit join\n\n\nvoid foo(item* a, int n)\n{\n    int i;\n    #pragma omp for shared (a, n) private (i)\n    for (i = 0; i &lt; n; ++i)\n    {\n        a[i] += foo(i);\n    } // Implicit join\n} // Note: If foo() is called outside a parallel region, it is orphaned\n</code></pre> <pre><code>#pragma omp parallel for default (none) shared (a, n) private (i)\nfor (i = 0; i &lt; n; ++i)\n{\n    a[i] += foo (i);\n} // Implicity join\n</code></pre>"},{"location":"software/concurrency/open_mp/open_mp/#if-statement","title":"If Statement","text":"<pre><code>const int B = ...;\n#pragma omp parallel for if (n &gt; B) default (none) shared (a, n) private (i)\nfor (i = 0; i &lt; n; ++i)\n{\n    a[i] += foo (i);\n} // Implicit join\n</code></pre>"},{"location":"software/concurrency/open_mp/overview/","title":"Open MP","text":""},{"location":"software/concurrency/open_mp/overview/#overview","title":"Overview","text":"<p>OpenMP has three specific use-case scenarios. </p>"},{"location":"software/concurrency/open_mp/loop_level/loop_level_openmp/","title":"Loop-level OpenMP","text":""},{"location":"software/concurrency/open_mp/loop_level/loop_level_openmp/#applications-characteristics","title":"Applications Characteristics","text":"<p>Standard OpenMP starts from the bottom-up and applies the parallelism constructs at the loop level. Some characteristics are:</p> <ol> <li>Modest parallelism</li> <li>Has plenty of memory resources (low memory requirements)</li> <li>Expensive part of calculation is in just a few <code>for</code> or <code>do</code> loops.</li> </ol> <p>OpenMP relies on the OS kernel for its memory handling. OpenMP has a relaxed memory model. Each thread has a temporary view of memory so that it doesn't have the cost of storing memory with every operation. When the temporary view finally must be reconciled with main memory, an OpenMP barrier or flush operation is required to synchronize memory.</p> <p>Threads are allocated by cores, and thread binding is enabled using the following OpenMP enviornment variables to reduce the performance variation of runs:</p> <pre><code>export OMP_PLACES=cores\nexport OMP_CPU_BIND=true\n</code></pre>"},{"location":"software/timing/time/","title":"Time","text":""},{"location":"software/timing/time/#unix-epoch","title":"Unix Epoch","text":"<p>The Unix epoch is the number of seconds that have elapsed since January 1, 1970 at midnight UTC time minus the leap seconds. This means that at midnight of January 1, 1970, Unix time was 0. The Unix epoch is also called Unix time, POSIX time, or Unix timestamp. On systems where the representation of Unix time is as a signed 32-bit number, the representation will end after \\(2^31 - 1\\) seconds which will happen at 3:14:08 on 19 January 2038 UTC. This is called the Year 2038 problem where the 32-bit signed Unix time will overflow.</p> <p>The Linux <code>time()</code> returns <code>time_t</code> which is the time as the number of seconds since the Epoch, 1970-01-01 00:00:00 +0000 (UTC).</p> <p>An easy way to get Unix timestamp via chrono is:</p> <pre><code>auto unix_timestamp = std::chrono::seconds(std::time(NULL));\n</code></pre>"}]}